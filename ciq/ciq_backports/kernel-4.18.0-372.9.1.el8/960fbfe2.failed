net/mlx5e: Allow coexistence of CQE compression and HW TS PTP

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Aya Levin <ayal@nvidia.com>
commit 960fbfe222a490622cfb3949061b20f83ef46fb0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/960fbfe2.failed

Update setting HW time-stamp to allow coexistence with CQE compression.
Turn on RX PTP indication and try to reopen the channels. On success,
coexistence with CQE compression is enabled. Otherwise, fall-back to
turning off CQE compression.

	Signed-off-by: Aya Levin <ayal@nvidia.com>
	Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 960fbfe222a490622cfb3949061b20f83ef46fb0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
index f9afbdefded5,72e7dd6d78c0..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
@@@ -441,14 -562,103 +441,102 @@@ close_cqs
  	return err;
  }
  
 -static void mlx5e_ptp_close_queues(struct mlx5e_ptp *c)
 +static void mlx5e_ptp_close_queues(struct mlx5e_port_ptp *c)
  {
 -	if (test_bit(MLX5E_PTP_STATE_RX, c->state)) {
 -		mlx5e_close_rq(&c->rq);
 -		mlx5e_close_cq(&c->rq.cq);
 -	}
 -	if (test_bit(MLX5E_PTP_STATE_TX, c->state)) {
 -		mlx5e_ptp_close_txqsqs(c);
 -		mlx5e_ptp_close_tx_cqs(c);
 -	}
 +	mlx5e_ptp_close_txqsqs(c);
 +	mlx5e_ptp_close_cqs(c);
  }
  
++<<<<<<< HEAD
 +int mlx5e_port_ptp_open(struct mlx5e_priv *priv, struct mlx5e_params *params,
 +			u8 lag_port, struct mlx5e_port_ptp **cp)
++=======
+ static int mlx5e_ptp_set_state(struct mlx5e_ptp *c, struct mlx5e_params *params)
+ {
+ 	if (MLX5E_GET_PFLAG(params, MLX5E_PFLAG_TX_PORT_TS))
+ 		__set_bit(MLX5E_PTP_STATE_TX, c->state);
+ 
+ 	if (params->ptp_rx)
+ 		__set_bit(MLX5E_PTP_STATE_RX, c->state);
+ 
+ 	return bitmap_empty(c->state, MLX5E_PTP_STATE_NUM_STATES) ? -EINVAL : 0;
+ }
+ 
+ static void mlx5e_ptp_rx_unset_fs(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ptp_fs *ptp_fs = priv->fs.ptp_fs;
+ 
+ 	if (!ptp_fs->valid)
+ 		return;
+ 
+ 	mlx5e_fs_tt_redirect_del_rule(ptp_fs->l2_rule);
+ 	mlx5e_fs_tt_redirect_any_destroy(priv);
+ 
+ 	mlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v6_rule);
+ 	mlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v4_rule);
+ 	mlx5e_fs_tt_redirect_udp_destroy(priv);
+ 	ptp_fs->valid = false;
+ }
+ 
+ static int mlx5e_ptp_rx_set_fs(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ptp_fs *ptp_fs = priv->fs.ptp_fs;
+ 	struct mlx5_flow_handle *rule;
+ 	u32 tirn = priv->ptp_tir.tirn;
+ 	int err;
+ 
+ 	if (ptp_fs->valid)
+ 		return 0;
+ 
+ 	err = mlx5e_fs_tt_redirect_udp_create(priv);
+ 	if (err)
+ 		goto out_free;
+ 
+ 	rule = mlx5e_fs_tt_redirect_udp_add_rule(priv, MLX5E_TT_IPV4_UDP,
+ 						 tirn, PTP_EV_PORT);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		goto out_destroy_fs_udp;
+ 	}
+ 	ptp_fs->udp_v4_rule = rule;
+ 
+ 	rule = mlx5e_fs_tt_redirect_udp_add_rule(priv, MLX5E_TT_IPV6_UDP,
+ 						 tirn, PTP_EV_PORT);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		goto out_destroy_udp_v4_rule;
+ 	}
+ 	ptp_fs->udp_v6_rule = rule;
+ 
+ 	err = mlx5e_fs_tt_redirect_any_create(priv);
+ 	if (err)
+ 		goto out_destroy_udp_v6_rule;
+ 
+ 	rule = mlx5e_fs_tt_redirect_any_add_rule(priv, tirn, ETH_P_1588);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		goto out_destroy_fs_any;
+ 	}
+ 	ptp_fs->l2_rule = rule;
+ 	ptp_fs->valid = true;
+ 
+ 	return 0;
+ 
+ out_destroy_fs_any:
+ 	mlx5e_fs_tt_redirect_any_destroy(priv);
+ out_destroy_udp_v6_rule:
+ 	mlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v6_rule);
+ out_destroy_udp_v4_rule:
+ 	mlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v4_rule);
+ out_destroy_fs_udp:
+ 	mlx5e_fs_tt_redirect_udp_destroy(priv);
+ out_free:
+ 	return err;
+ }
+ 
+ int mlx5e_ptp_open(struct mlx5e_priv *priv, struct mlx5e_params *params,
+ 		   u8 lag_port, struct mlx5e_ptp **cp)
++>>>>>>> 960fbfe222a4 (net/mlx5e: Allow coexistence of CQE compression and HW TS PTP)
  {
  	struct net_device *netdev = priv->netdev;
  	struct mlx5_core_dev *mdev = priv->mdev;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index fca0e8f30721,c6227725733a..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2090,9 -2087,8 +2090,14 @@@ int mlx5e_open_channels(struct mlx5e_pr
  			goto err_close_channels;
  	}
  
++<<<<<<< HEAD
 +	if (MLX5E_GET_PFLAG(&chs->params, MLX5E_PFLAG_TX_PORT_TS)) {
 +		err = mlx5e_port_ptp_open(priv, &chs->params, chs->c[0]->lag_port,
 +					  &chs->port_ptp);
++=======
+ 	if (MLX5E_GET_PFLAG(&chs->params, MLX5E_PFLAG_TX_PORT_TS) || chs->params.ptp_rx) {
+ 		err = mlx5e_ptp_open(priv, &chs->params, chs->c[0]->lag_port, &chs->ptp);
++>>>>>>> 960fbfe222a4 (net/mlx5e: Allow coexistence of CQE compression and HW TS PTP)
  		if (err)
  			goto err_close_channels;
  	}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h
index 9cd4c188c5a0..bf5d0e9391da 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@ -269,6 +269,7 @@ struct mlx5e_params {
 	struct mlx5e_xsk *xsk;
 	unsigned int sw_mtu;
 	int hard_mtu;
+	bool ptp_rx;
 };
 
 enum {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
