net/mlx5: Bridge, filter tagged packets that didn't match tagged fg

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Vlad Buslov <vladbu@nvidia.com>
commit cc2987c44be5d188b0fdf5c07b65a5c952457ef9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/cc2987c4.failed

With support for pvid vlans in mlx5 bridge it is possible to have rules in
untagged flow group when vlan filtering is enabled. However, such rules can
also match tagged packets that didn't match anything in tagged flow group.
Filter such packets by introducing additional flow group between tagged and
untagged groups. When filtering is enabled on the bridge create additional
flow in vlan filtering flow group and matches tagged packets with specified
source MAC address and redirects them to new "skip" table. The skip table
is new lowest-level empty table that is used to skip all further processing
on packet in bridge priority.

	Signed-off-by: Vlad Buslov <vladbu@nvidia.com>
	Reviewed-by: Jianbo Liu <jianbol@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit cc2987c44be5d188b0fdf5c07b65a5c952457ef9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
#	drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
index b503562f97d0,b6345619cbfe..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
@@@ -9,18 -14,80 +9,84 @@@
  #include "fs_core.h"
  
  #define MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE 64000
++<<<<<<< HEAD
 +#define MLX5_ESW_BRIDGE_INGRESS_TABLE_MAC_GRP_IDX_FROM 0
++=======
+ #define MLX5_ESW_BRIDGE_INGRESS_TABLE_VLAN_GRP_IDX_FROM 0
+ #define MLX5_ESW_BRIDGE_INGRESS_TABLE_VLAN_GRP_IDX_TO (MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE / 4 - 1)
+ #define MLX5_ESW_BRIDGE_INGRESS_TABLE_FILTER_GRP_IDX_FROM \
+ 	(MLX5_ESW_BRIDGE_INGRESS_TABLE_VLAN_GRP_IDX_TO + 1)
+ #define MLX5_ESW_BRIDGE_INGRESS_TABLE_FILTER_GRP_IDX_TO \
+ 	(MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE / 2 - 1)
+ #define MLX5_ESW_BRIDGE_INGRESS_TABLE_MAC_GRP_IDX_FROM \
+ 	(MLX5_ESW_BRIDGE_INGRESS_TABLE_FILTER_GRP_IDX_TO + 1)
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  #define MLX5_ESW_BRIDGE_INGRESS_TABLE_MAC_GRP_IDX_TO (MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE - 1)
  
  #define MLX5_ESW_BRIDGE_EGRESS_TABLE_SIZE 64000
 -#define MLX5_ESW_BRIDGE_EGRESS_TABLE_VLAN_GRP_IDX_FROM 0
 -#define MLX5_ESW_BRIDGE_EGRESS_TABLE_VLAN_GRP_IDX_TO (MLX5_ESW_BRIDGE_EGRESS_TABLE_SIZE / 2 - 1)
 -#define MLX5_ESW_BRIDGE_EGRESS_TABLE_MAC_GRP_IDX_FROM \
 -	(MLX5_ESW_BRIDGE_EGRESS_TABLE_VLAN_GRP_IDX_TO + 1)
 +#define MLX5_ESW_BRIDGE_EGRESS_TABLE_MAC_GRP_IDX_FROM 0
  #define MLX5_ESW_BRIDGE_EGRESS_TABLE_MAC_GRP_IDX_TO (MLX5_ESW_BRIDGE_EGRESS_TABLE_SIZE - 1)
  
+ #define MLX5_ESW_BRIDGE_SKIP_TABLE_SIZE 0
+ 
  enum {
  	MLX5_ESW_BRIDGE_LEVEL_INGRESS_TABLE,
  	MLX5_ESW_BRIDGE_LEVEL_EGRESS_TABLE,
+ 	MLX5_ESW_BRIDGE_LEVEL_SKIP_TABLE,
+ };
+ 
++<<<<<<< HEAD
++=======
+ struct mlx5_esw_bridge_fdb_key {
+ 	unsigned char addr[ETH_ALEN];
+ 	u16 vid;
+ };
+ 
+ enum {
+ 	MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER = BIT(0),
+ };
+ 
+ struct mlx5_esw_bridge_fdb_entry {
+ 	struct mlx5_esw_bridge_fdb_key key;
+ 	struct rhash_head ht_node;
+ 	struct net_device *dev;
+ 	struct list_head list;
+ 	struct list_head vlan_list;
+ 	u16 vport_num;
+ 	u16 flags;
+ 
+ 	struct mlx5_flow_handle *ingress_handle;
+ 	struct mlx5_fc *ingress_counter;
+ 	unsigned long lastuse;
+ 	struct mlx5_flow_handle *egress_handle;
+ 	struct mlx5_flow_handle *filter_handle;
+ };
+ 
+ static const struct rhashtable_params fdb_ht_params = {
+ 	.key_offset = offsetof(struct mlx5_esw_bridge_fdb_entry, key),
+ 	.key_len = sizeof(struct mlx5_esw_bridge_fdb_key),
+ 	.head_offset = offsetof(struct mlx5_esw_bridge_fdb_entry, ht_node),
+ 	.automatic_shrinking = true,
+ };
+ 
+ struct mlx5_esw_bridge_vlan {
+ 	u16 vid;
+ 	u16 flags;
+ 	struct list_head fdb_list;
+ 	struct mlx5_pkt_reformat *pkt_reformat_push;
+ 	struct mlx5_pkt_reformat *pkt_reformat_pop;
+ };
+ 
+ struct mlx5_esw_bridge_port {
+ 	u16 vport_num;
+ 	struct xarray vlans;
  };
  
+ enum {
+ 	MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG = BIT(0),
+ };
+ 
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  struct mlx5_esw_bridge {
  	int ifindex;
  	int refcnt;
@@@ -55,6 -143,82 +121,85 @@@ mlx5_esw_bridge_table_create(int max_ft
  }
  
  static struct mlx5_flow_group *
++<<<<<<< HEAD
++=======
+ mlx5_esw_bridge_ingress_vlan_fg_create(struct mlx5_eswitch *esw, struct mlx5_flow_table *ingress_ft)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5_flow_group *fg;
+ 	u32 *in, *match;
+ 
+ 	in = kvzalloc(inlen, GFP_KERNEL);
+ 	if (!in)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	MLX5_SET(create_flow_group_in, in, match_criteria_enable,
+ 		 MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2);
+ 	match = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.smac_47_16);
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.smac_15_0);
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.cvlan_tag);
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.first_vid);
+ 
+ 	MLX5_SET(fte_match_param, match, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_mask());
+ 
+ 	MLX5_SET(create_flow_group_in, in, start_flow_index,
+ 		 MLX5_ESW_BRIDGE_INGRESS_TABLE_VLAN_GRP_IDX_FROM);
+ 	MLX5_SET(create_flow_group_in, in, end_flow_index,
+ 		 MLX5_ESW_BRIDGE_INGRESS_TABLE_VLAN_GRP_IDX_TO);
+ 
+ 	fg = mlx5_create_flow_group(ingress_ft, in);
+ 	kvfree(in);
+ 	if (IS_ERR(fg))
+ 		esw_warn(esw->dev,
+ 			 "Failed to create VLAN flow group for bridge ingress table (err=%ld)\n",
+ 			 PTR_ERR(fg));
+ 
+ 	return fg;
+ }
+ 
+ static struct mlx5_flow_group *
+ mlx5_esw_bridge_ingress_filter_fg_create(struct mlx5_eswitch *esw,
+ 					 struct mlx5_flow_table *ingress_ft)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5_flow_group *fg;
+ 	u32 *in, *match;
+ 
+ 	in = kvzalloc(inlen, GFP_KERNEL);
+ 	if (!in)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	MLX5_SET(create_flow_group_in, in, match_criteria_enable,
+ 		 MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2);
+ 	match = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.smac_47_16);
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.smac_15_0);
+ 	MLX5_SET_TO_ONES(fte_match_param, match, outer_headers.cvlan_tag);
+ 
+ 	MLX5_SET(fte_match_param, match, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_mask());
+ 
+ 	MLX5_SET(create_flow_group_in, in, start_flow_index,
+ 		 MLX5_ESW_BRIDGE_INGRESS_TABLE_FILTER_GRP_IDX_FROM);
+ 	MLX5_SET(create_flow_group_in, in, end_flow_index,
+ 		 MLX5_ESW_BRIDGE_INGRESS_TABLE_FILTER_GRP_IDX_TO);
+ 
+ 	fg = mlx5_create_flow_group(ingress_ft, in);
+ 	if (IS_ERR(fg))
+ 		esw_warn(esw->dev,
+ 			 "Failed to create bridge ingress table VLAN filter flow group (err=%ld)\n",
+ 			 PTR_ERR(fg));
+ 
+ 	kvfree(in);
+ 	return fg;
+ }
+ 
+ static struct mlx5_flow_group *
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  mlx5_esw_bridge_ingress_mac_fg_create(struct mlx5_eswitch *esw, struct mlx5_flow_table *ingress_ft)
  {
  	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
@@@ -124,16 -321,39 +269,44 @@@ mlx5_esw_bridge_egress_mac_fg_create(st
  static int
  mlx5_esw_bridge_ingress_table_init(struct mlx5_esw_bridge_offloads *br_offloads)
  {
++<<<<<<< HEAD
 +	struct mlx5_flow_table *ingress_ft;
 +	struct mlx5_flow_group *mac_fg;
++=======
+ 	struct mlx5_flow_group *mac_fg, *filter_fg, *vlan_fg;
+ 	struct mlx5_flow_table *ingress_ft, *skip_ft;
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	int err;
  
 -	if (!mlx5_eswitch_vport_match_metadata_enabled(br_offloads->esw))
 -		return -EOPNOTSUPP;
 -
  	ingress_ft = mlx5_esw_bridge_table_create(MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE,
  						  MLX5_ESW_BRIDGE_LEVEL_INGRESS_TABLE,
  						  br_offloads->esw);
  	if (IS_ERR(ingress_ft))
  		return PTR_ERR(ingress_ft);
  
++<<<<<<< HEAD
++=======
+ 	skip_ft = mlx5_esw_bridge_table_create(MLX5_ESW_BRIDGE_SKIP_TABLE_SIZE,
+ 					       MLX5_ESW_BRIDGE_LEVEL_SKIP_TABLE,
+ 					       br_offloads->esw);
+ 	if (IS_ERR(skip_ft)) {
+ 		err = PTR_ERR(skip_ft);
+ 		goto err_skip_tbl;
+ 	}
+ 
+ 	vlan_fg = mlx5_esw_bridge_ingress_vlan_fg_create(br_offloads->esw, ingress_ft);
+ 	if (IS_ERR(vlan_fg)) {
+ 		err = PTR_ERR(vlan_fg);
+ 		goto err_vlan_fg;
+ 	}
+ 
+ 	filter_fg = mlx5_esw_bridge_ingress_filter_fg_create(br_offloads->esw, ingress_ft);
+ 	if (IS_ERR(filter_fg)) {
+ 		err = PTR_ERR(filter_fg);
+ 		goto err_filter_fg;
+ 	}
+ 
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	mac_fg = mlx5_esw_bridge_ingress_mac_fg_create(br_offloads->esw, ingress_ft);
  	if (IS_ERR(mac_fg)) {
  		err = PTR_ERR(mac_fg);
@@@ -141,10 -361,19 +314,25 @@@
  	}
  
  	br_offloads->ingress_ft = ingress_ft;
++<<<<<<< HEAD
++=======
+ 	br_offloads->skip_ft = skip_ft;
+ 	br_offloads->ingress_vlan_fg = vlan_fg;
+ 	br_offloads->ingress_filter_fg = filter_fg;
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	br_offloads->ingress_mac_fg = mac_fg;
  	return 0;
  
  err_mac_fg:
++<<<<<<< HEAD
++=======
+ 	mlx5_destroy_flow_group(filter_fg);
+ err_filter_fg:
+ 	mlx5_destroy_flow_group(vlan_fg);
+ err_vlan_fg:
+ 	mlx5_destroy_flow_table(skip_ft);
+ err_skip_tbl:
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	mlx5_destroy_flow_table(ingress_ft);
  	return err;
  }
@@@ -154,6 -383,12 +342,15 @@@ mlx5_esw_bridge_ingress_table_cleanup(s
  {
  	mlx5_destroy_flow_group(br_offloads->ingress_mac_fg);
  	br_offloads->ingress_mac_fg = NULL;
++<<<<<<< HEAD
++=======
+ 	mlx5_destroy_flow_group(br_offloads->ingress_filter_fg);
+ 	br_offloads->ingress_filter_fg = NULL;
+ 	mlx5_destroy_flow_group(br_offloads->ingress_vlan_fg);
+ 	br_offloads->ingress_vlan_fg = NULL;
+ 	mlx5_destroy_flow_table(br_offloads->skip_ft);
+ 	br_offloads->skip_ft = NULL;
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	mlx5_destroy_flow_table(br_offloads->ingress_ft);
  	br_offloads->ingress_ft = NULL;
  }
@@@ -194,6 -438,164 +391,166 @@@ mlx5_esw_bridge_egress_table_cleanup(st
  	mlx5_destroy_flow_table(bridge->egress_ft);
  }
  
++<<<<<<< HEAD
++=======
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_ingress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				    struct mlx5_esw_bridge_vlan *vlan, u32 counter_id,
+ 				    struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_offloads *br_offloads = bridge->br_offloads;
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST | MLX5_FLOW_CONTEXT_ACTION_COUNT,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_destination dests[2] = {};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *smac_v, *smac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2;
+ 
+ 	smac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.smac_47_16);
+ 	ether_addr_copy(smac_v, addr);
+ 	smac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.smac_47_16);
+ 	eth_broadcast_addr(smac_c);
+ 
+ 	MLX5_SET(fte_match_param, rule_spec->match_criteria,
+ 		 misc_parameters_2.metadata_reg_c_0, mlx5_eswitch_get_vport_metadata_mask());
+ 	MLX5_SET(fte_match_param, rule_spec->match_value, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_for_match(br_offloads->esw, vport_num));
+ 
+ 	if (vlan && vlan->pkt_reformat_push) {
+ 		flow_act.action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT;
+ 		flow_act.pkt_reformat = vlan->pkt_reformat_push;
+ 	} else if (vlan) {
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	dests[0].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dests[0].ft = bridge->egress_ft;
+ 	dests[1].type = MLX5_FLOW_DESTINATION_TYPE_COUNTER;
+ 	dests[1].counter_id = counter_id;
+ 
+ 	handle = mlx5_add_flow_rules(br_offloads->ingress_ft, rule_spec, &flow_act, dests,
+ 				     ARRAY_SIZE(dests));
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_ingress_filter_flow_create(u16 vport_num, const unsigned char *addr,
+ 					   struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_offloads *br_offloads = bridge->br_offloads;
+ 	struct mlx5_flow_destination dest = {
+ 		.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE,
+ 		.ft = br_offloads->skip_ft,
+ 	};
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *smac_v, *smac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2;
+ 
+ 	smac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.smac_47_16);
+ 	ether_addr_copy(smac_v, addr);
+ 	smac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.smac_47_16);
+ 	eth_broadcast_addr(smac_c);
+ 
+ 	MLX5_SET(fte_match_param, rule_spec->match_criteria,
+ 		 misc_parameters_2.metadata_reg_c_0, mlx5_eswitch_get_vport_metadata_mask());
+ 	MLX5_SET(fte_match_param, rule_spec->match_value, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_for_match(br_offloads->esw, vport_num));
+ 
+ 	MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 			 outer_headers.cvlan_tag);
+ 	MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 			 outer_headers.cvlan_tag);
+ 
+ 	handle = mlx5_add_flow_rules(br_offloads->ingress_ft, rule_spec, &flow_act, &dest, 1);
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_egress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				   struct mlx5_esw_bridge_vlan *vlan,
+ 				   struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_flow_destination dest = {
+ 		.type = MLX5_FLOW_DESTINATION_TYPE_VPORT,
+ 		.vport.num = vport_num,
+ 	};
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *dmac_v, *dmac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 
+ 	dmac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.dmac_47_16);
+ 	ether_addr_copy(dmac_v, addr);
+ 	dmac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.dmac_47_16);
+ 	eth_broadcast_addr(dmac_c);
+ 
+ 	if (vlan) {
+ 		if (vlan->pkt_reformat_pop) {
+ 			flow_act.action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT;
+ 			flow_act.pkt_reformat = vlan->pkt_reformat_pop;
+ 		}
+ 
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	handle = mlx5_add_flow_rules(bridge->egress_ft, rule_spec, &flow_act, &dest, 1);
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  static struct mlx5_esw_bridge *mlx5_esw_bridge_create(int ifindex,
  						      struct mlx5_esw_bridge_offloads *br_offloads)
  {
@@@ -265,11 -679,414 +622,393 @@@ mlx5_esw_bridge_lookup(int ifindex, str
  	return bridge;
  }
  
++<<<<<<< HEAD
 +static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge *bridge,
++=======
+ static int mlx5_esw_bridge_port_insert(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_insert(&bridge->vports, port->vport_num, port, GFP_KERNEL);
+ }
+ 
+ static struct mlx5_esw_bridge_port *
+ mlx5_esw_bridge_port_lookup(u16 vport_num, struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_load(&bridge->vports, vport_num);
+ }
+ 
+ static void mlx5_esw_bridge_port_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	xa_erase(&bridge->vports, port->vport_num);
+ }
+ 
+ static void
+ mlx5_esw_bridge_fdb_entry_cleanup(struct mlx5_esw_bridge_fdb_entry *entry,
+ 				  struct mlx5_esw_bridge *bridge)
+ {
+ 	rhashtable_remove_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ 	if (entry->filter_handle)
+ 		mlx5_del_flow_rules(entry->filter_handle);
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ 	mlx5_fc_destroy(bridge->br_offloads->esw->dev, entry->ingress_counter);
+ 	list_del(&entry->vlan_list);
+ 	list_del(&entry->list);
+ 	kvfree(entry);
+ }
+ 
+ static void mlx5_esw_bridge_fdb_flush(struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 		if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 			mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 							   entry->key.vid,
+ 							   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_lookup(u16 vid, struct mlx5_esw_bridge_port *port)
+ {
+ 	return xa_load(&port->vlans, vid);
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_push_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct {
+ 		__be16	h_vlan_proto;
+ 		__be16	h_vlan_TCI;
+ 	} vlan_hdr = { htons(ETH_P_8021Q), htons(vlan->vid) };
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_insert)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_size) < sizeof(vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat INSERT_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_INSERT_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(vlan_hdr);
+ 	reformat_params.data = &vlan_hdr;
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat INSERT_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_push = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_push_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_push);
+ 	vlan->pkt_reformat_push = NULL;
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_pop_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_remove)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_size) < sizeof(struct vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat REMOVE_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_REMOVE_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(struct vlan_hdr);
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat REMOVE_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_pop = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_pop_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_pop);
+ 	vlan->pkt_reformat_pop = NULL;
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_create(u16 vid, u16 flags, struct mlx5_esw_bridge_port *port,
+ 			    struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	int err;
+ 
+ 	vlan = kvzalloc(sizeof(*vlan), GFP_KERNEL);
+ 	if (!vlan)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	vlan->vid = vid;
+ 	vlan->flags = flags;
+ 	INIT_LIST_HEAD(&vlan->fdb_list);
+ 
+ 	if (flags & BRIDGE_VLAN_INFO_PVID) {
+ 		err = mlx5_esw_bridge_vlan_push_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_push;
+ 	}
+ 	if (flags & BRIDGE_VLAN_INFO_UNTAGGED) {
+ 		err = mlx5_esw_bridge_vlan_pop_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_pop;
+ 	}
+ 
+ 	err = xa_insert(&port->vlans, vid, vlan, GFP_KERNEL);
+ 	if (err)
+ 		goto err_xa_insert;
+ 
+ 	return vlan;
+ 
+ err_xa_insert:
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, esw);
+ err_vlan_pop:
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, esw);
+ err_vlan_push:
+ 	kvfree(vlan);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_vlan *vlan)
+ {
+ 	xa_erase(&port->vlans, vlan->vid);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_flush(struct mlx5_esw_bridge_vlan *vlan,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &vlan->fdb_list, vlan_list) {
+ 		if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 			mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 							   entry->key.vid,
+ 							   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ 
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, bridge->br_offloads->esw);
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, bridge->br_offloads->esw);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_cleanup(struct mlx5_esw_bridge_port *port,
+ 					 struct mlx5_esw_bridge_vlan *vlan,
+ 					 struct mlx5_esw_bridge *bridge)
+ {
+ 	mlx5_esw_bridge_vlan_flush(vlan, bridge);
+ 	mlx5_esw_bridge_vlan_erase(port, vlan);
+ 	kvfree(vlan);
+ }
+ 
+ static void mlx5_esw_bridge_port_vlans_flush(struct mlx5_esw_bridge_port *port,
+ 					     struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	unsigned long index;
+ 
+ 	xa_for_each(&port->vlans, index, vlan)
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan, bridge);
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_port_vlan_lookup(u16 vid, u16 vport_num, struct mlx5_esw_bridge *bridge,
+ 				 struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, bridge);
+ 	if (!port) {
+ 		/* FDB is added asynchronously on wq while port might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port (vport=%u)\n", vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan) {
+ 		/* FDB is added asynchronously on wq while vlan might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port vlan metadata (vport=%u)\n",
+ 			 vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	return vlan;
+ }
+ 
+ static struct mlx5_esw_bridge_fdb_entry *
+ mlx5_esw_bridge_fdb_entry_init(struct net_device *dev, u16 vport_num, const unsigned char *addr,
+ 			       u16 vid, bool added_by_user, struct mlx5_eswitch *esw,
+ 			       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan = NULL;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_flow_handle *handle;
+ 	struct mlx5_fc *counter;
+ 	struct mlx5e_priv *priv;
+ 	int err;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG && vid) {
+ 		vlan = mlx5_esw_bridge_port_vlan_lookup(vid, vport_num, bridge, esw);
+ 		if (IS_ERR(vlan))
+ 			return ERR_CAST(vlan);
+ 	}
+ 
+ 	priv = netdev_priv(dev);
+ 	entry = kvzalloc(sizeof(*entry), GFP_KERNEL);
+ 	if (!entry)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ether_addr_copy(entry->key.addr, addr);
+ 	entry->key.vid = vid;
+ 	entry->dev = dev;
+ 	entry->vport_num = vport_num;
+ 	entry->lastuse = jiffies;
+ 	if (added_by_user)
+ 		entry->flags |= MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER;
+ 
+ 	counter = mlx5_fc_create(priv->mdev, true);
+ 	if (IS_ERR(counter)) {
+ 		err = PTR_ERR(counter);
+ 		goto err_ingress_fc_create;
+ 	}
+ 	entry->ingress_counter = counter;
+ 
+ 	handle = mlx5_esw_bridge_ingress_flow_create(vport_num, addr, vlan, mlx5_fc_id(counter),
+ 						     bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create ingress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_ingress_flow_create;
+ 	}
+ 	entry->ingress_handle = handle;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG) {
+ 		handle = mlx5_esw_bridge_ingress_filter_flow_create(vport_num, addr, bridge);
+ 		if (IS_ERR(handle)) {
+ 			err = PTR_ERR(handle);
+ 			esw_warn(esw->dev, "Failed to create ingress filter(vport=%u,err=%d)\n",
+ 				 vport_num, err);
+ 			goto err_ingress_filter_flow_create;
+ 		}
+ 		entry->filter_handle = handle;
+ 	}
+ 
+ 	handle = mlx5_esw_bridge_egress_flow_create(vport_num, addr, vlan, bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create egress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_egress_flow_create;
+ 	}
+ 	entry->egress_handle = handle;
+ 
+ 	err = rhashtable_insert_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	if (err) {
+ 		esw_warn(esw->dev, "Failed to insert FDB flow(vport=%u,err=%d)\n", vport_num, err);
+ 		goto err_ht_init;
+ 	}
+ 
+ 	if (vlan)
+ 		list_add(&entry->vlan_list, &vlan->fdb_list);
+ 	else
+ 		INIT_LIST_HEAD(&entry->vlan_list);
+ 	list_add(&entry->list, &bridge->fdb_list);
+ 	return entry;
+ 
+ err_ht_init:
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ err_egress_flow_create:
+ 	if (entry->filter_handle)
+ 		mlx5_del_flow_rules(entry->filter_handle);
+ err_ingress_filter_flow_create:
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ err_ingress_flow_create:
+ 	mlx5_fc_destroy(priv->mdev, entry->ingress_counter);
+ err_ingress_fc_create:
+ 	kvfree(entry);
+ 	return ERR_PTR(err);
+ }
+ 
+ int mlx5_esw_bridge_ageing_time_set(unsigned long ageing_time, struct mlx5_eswitch *esw,
+ 				    struct mlx5_vport *vport)
+ {
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	vport->bridge->ageing_time = ageing_time;
+ 	return 0;
+ }
+ 
+ int mlx5_esw_bridge_vlan_filtering_set(bool enable, struct mlx5_eswitch *esw,
+ 				       struct mlx5_vport *vport)
+ {
+ 	struct mlx5_esw_bridge *bridge;
+ 	bool filtering;
+ 
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	bridge = vport->bridge;
+ 	filtering = bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	if (filtering == enable)
+ 		return 0;
+ 
+ 	mlx5_esw_bridge_fdb_flush(bridge);
+ 	if (enable)
+ 		bridge->flags |= MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	else
+ 		bridge->flags &= ~MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge_offloads *br_offloads,
+ 				      struct mlx5_esw_bridge *bridge,
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  				      struct mlx5_vport *vport)
  {
 -	struct mlx5_eswitch *esw = br_offloads->esw;
 -	struct mlx5_esw_bridge_port *port;
 -	int err;
 -
 -	port = kvzalloc(sizeof(*port), GFP_KERNEL);
 -	if (!port) {
 -		err = -ENOMEM;
 -		goto err_port_alloc;
 -	}
 -
 -	port->vport_num = vport->vport;
 -	xa_init(&port->vlans);
 -	err = mlx5_esw_bridge_port_insert(port, bridge);
 -	if (err) {
 -		esw_warn(esw->dev, "Failed to insert port metadata (vport=%u,err=%d)\n",
 -			 vport->vport, err);
 -		goto err_port_insert;
 -	}
 -
  	vport->bridge = bridge;
  	return 0;
 -
 -err_port_insert:
 -	kvfree(port);
 -err_port_alloc:
 -	mlx5_esw_bridge_put(br_offloads, bridge);
 -	return err;
  }
  
  static int mlx5_esw_bridge_vport_cleanup(struct mlx5_esw_bridge_offloads *br_offloads,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
index 319b6f1db0ba,d826942b27fc..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
@@@ -15,9 -16,17 +15,16 @@@ struct mlx5_esw_bridge_offloads 
  	struct mlx5_eswitch *esw;
  	struct list_head bridges;
  	struct notifier_block netdev_nb;
 -	struct notifier_block nb_blk;
 -	struct notifier_block nb;
 -	struct workqueue_struct *wq;
 -	struct delayed_work update_work;
  
  	struct mlx5_flow_table *ingress_ft;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_flow_group *ingress_vlan_fg;
+ 	struct mlx5_flow_group *ingress_filter_fg;
++>>>>>>> cc2987c44be5 (net/mlx5: Bridge, filter tagged packets that didn't match tagged fg)
  	struct mlx5_flow_group *ingress_mac_fg;
+ 
+ 	struct mlx5_flow_table *skip_ft;
  };
  
  struct mlx5_esw_bridge_offloads *mlx5_esw_bridge_init(struct mlx5_eswitch *esw);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index cd94d494e5d3..9cee92a18505 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -2788,7 +2788,7 @@ static int init_fdb_root_ns(struct mlx5_flow_steering *steering)
 		goto out_err;
 	}
 
-	maj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_BR_OFFLOAD, 2);
+	maj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_BR_OFFLOAD, 3);
 	if (IS_ERR(maj_prio)) {
 		err = PTR_ERR(maj_prio);
 		goto out_err;
