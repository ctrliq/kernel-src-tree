ice: xsk: Stop Rx processing when ntc catches ntu

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Maciej Fijalkowski <maciej.fijalkowski@intel.com>
commit 0ec1713009c5cc24244c918def1cd14080be27e3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/0ec17130.failed

This can happen with big budget values and some breakage of re-filling
descriptors as we do not clear the entry that ntu is pointing at the end
of ice_alloc_rx_bufs_zc. So if ntc is at ntu then it might be the case
that status_error0 has an old, uncleared value and ntc would go over
with processing which would result in false results.

Break Rx loop when ntc == ntu to avoid broken behavior.

Fixes: 3876ff525de7 ("ice: xsk: Handle SW XDP ring wrap and bump tail more often")
	Signed-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20220328142123.170157-4-maciej.fijalkowski@intel.com
(cherry picked from commit 0ec1713009c5cc24244c918def1cd14080be27e3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_xsk.c
diff --cc drivers/net/ethernet/intel/ice/ice_xsk.c
index 295bfdac4d32,dfbcaf08520e..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_xsk.c
+++ b/drivers/net/ethernet/intel/ice/ice_xsk.c
@@@ -545,16 -608,25 +545,24 @@@ int ice_clean_rx_irq_zc(struct ice_rx_r
  		 */
  		dma_rmb();
  
++<<<<<<< HEAD
++=======
+ 		if (unlikely(rx_ring->next_to_clean == rx_ring->next_to_use))
+ 			break;
+ 
+ 		xdp = *ice_xdp_buf(rx_ring, rx_ring->next_to_clean);
+ 
++>>>>>>> 0ec1713009c5 (ice: xsk: Stop Rx processing when ntc catches ntu)
  		size = le16_to_cpu(rx_desc->wb.pkt_len) &
  				   ICE_RX_FLX_DESC_PKT_LEN_M;
 -		if (!size) {
 -			xdp->data = NULL;
 -			xdp->data_end = NULL;
 -			xdp->data_hard_start = NULL;
 -			xdp->data_meta = NULL;
 -			goto construct_skb;
 -		}
 +		if (!size)
 +			break;
  
 -		xsk_buff_set_size(xdp, size);
 -		xsk_buff_dma_sync_for_cpu(xdp, rx_ring->xsk_pool);
 +		rx_buf = &rx_ring->rx_buf[rx_ring->next_to_clean];
 +		rx_buf->xdp->data_end = rx_buf->xdp->data + size;
 +		xsk_buff_dma_sync_for_cpu(rx_buf->xdp, rx_ring->xsk_pool);
  
 -		xdp_res = ice_run_xdp_zc(rx_ring, xdp, xdp_prog, xdp_ring);
 +		xdp_res = ice_run_xdp_zc(rx_ring, rx_buf->xdp);
  		if (xdp_res) {
  			if (xdp_res & (ICE_XDP_TX | ICE_XDP_REDIR))
  				xdp_xmit |= xdp_res;
* Unmerged path drivers/net/ethernet/intel/ice/ice_xsk.c
