net/mlx5: Bridge, extract FDB delete notification to function

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Vlad Buslov <vladbu@nvidia.com>
commit bf3d56d8f55f96024d18e94d2a87e31d9c1a6682
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/bf3d56d8.failed

SWITCHDEV_FDB_DEL_TO_BRIDGE notification is generated in multiple places in
bridge code. Following patch in series changes the condition for the
notification. Extract the notification into dedicated helper function
mlx5_esw_bridge_fdb_del_notify() to only modify it in single place in the
future changes.

	Signed-off-by: Vlad Buslov <vladbu@nvidia.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Reviewed-by: Mark Bloch <mbloch@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit bf3d56d8f55f96024d18e94d2a87e31d9c1a6682)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
index b503562f97d0,5f5571190ffe..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
@@@ -25,11 -52,39 +25,35 @@@ struct mlx5_esw_bridge 
  	int ifindex;
  	int refcnt;
  	struct list_head list;
 -	struct mlx5_esw_bridge_offloads *br_offloads;
 -
 -	struct list_head fdb_list;
 -	struct rhashtable fdb_ht;
  
  	struct mlx5_flow_table *egress_ft;
 -	struct mlx5_flow_group *egress_vlan_fg;
  	struct mlx5_flow_group *egress_mac_fg;
 -	unsigned long ageing_time;
 -	u32 flags;
  };
  
++<<<<<<< HEAD
++=======
+ static void
+ mlx5_esw_bridge_fdb_offload_notify(struct net_device *dev, const unsigned char *addr, u16 vid,
+ 				   unsigned long val)
+ {
+ 	struct switchdev_notifier_fdb_info send_info = {};
+ 
+ 	send_info.addr = addr;
+ 	send_info.vid = vid;
+ 	send_info.offloaded = true;
+ 	call_switchdev_notifiers(val, dev, &send_info.info, NULL);
+ }
+ 
+ static void
+ mlx5_esw_bridge_fdb_del_notify(struct mlx5_esw_bridge_fdb_entry *entry)
+ {
+ 	if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 		mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 						   entry->key.vid,
+ 						   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ }
+ 
++>>>>>>> bf3d56d8f55f (net/mlx5: Bridge, extract FDB delete notification to function)
  static struct mlx5_flow_table *
  mlx5_esw_bridge_table_create(int max_fte, u32 level, struct mlx5_eswitch *esw)
  {
@@@ -265,18 -645,459 +289,456 @@@ mlx5_esw_bridge_lookup(int ifindex, str
  	return bridge;
  }
  
 -static unsigned long mlx5_esw_bridge_port_key_from_data(u16 vport_num, u16 esw_owner_vhca_id)
 +static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge *bridge,
 +				      struct mlx5_vport *vport)
  {
++<<<<<<< HEAD
 +	vport->bridge = bridge;
 +	return 0;
 +}
 +
++=======
+ 	return vport_num | (unsigned long)esw_owner_vhca_id << sizeof(vport_num) * BITS_PER_BYTE;
+ }
+ 
+ static unsigned long mlx5_esw_bridge_port_key(struct mlx5_esw_bridge_port *port)
+ {
+ 	return mlx5_esw_bridge_port_key_from_data(port->vport_num, port->esw_owner_vhca_id);
+ }
+ 
+ static int mlx5_esw_bridge_port_insert(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	return xa_insert(&br_offloads->ports, mlx5_esw_bridge_port_key(port), port, GFP_KERNEL);
+ }
+ 
+ static struct mlx5_esw_bridge_port *
+ mlx5_esw_bridge_port_lookup(u16 vport_num, u16 esw_owner_vhca_id,
+ 			    struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	return xa_load(&br_offloads->ports, mlx5_esw_bridge_port_key_from_data(vport_num,
+ 									       esw_owner_vhca_id));
+ }
+ 
+ static void mlx5_esw_bridge_port_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	xa_erase(&br_offloads->ports, mlx5_esw_bridge_port_key(port));
+ }
+ 
+ static void mlx5_esw_bridge_fdb_entry_refresh(unsigned long lastuse,
+ 					      struct mlx5_esw_bridge_fdb_entry *entry)
+ {
+ 	trace_mlx5_esw_bridge_fdb_entry_refresh(entry);
+ 
+ 	entry->lastuse = lastuse;
+ 	mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 					   entry->key.vid,
+ 					   SWITCHDEV_FDB_ADD_TO_BRIDGE);
+ }
+ 
+ static void
+ mlx5_esw_bridge_fdb_entry_cleanup(struct mlx5_esw_bridge_fdb_entry *entry,
+ 				  struct mlx5_esw_bridge *bridge)
+ {
+ 	trace_mlx5_esw_bridge_fdb_entry_cleanup(entry);
+ 
+ 	rhashtable_remove_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ 	if (entry->filter_handle)
+ 		mlx5_del_flow_rules(entry->filter_handle);
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ 	mlx5_fc_destroy(bridge->br_offloads->esw->dev, entry->ingress_counter);
+ 	list_del(&entry->vlan_list);
+ 	list_del(&entry->list);
+ 	kvfree(entry);
+ }
+ 
+ static void mlx5_esw_bridge_fdb_flush(struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 		mlx5_esw_bridge_fdb_del_notify(entry);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_lookup(u16 vid, struct mlx5_esw_bridge_port *port)
+ {
+ 	return xa_load(&port->vlans, vid);
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_push_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct {
+ 		__be16	h_vlan_proto;
+ 		__be16	h_vlan_TCI;
+ 	} vlan_hdr = { htons(ETH_P_8021Q), htons(vlan->vid) };
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_insert)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_size) < sizeof(vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat INSERT_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_INSERT_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(vlan_hdr);
+ 	reformat_params.data = &vlan_hdr;
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat INSERT_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_push = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_push_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_push);
+ 	vlan->pkt_reformat_push = NULL;
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_pop_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_remove)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_size) < sizeof(struct vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat REMOVE_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_REMOVE_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(struct vlan_hdr);
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat REMOVE_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_pop = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_pop_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_pop);
+ 	vlan->pkt_reformat_pop = NULL;
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_create(u16 vid, u16 flags, struct mlx5_esw_bridge_port *port,
+ 			    struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	int err;
+ 
+ 	vlan = kvzalloc(sizeof(*vlan), GFP_KERNEL);
+ 	if (!vlan)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	vlan->vid = vid;
+ 	vlan->flags = flags;
+ 	INIT_LIST_HEAD(&vlan->fdb_list);
+ 
+ 	if (flags & BRIDGE_VLAN_INFO_PVID) {
+ 		err = mlx5_esw_bridge_vlan_push_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_push;
+ 	}
+ 	if (flags & BRIDGE_VLAN_INFO_UNTAGGED) {
+ 		err = mlx5_esw_bridge_vlan_pop_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_pop;
+ 	}
+ 
+ 	err = xa_insert(&port->vlans, vid, vlan, GFP_KERNEL);
+ 	if (err)
+ 		goto err_xa_insert;
+ 
+ 	trace_mlx5_esw_bridge_vlan_create(vlan);
+ 	return vlan;
+ 
+ err_xa_insert:
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, esw);
+ err_vlan_pop:
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, esw);
+ err_vlan_push:
+ 	kvfree(vlan);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_vlan *vlan)
+ {
+ 	xa_erase(&port->vlans, vlan->vid);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_flush(struct mlx5_esw_bridge_vlan *vlan,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &vlan->fdb_list, vlan_list) {
+ 		mlx5_esw_bridge_fdb_del_notify(entry);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ 
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, bridge->br_offloads->esw);
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, bridge->br_offloads->esw);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_cleanup(struct mlx5_esw_bridge_port *port,
+ 					 struct mlx5_esw_bridge_vlan *vlan,
+ 					 struct mlx5_esw_bridge *bridge)
+ {
+ 	trace_mlx5_esw_bridge_vlan_cleanup(vlan);
+ 	mlx5_esw_bridge_vlan_flush(vlan, bridge);
+ 	mlx5_esw_bridge_vlan_erase(port, vlan);
+ 	kvfree(vlan);
+ }
+ 
+ static void mlx5_esw_bridge_port_vlans_flush(struct mlx5_esw_bridge_port *port,
+ 					     struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	unsigned long index;
+ 
+ 	xa_for_each(&port->vlans, index, vlan)
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan, bridge);
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_port_vlan_lookup(u16 vid, u16 vport_num, u16 esw_owner_vhca_id,
+ 				 struct mlx5_esw_bridge *bridge, struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, bridge->br_offloads);
+ 	if (!port) {
+ 		/* FDB is added asynchronously on wq while port might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port (vport=%u)\n", vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan) {
+ 		/* FDB is added asynchronously on wq while vlan might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port vlan metadata (vport=%u)\n",
+ 			 vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	return vlan;
+ }
+ 
+ static struct mlx5_esw_bridge_fdb_entry *
+ mlx5_esw_bridge_fdb_entry_init(struct net_device *dev, u16 vport_num, u16 esw_owner_vhca_id,
+ 			       const unsigned char *addr, u16 vid, bool added_by_user,
+ 			       struct mlx5_eswitch *esw, struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan = NULL;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_flow_handle *handle;
+ 	struct mlx5_fc *counter;
+ 	int err;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG && vid) {
+ 		vlan = mlx5_esw_bridge_port_vlan_lookup(vid, vport_num, esw_owner_vhca_id, bridge,
+ 							esw);
+ 		if (IS_ERR(vlan))
+ 			return ERR_CAST(vlan);
+ 	}
+ 
+ 	entry = kvzalloc(sizeof(*entry), GFP_KERNEL);
+ 	if (!entry)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ether_addr_copy(entry->key.addr, addr);
+ 	entry->key.vid = vid;
+ 	entry->dev = dev;
+ 	entry->vport_num = vport_num;
+ 	entry->esw_owner_vhca_id = esw_owner_vhca_id;
+ 	entry->lastuse = jiffies;
+ 	if (added_by_user)
+ 		entry->flags |= MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER;
+ 
+ 	counter = mlx5_fc_create(esw->dev, true);
+ 	if (IS_ERR(counter)) {
+ 		err = PTR_ERR(counter);
+ 		goto err_ingress_fc_create;
+ 	}
+ 	entry->ingress_counter = counter;
+ 
+ 	handle = mlx5_esw_bridge_ingress_flow_create(vport_num, addr, vlan, mlx5_fc_id(counter),
+ 						     bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create ingress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_ingress_flow_create;
+ 	}
+ 	entry->ingress_handle = handle;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG) {
+ 		handle = mlx5_esw_bridge_ingress_filter_flow_create(vport_num, addr, bridge);
+ 		if (IS_ERR(handle)) {
+ 			err = PTR_ERR(handle);
+ 			esw_warn(esw->dev, "Failed to create ingress filter(vport=%u,err=%d)\n",
+ 				 vport_num, err);
+ 			goto err_ingress_filter_flow_create;
+ 		}
+ 		entry->filter_handle = handle;
+ 	}
+ 
+ 	handle = mlx5_esw_bridge_egress_flow_create(vport_num, addr, vlan, bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create egress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_egress_flow_create;
+ 	}
+ 	entry->egress_handle = handle;
+ 
+ 	err = rhashtable_insert_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	if (err) {
+ 		esw_warn(esw->dev, "Failed to insert FDB flow(vport=%u,err=%d)\n", vport_num, err);
+ 		goto err_ht_init;
+ 	}
+ 
+ 	if (vlan)
+ 		list_add(&entry->vlan_list, &vlan->fdb_list);
+ 	else
+ 		INIT_LIST_HEAD(&entry->vlan_list);
+ 	list_add(&entry->list, &bridge->fdb_list);
+ 
+ 	trace_mlx5_esw_bridge_fdb_entry_init(entry);
+ 	return entry;
+ 
+ err_ht_init:
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ err_egress_flow_create:
+ 	if (entry->filter_handle)
+ 		mlx5_del_flow_rules(entry->filter_handle);
+ err_ingress_filter_flow_create:
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ err_ingress_flow_create:
+ 	mlx5_fc_destroy(esw->dev, entry->ingress_counter);
+ err_ingress_fc_create:
+ 	kvfree(entry);
+ 	return ERR_PTR(err);
+ }
+ 
+ int mlx5_esw_bridge_ageing_time_set(u16 vport_num, u16 esw_owner_vhca_id, unsigned long ageing_time,
+ 				    struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return -EINVAL;
+ 
+ 	port->bridge->ageing_time = clock_t_to_jiffies(ageing_time);
+ 	return 0;
+ }
+ 
+ int mlx5_esw_bridge_vlan_filtering_set(u16 vport_num, u16 esw_owner_vhca_id, bool enable,
+ 				       struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge *bridge;
+ 	bool filtering;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return -EINVAL;
+ 
+ 	bridge = port->bridge;
+ 	filtering = bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	if (filtering == enable)
+ 		return 0;
+ 
+ 	mlx5_esw_bridge_fdb_flush(bridge);
+ 	if (enable)
+ 		bridge->flags |= MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	else
+ 		bridge->flags &= ~MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_esw_bridge_vport_init(u16 vport_num, u16 esw_owner_vhca_id,
+ 				      struct mlx5_esw_bridge_offloads *br_offloads,
+ 				      struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_eswitch *esw = br_offloads->esw;
+ 	struct mlx5_esw_bridge_port *port;
+ 	int err;
+ 
+ 	port = kvzalloc(sizeof(*port), GFP_KERNEL);
+ 	if (!port)
+ 		return -ENOMEM;
+ 
+ 	port->vport_num = vport_num;
+ 	port->esw_owner_vhca_id = esw_owner_vhca_id;
+ 	port->bridge = bridge;
+ 	xa_init(&port->vlans);
+ 	err = mlx5_esw_bridge_port_insert(port, br_offloads);
+ 	if (err) {
+ 		esw_warn(esw->dev,
+ 			 "Failed to insert port metadata (vport=%u,esw_owner_vhca_id=%u,err=%d)\n",
+ 			 port->vport_num, port->esw_owner_vhca_id, err);
+ 		goto err_port_insert;
+ 	}
+ 	trace_mlx5_esw_bridge_vport_init(port);
+ 
+ 	return 0;
+ 
+ err_port_insert:
+ 	kvfree(port);
+ 	return err;
+ }
+ 
++>>>>>>> bf3d56d8f55f (net/mlx5: Bridge, extract FDB delete notification to function)
  static int mlx5_esw_bridge_vport_cleanup(struct mlx5_esw_bridge_offloads *br_offloads,
 -					 struct mlx5_esw_bridge_port *port)
 +					 struct mlx5_vport *vport)
  {
 -	u16 vport_num = port->vport_num, esw_owner_vhca_id = port->esw_owner_vhca_id;
 -	struct mlx5_esw_bridge *bridge = port->bridge;
 -	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
 -
 -	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list)
 -		if (entry->vport_num == vport_num && entry->esw_owner_vhca_id == esw_owner_vhca_id)
 -			mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
 -
 -	trace_mlx5_esw_bridge_vport_cleanup(port);
 -	mlx5_esw_bridge_port_vlans_flush(port, bridge);
 -	mlx5_esw_bridge_port_erase(port, br_offloads);
 -	kvfree(port);
 -	mlx5_esw_bridge_put(br_offloads, bridge);
 +	mlx5_esw_bridge_put(br_offloads, vport->bridge);
 +	vport->bridge = NULL;
  	return 0;
  }
  
@@@ -308,7 -1143,132 +770,136 @@@ int mlx5_esw_bridge_vport_unlink(int if
  		return -EINVAL;
  	}
  
++<<<<<<< HEAD
 +	return mlx5_esw_bridge_vport_cleanup(br_offloads, vport);
++=======
+ 	err = mlx5_esw_bridge_vport_cleanup(br_offloads, port);
+ 	if (err)
+ 		NL_SET_ERR_MSG_MOD(extack, "Port cleanup failed");
+ 	return err;
+ }
+ 
+ int mlx5_esw_bridge_port_vlan_add(u16 vport_num, u16 esw_owner_vhca_id, u16 vid, u16 flags,
+ 				  struct mlx5_esw_bridge_offloads *br_offloads,
+ 				  struct netlink_ext_ack *extack)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return -EINVAL;
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (vlan) {
+ 		if (vlan->flags == flags)
+ 			return 0;
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan, port->bridge);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_create(vid, flags, port, br_offloads->esw);
+ 	if (IS_ERR(vlan)) {
+ 		NL_SET_ERR_MSG_MOD(extack, "Failed to create VLAN entry");
+ 		return PTR_ERR(vlan);
+ 	}
+ 	return 0;
+ }
+ 
+ void mlx5_esw_bridge_port_vlan_del(u16 vport_num, u16 esw_owner_vhca_id, u16 vid,
+ 				   struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return;
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan)
+ 		return;
+ 	mlx5_esw_bridge_vlan_cleanup(port, vlan, port->bridge);
+ }
+ 
+ void mlx5_esw_bridge_fdb_create(struct net_device *dev, u16 vport_num, u16 esw_owner_vhca_id,
+ 				struct mlx5_esw_bridge_offloads *br_offloads,
+ 				struct switchdev_notifier_fdb_info *fdb_info)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge *bridge;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return;
+ 
+ 	bridge = port->bridge;
+ 	entry = mlx5_esw_bridge_fdb_entry_init(dev, vport_num, esw_owner_vhca_id, fdb_info->addr,
+ 					       fdb_info->vid, fdb_info->added_by_user,
+ 					       br_offloads->esw, bridge);
+ 	if (IS_ERR(entry))
+ 		return;
+ 
+ 	if (entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER)
+ 		mlx5_esw_bridge_fdb_offload_notify(dev, entry->key.addr, entry->key.vid,
+ 						   SWITCHDEV_FDB_OFFLOADED);
+ 	else
+ 		/* Take over dynamic entries to prevent kernel bridge from aging them out. */
+ 		mlx5_esw_bridge_fdb_offload_notify(dev, entry->key.addr, entry->key.vid,
+ 						   SWITCHDEV_FDB_ADD_TO_BRIDGE);
+ }
+ 
+ void mlx5_esw_bridge_fdb_remove(struct net_device *dev, u16 vport_num, u16 esw_owner_vhca_id,
+ 				struct mlx5_esw_bridge_offloads *br_offloads,
+ 				struct switchdev_notifier_fdb_info *fdb_info)
+ {
+ 	struct mlx5_eswitch *esw = br_offloads->esw;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_esw_bridge_fdb_key key;
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge *bridge;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, esw_owner_vhca_id, br_offloads);
+ 	if (!port)
+ 		return;
+ 
+ 	bridge = port->bridge;
+ 	ether_addr_copy(key.addr, fdb_info->addr);
+ 	key.vid = fdb_info->vid;
+ 	entry = rhashtable_lookup_fast(&bridge->fdb_ht, &key, fdb_ht_params);
+ 	if (!entry) {
+ 		esw_warn(esw->dev,
+ 			 "FDB entry with specified key not found (MAC=%pM,vid=%u,vport=%u)\n",
+ 			 key.addr, key.vid, vport_num);
+ 		return;
+ 	}
+ 
+ 	mlx5_esw_bridge_fdb_del_notify(entry);
+ 	mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ }
+ 
+ void mlx5_esw_bridge_update(struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 	struct mlx5_esw_bridge *bridge;
+ 
+ 	list_for_each_entry(bridge, &br_offloads->bridges, list) {
+ 		list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 			unsigned long lastuse =
+ 				(unsigned long)mlx5_fc_query_lastuse(entry->ingress_counter);
+ 
+ 			if (entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER)
+ 				continue;
+ 
+ 			if (time_after(lastuse, entry->lastuse)) {
+ 				mlx5_esw_bridge_fdb_entry_refresh(lastuse, entry);
+ 			} else if (time_is_before_jiffies(entry->lastuse + bridge->ageing_time)) {
+ 				mlx5_esw_bridge_fdb_del_notify(entry);
+ 				mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 			}
+ 		}
+ 	}
++>>>>>>> bf3d56d8f55f (net/mlx5: Bridge, extract FDB delete notification to function)
  }
  
  static void mlx5_esw_bridge_flush(struct mlx5_esw_bridge_offloads *br_offloads)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
