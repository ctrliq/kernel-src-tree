net/mlx5e: Fix page allocation failure for trap-RQ over SF

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Aya Levin <ayal@nvidia.com>
commit 497008e783452a2ec45c7ec5835cfe6950dcb097
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/497008e7.failed

Set the correct device pointer to the trap-RQ, to allow access to
dma_mask and avoid allocation request with the wrong pci-dev.

WARNING: CPU: 1 PID: 12005 at kernel/dma/mapping.c:151 dma_map_page_attrs+0x139/0x1c0
...
all Trace:
<IRQ>
? __page_pool_alloc_pages_slow+0x5a/0x210
mlx5e_post_rx_wqes+0x258/0x400 [mlx5_core]
mlx5e_trap_napi_poll+0x44/0xc0 [mlx5_core]
__napi_poll+0x24/0x150
net_rx_action+0x22b/0x280
__do_softirq+0xc7/0x27e
do_softirq+0x61/0x80
</IRQ>
__local_bh_enable_ip+0x4b/0x50
mlx5e_handle_action_trap+0x2dd/0x4d0 [mlx5_core]
blocking_notifier_call_chain+0x5a/0x80
mlx5_devlink_trap_action_set+0x8b/0x100 [mlx5_core]

Fixes: 5543e989fe5e ("net/mlx5e: Add trap entity to ETH driver")
	Signed-off-by: Aya Levin <ayal@nvidia.com>
	Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 497008e783452a2ec45c7ec5835cfe6950dcb097)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/trap.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/trap.c
index 90bd7328df42,7f94508594fb..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/trap.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/trap.c
@@@ -30,128 -30,29 +30,151 @@@ static int mlx5e_trap_napi_poll(struct 
  	return work_done;
  }
  
 -static void mlx5e_init_trap_rq(struct mlx5e_trap *t, struct mlx5e_params *params,
 +static int mlx5e_alloc_trap_rq(struct mlx5e_priv *priv, struct mlx5e_rq_param *rqp,
 +			       struct mlx5e_rq_stats *stats, struct mlx5e_params *params,
 +			       struct mlx5e_ch_stats *ch_stats,
  			       struct mlx5e_rq *rq)
  {
++<<<<<<< HEAD
 +	void *rqc_wq = MLX5_ADDR_OF(rqc, rqp->rqc, wq);
++=======
+ 	struct mlx5_core_dev *mdev = t->mdev;
+ 	struct mlx5e_priv *priv = t->priv;
+ 
+ 	rq->wq_type      = params->rq_wq_type;
+ 	rq->pdev         = t->pdev;
+ 	rq->netdev       = priv->netdev;
+ 	rq->priv         = priv;
+ 	rq->clock        = &mdev->clock;
+ 	rq->tstamp       = &priv->tstamp;
+ 	rq->mdev         = mdev;
+ 	rq->hw_mtu       = MLX5E_SW2HW_MTU(params, params->sw_mtu);
+ 	rq->stats        = &priv->trap_stats.rq;
+ 	rq->ptp_cyc2time = mlx5_rq_ts_translator(mdev);
+ 	xdp_rxq_info_unused(&rq->xdp_rxq);
+ 	mlx5e_rq_set_trap_handlers(rq, params);
+ }
+ 
+ static int mlx5e_open_trap_rq(struct mlx5e_priv *priv, struct mlx5e_trap *t)
+ {
+ 	struct mlx5e_rq_param *rq_param = &t->rq_param;
++>>>>>>> 497008e78345 (net/mlx5e: Fix page allocation failure for trap-RQ over SF)
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +	struct page_pool_params pp_params = {};
 +	int node = dev_to_node(mdev->device);
 +	u32 pool_size;
 +	int wq_sz;
 +	int err;
 +	int i;
 +
 +	rqp->wq.db_numa_node = node;
 +
 +	rq->wq_type  = params->rq_wq_type;
 +	rq->pdev     = mdev->device;
 +	rq->netdev   = priv->netdev;
 +	rq->mdev     = mdev;
 +	rq->priv     = priv;
 +	rq->stats    = stats;
 +	rq->clock    = &mdev->clock;
 +	rq->tstamp   = &priv->tstamp;
 +	rq->hw_mtu   = MLX5E_SW2HW_MTU(params, params->sw_mtu);
 +
 +	xdp_rxq_info_unused(&rq->xdp_rxq);
 +
 +	rq->buff.map_dir = DMA_FROM_DEVICE;
 +	rq->buff.headroom = mlx5e_get_rq_headroom(mdev, params, NULL);
 +	pool_size = 1 << params->log_rq_mtu_frames;
 +
 +	err = mlx5_wq_cyc_create(mdev, &rqp->wq, rqc_wq, &rq->wqe.wq, &rq->wq_ctrl);
 +	if (err)
 +		return err;
 +
 +	rq->wqe.wq.db = &rq->wqe.wq.db[MLX5_RCV_DBR];
 +
 +	wq_sz = mlx5_wq_cyc_get_size(&rq->wqe.wq);
 +
 +	rq->wqe.info = rqp->frags_info;
 +	rq->buff.frame0_sz = rq->wqe.info.arr[0].frag_stride;
 +	rq->wqe.frags =	kvzalloc_node(array_size(sizeof(*rq->wqe.frags),
 +						 (wq_sz << rq->wqe.info.log_num_frags)),
 +				      GFP_KERNEL, node);
 +	if (!rq->wqe.frags) {
 +		err = -ENOMEM;
 +		goto err_wq_cyc_destroy;
 +	}
 +
 +	err = mlx5e_init_di_list(rq, wq_sz, node);
 +	if (err)
 +		goto err_free_frags;
 +
 +	rq->mkey_be = cpu_to_be32(mdev->mlx5e_res.hw_objs.mkey.key);
 +
 +	mlx5e_rq_set_trap_handlers(rq, params);
 +
 +	/* Create a page_pool and register it with rxq */
 +	pp_params.order     = 0;
 +	pp_params.flags     = 0; /* No-internal DMA mapping in page_pool */
 +	pp_params.pool_size = pool_size;
 +	pp_params.nid       = node;
 +	pp_params.dev       = mdev->device;
 +	pp_params.dma_dir   = rq->buff.map_dir;
 +
 +	/* page_pool can be used even when there is no rq->xdp_prog,
 +	 * given page_pool does not handle DMA mapping there is no
 +	 * required state to clear. And page_pool gracefully handle
 +	 * elevated refcnt.
 +	 */
 +	rq->page_pool = page_pool_create(&pp_params);
 +	if (IS_ERR(rq->page_pool)) {
 +		err = PTR_ERR(rq->page_pool);
 +		rq->page_pool = NULL;
 +		goto err_free_di_list;
 +	}
 +	for (i = 0; i < wq_sz; i++) {
 +		struct mlx5e_rx_wqe_cyc *wqe =
 +			mlx5_wq_cyc_get_wqe(&rq->wqe.wq, i);
 +		int f;
 +
 +		for (f = 0; f < rq->wqe.info.num_frags; f++) {
 +			u32 frag_size = rq->wqe.info.arr[f].frag_size |
 +				MLX5_HW_START_PADDING;
 +
 +			wqe->data[f].byte_count = cpu_to_be32(frag_size);
 +			wqe->data[f].lkey = rq->mkey_be;
 +		}
 +		/* check if num_frags is not a pow of two */
 +		if (rq->wqe.info.num_frags < (1 << rq->wqe.info.log_num_frags)) {
 +			wqe->data[f].byte_count = 0;
 +			wqe->data[f].lkey = cpu_to_be32(MLX5_INVALID_LKEY);
 +			wqe->data[f].addr = 0;
 +		}
 +	}
 +	return 0;
 +
 +err_free_di_list:
 +	mlx5e_free_di_list(rq);
 +err_free_frags:
 +	kvfree(rq->wqe.frags);
 +err_wq_cyc_destroy:
 +	mlx5_wq_destroy(&rq->wq_ctrl);
 +
 +	return err;
 +}
 +
 +static void mlx5e_free_trap_rq(struct mlx5e_rq *rq)
 +{
 +	page_pool_destroy(rq->page_pool);
 +	mlx5e_free_di_list(rq);
 +	kvfree(rq->wqe.frags);
 +	mlx5_wq_destroy(&rq->wq_ctrl);
 +}
 +
 +static int mlx5e_open_trap_rq(struct mlx5e_priv *priv, struct napi_struct *napi,
 +			      struct mlx5e_rq_stats *stats, struct mlx5e_params *params,
 +			      struct mlx5e_rq_param *rq_param,
 +			      struct mlx5e_ch_stats *ch_stats,
 +			      struct mlx5e_rq *rq)
 +{
  	struct mlx5_core_dev *mdev = priv->mdev;
  	struct mlx5e_create_cq_param ccp = {};
  	struct dim_cq_moder trap_moder = {};
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/trap.c
