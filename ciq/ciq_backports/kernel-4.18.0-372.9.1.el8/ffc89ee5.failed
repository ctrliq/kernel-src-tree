net/mlx5: Bridge, match FDB entry vlan tag

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.9.1.el8
commit-author Vlad Buslov <vladbu@nvidia.com>
commit ffc89ee5e5e88aa5924034c28d5e5aae75229e0f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.9.1.el8/ffc89ee5.failed

Add support for FDB vlan-tagged entries. Extend ingress and egress flow
tables with flow groups to match packet vlan tag. Modify the flow creation
code to include vlan tag, if vlan is configured on port and vlan
configuration is supported for offload.

	Signed-off-by: Vlad Buslov <vladbu@nvidia.com>
	Reviewed-by: Jianbo Liu <jianbol@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit ffc89ee5e5e88aa5924034c28d5e5aae75229e0f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
#	drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
index b503562f97d0,e1467dbe80dc..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
@@@ -25,11 -78,31 +31,12 @@@ struct mlx5_esw_bridge 
  	int ifindex;
  	int refcnt;
  	struct list_head list;
 -	struct mlx5_esw_bridge_offloads *br_offloads;
 -
 -	struct list_head fdb_list;
 -	struct rhashtable fdb_ht;
 -	struct xarray vports;
  
  	struct mlx5_flow_table *egress_ft;
+ 	struct mlx5_flow_group *egress_vlan_fg;
  	struct mlx5_flow_group *egress_mac_fg;
 -	unsigned long ageing_time;
 -	u32 flags;
  };
  
 -static void
 -mlx5_esw_bridge_fdb_offload_notify(struct net_device *dev, const unsigned char *addr, u16 vid,
 -				   unsigned long val)
 -{
 -	struct switchdev_notifier_fdb_info send_info;
 -
 -	send_info.addr = addr;
 -	send_info.vid = vid;
 -	send_info.offloaded = true;
 -	call_switchdev_notifiers(val, dev, &send_info.info, NULL);
 -}
 -
  static struct mlx5_flow_table *
  mlx5_esw_bridge_table_create(int max_fte, u32 level, struct mlx5_eswitch *esw)
  {
@@@ -124,10 -268,13 +202,10 @@@ mlx5_esw_bridge_egress_mac_fg_create(st
  static int
  mlx5_esw_bridge_ingress_table_init(struct mlx5_esw_bridge_offloads *br_offloads)
  {
+ 	struct mlx5_flow_group *mac_fg, *vlan_fg;
  	struct mlx5_flow_table *ingress_ft;
- 	struct mlx5_flow_group *mac_fg;
  	int err;
  
 -	if (!mlx5_eswitch_vport_match_metadata_enabled(br_offloads->esw))
 -		return -EOPNOTSUPP;
 -
  	ingress_ft = mlx5_esw_bridge_table_create(MLX5_ESW_BRIDGE_INGRESS_TABLE_SIZE,
  						  MLX5_ESW_BRIDGE_LEVEL_INGRESS_TABLE,
  						  br_offloads->esw);
@@@ -194,6 -362,109 +293,112 @@@ mlx5_esw_bridge_egress_table_cleanup(st
  	mlx5_destroy_flow_table(bridge->egress_ft);
  }
  
++<<<<<<< HEAD
++=======
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_ingress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				    struct mlx5_esw_bridge_vlan *vlan, u32 counter_id,
+ 				    struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_offloads *br_offloads = bridge->br_offloads;
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST | MLX5_FLOW_CONTEXT_ACTION_COUNT,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_destination dests[2] = {};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *smac_v, *smac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2;
+ 
+ 	smac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.smac_47_16);
+ 	ether_addr_copy(smac_v, addr);
+ 	smac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.smac_47_16);
+ 	eth_broadcast_addr(smac_c);
+ 
+ 	MLX5_SET(fte_match_param, rule_spec->match_criteria,
+ 		 misc_parameters_2.metadata_reg_c_0, mlx5_eswitch_get_vport_metadata_mask());
+ 	MLX5_SET(fte_match_param, rule_spec->match_value, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_for_match(br_offloads->esw, vport_num));
+ 
+ 	if (vlan) {
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	dests[0].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dests[0].ft = bridge->egress_ft;
+ 	dests[1].type = MLX5_FLOW_DESTINATION_TYPE_COUNTER;
+ 	dests[1].counter_id = counter_id;
+ 
+ 	handle = mlx5_add_flow_rules(br_offloads->ingress_ft, rule_spec, &flow_act, dests,
+ 				     ARRAY_SIZE(dests));
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_egress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				   struct mlx5_esw_bridge_vlan *vlan,
+ 				   struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_flow_destination dest = {
+ 		.type = MLX5_FLOW_DESTINATION_TYPE_VPORT,
+ 		.vport.num = vport_num,
+ 	};
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *dmac_v, *dmac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 
+ 	dmac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.dmac_47_16);
+ 	ether_addr_copy(dmac_v, addr);
+ 	dmac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.dmac_47_16);
+ 	eth_broadcast_addr(dmac_c);
+ 
+ 	if (vlan) {
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	handle = mlx5_add_flow_rules(bridge->egress_ft, rule_spec, &flow_act, &dest, 1);
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
++>>>>>>> ffc89ee5e5e8 (net/mlx5: Bridge, match FDB entry vlan tag)
  static struct mlx5_esw_bridge *mlx5_esw_bridge_create(int ifindex,
  						      struct mlx5_esw_bridge_offloads *br_offloads)
  {
@@@ -265,11 -548,270 +470,249 @@@ mlx5_esw_bridge_lookup(int ifindex, str
  	return bridge;
  }
  
++<<<<<<< HEAD
 +static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge *bridge,
++=======
+ static int mlx5_esw_bridge_port_insert(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_insert(&bridge->vports, port->vport_num, port, GFP_KERNEL);
+ }
+ 
+ static struct mlx5_esw_bridge_port *
+ mlx5_esw_bridge_port_lookup(u16 vport_num, struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_load(&bridge->vports, vport_num);
+ }
+ 
+ static void mlx5_esw_bridge_port_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	xa_erase(&bridge->vports, port->vport_num);
+ }
+ 
+ static void
+ mlx5_esw_bridge_fdb_entry_cleanup(struct mlx5_esw_bridge_fdb_entry *entry,
+ 				  struct mlx5_esw_bridge *bridge)
+ {
+ 	rhashtable_remove_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ 	mlx5_fc_destroy(bridge->br_offloads->esw->dev, entry->ingress_counter);
+ 	list_del(&entry->list);
+ 	kvfree(entry);
+ }
+ 
+ static void mlx5_esw_bridge_fdb_flush(struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 		if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 			mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 							   entry->key.vid,
+ 							   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_lookup(u16 vid, struct mlx5_esw_bridge_port *port)
+ {
+ 	return xa_load(&port->vlans, vid);
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_create(u16 vid, u16 flags, struct mlx5_esw_bridge_port *port)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	int err;
+ 
+ 	vlan = kvzalloc(sizeof(*vlan), GFP_KERNEL);
+ 	if (!vlan)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	vlan->vid = vid;
+ 	vlan->flags = flags;
+ 	err = xa_insert(&port->vlans, vid, vlan, GFP_KERNEL);
+ 	if (err) {
+ 		kvfree(vlan);
+ 		return ERR_PTR(err);
+ 	}
+ 
+ 	return vlan;
+ }
+ 
+ static void mlx5_esw_bridge_vlan_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_vlan *vlan)
+ {
+ 	xa_erase(&port->vlans, vlan->vid);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_cleanup(struct mlx5_esw_bridge_port *port,
+ 					 struct mlx5_esw_bridge_vlan *vlan)
+ {
+ 	mlx5_esw_bridge_vlan_erase(port, vlan);
+ 	kvfree(vlan);
+ }
+ 
+ static void mlx5_esw_bridge_port_vlans_flush(struct mlx5_esw_bridge_port *port)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	unsigned long index;
+ 
+ 	xa_for_each(&port->vlans, index, vlan)
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan);
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_port_vlan_lookup(u16 vid, u16 vport_num, struct mlx5_esw_bridge *bridge,
+ 				 struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, bridge);
+ 	if (!port) {
+ 		/* FDB is added asynchronously on wq while port might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port (vport=%u)\n", vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan) {
+ 		/* FDB is added asynchronously on wq while vlan might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port vlan metadata (vport=%u)\n",
+ 			 vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	return vlan;
+ }
+ 
+ static struct mlx5_esw_bridge_fdb_entry *
+ mlx5_esw_bridge_fdb_entry_init(struct net_device *dev, u16 vport_num, const unsigned char *addr,
+ 			       u16 vid, bool added_by_user, struct mlx5_eswitch *esw,
+ 			       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan = NULL;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_flow_handle *handle;
+ 	struct mlx5_fc *counter;
+ 	struct mlx5e_priv *priv;
+ 	int err;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG && vid) {
+ 		vlan = mlx5_esw_bridge_port_vlan_lookup(vid, vport_num, bridge, esw);
+ 		if (IS_ERR(vlan))
+ 			return ERR_CAST(vlan);
+ 		if (vlan->flags & (BRIDGE_VLAN_INFO_PVID | BRIDGE_VLAN_INFO_UNTAGGED))
+ 			return ERR_PTR(-EOPNOTSUPP); /* can't offload vlan push/pop */
+ 	}
+ 
+ 	priv = netdev_priv(dev);
+ 	entry = kvzalloc(sizeof(*entry), GFP_KERNEL);
+ 	if (!entry)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ether_addr_copy(entry->key.addr, addr);
+ 	entry->key.vid = vid;
+ 	entry->dev = dev;
+ 	entry->vport_num = vport_num;
+ 	entry->lastuse = jiffies;
+ 	if (added_by_user)
+ 		entry->flags |= MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER;
+ 
+ 	counter = mlx5_fc_create(priv->mdev, true);
+ 	if (IS_ERR(counter)) {
+ 		err = PTR_ERR(counter);
+ 		goto err_ingress_fc_create;
+ 	}
+ 	entry->ingress_counter = counter;
+ 
+ 	handle = mlx5_esw_bridge_ingress_flow_create(vport_num, addr, vlan, mlx5_fc_id(counter),
+ 						     bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create ingress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_ingress_flow_create;
+ 	}
+ 	entry->ingress_handle = handle;
+ 
+ 	handle = mlx5_esw_bridge_egress_flow_create(vport_num, addr, vlan, bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create egress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_egress_flow_create;
+ 	}
+ 	entry->egress_handle = handle;
+ 
+ 	err = rhashtable_insert_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	if (err) {
+ 		esw_warn(esw->dev, "Failed to insert FDB flow(vport=%u,err=%d)\n", vport_num, err);
+ 		goto err_ht_init;
+ 	}
+ 
+ 	list_add(&entry->list, &bridge->fdb_list);
+ 	return entry;
+ 
+ err_ht_init:
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ err_egress_flow_create:
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ err_ingress_flow_create:
+ 	mlx5_fc_destroy(priv->mdev, entry->ingress_counter);
+ err_ingress_fc_create:
+ 	kvfree(entry);
+ 	return ERR_PTR(err);
+ }
+ 
+ int mlx5_esw_bridge_ageing_time_set(unsigned long ageing_time, struct mlx5_eswitch *esw,
+ 				    struct mlx5_vport *vport)
+ {
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	vport->bridge->ageing_time = ageing_time;
+ 	return 0;
+ }
+ 
+ int mlx5_esw_bridge_vlan_filtering_set(bool enable, struct mlx5_eswitch *esw,
+ 				       struct mlx5_vport *vport)
+ {
+ 	struct mlx5_esw_bridge *bridge;
+ 	bool filtering;
+ 
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	bridge = vport->bridge;
+ 	filtering = bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	if (filtering == enable)
+ 		return 0;
+ 
+ 	mlx5_esw_bridge_fdb_flush(bridge);
+ 	if (enable)
+ 		bridge->flags |= MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	else
+ 		bridge->flags &= ~MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge_offloads *br_offloads,
+ 				      struct mlx5_esw_bridge *bridge,
++>>>>>>> ffc89ee5e5e8 (net/mlx5: Bridge, match FDB entry vlan tag)
  				      struct mlx5_vport *vport)
  {
 -	struct mlx5_eswitch *esw = br_offloads->esw;
 -	struct mlx5_esw_bridge_port *port;
 -	int err;
 -
 -	port = kvzalloc(sizeof(*port), GFP_KERNEL);
 -	if (!port) {
 -		err = -ENOMEM;
 -		goto err_port_alloc;
 -	}
 -
 -	port->vport_num = vport->vport;
 -	xa_init(&port->vlans);
 -	err = mlx5_esw_bridge_port_insert(port, bridge);
 -	if (err) {
 -		esw_warn(esw->dev, "Failed to insert port metadata (vport=%u,err=%d)\n",
 -			 vport->vport, err);
 -		goto err_port_insert;
 -	}
 -
  	vport->bridge = bridge;
  	return 0;
 -
 -err_port_insert:
 -	kvfree(port);
 -err_port_alloc:
 -	mlx5_esw_bridge_put(br_offloads, bridge);
 -	return err;
  }
  
  static int mlx5_esw_bridge_vport_cleanup(struct mlx5_esw_bridge_offloads *br_offloads,
* Unmerged path Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
* Unmerged path Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
index 319b6f1db0ba..290feec54cbf 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.h
@@ -17,6 +17,7 @@ struct mlx5_esw_bridge_offloads {
 	struct notifier_block netdev_nb;
 
 	struct mlx5_flow_table *ingress_ft;
+	struct mlx5_flow_group *ingress_vlan_fg;
 	struct mlx5_flow_group *ingress_mac_fg;
 };
 
