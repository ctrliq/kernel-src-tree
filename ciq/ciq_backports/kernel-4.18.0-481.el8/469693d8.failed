x86/head/64: Re-enable stack protection

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Michael Roth <michael.roth@amd.com>
commit 469693d8f62299709e8ba56d8fb3da9ea990213c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/469693d8.failed

Due to

  103a4908ad4d ("x86/head/64: Disable stack protection for head$(BITS).o")

kernel/head{32,64}.c are compiled with -fno-stack-protector to allow
a call to set_bringup_idt_handler(), which would otherwise have stack
protection enabled with CONFIG_STACKPROTECTOR_STRONG.

While sufficient for that case, there may still be issues with calls to
any external functions that were compiled with stack protection enabled
that in-turn make stack-protected calls, or if the exception handlers
set up by set_bringup_idt_handler() make calls to stack-protected
functions.

Subsequent patches for SEV-SNP CPUID validation support will introduce
both such cases. Attempting to disable stack protection for everything
in scope to address that is prohibitive since much of the code, like the
SEV-ES #VC handler, is shared code that remains in use after boot and
could benefit from having stack protection enabled. Attempting to inline
calls is brittle and can quickly balloon out to library/helper code
where that's not really an option.

Instead, re-enable stack protection for head32.c/head64.c, and make the
appropriate changes to ensure the segment used for the stack canary is
initialized in advance of any stack-protected C calls.

For head64.c:

- The BSP will enter from startup_64() and call into C code
  (startup_64_setup_env()) shortly after setting up the stack, which
  may result in calls to stack-protected code. Set up %gs early to allow
  for this safely.
- APs will enter from secondary_startup_64*(), and %gs will be set up
  soon after. There is one call to C code prior to %gs being setup
  (__startup_secondary_64()), but it is only to fetch 'sme_me_mask'
  global, so just load 'sme_me_mask' directly instead, and remove the
  now-unused __startup_secondary_64() function.

For head32.c:

- BSPs/APs will set %fs to __BOOT_DS prior to any C calls. In recent
  kernels, the compiler is configured to access the stack canary at
  %fs:__stack_chk_guard [1], which overlaps with the initial per-cpu
  '__stack_chk_guard' variable in the initial/"master" .data..percpu
  area. This is sufficient to allow access to the canary for use
  during initial startup, so no changes are needed there.

[1] 3fb0fdb3bbe7 ("x86/stackprotector/32: Make the canary into a regular percpu variable")

  [ bp: Massage commit message. ]

	Suggested-by: Joerg Roedel <jroedel@suse.de> #for 64-bit %gs set up
	Signed-off-by: Michael Roth <michael.roth@amd.com>
	Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lore.kernel.org/r/20220307213356.2797205-24-brijesh.singh@amd.com
(cherry picked from commit 469693d8f62299709e8ba56d8fb3da9ea990213c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/setup.h
#	arch/x86/kernel/Makefile
diff --cc arch/x86/include/asm/setup.h
index 98ca067b4c55,a1b107f2a12a..000000000000
--- a/arch/x86/include/asm/setup.h
+++ b/arch/x86/include/asm/setup.h
@@@ -48,6 -49,7 +48,10 @@@ extern unsigned long saved_video_mode
  
  extern void reserve_standard_io_resources(void);
  extern void i386_reserve_resources(void);
++<<<<<<< HEAD
++=======
+ extern unsigned long __startup_64(unsigned long physaddr, struct boot_params *bp);
++>>>>>>> 469693d8f622 (x86/head/64: Re-enable stack protection)
  extern void startup_64_setup_env(unsigned long physbase);
  extern void early_setup_idt(void);
  extern void __init do_early_exception(struct pt_regs *regs, int trapnr);
diff --cc arch/x86/kernel/Makefile
index 94ab02138888,1a2dc328cb5e..000000000000
--- a/arch/x86/kernel/Makefile
+++ b/arch/x86/kernel/Makefile
@@@ -49,10 -46,7 +49,14 @@@ endi
  # non-deterministic coverage.
  KCOV_INSTRUMENT		:= n
  
++<<<<<<< HEAD
 +CFLAGS_head$(BITS).o	+= -fno-stack-protector
 +CFLAGS_cc_platform.o	+= -fno-stack-protector
 +
 +CFLAGS_irq.o := -I$(src)/../include/asm/trace
++=======
+ CFLAGS_irq.o := -I $(srctree)/$(src)/../include/asm/trace
++>>>>>>> 469693d8f622 (x86/head/64: Re-enable stack protection)
  
  obj-y			:= process_$(BITS).o signal.o
  obj-$(CONFIG_COMPAT)	+= signal_compat.o
* Unmerged path arch/x86/include/asm/setup.h
* Unmerged path arch/x86/kernel/Makefile
diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c
index f26bda1467d6..7dbf532110b8 100644
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@ -319,15 +319,6 @@ unsigned long __head __startup_64(unsigned long physaddr,
 	return sme_postprocess_startup(bp, pmd);
 }
 
-unsigned long __startup_secondary_64(void)
-{
-	/*
-	 * Return the SME encryption mask (if SME is active) to be used as a
-	 * modifier for the initial pgdir entry programmed into CR3.
-	 */
-	return sme_get_me_mask();
-}
-
 /* Wipe all early page tables except for the kernel symbol map */
 static void __init reset_early_page_tables(void)
 {
diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S
index 228839afbc73..9c554a1f3f9c 100644
--- a/arch/x86/kernel/head_64.S
+++ b/arch/x86/kernel/head_64.S
@@ -75,6 +75,22 @@ SYM_CODE_START_NOALIGN(startup_64)
 	leaq	(__end_init_task - SIZEOF_PTREGS)(%rip), %rsp
 
 	leaq	_text(%rip), %rdi
+
+	/*
+	 * initial_gs points to initial fixed_percpu_data struct with storage for
+	 * the stack protector canary. Global pointer fixups are needed at this
+	 * stage, so apply them as is done in fixup_pointer(), and initialize %gs
+	 * such that the canary can be accessed at %gs:40 for subsequent C calls.
+	 */
+	movl	$MSR_GS_BASE, %ecx
+	movq	initial_gs(%rip), %rax
+	movq	$_text, %rdx
+	subq	%rdx, %rax
+	addq	%rdi, %rax
+	movq	%rax, %rdx
+	shrq	$32,  %rdx
+	wrmsr
+
 	pushq	%rsi
 	call	startup_64_setup_env
 	popq	%rsi
@@ -155,9 +171,11 @@ SYM_INNER_LABEL(secondary_startup_64_no_verify, SYM_L_GLOBAL)
 	 * Retrieve the modifier (SME encryption mask if SME is active) to be
 	 * added to the initial pgdir entry that will be programmed into CR3.
 	 */
-	pushq	%rsi
-	call	__startup_secondary_64
-	popq	%rsi
+#ifdef CONFIG_AMD_MEM_ENCRYPT
+	movq	sme_me_mask, %rax
+#else
+	xorq	%rax, %rax
+#endif
 
 	/* Form the CR3 value being sure to include the CR3 modifier */
 	addq	$(init_top_pgt - __START_KERNEL_map), %rax
