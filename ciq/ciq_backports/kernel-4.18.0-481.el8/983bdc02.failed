bpf ppc64: Add BPF_PROBE_MEM support for JIT

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Ravi Bangoria <ravi.bangoria@linux.ibm.com>
commit 983bdc0245a29cdefcd30d9d484d3edbc4b6d787
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/983bdc02.failed

BPF load instruction with BPF_PROBE_MEM mode can cause a fault
inside kernel. Append exception table for such instructions
within BPF program.

Unlike other archs which uses extable 'fixup' field to pass dest_reg
and nip, BPF exception table on PowerPC follows the generic PowerPC
exception table design, where it populates both fixup and extable
sections within BPF program. fixup section contains two instructions,
first instruction clears dest_reg and 2nd jumps to next instruction
in the BPF code. extable 'insn' field contains relative offset of
the instruction and 'fixup' field contains relative offset of the
fixup entry. Example layout of BPF program with extable present:

             +------------------+
             |                  |
             |                  |
   0x4020 -->| ld   r27,4(r3)   |
             |                  |
             |                  |
   0x40ac -->| lwz  r3,0(r4)    |
             |                  |
             |                  |
             |------------------|
   0x4280 -->| li  r27,0        |  \ fixup entry
             | b   0x4024       |  /
   0x4288 -->| li  r3,0         |
             | b   0x40b0       |
             |------------------|
   0x4290 -->| insn=0xfffffd90  |  \ extable entry
             | fixup=0xffffffec |  /
   0x4298 -->| insn=0xfffffe14  |
             | fixup=0xffffffec |
             +------------------+

   (Addresses shown here are chosen random, not real)

	Signed-off-by: Ravi Bangoria <ravi.bangoria@linux.ibm.com>
	Signed-off-by: Hari Bathini <hbathini@linux.ibm.com>
	Reviewed-by: Christophe Leroy <christophe.leroy@csgroup.eu>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/20211012123056.485795-6-hbathini@linux.ibm.com

(cherry picked from commit 983bdc0245a29cdefcd30d9d484d3edbc4b6d787)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/net/bpf_jit.h
#	arch/powerpc/net/bpf_jit_comp.c
#	arch/powerpc/net/bpf_jit_comp32.c
#	arch/powerpc/net/bpf_jit_comp64.c
diff --cc arch/powerpc/net/bpf_jit.h
index d22140878361,444c9debce91..000000000000
--- a/arch/powerpc/net/bpf_jit.h
+++ b/arch/powerpc/net/bpf_jit.h
@@@ -166,7 -178,7 +169,11 @@@ static inline void bpf_clear_seen_regis
  
  void bpf_jit_emit_func_call_rel(u32 *image, struct codegen_context *ctx, u64 func);
  int bpf_jit_build_body(struct bpf_prog *fp, u32 *image, struct codegen_context *ctx,
++<<<<<<< HEAD
 +		       u32 *addrs, bool extra_pass);
++=======
+ 		       u32 *addrs, int pass);
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  void bpf_jit_build_prologue(u32 *image, struct codegen_context *ctx);
  void bpf_jit_build_epilogue(u32 *image, struct codegen_context *ctx);
  void bpf_jit_realloc_regs(struct codegen_context *ctx);
diff --cc arch/powerpc/net/bpf_jit_comp.c
index 16ef5fa3992f,a936dca7331e..000000000000
--- a/arch/powerpc/net/bpf_jit_comp.c
+++ b/arch/powerpc/net/bpf_jit_comp.c
@@@ -166,7 -150,7 +167,11 @@@ struct bpf_prog *bpf_int_jit_compile(st
  	cgctx.stack_size = round_up(fp->aux->stack_depth, 16);
  
  	/* Scouting faux-generate pass 0 */
++<<<<<<< HEAD
 +	if (bpf_jit_build_body(fp, 0, &cgctx, addrs, false)) {
++=======
+ 	if (bpf_jit_build_body(fp, 0, &cgctx, addrs, 0)) {
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  		/* We hit something illegal or unsupported. */
  		fp = org_fp;
  		goto out_addrs;
@@@ -179,7 -163,7 +184,11 @@@
  	 */
  	if (cgctx.seen & SEEN_TAILCALL) {
  		cgctx.idx = 0;
++<<<<<<< HEAD
 +		if (bpf_jit_build_body(fp, 0, &cgctx, addrs, false)) {
++=======
+ 		if (bpf_jit_build_body(fp, 0, &cgctx, addrs, 0)) {
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  			fp = org_fp;
  			goto out_addrs;
  		}
@@@ -227,7 -217,11 +242,15 @@@ skip_init_ctx
  		/* Now build the prologue, body code & epilogue for real. */
  		cgctx.idx = 0;
  		bpf_jit_build_prologue(code_base, &cgctx);
++<<<<<<< HEAD
 +		bpf_jit_build_body(fp, code_base, &cgctx, addrs, extra_pass);
++=======
+ 		if (bpf_jit_build_body(fp, code_base, &cgctx, addrs, pass)) {
+ 			bpf_jit_binary_free(bpf_hdr);
+ 			fp = org_fp;
+ 			goto out_addrs;
+ 		}
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  		bpf_jit_build_epilogue(code_base, &cgctx);
  
  		if (bpf_jit_enable > 1)
diff --cc arch/powerpc/net/bpf_jit_comp64.c
index cbb5838adebc,ede8cb3e453f..000000000000
--- a/arch/powerpc/net/bpf_jit_comp64.c
+++ b/arch/powerpc/net/bpf_jit_comp64.c
@@@ -298,7 -297,7 +298,11 @@@ asm 
  
  /* Assemble the body code between the prologue & epilogue */
  int bpf_jit_build_body(struct bpf_prog *fp, u32 *image, struct codegen_context *ctx,
++<<<<<<< HEAD
 +		       u32 *addrs, bool extra_pass)
++=======
+ 		       u32 *addrs, int pass)
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  {
  	enum stf_barrier_type stf_barrier = stf_barrier_type_get();
  	const struct bpf_insn *insn = fp->insnsi;
@@@ -780,25 -779,40 +784,62 @@@ emit_clear
  		 */
  		/* dst = *(u8 *)(ul) (src + off) */
  		case BPF_LDX | BPF_MEM | BPF_B:
++<<<<<<< HEAD
 +			EMIT(PPC_RAW_LBZ(dst_reg, src_reg, off));
 +			if (insn_is_zext(&insn[i + 1]))
 +				addrs[++i] = ctx->idx * 4;
 +			break;
 +		/* dst = *(u16 *)(ul) (src + off) */
 +		case BPF_LDX | BPF_MEM | BPF_H:
 +			EMIT(PPC_RAW_LHZ(dst_reg, src_reg, off));
 +			if (insn_is_zext(&insn[i + 1]))
 +				addrs[++i] = ctx->idx * 4;
 +			break;
 +		/* dst = *(u32 *)(ul) (src + off) */
 +		case BPF_LDX | BPF_MEM | BPF_W:
 +			EMIT(PPC_RAW_LWZ(dst_reg, src_reg, off));
 +			if (insn_is_zext(&insn[i + 1]))
 +				addrs[++i] = ctx->idx * 4;
 +			break;
 +		/* dst = *(u64 *)(ul) (src + off) */
 +		case BPF_LDX | BPF_MEM | BPF_DW:
 +			PPC_BPF_LL(dst_reg, src_reg, off);
++=======
+ 		case BPF_LDX | BPF_PROBE_MEM | BPF_B:
+ 		/* dst = *(u16 *)(ul) (src + off) */
+ 		case BPF_LDX | BPF_MEM | BPF_H:
+ 		case BPF_LDX | BPF_PROBE_MEM | BPF_H:
+ 		/* dst = *(u32 *)(ul) (src + off) */
+ 		case BPF_LDX | BPF_MEM | BPF_W:
+ 		case BPF_LDX | BPF_PROBE_MEM | BPF_W:
+ 		/* dst = *(u64 *)(ul) (src + off) */
+ 		case BPF_LDX | BPF_MEM | BPF_DW:
+ 		case BPF_LDX | BPF_PROBE_MEM | BPF_DW:
+ 			switch (size) {
+ 			case BPF_B:
+ 				EMIT(PPC_RAW_LBZ(dst_reg, src_reg, off));
+ 				break;
+ 			case BPF_H:
+ 				EMIT(PPC_RAW_LHZ(dst_reg, src_reg, off));
+ 				break;
+ 			case BPF_W:
+ 				EMIT(PPC_RAW_LWZ(dst_reg, src_reg, off));
+ 				break;
+ 			case BPF_DW:
+ 				PPC_BPF_LL(dst_reg, src_reg, off);
+ 				break;
+ 			}
+ 
+ 			if (size != BPF_DW && insn_is_zext(&insn[i + 1]))
+ 				addrs[++i] = ctx->idx * 4;
+ 
+ 			if (BPF_MODE(code) == BPF_PROBE_MEM) {
+ 				ret = bpf_add_extable_entry(fp, image, pass, ctx, ctx->idx - 1,
+ 							    4, dst_reg);
+ 				if (ret)
+ 					return ret;
+ 			}
++>>>>>>> 983bdc0245a2 (bpf ppc64: Add BPF_PROBE_MEM support for JIT)
  			break;
  
  		/*
* Unmerged path arch/powerpc/net/bpf_jit_comp32.c
* Unmerged path arch/powerpc/net/bpf_jit.h
* Unmerged path arch/powerpc/net/bpf_jit_comp.c
* Unmerged path arch/powerpc/net/bpf_jit_comp32.c
* Unmerged path arch/powerpc/net/bpf_jit_comp64.c
