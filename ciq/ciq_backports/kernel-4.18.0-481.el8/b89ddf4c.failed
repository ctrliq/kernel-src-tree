arm64/bpf: Remove 128MB limit for BPF JIT programs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Russell King <russell.king@oracle.com>
commit b89ddf4cca43f1269093942cf5c4e457fd45c335
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/b89ddf4c.failed

Commit 91fc957c9b1d ("arm64/bpf: don't allocate BPF JIT programs in module
memory") restricts BPF JIT program allocation to a 128MB region to ensure
BPF programs are still in branching range of each other. However this
restriction should not apply to the aarch64 JIT, since BPF_JMP | BPF_CALL
are implemented as a 64-bit move into a register and then a BLR instruction -
which has the effect of being able to call anything without proximity
limitation.

The practical reason to relax this restriction on JIT memory is that 128MB of
JIT memory can be quickly exhausted, especially where PAGE_SIZE is 64KB - one
page is needed per program. In cases where seccomp filters are applied to
multiple VMs on VM launch - such filters are classic BPF but converted to
BPF - this can severely limit the number of VMs that can be launched. In a
world where we support BPF JIT always on, turning off the JIT isn't always an
option either.

Fixes: 91fc957c9b1d ("arm64/bpf: don't allocate BPF JIT programs in module memory")
	Suggested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
	Signed-off-by: Russell King <russell.king@oracle.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Tested-by: Alan Maguire <alan.maguire@oracle.com>
Link: https://lore.kernel.org/bpf/1636131046-5982-2-git-send-email-alan.maguire@oracle.com
(cherry picked from commit b89ddf4cca43f1269093942cf5c4e457fd45c335)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/extable.h
#	arch/arm64/kernel/traps.c
diff --cc arch/arm64/include/asm/extable.h
index c5b899b4a700,72b0e71cc3de..000000000000
--- a/arch/arm64/include/asm/extable.h
+++ b/arch/arm64/include/asm/extable.h
@@@ -22,13 -23,23 +22,26 @@@ struct exception_table_entr
  
  #define ARCH_HAS_RELATIVE_EXTABLE
  
++<<<<<<< HEAD
++=======
+ #define swap_ex_entry_fixup(a, b, tmp, delta)		\
+ do {							\
+ 	(a)->fixup = (b)->fixup + (delta);		\
+ 	(b)->fixup = (tmp).fixup - (delta);		\
+ 	(a)->type = (b)->type;				\
+ 	(b)->type = (tmp).type;				\
+ 	(a)->data = (b)->data;				\
+ 	(b)->data = (tmp).data;				\
+ } while (0)
+ 
++>>>>>>> b89ddf4cca43 (arm64/bpf: Remove 128MB limit for BPF JIT programs)
  #ifdef CONFIG_BPF_JIT
 -bool ex_handler_bpf(const struct exception_table_entry *ex,
 -		    struct pt_regs *regs);
 +bool arm64_bpf_fixup_exception(const struct exception_table_entry *ex,
 +			      struct pt_regs *regs);
  #else /* !CONFIG_BPF_JIT */
  static inline
 -bool ex_handler_bpf(const struct exception_table_entry *ex,
 -		    struct pt_regs *regs)
 +bool arm64_bpf_fixup_exception(const struct exception_table_entry *ex,
 +			       struct pt_regs *regs)
  {
  	return false;
  }
diff --cc arch/arm64/kernel/traps.c
index ace19f467da4,e8986e6067a9..000000000000
--- a/arch/arm64/kernel/traps.c
+++ b/arch/arm64/kernel/traps.c
@@@ -1017,6 -991,21 +1017,24 @@@ static struct break_hook bug_break_hoo
  	.imm = BUG_BRK_IMM,
  };
  
++<<<<<<< HEAD
++=======
+ static int reserved_fault_handler(struct pt_regs *regs, unsigned int esr)
+ {
+ 	pr_err("%s generated an invalid instruction at %pS!\n",
+ 		"Kernel text patching",
+ 		(void *)instruction_pointer(regs));
+ 
+ 	/* We cannot handle this */
+ 	return DBG_HOOK_ERROR;
+ }
+ 
+ static struct break_hook fault_break_hook = {
+ 	.fn = reserved_fault_handler,
+ 	.imm = FAULT_BRK_IMM,
+ };
+ 
++>>>>>>> b89ddf4cca43 (arm64/bpf: Remove 128MB limit for BPF JIT programs)
  #ifdef CONFIG_KASAN_SW_TAGS
  
  #define KASAN_ESR_RECOVER	0x20
* Unmerged path arch/arm64/include/asm/extable.h
diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h
index e098ed9484b3..8110b51a089e 100644
--- a/arch/arm64/include/asm/memory.h
+++ b/arch/arm64/include/asm/memory.h
@@ -67,11 +67,8 @@
 #define _PAGE_OFFSET(va)	(-(UL(1) << (va)))
 #define PAGE_OFFSET		(_PAGE_OFFSET(VA_BITS))
 #define KIMAGE_VADDR		(MODULES_END)
-#define BPF_JIT_REGION_START	(_PAGE_END(VA_BITS_MIN))
-#define BPF_JIT_REGION_SIZE	(SZ_128M)
-#define BPF_JIT_REGION_END	(BPF_JIT_REGION_START + BPF_JIT_REGION_SIZE)
 #define MODULES_END		(MODULES_VADDR + MODULES_VSIZE)
-#define MODULES_VADDR		(BPF_JIT_REGION_END)
+#define MODULES_VADDR		(_PAGE_END(VA_BITS_MIN))
 #define MODULES_VSIZE		(SZ_128M)
 #define VMEMMAP_START		(-VMEMMAP_SIZE - SZ_2M)
 #define VMEMMAP_END		(VMEMMAP_START + VMEMMAP_SIZE)
* Unmerged path arch/arm64/kernel/traps.c
diff --git a/arch/arm64/net/bpf_jit_comp.c b/arch/arm64/net/bpf_jit_comp.c
index e7a68f01f8dc..5f952374e456 100644
--- a/arch/arm64/net/bpf_jit_comp.c
+++ b/arch/arm64/net/bpf_jit_comp.c
@@ -1151,15 +1151,12 @@ struct bpf_prog *bpf_int_jit_compile(struct bpf_prog *prog)
 
 u64 bpf_jit_alloc_exec_limit(void)
 {
-	return BPF_JIT_REGION_SIZE;
+	return VMALLOC_END - VMALLOC_START;
 }
 
 void *bpf_jit_alloc_exec(unsigned long size)
 {
-	return __vmalloc_node_range(size, PAGE_SIZE, BPF_JIT_REGION_START,
-				    BPF_JIT_REGION_END, GFP_KERNEL,
-				    PAGE_KERNEL, 0, NUMA_NO_NODE,
-				    __builtin_return_address(0));
+	return vmalloc(size);
 }
 
 void bpf_jit_free_exec(void *addr)
