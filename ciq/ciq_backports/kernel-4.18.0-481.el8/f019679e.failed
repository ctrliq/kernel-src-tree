net/mlx5: E-switch, Remove dependency between sriov and eswitch mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Chris Mi <cmi@nvidia.com>
commit f019679ea5f2ab650c3348a79e7d9c3625f62899
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/f019679e.failed

Currently, there are three eswitch modes, none, legacy and switchdev.
None is the default mode. Remove redundant none mode as eswitch mode
should always be either legacy mode or switchdev mode.

With this patch, there are two behavior changes:

1. Legacy becomes the default mode. When querying eswitch mode using
   devlink, a valid mode is always returned.
2. When disabling sriov, the eswitch mode will not change, only vfs
   are unloaded.

	Signed-off-by: Chris Mi <cmi@nvidia.com>
	Reviewed-by: Maor Dickman <maord@nvidia.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit f019679ea5f2ab650c3348a79e7d9c3625f62899)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 7af76810cb8f,82b62ab1d1d9..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1335,47 -1335,72 +1333,89 @@@ int mlx5_eswitch_enable(struct mlx5_esw
  	return ret;
  }
  
- void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw, bool clear_vf)
+ /* When disabling sriov, free driver level resources. */
+ void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw, bool clear_vf)
+ {
+ 	if (!mlx5_esw_allowed(esw))
+ 		return;
+ 
+ 	down_write(&esw->mode_lock);
+ 	/* If driver is unloaded, this function is called twice by remove_one()
+ 	 * and mlx5_unload(). Prevent the second call.
+ 	 */
+ 	if (!esw->esw_funcs.num_vfs && !clear_vf)
+ 		goto unlock;
+ 
+ 	esw_info(esw->dev, "Unload vfs: mode(%s), nvfs(%d), active vports(%d)\n",
+ 		 esw->mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
+ 		 esw->esw_funcs.num_vfs, esw->enabled_vports);
+ 
+ 	mlx5_eswitch_unload_vf_vports(esw, esw->esw_funcs.num_vfs);
+ 	if (clear_vf)
+ 		mlx5_eswitch_clear_vf_vports_info(esw);
+ 	/* If disabling sriov in switchdev mode, free meta rules here
+ 	 * because it depends on num_vfs.
+ 	 */
+ 	if (esw->mode == MLX5_ESWITCH_OFFLOADS) {
+ 		struct devlink *devlink = priv_to_devlink(esw->dev);
+ 
+ 		esw_offloads_del_send_to_vport_meta_rules(esw);
+ 		devlink_rate_nodes_destroy(devlink);
+ 	}
+ 
+ 	esw->esw_funcs.num_vfs = 0;
+ 
+ unlock:
+ 	up_write(&esw->mode_lock);
+ }
+ 
+ /* Free resources for corresponding eswitch mode. It is called by devlink
+  * when changing eswitch mode or modprobe when unloading driver.
+  */
+ void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw)
  {
  	struct devlink *devlink = priv_to_devlink(esw->dev);
- 	int old_mode;
  
++<<<<<<< HEAD
 +	lockdep_assert_held_exclusive(&esw->mode_lock);
++=======
+ 	/* Notify eswitch users that it is exiting from current mode.
+ 	 * So that it can do necessary cleanup before the eswitch is disabled.
+ 	 */
+ 	mlx5_esw_mode_change_notify(esw, MLX5_ESWITCH_LEGACY);
++>>>>>>> f019679ea5f2 (net/mlx5: E-switch, Remove dependency between sriov and eswitch mode)
  
- 	if (esw->mode == MLX5_ESWITCH_NONE)
- 		return;
+ 	mlx5_eswitch_event_handlers_unregister(esw);
  
  	esw_info(esw->dev, "Disable: mode(%s), nvfs(%d), active vports(%d)\n",
  		 esw->mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
  		 esw->esw_funcs.num_vfs, esw->enabled_vports);
  
++<<<<<<< HEAD
 +	/* Notify eswitch users that it is exiting from current mode.
 +	 * So that it can do necessary cleanup before the eswitch is disabled.
 +	 */
 +	mlx5_esw_mode_change_notify(esw, MLX5_ESWITCH_NONE);
 +
 +	mlx5_eswitch_event_handlers_unregister(esw);
 +
 +	if (esw->mode == MLX5_ESWITCH_LEGACY)
 +		esw_legacy_disable(esw);
 +	else if (esw->mode == MLX5_ESWITCH_OFFLOADS)
++=======
+ 	esw->fdb_table.flags &= ~MLX5_ESW_FDB_CREATED;
+ 	if (esw->mode == MLX5_ESWITCH_OFFLOADS)
++>>>>>>> f019679ea5f2 (net/mlx5: E-switch, Remove dependency between sriov and eswitch mode)
  		esw_offloads_disable(esw);
- 
- 	old_mode = esw->mode;
- 	esw->mode = MLX5_ESWITCH_NONE;
- 
- 	if (old_mode == MLX5_ESWITCH_OFFLOADS)
- 		mlx5_rescan_drivers(esw->dev);
- 
- 	devlink_rate_nodes_destroy(devlink);
- 
+ 	else if (esw->mode == MLX5_ESWITCH_LEGACY)
+ 		esw_legacy_disable(esw);
  	mlx5_esw_acls_ns_cleanup(esw);
  
- 	if (clear_vf)
- 		mlx5_eswitch_clear_vf_vports_info(esw);
+ 	if (esw->mode == MLX5_ESWITCH_OFFLOADS)
+ 		devlink_rate_nodes_destroy(devlink);
  }
  
- void mlx5_eswitch_disable(struct mlx5_eswitch *esw, bool clear_vf)
+ void mlx5_eswitch_disable(struct mlx5_eswitch *esw)
  {
  	if (!mlx5_esw_allowed(esw))
  		return;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index aaa5e6840908,7c51011aed2b..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -2025,6 -2033,44 +2034,47 @@@ out
  	return flow_rule;
  }
  
++<<<<<<< HEAD
++=======
+ static int mlx5_eswitch_inline_mode_get(struct mlx5_eswitch *esw, u8 *mode)
+ {
+ 	u8 prev_mlx5_mode, mlx5_mode = MLX5_INLINE_MODE_L2;
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	struct mlx5_vport *vport;
+ 	unsigned long i;
+ 
+ 	if (!MLX5_CAP_GEN(dev, vport_group_manager))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (!mlx5_esw_is_fdb_created(esw))
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (MLX5_CAP_ETH(dev, wqe_inline_mode)) {
+ 	case MLX5_CAP_INLINE_MODE_NOT_REQUIRED:
+ 		mlx5_mode = MLX5_INLINE_MODE_NONE;
+ 		goto out;
+ 	case MLX5_CAP_INLINE_MODE_L2:
+ 		mlx5_mode = MLX5_INLINE_MODE_L2;
+ 		goto out;
+ 	case MLX5_CAP_INLINE_MODE_VPORT_CONTEXT:
+ 		goto query_vports;
+ 	}
+ 
+ query_vports:
+ 	mlx5_query_nic_vport_min_inline(dev, esw->first_host_vport, &prev_mlx5_mode);
+ 	mlx5_esw_for_each_host_func_vport(esw, i, vport, esw->esw_funcs.num_vfs) {
+ 		mlx5_query_nic_vport_min_inline(dev, vport->vport, &mlx5_mode);
+ 		if (prev_mlx5_mode != mlx5_mode)
+ 			return -EINVAL;
+ 		prev_mlx5_mode = mlx5_mode;
+ 	}
+ 
+ out:
+ 	*mode = mlx5_mode;
+ 	return 0;
+ }
+ 
++>>>>>>> f019679ea5f2 (net/mlx5: E-switch, Remove dependency between sriov and eswitch mode)
  static void esw_destroy_restore_table(struct mlx5_eswitch *esw)
  {
  	struct mlx5_esw_offload *offloads = &esw->offloads;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 7682abe70a34..326aa30c69b8 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -338,6 +338,7 @@ void esw_offloads_disable(struct mlx5_eswitch *esw);
 int esw_offloads_enable(struct mlx5_eswitch *esw);
 void esw_offloads_cleanup_reps(struct mlx5_eswitch *esw);
 int esw_offloads_init_reps(struct mlx5_eswitch *esw);
+void esw_offloads_del_send_to_vport_meta_rules(struct mlx5_eswitch *esw);
 
 bool mlx5_esw_vport_match_metadata_supported(const struct mlx5_eswitch *esw);
 int mlx5_esw_offloads_vport_metadata_set(struct mlx5_eswitch *esw, bool enable);
@@ -353,8 +354,9 @@ void mlx5_eswitch_cleanup(struct mlx5_eswitch *esw);
 #define MLX5_ESWITCH_IGNORE_NUM_VFS (-1)
 int mlx5_eswitch_enable_locked(struct mlx5_eswitch *esw, int mode, int num_vfs);
 int mlx5_eswitch_enable(struct mlx5_eswitch *esw, int num_vfs);
-void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw, bool clear_vf);
-void mlx5_eswitch_disable(struct mlx5_eswitch *esw, bool clear_vf);
+void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw, bool clear_vf);
+void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw);
+void mlx5_eswitch_disable(struct mlx5_eswitch *esw);
 int mlx5_eswitch_set_vport_mac(struct mlx5_eswitch *esw,
 			       u16 vport, const u8 *mac);
 int mlx5_eswitch_set_vport_state(struct mlx5_eswitch *esw,
@@ -720,7 +722,8 @@ int mlx5_eswitch_reload_reps(struct mlx5_eswitch *esw);
 static inline int  mlx5_eswitch_init(struct mlx5_core_dev *dev) { return 0; }
 static inline void mlx5_eswitch_cleanup(struct mlx5_eswitch *esw) {}
 static inline int mlx5_eswitch_enable(struct mlx5_eswitch *esw, int num_vfs) { return 0; }
-static inline void mlx5_eswitch_disable(struct mlx5_eswitch *esw, bool clear_vf) {}
+static inline void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw, bool clear_vf) {}
+static inline void mlx5_eswitch_disable(struct mlx5_eswitch *esw) {}
 static inline bool mlx5_eswitch_is_funcs_handler(struct mlx5_core_dev *dev) { return false; }
 static inline
 int mlx5_eswitch_set_vport_state(struct mlx5_eswitch *esw, u16 vport, int link_state) { return 0; }
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c b/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c
index 5d41e19378e0..0f34e3c80d1f 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c
@@ -638,6 +638,7 @@ static int mlx5_deactivate_lag(struct mlx5_lag *ldev)
 static bool mlx5_lag_check_prereq(struct mlx5_lag *ldev)
 {
 #ifdef CONFIG_MLX5_ESWITCH
+	struct mlx5_core_dev *dev;
 	u8 mode;
 #endif
 	int i;
@@ -647,11 +648,11 @@ static bool mlx5_lag_check_prereq(struct mlx5_lag *ldev)
 			return false;
 
 #ifdef CONFIG_MLX5_ESWITCH
-	mode = mlx5_eswitch_mode(ldev->pf[MLX5_LAG_P1].dev);
-
-	if (mode != MLX5_ESWITCH_NONE && mode != MLX5_ESWITCH_OFFLOADS)
+	dev = ldev->pf[MLX5_LAG_P1].dev;
+	if ((mlx5_sriov_is_enabled(dev)) && !is_mdev_switchdev_mode(dev))
 		return false;
 
+	mode = mlx5_eswitch_mode(dev);
 	for (i = 0; i < ldev->ports; i++)
 		if (mlx5_eswitch_mode(ldev->pf[i].dev) != mode)
 			return false;
@@ -766,8 +767,7 @@ static bool mlx5_lag_is_roce_lag(struct mlx5_lag *ldev)
 
 #ifdef CONFIG_MLX5_ESWITCH
 	for (i = 0; i < ldev->ports; i++)
-		roce_lag = roce_lag &&
-			ldev->pf[i].dev->priv.eswitch->mode == MLX5_ESWITCH_NONE;
+		roce_lag = roce_lag && is_mdev_legacy_mode(ldev->pf[i].dev);
 #endif
 
 	return roce_lag;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/main.c b/drivers/net/ethernet/mellanox/mlx5/core/main.c
index a854fd572bf8..7abf89b61009 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@ -1271,6 +1271,7 @@ static void mlx5_unload(struct mlx5_core_dev *dev)
 {
 	mlx5_sf_dev_table_destroy(dev);
 	mlx5_sriov_detach(dev);
+	mlx5_eswitch_disable(dev->priv.eswitch);
 	mlx5_lag_remove_mdev(dev);
 	mlx5_ec_cleanup(dev);
 	mlx5_sf_hw_table_destroy(dev);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/sf/devlink.c b/drivers/net/ethernet/mellanox/mlx5/core/sf/devlink.c
index 3be659cd91f1..7d955a4d9f14 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/sf/devlink.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/sf/devlink.c
@@ -501,7 +501,7 @@ static int mlx5_sf_esw_event(struct notifier_block *nb, unsigned long event, voi
 	case MLX5_ESWITCH_OFFLOADS:
 		mlx5_sf_table_enable(table);
 		break;
-	case MLX5_ESWITCH_NONE:
+	case MLX5_ESWITCH_LEGACY:
 		mlx5_sf_table_disable(table);
 		break;
 	default:
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/sriov.c b/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
index 2935614f6fa9..5757cd6e1819 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
@@ -145,8 +145,7 @@ mlx5_device_disable_sriov(struct mlx5_core_dev *dev, int num_vfs, bool clear_vf)
 		sriov->vfs_ctx[vf].enabled = 0;
 	}
 
-	if (MLX5_ESWITCH_MANAGER(dev))
-		mlx5_eswitch_disable(dev->priv.eswitch, clear_vf);
+	mlx5_eswitch_disable_sriov(dev->priv.eswitch, clear_vf);
 
 	if (mlx5_wait_for_pages(dev, &dev->priv.vfs_pages))
 		mlx5_core_warn(dev, "timeout reclaiming VFs pages\n");
diff --git a/include/linux/mlx5/eswitch.h b/include/linux/mlx5/eswitch.h
index 8b18fe9771f9..e2701ed0200e 100644
--- a/include/linux/mlx5/eswitch.h
+++ b/include/linux/mlx5/eswitch.h
@@ -12,7 +12,6 @@
 #define MLX5_ESWITCH_MANAGER(mdev) MLX5_CAP_GEN(mdev, eswitch_manager)
 
 enum {
-	MLX5_ESWITCH_NONE,
 	MLX5_ESWITCH_LEGACY,
 	MLX5_ESWITCH_OFFLOADS
 };
@@ -153,7 +152,7 @@ struct mlx5_core_dev *mlx5_eswitch_get_core_dev(struct mlx5_eswitch *esw);
 
 static inline u8 mlx5_eswitch_mode(const struct mlx5_core_dev *dev)
 {
-	return MLX5_ESWITCH_NONE;
+	return MLX5_ESWITCH_LEGACY;
 }
 
 static inline enum devlink_eswitch_encap_mode
@@ -198,6 +197,11 @@ static inline struct mlx5_core_dev *mlx5_eswitch_get_core_dev(struct mlx5_eswitc
 
 #endif /* CONFIG_MLX5_ESWITCH */
 
+static inline bool is_mdev_legacy_mode(struct mlx5_core_dev *dev)
+{
+	return mlx5_eswitch_mode(dev) == MLX5_ESWITCH_LEGACY;
+}
+
 static inline bool is_mdev_switchdev_mode(struct mlx5_core_dev *dev)
 {
 	return mlx5_eswitch_mode(dev) == MLX5_ESWITCH_OFFLOADS;
