x86/sev: Provide support for SNP guest request NAEs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Brijesh Singh <brijesh.singh@amd.com>
commit d5af44dde5461d125d1602ac913ab5c6bdf09b8b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/d5af44dd.failed

Version 2 of GHCB specification provides SNP_GUEST_REQUEST and
SNP_EXT_GUEST_REQUEST NAE that can be used by the SNP guest to
communicate with the PSP.

While at it, add a snp_issue_guest_request() helper that will be used by
driver or other subsystem to issue the request to PSP.

See SEV-SNP firmware and GHCB spec for more details.

	Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lore.kernel.org/r/20220307213356.2797205-42-brijesh.singh@amd.com
(cherry picked from commit d5af44dde5461d125d1602ac913ab5c6bdf09b8b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/sev.h
#	arch/x86/include/uapi/asm/svm.h
#	arch/x86/kernel/sev.c
diff --cc arch/x86/include/asm/sev.h
index 904ff9242b92,c63a1d485c20..000000000000
--- a/arch/x86/include/asm/sev.h
+++ b/arch/x86/include/asm/sev.h
@@@ -81,6 -82,19 +81,22 @@@ extern bool handle_vc_boot_ghcb(struct 
  /* Software defined (when rFlags.CF = 1) */
  #define PVALIDATE_FAIL_NOUPDATE		255
  
++<<<<<<< HEAD
++=======
+ /* RMP page size */
+ #define RMP_PG_SIZE_4K			0
+ 
+ #define RMPADJUST_VMSA_PAGE_BIT		BIT(16)
+ 
+ /* SNP Guest message request */
+ struct snp_req_data {
+ 	unsigned long req_gpa;
+ 	unsigned long resp_gpa;
+ 	unsigned long data_gpa;
+ 	unsigned int data_npages;
+ };
+ 
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
  #ifdef CONFIG_AMD_MEM_ENCRYPT
  extern struct static_key_false sev_es_enable_key;
  extern void __sev_es_ist_enter(struct pt_regs *regs);
@@@ -125,6 -151,18 +141,21 @@@ static inline int pvalidate(unsigned lo
  
  	return rc;
  }
++<<<<<<< HEAD
++=======
+ void setup_ghcb(void);
+ void __init early_snp_set_memory_private(unsigned long vaddr, unsigned long paddr,
+ 					 unsigned int npages);
+ void __init early_snp_set_memory_shared(unsigned long vaddr, unsigned long paddr,
+ 					unsigned int npages);
+ void __init snp_prep_memory(unsigned long paddr, unsigned int sz, enum psc_op op);
+ void snp_set_memory_shared(unsigned long vaddr, unsigned int npages);
+ void snp_set_memory_private(unsigned long vaddr, unsigned int npages);
+ void snp_set_wakeup_secondary_cpu(void);
+ bool snp_init(struct boot_params *bp);
+ void snp_abort(void);
+ int snp_issue_guest_request(u64 exit_code, struct snp_req_data *input, unsigned long *fw_err);
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
  #else
  static inline void sev_es_ist_enter(struct pt_regs *regs) { }
  static inline void sev_es_ist_exit(void) { }
@@@ -132,6 -170,23 +163,26 @@@ static inline int sev_es_setup_ap_jump_
  static inline void sev_es_nmi_complete(void) { }
  static inline int sev_es_efi_map_ghcbs(pgd_t *pgd) { return 0; }
  static inline int pvalidate(unsigned long vaddr, bool rmp_psize, bool validate) { return 0; }
++<<<<<<< HEAD
++=======
+ static inline int rmpadjust(unsigned long vaddr, bool rmp_psize, unsigned long attrs) { return 0; }
+ static inline void setup_ghcb(void) { }
+ static inline void __init
+ early_snp_set_memory_private(unsigned long vaddr, unsigned long paddr, unsigned int npages) { }
+ static inline void __init
+ early_snp_set_memory_shared(unsigned long vaddr, unsigned long paddr, unsigned int npages) { }
+ static inline void __init snp_prep_memory(unsigned long paddr, unsigned int sz, enum psc_op op) { }
+ static inline void snp_set_memory_shared(unsigned long vaddr, unsigned int npages) { }
+ static inline void snp_set_memory_private(unsigned long vaddr, unsigned int npages) { }
+ static inline void snp_set_wakeup_secondary_cpu(void) { }
+ static inline bool snp_init(struct boot_params *bp) { return false; }
+ static inline void snp_abort(void) { }
+ static inline int snp_issue_guest_request(u64 exit_code, struct snp_req_data *input,
+ 					  unsigned long *fw_err)
+ {
+ 	return -ENOTTY;
+ }
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
  #endif
  
  #endif
diff --cc arch/x86/include/uapi/asm/svm.h
index efa969325ede,f69c168391aa..000000000000
--- a/arch/x86/include/uapi/asm/svm.h
+++ b/arch/x86/include/uapi/asm/svm.h
@@@ -108,6 -108,14 +108,17 @@@
  #define SVM_VMGEXIT_AP_JUMP_TABLE		0x80000005
  #define SVM_VMGEXIT_SET_AP_JUMP_TABLE		0
  #define SVM_VMGEXIT_GET_AP_JUMP_TABLE		1
++<<<<<<< HEAD
++=======
+ #define SVM_VMGEXIT_PSC				0x80000010
+ #define SVM_VMGEXIT_GUEST_REQUEST		0x80000011
+ #define SVM_VMGEXIT_EXT_GUEST_REQUEST		0x80000012
+ #define SVM_VMGEXIT_AP_CREATION			0x80000013
+ #define SVM_VMGEXIT_AP_CREATE_ON_INIT		0
+ #define SVM_VMGEXIT_AP_CREATE			1
+ #define SVM_VMGEXIT_AP_DESTROY			2
+ #define SVM_VMGEXIT_HV_FEATURES			0x8000fffd
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
  #define SVM_VMGEXIT_UNSUPPORTED_EVENT		0x8000ffff
  
  /* Exit code reserved for hypervisor/software use */
@@@ -218,6 -226,11 +229,14 @@@
  	{ SVM_VMGEXIT_NMI_COMPLETE,	"vmgexit_nmi_complete" }, \
  	{ SVM_VMGEXIT_AP_HLT_LOOP,	"vmgexit_ap_hlt_loop" }, \
  	{ SVM_VMGEXIT_AP_JUMP_TABLE,	"vmgexit_ap_jump_table" }, \
++<<<<<<< HEAD
++=======
+ 	{ SVM_VMGEXIT_PSC,		"vmgexit_page_state_change" }, \
+ 	{ SVM_VMGEXIT_GUEST_REQUEST,	"vmgexit_guest_request" }, \
+ 	{ SVM_VMGEXIT_EXT_GUEST_REQUEST, "vmgexit_ext_guest_request" }, \
+ 	{ SVM_VMGEXIT_AP_CREATION,	"vmgexit_ap_creation" }, \
+ 	{ SVM_VMGEXIT_HV_FEATURES,	"vmgexit_hypervisor_feature" }, \
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
  	{ SVM_EXIT_ERR,         "invalid_guest_state" }
  
  
diff --cc arch/x86/kernel/sev.c
index 9f3a4a57b1e6,7237b4178935..000000000000
--- a/arch/x86/kernel/sev.c
+++ b/arch/x86/kernel/sev.c
@@@ -1492,3 -1982,184 +1492,187 @@@ fail
  	while (true)
  		halt();
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * Initial set up of SNP relies on information provided by the
+  * Confidential Computing blob, which can be passed to the kernel
+  * in the following ways, depending on how it is booted:
+  *
+  * - when booted via the boot/decompress kernel:
+  *   - via boot_params
+  *
+  * - when booted directly by firmware/bootloader (e.g. CONFIG_PVH):
+  *   - via a setup_data entry, as defined by the Linux Boot Protocol
+  *
+  * Scan for the blob in that order.
+  */
+ static __init struct cc_blob_sev_info *find_cc_blob(struct boot_params *bp)
+ {
+ 	struct cc_blob_sev_info *cc_info;
+ 
+ 	/* Boot kernel would have passed the CC blob via boot_params. */
+ 	if (bp->cc_blob_address) {
+ 		cc_info = (struct cc_blob_sev_info *)(unsigned long)bp->cc_blob_address;
+ 		goto found_cc_info;
+ 	}
+ 
+ 	/*
+ 	 * If kernel was booted directly, without the use of the
+ 	 * boot/decompression kernel, the CC blob may have been passed via
+ 	 * setup_data instead.
+ 	 */
+ 	cc_info = find_cc_blob_setup_data(bp);
+ 	if (!cc_info)
+ 		return NULL;
+ 
+ found_cc_info:
+ 	if (cc_info->magic != CC_BLOB_SEV_HDR_MAGIC)
+ 		snp_abort();
+ 
+ 	return cc_info;
+ }
+ 
+ bool __init snp_init(struct boot_params *bp)
+ {
+ 	struct cc_blob_sev_info *cc_info;
+ 
+ 	if (!bp)
+ 		return false;
+ 
+ 	cc_info = find_cc_blob(bp);
+ 	if (!cc_info)
+ 		return false;
+ 
+ 	setup_cpuid_table(cc_info);
+ 
+ 	/*
+ 	 * The CC blob will be used later to access the secrets page. Cache
+ 	 * it here like the boot kernel does.
+ 	 */
+ 	bp->cc_blob_address = (u32)(unsigned long)cc_info;
+ 
+ 	return true;
+ }
+ 
+ void __init snp_abort(void)
+ {
+ 	sev_es_terminate(SEV_TERM_SET_GEN, GHCB_SNP_UNSUPPORTED);
+ }
+ 
+ static void dump_cpuid_table(void)
+ {
+ 	const struct snp_cpuid_table *cpuid_table = snp_cpuid_get_table();
+ 	int i = 0;
+ 
+ 	pr_info("count=%d reserved=0x%x reserved2=0x%llx\n",
+ 		cpuid_table->count, cpuid_table->__reserved1, cpuid_table->__reserved2);
+ 
+ 	for (i = 0; i < SNP_CPUID_COUNT_MAX; i++) {
+ 		const struct snp_cpuid_fn *fn = &cpuid_table->fn[i];
+ 
+ 		pr_info("index=%3d fn=0x%08x subfn=0x%08x: eax=0x%08x ebx=0x%08x ecx=0x%08x edx=0x%08x xcr0_in=0x%016llx xss_in=0x%016llx reserved=0x%016llx\n",
+ 			i, fn->eax_in, fn->ecx_in, fn->eax, fn->ebx, fn->ecx,
+ 			fn->edx, fn->xcr0_in, fn->xss_in, fn->__reserved);
+ 	}
+ }
+ 
+ /*
+  * It is useful from an auditing/testing perspective to provide an easy way
+  * for the guest owner to know that the CPUID table has been initialized as
+  * expected, but that initialization happens too early in boot to print any
+  * sort of indicator, and there's not really any other good place to do it,
+  * so do it here.
+  */
+ static int __init report_cpuid_table(void)
+ {
+ 	const struct snp_cpuid_table *cpuid_table = snp_cpuid_get_table();
+ 
+ 	if (!cpuid_table->count)
+ 		return 0;
+ 
+ 	pr_info("Using SNP CPUID table, %d entries present.\n",
+ 		cpuid_table->count);
+ 
+ 	if (sev_cfg.debug)
+ 		dump_cpuid_table();
+ 
+ 	return 0;
+ }
+ arch_initcall(report_cpuid_table);
+ 
+ static int __init init_sev_config(char *str)
+ {
+ 	char *s;
+ 
+ 	while ((s = strsep(&str, ","))) {
+ 		if (!strcmp(s, "debug")) {
+ 			sev_cfg.debug = true;
+ 			continue;
+ 		}
+ 
+ 		pr_info("SEV command-line option '%s' was not recognized\n", s);
+ 	}
+ 
+ 	return 1;
+ }
+ __setup("sev=", init_sev_config);
+ 
+ int snp_issue_guest_request(u64 exit_code, struct snp_req_data *input, unsigned long *fw_err)
+ {
+ 	struct ghcb_state state;
+ 	struct es_em_ctxt ctxt;
+ 	unsigned long flags;
+ 	struct ghcb *ghcb;
+ 	int ret;
+ 
+ 	if (!cc_platform_has(CC_ATTR_GUEST_SEV_SNP))
+ 		return -ENODEV;
+ 
+ 	if (!fw_err)
+ 		return -EINVAL;
+ 
+ 	/*
+ 	 * __sev_get_ghcb() needs to run with IRQs disabled because it is using
+ 	 * a per-CPU GHCB.
+ 	 */
+ 	local_irq_save(flags);
+ 
+ 	ghcb = __sev_get_ghcb(&state);
+ 	if (!ghcb) {
+ 		ret = -EIO;
+ 		goto e_restore_irq;
+ 	}
+ 
+ 	vc_ghcb_invalidate(ghcb);
+ 
+ 	if (exit_code == SVM_VMGEXIT_EXT_GUEST_REQUEST) {
+ 		ghcb_set_rax(ghcb, input->data_gpa);
+ 		ghcb_set_rbx(ghcb, input->data_npages);
+ 	}
+ 
+ 	ret = sev_es_ghcb_hv_call(ghcb, true, &ctxt, exit_code, input->req_gpa, input->resp_gpa);
+ 	if (ret)
+ 		goto e_put;
+ 
+ 	if (ghcb->save.sw_exit_info_2) {
+ 		/* Number of expected pages are returned in RBX */
+ 		if (exit_code == SVM_VMGEXIT_EXT_GUEST_REQUEST &&
+ 		    ghcb->save.sw_exit_info_2 == SNP_GUEST_REQ_INVALID_LEN)
+ 			input->data_npages = ghcb_get_rbx(ghcb);
+ 
+ 		*fw_err = ghcb->save.sw_exit_info_2;
+ 
+ 		ret = -EIO;
+ 	}
+ 
+ e_put:
+ 	__sev_put_ghcb(&state);
+ e_restore_irq:
+ 	local_irq_restore(flags);
+ 
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(snp_issue_guest_request);
++>>>>>>> d5af44dde546 (x86/sev: Provide support for SNP guest request NAEs)
diff --git a/arch/x86/include/asm/sev-common.h b/arch/x86/include/asm/sev-common.h
index 94f0ea574049..d7baa0f2ac28 100644
--- a/arch/x86/include/asm/sev-common.h
+++ b/arch/x86/include/asm/sev-common.h
@@ -61,6 +61,9 @@
 #define GHCB_MSR_HV_FT_REQ		0x080
 #define GHCB_MSR_HV_FT_RESP		0x081
 
+/* Guest message request error code */
+#define SNP_GUEST_REQ_INVALID_LEN	BIT_ULL(32)
+
 #define GHCB_MSR_TERM_REQ		0x100
 #define GHCB_MSR_TERM_REASON_SET_POS	12
 #define GHCB_MSR_TERM_REASON_SET_MASK	0xf
* Unmerged path arch/x86/include/asm/sev.h
* Unmerged path arch/x86/include/uapi/asm/svm.h
* Unmerged path arch/x86/kernel/sev.c
