x86/compressed/64: Detect/setup SEV/SME features earlier during boot

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Michael Roth <michael.roth@amd.com>
commit ec1c66af3a30d45c2420da0974c01d3515dba26e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/ec1c66af.failed

With upcoming SEV-SNP support, SEV-related features need to be
initialized earlier during boot, at the same point the initial #VC
handler is set up, so that the SEV-SNP CPUID table can be utilized
during the initial feature checks. Also, SEV-SNP feature detection
will rely on EFI helper functions to scan the EFI config table for the
Confidential Computing blob, and so would need to be implemented at
least partially in C.

Currently set_sev_encryption_mask() is used to initialize the
sev_status and sme_me_mask globals that advertise what SEV/SME features
are available in a guest. Rename it to sev_enable() to better reflect
that (SME is only enabled in the case of SEV guests in the
boot/compressed kernel), and move it to just after the stage1 #VC
handler is set up so that it can be used to initialize SEV-SNP as well
in future patches.

While at it, re-implement it as C code so that all SEV feature
detection can be better consolidated with upcoming SEV-SNP feature
detection, which will also be in C.

The 32-bit entry path remains unchanged, as it never relied on the
set_sev_encryption_mask() initialization to begin with.

  [ bp: Massage commit message. ]

	Signed-off-by: Michael Roth <michael.roth@amd.com>
	Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lore.kernel.org/r/20220307213356.2797205-8-brijesh.singh@amd.com
(cherry picked from commit ec1c66af3a30d45c2420da0974c01d3515dba26e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/boot/compressed/head_64.S
#	arch/x86/boot/compressed/mem_encrypt.S
diff --cc arch/x86/boot/compressed/head_64.S
index f7943d0ad386,4cd661165d4a..000000000000
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@@ -143,10 -188,19 +143,21 @@@ SYM_FUNC_START(startup_32
  	jz	1f
  	subl	$32, %eax	/* Encryption bit is always above bit 31 */
  	bts	%eax, %edx	/* Set encryption mask for page tables */
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * Set MSR_AMD64_SEV_ENABLED_BIT in sev_status so that
+ 	 * startup32_check_sev_cbit() will do a check. sev_enable() will
+ 	 * initialize sev_status with all the bits reported by
+ 	 * MSR_AMD_SEV_STATUS later, but only MSR_AMD64_SEV_ENABLED_BIT
+ 	 * needs to be set for now.
+ 	 */
+ 	movl	$1, rva(sev_status)(%ebp)
++>>>>>>> ec1c66af3a30 (x86/compressed/64: Detect/setup SEV/SME features earlier during boot)
  1:
 -#endif
  
  	/* Initialize Page tables to 0 */
 -	leal	rva(pgtable)(%ebx), %edi
 +	leal	pgtable(%ebx), %edi
  	xorl	%eax, %eax
  	movl	$(BOOT_INIT_PGT_SIZE/4), %ecx
  	rep	stosl
diff --cc arch/x86/boot/compressed/mem_encrypt.S
index 717a7416ccd2,a73e4d783cae..000000000000
--- a/arch/x86/boot/compressed/mem_encrypt.S
+++ b/arch/x86/boot/compressed/mem_encrypt.S
@@@ -61,49 -58,135 +61,52 @@@ SYM_FUNC_START(get_sev_encryption_bit
  
  #endif	/* CONFIG_AMD_MEM_ENCRYPT */
  
 -	RET
 +	ret
  SYM_FUNC_END(get_sev_encryption_bit)
  
 -/**
 - * sev_es_req_cpuid - Request a CPUID value from the Hypervisor using
 - *		      the GHCB MSR protocol
 - *
 - * @%eax:	Register to request (0=EAX, 1=EBX, 2=ECX, 3=EDX)
 - * @%edx:	CPUID Function
 - *
 - * Returns 0 in %eax on success, non-zero on failure
 - * %edx returns CPUID value on success
 - */
 -SYM_CODE_START_LOCAL(sev_es_req_cpuid)
 -	shll	$30, %eax
 -	orl     $0x00000004, %eax
 -	movl    $MSR_AMD64_SEV_ES_GHCB, %ecx
 -	wrmsr
 -	rep; vmmcall		# VMGEXIT
 -	rdmsr
 +	.code64
 +
 +#include "../../kernel/sev_verify_cbit.S"
++<<<<<<< HEAD
 +
 +SYM_FUNC_START(set_sev_encryption_mask)
 +#ifdef CONFIG_AMD_MEM_ENCRYPT
 +	push	%rbp
 +	push	%rdx
 +
 +	movq	%rsp, %rbp		/* Save current stack pointer */
 +
 +	call	get_sev_encryption_bit	/* Get the encryption bit position */
 +	testl	%eax, %eax
 +	jz	.Lno_sev_mask
  
 -	/* Check response */
 -	movl	%eax, %ecx
 -	andl	$0x3ffff000, %ecx	# Bits [12-29] MBZ
 -	jnz	2f
 -
 -	/* Check return code */
 -	andl    $0xfff, %eax
 -	cmpl    $5, %eax
 -	jne	2f
 -
 -	/* All good - return success */
 -	xorl	%eax, %eax
 -1:
 -	RET
 -2:
 -	movl	$-1, %eax
 -	jmp	1b
 -SYM_CODE_END(sev_es_req_cpuid)
 -
 -SYM_CODE_START(startup32_vc_handler)
 -	pushl	%eax
 -	pushl	%ebx
 -	pushl	%ecx
 -	pushl	%edx
 -
 -	/* Keep CPUID function in %ebx */
 -	movl	%eax, %ebx
 -
 -	/* Check if error-code == SVM_EXIT_CPUID */
 -	cmpl	$0x72, 16(%esp)
 -	jne	.Lfail
 -
 -	movl	$0, %eax		# Request CPUID[fn].EAX
 -	movl	%ebx, %edx		# CPUID fn
 -	call	sev_es_req_cpuid	# Call helper
 -	testl	%eax, %eax		# Check return code
 -	jnz	.Lfail
 -	movl	%edx, 12(%esp)		# Store result
 -
 -	movl	$1, %eax		# Request CPUID[fn].EBX
 -	movl	%ebx, %edx		# CPUID fn
 -	call	sev_es_req_cpuid	# Call helper
 -	testl	%eax, %eax		# Check return code
 -	jnz	.Lfail
 -	movl	%edx, 8(%esp)		# Store result
 -
 -	movl	$2, %eax		# Request CPUID[fn].ECX
 -	movl	%ebx, %edx		# CPUID fn
 -	call	sev_es_req_cpuid	# Call helper
 -	testl	%eax, %eax		# Check return code
 -	jnz	.Lfail
 -	movl	%edx, 4(%esp)		# Store result
 -
 -	movl	$3, %eax		# Request CPUID[fn].EDX
 -	movl	%ebx, %edx		# CPUID fn
 -	call	sev_es_req_cpuid	# Call helper
 -	testl	%eax, %eax		# Check return code
 -	jnz	.Lfail
 -	movl	%edx, 0(%esp)		# Store result
 +	bts	%rax, sme_me_mask(%rip)	/* Create the encryption mask */
  
  	/*
 -	 * Sanity check CPUID results from the Hypervisor. See comment in
 -	 * do_vc_no_ghcb() for more details on why this is necessary.
 +	 * Read MSR_AMD64_SEV again and store it to sev_status. Can't do this in
 +	 * get_sev_encryption_bit() because this function is 32-bit code and
 +	 * shared between 64-bit and 32-bit boot path.
  	 */
 +	movl	$MSR_AMD64_SEV, %ecx	/* Read the SEV MSR */
 +	rdmsr
  
 -	/* Fail if SEV leaf not available in CPUID[0x80000000].EAX */
 -	cmpl    $0x80000000, %ebx
 -	jne     .Lcheck_sev
 -	cmpl    $0x8000001f, 12(%esp)
 -	jb      .Lfail
 -	jmp     .Ldone
 -
 -.Lcheck_sev:
 -	/* Fail if SEV bit not set in CPUID[0x8000001f].EAX[1] */
 -	cmpl    $0x8000001f, %ebx
 -	jne     .Ldone
 -	btl     $1, 12(%esp)
 -	jnc     .Lfail
 -
 -.Ldone:
 -	popl	%edx
 -	popl	%ecx
 -	popl	%ebx
 -	popl	%eax
 -
 -	/* Remove error code */
 -	addl	$4, %esp
 -
 -	/* Jump over CPUID instruction */
 -	addl	$2, (%esp)
 -
 -	iret
 -.Lfail:
 -	/* Send terminate request to Hypervisor */
 -	movl    $0x100, %eax
 -	xorl    %edx, %edx
 -	movl    $MSR_AMD64_SEV_ES_GHCB, %ecx
 -	wrmsr
 -	rep; vmmcall
 -
 -	/* If request fails, go to hlt loop */
 -	hlt
 -	jmp .Lfail
 -SYM_CODE_END(startup32_vc_handler)
 +	/* Store MSR value in sev_status */
 +	shlq	$32, %rdx
 +	orq	%rdx, %rax
 +	movq	%rax, sev_status(%rip)
  
 -	.code64
 +.Lno_sev_mask:
 +	movq	%rbp, %rsp		/* Restore original stack pointer */
  
 -#include "../../kernel/sev_verify_cbit.S"
 +	pop	%rdx
 +	pop	%rbp
 +#endif
 +
 +	xor	%rax, %rax
 +	ret
 +SYM_FUNC_END(set_sev_encryption_mask)
++=======
++>>>>>>> ec1c66af3a30 (x86/compressed/64: Detect/setup SEV/SME features earlier during boot)
  
  	.data
  
* Unmerged path arch/x86/boot/compressed/head_64.S
* Unmerged path arch/x86/boot/compressed/mem_encrypt.S
diff --git a/arch/x86/boot/compressed/misc.h b/arch/x86/boot/compressed/misc.h
index 5bf08eb0ecdc..cd8a1e660c56 100644
--- a/arch/x86/boot/compressed/misc.h
+++ b/arch/x86/boot/compressed/misc.h
@@ -116,12 +116,12 @@ static inline void console_init(void)
 { }
 #endif
 
-void set_sev_encryption_mask(void);
-
 #ifdef CONFIG_AMD_MEM_ENCRYPT
+void sev_enable(struct boot_params *bp);
 void sev_es_shutdown_ghcb(void);
 extern bool sev_es_check_ghcb_fault(unsigned long address);
 #else
+static inline void sev_enable(struct boot_params *bp) { }
 static inline void sev_es_shutdown_ghcb(void) { }
 static inline bool sev_es_check_ghcb_fault(unsigned long address)
 {
diff --git a/arch/x86/boot/compressed/sev.c b/arch/x86/boot/compressed/sev.c
index 213b126ba7e3..781c645b5fd6 100644
--- a/arch/x86/boot/compressed/sev.c
+++ b/arch/x86/boot/compressed/sev.c
@@ -202,3 +202,39 @@ void do_boot_stage2_vc(struct pt_regs *regs, unsigned long exit_code)
 	else if (result != ES_RETRY)
 		sev_es_terminate(SEV_TERM_SET_GEN, GHCB_SEV_ES_GEN_REQ);
 }
+
+void sev_enable(struct boot_params *bp)
+{
+	unsigned int eax, ebx, ecx, edx;
+	struct msr m;
+
+	/* Check for the SME/SEV support leaf */
+	eax = 0x80000000;
+	ecx = 0;
+	native_cpuid(&eax, &ebx, &ecx, &edx);
+	if (eax < 0x8000001f)
+		return;
+
+	/*
+	 * Check for the SME/SEV feature:
+	 *   CPUID Fn8000_001F[EAX]
+	 *   - Bit 0 - Secure Memory Encryption support
+	 *   - Bit 1 - Secure Encrypted Virtualization support
+	 *   CPUID Fn8000_001F[EBX]
+	 *   - Bits 5:0 - Pagetable bit position used to indicate encryption
+	 */
+	eax = 0x8000001f;
+	ecx = 0;
+	native_cpuid(&eax, &ebx, &ecx, &edx);
+	/* Check whether SEV is supported */
+	if (!(eax & BIT(1)))
+		return;
+
+	/* Set the SME mask if this is an SEV guest. */
+	boot_rdmsr(MSR_AMD64_SEV, &m);
+	sev_status = m.q;
+	if (!(sev_status & MSR_AMD64_SEV_ENABLED))
+		return;
+
+	sme_me_mask = BIT_ULL(ebx & 0x3f);
+}
