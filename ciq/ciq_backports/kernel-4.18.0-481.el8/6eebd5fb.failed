locking/rwsem: Allow slowpath writer to ignore handoff bit if not set by first waiter

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-481.el8
commit-author Waiman Long <longman@redhat.com>
commit 6eebd5fb20838f5971ba17df9f55cc4f84a31053
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-481.el8/6eebd5fb.failed

With commit d257cc8cb8d5 ("locking/rwsem: Make handoff bit handling more
consistent"), the writer that sets the handoff bit can be interrupted
out without clearing the bit if the wait queue isn't empty. This disables
reader and writer optimistic lock spinning and stealing.

Now if a non-first writer in the queue is somehow woken up or a new
waiter enters the slowpath, it can't acquire the lock.  This is not the
case before commit d257cc8cb8d5 as the writer that set the handoff bit
will clear it when exiting out via the out_nolock path. This is less
efficient as the busy rwsem stays in an unlock state for a longer time.

In some cases, this new behavior may cause lockups as shown in [1] and
[2].

This patch allows a non-first writer to ignore the handoff bit if it
is not originally set or initiated by the first waiter. This patch is
shown to be effective in fixing the lockup problem reported in [1].

[1] https://lore.kernel.org/lkml/20220617134325.GC30825@techsingularity.net/
[2] https://lore.kernel.org/lkml/3f02975c-1a9d-be20-32cf-f1d8e3dfafcc@oracle.com/

Fixes: d257cc8cb8d5 ("locking/rwsem: Make handoff bit handling more consistent")
	Signed-off-by: Waiman Long <longman@redhat.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Acked-by: John Donnelly <john.p.donnelly@oracle.com>
	Tested-by: Mel Gorman <mgorman@techsingularity.net>
Link: https://lore.kernel.org/r/20220622200419.778799-1-longman@redhat.com
(cherry picked from commit 6eebd5fb20838f5971ba17df9f55cc4f84a31053)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/rwsem.c
diff --cc kernel/locking/rwsem.c
index 665677d32e74,65f0262f635e..000000000000
--- a/kernel/locking/rwsem.c
+++ b/kernel/locking/rwsem.c
@@@ -353,6 -335,7 +353,10 @@@ struct rwsem_waiter 
  	struct task_struct *task;
  	enum rwsem_waiter_type type;
  	unsigned long timeout;
++<<<<<<< HEAD
++=======
+ 	bool handoff_set;
++>>>>>>> 6eebd5fb2083 (locking/rwsem: Allow slowpath writer to ignore handoff bit if not set by first waiter)
  };
  #define rwsem_first_waiter(sem) \
  	list_first_entry(&sem->wait_list, struct rwsem_waiter, list)
@@@ -551,12 -594,12 +557,16 @@@ static void rwsem_mark_wake(struct rw_s
   * race conditions between checking the rwsem wait list and setting the
   * sem->count accordingly.
   *
 - * Implies rwsem_del_waiter() on success.
 + * If wstate is WRITER_HANDOFF, it will make sure that either the handoff
 + * bit is set or the lock is acquired with handoff bit cleared.
   */
  static inline bool rwsem_try_write_lock(struct rw_semaphore *sem,
 -					struct rwsem_waiter *waiter)
 +					enum writer_wait_state wstate)
  {
++<<<<<<< HEAD
++=======
+ 	struct rwsem_waiter *first = rwsem_first_waiter(sem);
++>>>>>>> 6eebd5fb2083 (locking/rwsem: Allow slowpath writer to ignore handoff bit if not set by first waiter)
  	long count, new;
  
  	lockdep_assert_held(&sem->wait_lock);
@@@ -565,8 -608,22 +575,27 @@@
  	do {
  		bool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);
  
++<<<<<<< HEAD
 +		if (has_handoff && wstate == WRITER_NOT_FIRST)
 +			return false;
++=======
+ 		if (has_handoff) {
+ 			/*
+ 			 * Honor handoff bit and yield only when the first
+ 			 * waiter is the one that set it. Otherwisee, we
+ 			 * still try to acquire the rwsem.
+ 			 */
+ 			if (first->handoff_set && (waiter != first))
+ 				return false;
+ 
+ 			/*
+ 			 * First waiter can inherit a previously set handoff
+ 			 * bit and spin on rwsem if lock acquisition fails.
+ 			 */
+ 			if (waiter == first)
+ 				waiter->handoff_set = true;
+ 		}
++>>>>>>> 6eebd5fb2083 (locking/rwsem: Allow slowpath writer to ignore handoff bit if not set by first waiter)
  
  		new = count;
  
* Unmerged path kernel/locking/rwsem.c
