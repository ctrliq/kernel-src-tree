x86/boot: Micro-optimize GDT loading instructions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-547.el8
commit-author Arvind Sankar <nivedita@alum.mit.edu>
commit 8a3abe30de9fffec8b44adeb78f93ecb0f09b0c5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-547.el8/8a3abe30.failed

Rearrange the instructions a bit to use a 32-bit displacement once
instead of 2/3 times. This saves 8 bytes of machine code.

	Signed-off-by: Arvind Sankar <nivedita@alum.mit.edu>
Link: https://lore.kernel.org/r/20200202171353.3736319-8-nivedita@alum.mit.edu
	Signed-off-by: Ard Biesheuvel <ardb@kernel.org>
(cherry picked from commit 8a3abe30de9fffec8b44adeb78f93ecb0f09b0c5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/boot/compressed/head_64.S
diff --cc arch/x86/boot/compressed/head_64.S
index d574fecca8fb,a4f5561c1c0e..000000000000
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@@ -80,10 -68,21 +80,26 @@@ SYM_FUNC_START(startup_32
  1:	popl	%ebp
  	subl	$1b, %ebp
  
++<<<<<<< HEAD
++=======
+ 	/* Load new GDT with the 64bit segments using 32bit descriptor */
+ 	leal	gdt(%ebp), %eax
+ 	movl	%eax, 2(%eax)
+ 	lgdt	(%eax)
+ 
+ 	/* Load segment registers with our descriptors */
+ 	movl	$__BOOT_DS, %eax
+ 	movl	%eax, %ds
+ 	movl	%eax, %es
+ 	movl	%eax, %fs
+ 	movl	%eax, %gs
+ 	movl	%eax, %ss
+ 
++>>>>>>> 8a3abe30de9f (x86/boot: Micro-optimize GDT loading instructions)
  /* setup a stack and make sure cpu supports long mode. */
 -	leal	boot_stack_end(%ebp), %esp
 +	movl	$boot_stack_end, %eax
 +	addl	%ebp, %eax
 +	movl	%eax, %esp
  
  	call	verify_cpu
  	testl	%eax, %eax
@@@ -338,39 -356,10 +354,39 @@@ SYM_CODE_START(startup_64
  	 */
  
  	/* Make sure we have GDT with 32-bit code segment */
- 	leaq	gdt(%rip), %rax
- 	movq	%rax, gdt64+2(%rip)
- 	lgdt	gdt64(%rip)
+ 	leaq	gdt64(%rip), %rax
+ 	addq	%rax, 2(%rax)
+ 	lgdt	(%rax)
  
 +	/* Reload CS so IRET returns to a CS actually in the GDT */
 +	pushq	$__KERNEL_CS
 +	leaq	.Lon_kernel_cs(%rip), %rax
 +	pushq	%rax
 +	lretq
 +
 +.Lon_kernel_cs:
 +
 +	pushq	%rsi
 +	call	load_stage1_idt
 +	popq	%rsi
 +
 +#ifdef CONFIG_AMD_MEM_ENCRYPT
 +	/*
 +	 * Now that the stage1 interrupt handlers are set up, #VC exceptions from
 +	 * CPUID instructions can be properly handled for SEV-ES guests.
 +	 *
 +	 * For SEV-SNP, the CPUID table also needs to be set up in advance of any
 +	 * CPUID instructions being issued, so go ahead and do that now via
 +	 * sev_enable(), which will also handle the rest of the SEV-related
 +	 * detection/setup to ensure that has been done in advance of any dependent
 +	 * code.
 +	 */
 +	pushq	%rsi
 +	movq	%rsi, %rdi		/* real mode address */
 +	call	sev_enable
 +	popq	%rsi
 +#endif
 +
  	/*
  	 * paging_prepare() sets up the trampoline and checks if we need to
  	 * enable 5-level paging.
@@@ -675,13 -624,14 +691,24 @@@ SYM_CODE_END(trampoline_32bit_src
  #include "../../kernel/verify_cpu.S"
  
  	.data
++<<<<<<< HEAD
 +gdt64:
 +	.word	gdt_end - gdt
 +	.quad   0
 +	.balign	8
 +gdt:
 +	.word	gdt_end - gdt
 +	.long	gdt
++=======
+ SYM_DATA_START_LOCAL(gdt64)
+ 	.word	gdt_end - gdt - 1
+ 	.quad   gdt - gdt64
+ SYM_DATA_END(gdt64)
+ 	.balign	8
+ SYM_DATA_START_LOCAL(gdt)
+ 	.word	gdt_end - gdt - 1
+ 	.long	0
++>>>>>>> 8a3abe30de9f (x86/boot: Micro-optimize GDT loading instructions)
  	.word	0
  	.quad	0x00cf9a000000ffff	/* __KERNEL32_CS */
  	.quad	0x00af9a000000ffff	/* __KERNEL_CS */
* Unmerged path arch/x86/boot/compressed/head_64.S
