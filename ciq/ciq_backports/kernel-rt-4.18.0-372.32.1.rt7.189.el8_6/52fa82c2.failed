x86: Add insn_decode_kernel()

jira LE-1907
cve CVE-2022-23825
cve CVE-2022-29901
cve CVE-2022-29900
cve CVE-2022-23816
Rebuild_History Non-Buildable kernel-rt-4.18.0-372.32.1.rt7.189.el8_6
commit-author Peter Zijlstra <peterz@infradead.org>
commit 52fa82c21f64e900a72437269a5cc9e0034b424e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-372.32.1.rt7.189.el8_6/52fa82c2.failed

Add a helper to decode kernel instructions; there's no point in
endlessly repeating those last two arguments.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20210326151259.379242587@infradead.org
(cherry picked from commit 52fa82c21f64e900a72437269a5cc9e0034b424e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/mce/severity.c
#	arch/x86/kernel/kprobes/core.c
#	arch/x86/kernel/kprobes/opt.c
#	arch/x86/kernel/traps.c
diff --cc arch/x86/kernel/cpu/mce/severity.c
index 7efbcbb76416,abdd2e40d7c4..000000000000
--- a/arch/x86/kernel/cpu/mce/severity.c
+++ b/arch/x86/kernel/cpu/mce/severity.c
@@@ -193,6 -215,43 +193,46 @@@ static struct severity 
  #define mc_recoverable(mcg) (((mcg) & (MCG_STATUS_RIPV|MCG_STATUS_EIPV)) == \
  				(MCG_STATUS_RIPV|MCG_STATUS_EIPV))
  
++<<<<<<< HEAD
++=======
+ static bool is_copy_from_user(struct pt_regs *regs)
+ {
+ 	u8 insn_buf[MAX_INSN_SIZE];
+ 	unsigned long addr;
+ 	struct insn insn;
+ 	int ret;
+ 
+ 	if (copy_from_kernel_nofault(insn_buf, (void *)regs->ip, MAX_INSN_SIZE))
+ 		return false;
+ 
+ 	ret = insn_decode_kernel(&insn, insn_buf);
+ 	if (ret < 0)
+ 		return false;
+ 
+ 	switch (insn.opcode.value) {
+ 	/* MOV mem,reg */
+ 	case 0x8A: case 0x8B:
+ 	/* MOVZ mem,reg */
+ 	case 0xB60F: case 0xB70F:
+ 		addr = (unsigned long)insn_get_addr_ref(&insn, regs);
+ 		break;
+ 	/* REP MOVS */
+ 	case 0xA4: case 0xA5:
+ 		addr = regs->si;
+ 		break;
+ 	default:
+ 		return false;
+ 	}
+ 
+ 	if (fault_in_kernel_space(addr))
+ 		return false;
+ 
+ 	current->mce_vaddr = (void __user *)addr;
+ 
+ 	return true;
+ }
+ 
++>>>>>>> 52fa82c21f64 (x86: Add insn_decode_kernel())
  /*
   * If mcgstatus indicated that ip/cs on the stack were
   * no good, then "m->cs" will be zero and we will have
diff --cc arch/x86/kernel/kprobes/core.c
index 914c7d77ba21,1319ff47c85c..000000000000
--- a/arch/x86/kernel/kprobes/core.c
+++ b/arch/x86/kernel/kprobes/core.c
@@@ -307,8 -284,10 +307,15 @@@ static int can_probe(unsigned long padd
  		__addr = recover_probed_instruction(buf, addr);
  		if (!__addr)
  			return 0;
++<<<<<<< HEAD
 +		kernel_insn_init(&insn, (void *)__addr, MAX_INSN_SIZE);
 +		insn_get_length(&insn);
++=======
+ 
+ 		ret = insn_decode_kernel(&insn, (void *)__addr);
+ 		if (ret < 0)
+ 			return 0;
++>>>>>>> 52fa82c21f64 (x86: Add insn_decode_kernel())
  
  		/*
  		 * Another debugging subsystem might insert this breakpoint.
@@@ -362,8 -322,9 +369,14 @@@ int __copy_instruction(u8 *dest, u8 *sr
  			MAX_INSN_SIZE))
  		return 0;
  
++<<<<<<< HEAD
 +	kernel_insn_init(insn, dest, MAX_INSN_SIZE);
 +	insn_get_length(insn);
++=======
+ 	ret = insn_decode_kernel(insn, dest);
+ 	if (ret < 0)
+ 		return 0;
++>>>>>>> 52fa82c21f64 (x86: Add insn_decode_kernel())
  
  	/* We can not probe force emulate prefixed instruction */
  	if (insn_has_emulate_prefix(insn))
diff --cc arch/x86/kernel/kprobes/opt.c
index 0448efa0d2f1,71425ebba98a..000000000000
--- a/arch/x86/kernel/kprobes/opt.c
+++ b/arch/x86/kernel/kprobes/opt.c
@@@ -300,11 -323,19 +300,17 @@@ static int can_optimize(unsigned long p
  		recovered_insn = recover_probed_instruction(buf, addr);
  		if (!recovered_insn)
  			return 0;
++<<<<<<< HEAD
 +		kernel_insn_init(&insn, (void *)recovered_insn, MAX_INSN_SIZE);
 +		insn_get_length(&insn);
 +		/* Another subsystem puts a breakpoint */
 +		if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION)
++=======
+ 
+ 		ret = insn_decode_kernel(&insn, (void *)recovered_insn);
+ 		if (ret < 0)
++>>>>>>> 52fa82c21f64 (x86: Add insn_decode_kernel())
  			return 0;
 -
 -		/*
 -		 * In the case of detecting unknown breakpoint, this could be
 -		 * a padding INT3 between functions. Let's check that all the
 -		 * rest of the bytes are also INT3.
 -		 */
 -		if (insn.opcode.bytes[0] == INT3_INSN_OPCODE)
 -			return is_padding_int3(addr, paddr - offset + size) ? 1 : 0;
 -
  		/* Recover address */
  		insn.kaddr = (void *)addr;
  		insn.next_byte = (void *)(addr + insn.length);
diff --cc arch/x86/kernel/traps.c
index ae070300154c,034f27fc230a..000000000000
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@@ -399,88 -475,67 +399,125 @@@ dotraplinkage void do_bounds(struct pt_
  	cond_local_irq_enable(regs);
  
  	if (!user_mode(regs))
 -		die("bounds", regs, 0);
 +		die("bounds", regs, error_code);
  
 -	do_trap(X86_TRAP_BR, SIGSEGV, "bounds", regs, 0, 0, NULL);
 +	if (!cpu_feature_enabled(X86_FEATURE_MPX)) {
 +		/* The exception is not from Intel MPX */
 +		goto exit_trap;
 +	}
  
++<<<<<<< HEAD
++=======
+ 	cond_local_irq_disable(regs);
+ }
+ 
+ enum kernel_gp_hint {
+ 	GP_NO_HINT,
+ 	GP_NON_CANONICAL,
+ 	GP_CANONICAL
+ };
+ 
+ /*
+  * When an uncaught #GP occurs, try to determine the memory address accessed by
+  * the instruction and return that address to the caller. Also, try to figure
+  * out whether any part of the access to that address was non-canonical.
+  */
+ static enum kernel_gp_hint get_kernel_gp_address(struct pt_regs *regs,
+ 						 unsigned long *addr)
+ {
+ 	u8 insn_buf[MAX_INSN_SIZE];
+ 	struct insn insn;
+ 	int ret;
+ 
+ 	if (copy_from_kernel_nofault(insn_buf, (void *)regs->ip,
+ 			MAX_INSN_SIZE))
+ 		return GP_NO_HINT;
+ 
+ 	ret = insn_decode_kernel(&insn, insn_buf);
+ 	if (ret < 0)
+ 		return GP_NO_HINT;
+ 
+ 	*addr = (unsigned long)insn_get_addr_ref(&insn, regs);
+ 	if (*addr == -1UL)
+ 		return GP_NO_HINT;
+ 
+ #ifdef CONFIG_X86_64
++>>>>>>> 52fa82c21f64 (x86: Add insn_decode_kernel())
  	/*
 -	 * Check that:
 -	 *  - the operand is not in the kernel half
 -	 *  - the last byte of the operand is not in the user canonical half
 +	 * We need to look at BNDSTATUS to resolve this exception.
 +	 * A NULL here might mean that it is in its 'init state',
 +	 * which is all zeros which indicates MPX was not
 +	 * responsible for the exception.
  	 */
 -	if (*addr < ~__VIRTUAL_MASK &&
 -	    *addr + insn.opnd_bytes - 1 > __VIRTUAL_MASK)
 -		return GP_NON_CANONICAL;
 -#endif
 +	bndcsr = get_xsave_field_ptr(XFEATURE_BNDCSR);
 +	if (!bndcsr)
 +		goto exit_trap;
  
 -	return GP_CANONICAL;
 -}
 +	trace_bounds_exception_mpx(bndcsr);
 +	/*
 +	 * The error code field of the BNDSTATUS register communicates status
 +	 * information of a bound range exception #BR or operation involving
 +	 * bound directory.
 +	 */
 +	switch (bndcsr->bndstatus & MPX_BNDSTA_ERROR_CODE) {
 +	case 2:	/* Bound directory has invalid entry. */
 +		if (mpx_handle_bd_fault())
 +			goto exit_trap;
 +		break; /* Success, it was handled */
 +	case 1: /* Bound violation. */
 +	{
 +		struct task_struct *tsk = current;
 +		struct mpx_fault_info mpx;
 +
 +		if (mpx_fault_info(&mpx, regs)) {
 +			/*
 +			 * We failed to decode the MPX instruction.  Act as if
 +			 * the exception was not caused by MPX.
 +			 */
 +			goto exit_trap;
 +		}
 +		/*
 +		 * Success, we decoded the instruction and retrieved
 +		 * an 'mpx' containing the address being accessed
 +		 * which caused the exception.  This information
 +		 * allows and application to possibly handle the
 +		 * #BR exception itself.
 +		 */
 +		if (!do_trap_no_signal(tsk, X86_TRAP_BR, "bounds", regs,
 +				       error_code))
 +			break;
  
 -#define GPFSTR "general protection fault"
 +		show_signal(tsk, SIGSEGV, "trap ", "bounds", regs, error_code);
  
 -DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
 +		force_sig_bnderr(mpx.addr, mpx.lower, mpx.upper);
 +		break;
 +	}
 +	case 0: /* No exception caused by Intel MPX operations. */
 +		goto exit_trap;
 +	default:
 +		die("bounds", regs, error_code);
 +	}
 +
 +	return;
 +
 +exit_trap:
 +	/*
 +	 * This path out is for all the cases where we could not
 +	 * handle the exception in some way (like allocating a
 +	 * table or telling userspace about it.  We will also end
 +	 * up here if the kernel has MPX turned off at compile
 +	 * time..
 +	 */
 +	do_trap(X86_TRAP_BR, SIGSEGV, "bounds", regs, error_code, 0, NULL);
 +}
 +
 +dotraplinkage void
 +do_general_protection(struct pt_regs *regs, long error_code)
  {
 -	char desc[sizeof(GPFSTR) + 50 + 2*sizeof(unsigned long) + 1] = GPFSTR;
 -	enum kernel_gp_hint hint = GP_NO_HINT;
 +	const char *desc = "general protection fault";
  	struct task_struct *tsk;
 -	unsigned long gp_addr;
 -	int ret;
  
 +	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
  	cond_local_irq_enable(regs);
  
  	if (static_cpu_has(X86_FEATURE_UMIP)) {
diff --git a/arch/x86/include/asm/insn.h b/arch/x86/include/asm/insn.h
index 3f8c5780b9d4..cb95ee5e7b0e 100644
--- a/arch/x86/include/asm/insn.h
+++ b/arch/x86/include/asm/insn.h
@@ -108,6 +108,8 @@ extern void insn_get_displacement(struct insn *insn);
 extern void insn_get_immediate(struct insn *insn);
 extern void insn_get_length(struct insn *insn);
 
+#define insn_decode_kernel(_insn, _ptr) insn_decode((_insn), (_ptr), MAX_INSN_SIZE, INSN_MODE_KERN)
+
 /* Attribute will be determined after getting ModRM (for opcode groups) */
 static inline void insn_get_attribute(struct insn *insn)
 {
diff --git a/arch/x86/kernel/alternative.c b/arch/x86/kernel/alternative.c
index 0b65a0cb501d..b1f392a3f3ee 100644
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@ -985,7 +985,7 @@ void text_poke_loc_init(struct text_poke_loc *tp, void *addr,
 	if (!emulate)
 		emulate = opcode;
 
-	ret = insn_decode(&insn, emulate, MAX_INSN_SIZE, INSN_MODE_KERN);
+	ret = insn_decode_kernel(&insn, emulate);
 
 	BUG_ON(ret < 0);
 	BUG_ON(len != insn.length);
* Unmerged path arch/x86/kernel/cpu/mce/severity.c
* Unmerged path arch/x86/kernel/kprobes/core.c
* Unmerged path arch/x86/kernel/kprobes/opt.c
* Unmerged path arch/x86/kernel/traps.c
diff --git a/tools/arch/x86/include/asm/insn.h b/tools/arch/x86/include/asm/insn.h
index 18137418a5d4..f140cfec4c92 100644
--- a/tools/arch/x86/include/asm/insn.h
+++ b/tools/arch/x86/include/asm/insn.h
@@ -108,6 +108,8 @@ extern void insn_get_displacement(struct insn *insn);
 extern void insn_get_immediate(struct insn *insn);
 extern void insn_get_length(struct insn *insn);
 
+#define insn_decode_kernel(_insn, _ptr) insn_decode((_insn), (_ptr), MAX_INSN_SIZE, INSN_MODE_KERN)
+
 /* Attribute will be determined after getting ModRM (for opcode groups) */
 static inline void insn_get_attribute(struct insn *insn)
 {
