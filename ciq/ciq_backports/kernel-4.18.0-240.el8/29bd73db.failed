net/smc: send failover validation message

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 29bd73dba4f72970895a2459f7190d388f5204f7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/29bd73db.failed

When a connection is switched to a new link then a link validation
message must be sent to the peer over the new link, containing the
sequence number of the last CDC message that was sent over the old link.
The peer will validate if this sequence number is the same or lower then
the number he received, and abort the connection if messages were lost.
Add smcr_cdc_msg_send_validation() to send the message validation
message and call it when a connection was switched in
smc_switch_cursor().

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 29bd73dba4f72970895a2459f7190d388f5204f7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_core.c
diff --cc net/smc/smc_core.c
index cf74dd642f9a,a558ce0bde97..000000000000
--- a/net/smc/smc_core.c
+++ b/net/smc/smc_core.c
@@@ -449,10 -432,139 +449,142 @@@ out
  	return rc;
  }
  
++<<<<<<< HEAD
++=======
+ static int smc_write_space(struct smc_connection *conn)
+ {
+ 	int buffer_len = conn->peer_rmbe_size;
+ 	union smc_host_cursor prod;
+ 	union smc_host_cursor cons;
+ 	int space;
+ 
+ 	smc_curs_copy(&prod, &conn->local_tx_ctrl.prod, conn);
+ 	smc_curs_copy(&cons, &conn->local_rx_ctrl.cons, conn);
+ 	/* determine rx_buf space */
+ 	space = buffer_len - smc_curs_diff(buffer_len, &cons, &prod);
+ 	return space;
+ }
+ 
+ static int smc_switch_cursor(struct smc_sock *smc)
+ {
+ 	struct smc_connection *conn = &smc->conn;
+ 	union smc_host_cursor cons, fin;
+ 	int rc = 0;
+ 	int diff;
+ 
+ 	smc_curs_copy(&conn->tx_curs_sent, &conn->tx_curs_fin, conn);
+ 	smc_curs_copy(&fin, &conn->local_tx_ctrl_fin, conn);
+ 	/* set prod cursor to old state, enforce tx_rdma_writes() */
+ 	smc_curs_copy(&conn->local_tx_ctrl.prod, &fin, conn);
+ 	smc_curs_copy(&cons, &conn->local_rx_ctrl.cons, conn);
+ 
+ 	if (smc_curs_comp(conn->peer_rmbe_size, &cons, &fin) < 0) {
+ 		/* cons cursor advanced more than fin, and prod was set
+ 		 * fin above, so now prod is smaller than cons. Fix that.
+ 		 */
+ 		diff = smc_curs_diff(conn->peer_rmbe_size, &fin, &cons);
+ 		smc_curs_add(conn->sndbuf_desc->len,
+ 			     &conn->tx_curs_sent, diff);
+ 		smc_curs_add(conn->sndbuf_desc->len,
+ 			     &conn->tx_curs_fin, diff);
+ 
+ 		smp_mb__before_atomic();
+ 		atomic_add(diff, &conn->sndbuf_space);
+ 		smp_mb__after_atomic();
+ 
+ 		smc_curs_add(conn->peer_rmbe_size,
+ 			     &conn->local_tx_ctrl.prod, diff);
+ 		smc_curs_add(conn->peer_rmbe_size,
+ 			     &conn->local_tx_ctrl_fin, diff);
+ 	}
+ 	/* recalculate, value is used by tx_rdma_writes() */
+ 	atomic_set(&smc->conn.peer_rmbe_space, smc_write_space(conn));
+ 
+ 	if (smc->sk.sk_state != SMC_INIT &&
+ 	    smc->sk.sk_state != SMC_CLOSED) {
+ 		rc = smcr_cdc_msg_send_validation(conn);
+ 		if (!rc) {
+ 			schedule_delayed_work(&conn->tx_work, 0);
+ 			smc->sk.sk_data_ready(&smc->sk);
+ 		}
+ 	}
+ 	return rc;
+ }
+ 
+ struct smc_link *smc_switch_conns(struct smc_link_group *lgr,
+ 				  struct smc_link *from_lnk, bool is_dev_err)
+ {
+ 	struct smc_link *to_lnk = NULL;
+ 	struct smc_connection *conn;
+ 	struct smc_sock *smc;
+ 	struct rb_node *node;
+ 	int i, rc = 0;
+ 
+ 	/* link is inactive, wake up tx waiters */
+ 	smc_wr_wakeup_tx_wait(from_lnk);
+ 
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (lgr->lnk[i].state != SMC_LNK_ACTIVE ||
+ 		    i == from_lnk->link_idx)
+ 			continue;
+ 		if (is_dev_err && from_lnk->smcibdev == lgr->lnk[i].smcibdev &&
+ 		    from_lnk->ibport == lgr->lnk[i].ibport) {
+ 			continue;
+ 		}
+ 		to_lnk = &lgr->lnk[i];
+ 		break;
+ 	}
+ 	if (!to_lnk) {
+ 		smc_lgr_terminate_sched(lgr);
+ 		return NULL;
+ 	}
+ again:
+ 	read_lock_bh(&lgr->conns_lock);
+ 	for (node = rb_first(&lgr->conns_all); node; node = rb_next(node)) {
+ 		conn = rb_entry(node, struct smc_connection, alert_node);
+ 		if (conn->lnk != from_lnk)
+ 			continue;
+ 		smc = container_of(conn, struct smc_sock, conn);
+ 		/* conn->lnk not yet set in SMC_INIT state */
+ 		if (smc->sk.sk_state == SMC_INIT)
+ 			continue;
+ 		if (smc->sk.sk_state == SMC_CLOSED ||
+ 		    smc->sk.sk_state == SMC_PEERCLOSEWAIT1 ||
+ 		    smc->sk.sk_state == SMC_PEERCLOSEWAIT2 ||
+ 		    smc->sk.sk_state == SMC_APPFINCLOSEWAIT ||
+ 		    smc->sk.sk_state == SMC_APPCLOSEWAIT1 ||
+ 		    smc->sk.sk_state == SMC_APPCLOSEWAIT2 ||
+ 		    smc->sk.sk_state == SMC_PEERFINCLOSEWAIT ||
+ 		    smc->sk.sk_state == SMC_PEERABORTWAIT ||
+ 		    smc->sk.sk_state == SMC_PROCESSABORT) {
+ 			spin_lock_bh(&conn->send_lock);
+ 			conn->lnk = to_lnk;
+ 			spin_unlock_bh(&conn->send_lock);
+ 			continue;
+ 		}
+ 		sock_hold(&smc->sk);
+ 		read_unlock_bh(&lgr->conns_lock);
+ 		/* avoid race with smcr_tx_sndbuf_nonempty() */
+ 		spin_lock_bh(&conn->send_lock);
+ 		conn->lnk = to_lnk;
+ 		rc = smc_switch_cursor(smc);
+ 		spin_unlock_bh(&conn->send_lock);
+ 		sock_put(&smc->sk);
+ 		if (rc) {
+ 			smcr_link_down_cond_sched(to_lnk);
+ 			return NULL;
+ 		}
+ 		goto again;
+ 	}
+ 	read_unlock_bh(&lgr->conns_lock);
+ 	return to_lnk;
+ }
+ 
++>>>>>>> 29bd73dba4f7 (net/smc: send failover validation message)
  static void smcr_buf_unuse(struct smc_buf_desc *rmb_desc,
 -			   struct smc_link_group *lgr)
 +			   struct smc_link *lnk)
  {
 -	int rc;
 +	struct smc_link_group *lgr = lnk->lgr;
  
  	if (rmb_desc->is_conf_rkey && !list_empty(&lgr->list)) {
  		/* unregister rmb with peer */
diff --git a/net/smc/smc_cdc.c b/net/smc/smc_cdc.c
index c5e33296e55c..e04e03eebe50 100644
--- a/net/smc/smc_cdc.c
+++ b/net/smc/smc_cdc.c
@@ -115,6 +115,31 @@ int smc_cdc_msg_send(struct smc_connection *conn,
 	return rc;
 }
 
+/* send a validation msg indicating the move of a conn to an other QP link */
+int smcr_cdc_msg_send_validation(struct smc_connection *conn)
+{
+	struct smc_host_cdc_msg *local = &conn->local_tx_ctrl;
+	struct smc_link *link = conn->lnk;
+	struct smc_cdc_tx_pend *pend;
+	struct smc_wr_buf *wr_buf;
+	struct smc_cdc_msg *peer;
+	int rc;
+
+	rc = smc_cdc_get_free_slot(conn, link, &wr_buf, NULL, &pend);
+	if (rc)
+		return rc;
+
+	peer = (struct smc_cdc_msg *)wr_buf;
+	peer->common.type = local->common.type;
+	peer->len = local->len;
+	peer->seqno = htons(conn->tx_cdc_seq_fin); /* seqno last compl. tx */
+	peer->token = htonl(local->token);
+	peer->prod_flags.failover_validation = 1;
+
+	rc = smc_wr_tx_send(link, (struct smc_wr_tx_pend_priv *)pend);
+	return rc;
+}
+
 static int smcr_cdc_get_slot_and_msg_send(struct smc_connection *conn)
 {
 	struct smc_cdc_tx_pend *pend;
diff --git a/net/smc/smc_cdc.h b/net/smc/smc_cdc.h
index 861dc24c588c..09252dfc301a 100644
--- a/net/smc/smc_cdc.h
+++ b/net/smc/smc_cdc.h
@@ -312,6 +312,7 @@ int smc_cdc_msg_send(struct smc_connection *conn, struct smc_wr_buf *wr_buf,
 		     struct smc_cdc_tx_pend *pend);
 int smc_cdc_get_slot_and_msg_send(struct smc_connection *conn);
 int smcd_cdc_msg_send(struct smc_connection *conn);
+int smcr_cdc_msg_send_validation(struct smc_connection *conn);
 int smc_cdc_init(void) __init;
 void smcd_cdc_rx_init(struct smc_connection *conn);
 
* Unmerged path net/smc/smc_core.c
