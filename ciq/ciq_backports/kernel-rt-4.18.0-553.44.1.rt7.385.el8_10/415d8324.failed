locking/atomic: Make test_and_*_bit() ordered on failure

jira LE-3201
Rebuild_History Non-Buildable kernel-rt-4.18.0-553.44.1.rt7.385.el8_10
commit-author Hector Martin <marcan@marcan.st>
commit 415d832497098030241605c52ea83d4e2cfa7879
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-553.44.1.rt7.385.el8_10/415d8324.failed

These operations are documented as always ordered in
include/asm-generic/bitops/instrumented-atomic.h, and producer-consumer
type use cases where one side needs to ensure a flag is left pending
after some shared data was updated rely on this ordering, even in the
failure case.

This is the case with the workqueue code, which currently suffers from a
reproducible ordering violation on Apple M1 platforms (which are
notoriously out-of-order) that ends up causing the TTY layer to fail to
deliver data to userspace properly under the right conditions.  This
change fixes that bug.

Change the documentation to restrict the "no order on failure" story to
the _lock() variant (for which it makes sense), and remove the
early-exit from the generic implementation, which is what causes the
missing barrier semantics in that case.  Without this, the remaining
atomic op is fully ordered (including on ARM64 LSE, as of recent
versions of the architecture spec).

	Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: stable@vger.kernel.org
Fixes: e986a0d6cb36 ("locking/atomics, asm-generic/bitops/atomic.h: Rewrite using atomic_*() APIs")
Fixes: 61e02392d3c7 ("locking/atomic/bitops: Document and clarify ordering semantics for failed test_and_{}_bit()")
	Signed-off-by: Hector Martin <marcan@marcan.st>
	Acked-by: Will Deacon <will@kernel.org>
	Reviewed-by: Arnd Bergmann <arnd@arndb.de>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 415d832497098030241605c52ea83d4e2cfa7879)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/asm-generic/bitops/atomic.h
diff --cc include/asm-generic/bitops/atomic.h
index dd90c9792909,71ab4ba9c25d..000000000000
--- a/include/asm-generic/bitops/atomic.h
+++ b/include/asm-generic/bitops/atomic.h
@@@ -35,10 -39,7 +35,14 @@@ static inline int test_and_set_bit(unsi
  	unsigned long mask = BIT_MASK(nr);
  
  	p += BIT_WORD(nr);
++<<<<<<< HEAD
 +	if (READ_ONCE(*p) & mask)
 +		return 1;
 +
 +	old = atomic_long_fetch_or(mask, (atomic_long_t *)p);
++=======
+ 	old = arch_atomic_long_fetch_or(mask, (atomic_long_t *)p);
++>>>>>>> 415d83249709 (locking/atomic: Make test_and_*_bit() ordered on failure)
  	return !!(old & mask);
  }
  
@@@ -48,10 -50,7 +52,14 @@@ static inline int test_and_clear_bit(un
  	unsigned long mask = BIT_MASK(nr);
  
  	p += BIT_WORD(nr);
++<<<<<<< HEAD
 +	if (!(READ_ONCE(*p) & mask))
 +		return 0;
 +
 +	old = atomic_long_fetch_andnot(mask, (atomic_long_t *)p);
++=======
+ 	old = arch_atomic_long_fetch_andnot(mask, (atomic_long_t *)p);
++>>>>>>> 415d83249709 (locking/atomic: Make test_and_*_bit() ordered on failure)
  	return !!(old & mask);
  }
  
diff --git a/Documentation/atomic_bitops.txt b/Documentation/atomic_bitops.txt
index be70b32c95d9..bc3fac8e1db3 100644
--- a/Documentation/atomic_bitops.txt
+++ b/Documentation/atomic_bitops.txt
@@ -59,7 +59,7 @@ Like with atomic_t, the rule of thumb is:
  - RMW operations that have a return value are fully ordered.
 
  - RMW operations that are conditional are unordered on FAILURE,
-   otherwise the above rules apply. In the case of test_and_{}_bit() operations,
+   otherwise the above rules apply. In the case of test_and_set_bit_lock(),
    if the bit in memory is unchanged by the operation then it is deemed to have
    failed.
 
* Unmerged path include/asm-generic/bitops/atomic.h
