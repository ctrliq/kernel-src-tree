IB/uverbs: Allow all DESTROY commands to succeed after disassociate

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Jason Gunthorpe <jgg@mellanox.com>
commit 0f50d88a6e9ae6d9dd14ed1a7d6b309280a9c23b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/0f50d88a.failed

The disassociate function was broken by design because it failed all
commands. This prevents userspace from calling destroy on a uobject after
it has detected a device fatal error and thus reclaiming the resources in
userspace is prevented.

This fix is now straightforward, when anything destroys a uobject that is
not the user the object remains on the IDR with a NULL context and object
pointer. All lookup locking modes other than DESTROY will fail. When the
user ultimately calls the destroy function it is simply dropped from the
IDR while any related information is returned.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 0f50d88a6e9ae6d9dd14ed1a7d6b309280a9c23b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/rdma_core.c
#	drivers/infiniband/core/uverbs_main.c
#	include/rdma/uverbs_types.h
diff --cc drivers/infiniband/core/rdma_core.c
index 586f179a9de6,4235b9ddc2ad..000000000000
--- a/drivers/infiniband/core/rdma_core.c
+++ b/drivers/infiniband/core/rdma_core.c
@@@ -129,11 -153,146 +129,138 @@@ static int uverbs_try_lock_object(struc
  }
  
  /*
 - * This must be called with the hw_destroy_rwsem locked for read or write,
 - * also the uobject itself must be locked for write.
 - *
 - * Upon return the HW object is guaranteed to be destroyed.
 - *
 - * For RDMA_REMOVE_ABORT, the hw_destroy_rwsem is not required to be held,
 - * however the type's allocat_commit function cannot have been called and the
 - * uobject cannot be on the uobjects_lists
 - *
 - * For RDMA_REMOVE_DESTROY the caller shold be holding a kref (eg via
 - * rdma_lookup_get_uobject) and the object is left in a state where the caller
 - * needs to call rdma_lookup_put_uobject.
 - *
 - * For all other destroy modes this function internally unlocks the uobject
 - * and consumes the kref on the uobj.
 + * Does both rdma_lookup_get_uobject() and rdma_remove_commit_uobject(), then
 + * returns success_res on success (negative errno on failure). For use by
 + * callers that do not need the uobj.
   */
++<<<<<<< HEAD
 +int __uobj_perform_destroy(const struct uverbs_obj_type *type, int id,
++=======
+ static int uverbs_destroy_uobject(struct ib_uobject *uobj,
+ 				  enum rdma_remove_reason reason)
+ {
+ 	struct ib_uverbs_file *ufile = uobj->ufile;
+ 	unsigned long flags;
+ 	int ret;
+ 
+ 	lockdep_assert_held(&ufile->hw_destroy_rwsem);
+ 	assert_uverbs_usecnt(uobj, UVERBS_LOOKUP_WRITE);
+ 
+ 	if (uobj->object) {
+ 		ret = uobj->type->type_class->destroy_hw(uobj, reason);
+ 		if (ret) {
+ 			if (ib_is_destroy_retryable(ret, reason, uobj))
+ 				return ret;
+ 
+ 			/* Nothing to be done, dangle the memory and move on */
+ 			WARN(true,
+ 			     "ib_uverbs: failed to remove uobject id %d, driver err=%d",
+ 			     uobj->id, ret);
+ 		}
+ 
+ 		uobj->object = NULL;
+ 	}
+ 
+ 	if (reason == RDMA_REMOVE_ABORT) {
+ 		WARN_ON(!list_empty(&uobj->list));
+ 		WARN_ON(!uobj->context);
+ 		uobj->type->type_class->alloc_abort(uobj);
+ 	}
+ 
+ 	uobj->context = NULL;
+ 
+ 	/*
+ 	 * For DESTROY the usecnt is held write locked, the caller is expected
+ 	 * to put it unlock and put the object when done with it. Only DESTROY
+ 	 * can remove the IDR handle.
+ 	 */
+ 	if (reason != RDMA_REMOVE_DESTROY)
+ 		atomic_set(&uobj->usecnt, 0);
+ 	else
+ 		uobj->type->type_class->remove_handle(uobj);
+ 
+ 	if (!list_empty(&uobj->list)) {
+ 		spin_lock_irqsave(&ufile->uobjects_lock, flags);
+ 		list_del_init(&uobj->list);
+ 		spin_unlock_irqrestore(&ufile->uobjects_lock, flags);
+ 
+ 		/*
+ 		 * Pairs with the get in rdma_alloc_commit_uobject(), could
+ 		 * destroy uobj.
+ 		 */
+ 		uverbs_uobject_put(uobj);
+ 	}
+ 
+ 	/*
+ 	 * When aborting the stack kref remains owned by the core code, and is
+ 	 * not transferred into the type. Pairs with the get in alloc_uobj
+ 	 */
+ 	if (reason == RDMA_REMOVE_ABORT)
+ 		uverbs_uobject_put(uobj);
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * This calls uverbs_destroy_uobject() using the RDMA_REMOVE_DESTROY
+  * sequence. It should only be used from command callbacks. On success the
+  * caller must pair this with rdma_lookup_put_uobject(LOOKUP_WRITE). This
+  * version requires the caller to have already obtained an
+  * LOOKUP_DESTROY uobject kref.
+  */
+ int uobj_destroy(struct ib_uobject *uobj)
+ {
+ 	struct ib_uverbs_file *ufile = uobj->ufile;
+ 	int ret;
+ 
+ 	down_read(&ufile->hw_destroy_rwsem);
+ 
+ 	ret = uverbs_try_lock_object(uobj, UVERBS_LOOKUP_WRITE);
+ 	if (ret)
+ 		goto out_unlock;
+ 
+ 	ret = uverbs_destroy_uobject(uobj, RDMA_REMOVE_DESTROY);
+ 	if (ret) {
+ 		atomic_set(&uobj->usecnt, 0);
+ 		goto out_unlock;
+ 	}
+ 
+ out_unlock:
+ 	up_read(&ufile->hw_destroy_rwsem);
+ 	return ret;
+ }
+ 
+ /*
+  * uobj_get_destroy destroys the HW object and returns a handle to the uobj
+  * with a NULL object pointer. The caller must pair this with
+  * uverbs_put_destroy.
+  */
+ struct ib_uobject *__uobj_get_destroy(const struct uverbs_obj_type *type,
+ 				      u32 id, struct ib_uverbs_file *ufile)
+ {
+ 	struct ib_uobject *uobj;
+ 	int ret;
+ 
+ 	uobj = rdma_lookup_get_uobject(type, ufile, id, UVERBS_LOOKUP_DESTROY);
+ 	if (IS_ERR(uobj))
+ 		return uobj;
+ 
+ 	ret = uobj_destroy(uobj);
+ 	if (ret) {
+ 		rdma_lookup_put_uobject(uobj, UVERBS_LOOKUP_DESTROY);
+ 		return ERR_PTR(ret);
+ 	}
+ 
+ 	return uobj;
+ }
+ 
+ /*
+  * Does both uobj_get_destroy() and uobj_put_destroy().  Returns success_res
+  * on success (negative errno on failure). For use by callers that do not need
+  * the uobj.
+  */
+ int __uobj_perform_destroy(const struct uverbs_obj_type *type, u32 id,
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  			   struct ib_uverbs_file *ufile, int success_res)
  {
  	struct ib_uobject *uobj;
@@@ -361,13 -527,38 +488,13 @@@ static struct ib_uobject *alloc_begin_f
  }
  
  struct ib_uobject *rdma_alloc_begin_uobject(const struct uverbs_obj_type *type,
 -					    struct ib_uverbs_file *ufile)
 +					    struct ib_ucontext *ucontext)
  {
 -	struct ib_uobject *ret;
 -
 -	/*
 -	 * The hw_destroy_rwsem is held across the entire object creation and
 -	 * released during rdma_alloc_commit_uobject or
 -	 * rdma_alloc_abort_uobject
 -	 */
 -	if (!down_read_trylock(&ufile->hw_destroy_rwsem))
 -		return ERR_PTR(-EIO);
 -
 -	ret = type->type_class->alloc_begin(type, ufile);
 -	if (IS_ERR(ret)) {
 -		up_read(&ufile->hw_destroy_rwsem);
 -		return ret;
 -	}
 -	return ret;
 -}
 -
 -static void alloc_abort_idr_uobject(struct ib_uobject *uobj)
 -{
 -	ib_rdmacg_uncharge(&uobj->cg_obj, uobj->context->device,
 -			   RDMACG_RESOURCE_HCA_OBJECT);
 -
 -	spin_lock(&uobj->ufile->idr_lock);
 -	idr_remove(&uobj->ufile->idr, uobj->id);
 -	spin_unlock(&uobj->ufile->idr_lock);
 +	return type->type_class->alloc_begin(type, ucontext);
  }
  
- static int __must_check remove_commit_idr_uobject(struct ib_uobject *uobj,
- 						  enum rdma_remove_reason why)
+ static int __must_check destroy_hw_idr_uobject(struct ib_uobject *uobj,
+ 					       enum rdma_remove_reason why)
  {
  	const struct uverbs_obj_idr_type *idr_type =
  		container_of(uobj->type, struct uverbs_obj_idr_type,
@@@ -376,42 -567,122 +503,138 @@@
  
  	/*
  	 * We can only fail gracefully if the user requested to destroy the
 -	 * object or when a retry may be called upon an error.
 -	 * In the rest of the cases, just remove whatever you can.
 +	 * object. In the rest of the cases, just remove whatever you can.
  	 */
 -	if (ib_is_destroy_retryable(ret, why, uobj))
 +	if (why == RDMA_REMOVE_DESTROY && ret)
  		return ret;
  
 -	if (why == RDMA_REMOVE_ABORT)
 -		return 0;
 +	uverbs_idr_remove_uobj(uobj);
  
++<<<<<<< HEAD
 +	return ret;
++=======
+ 	ib_rdmacg_uncharge(&uobj->cg_obj, uobj->context->device,
+ 			   RDMACG_RESOURCE_HCA_OBJECT);
+ 
+ 	return 0;
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
+ }
+ 
+ static void remove_handle_idr_uobject(struct ib_uobject *uobj)
+ {
+ 	spin_lock(&uobj->ufile->idr_lock);
+ 	idr_remove(&uobj->ufile->idr, uobj->id);
+ 	spin_unlock(&uobj->ufile->idr_lock);
+ 	/* Matches the kref in alloc_commit_idr_uobject */
+ 	uverbs_uobject_put(uobj);
  }
  
  static void alloc_abort_fd_uobject(struct ib_uobject *uobj)
  {
 -	put_unused_fd(uobj->id);
 +	struct ib_uobject_file *uobj_file =
 +		container_of(uobj, struct ib_uobject_file, uobj);
 +	struct file *filp = uobj->object;
 +	int id = uobj_file->uobj.id;
 +
 +	/* Unsuccessful NEW */
 +	fput(filp);
 +	put_unused_fd(id);
  }
  
- static int __must_check remove_commit_fd_uobject(struct ib_uobject *uobj,
- 						 enum rdma_remove_reason why)
+ static int __must_check destroy_hw_fd_uobject(struct ib_uobject *uobj,
+ 					      enum rdma_remove_reason why)
  {
  	const struct uverbs_obj_fd_type *fd_type =
  		container_of(uobj->type, struct uverbs_obj_fd_type, type);
 -	int ret = fd_type->context_closed(uobj, why);
 +	struct ib_uobject_file *uobj_file =
 +		container_of(uobj, struct ib_uobject_file, uobj);
 +	int ret = fd_type->context_closed(uobj_file, why);
  
 -	if (ib_is_destroy_retryable(ret, why, uobj))
 +	if (why == RDMA_REMOVE_DESTROY && ret)
  		return ret;
  
++<<<<<<< HEAD
 +	if (why == RDMA_REMOVE_DURING_CLEANUP) {
 +		alloc_abort_fd_uobject(uobj);
++=======
+ 	return 0;
+ }
+ 
+ static void remove_handle_fd_uobject(struct ib_uobject *uobj)
+ {
+ }
+ 
+ static int alloc_commit_idr_uobject(struct ib_uobject *uobj)
+ {
+ 	struct ib_uverbs_file *ufile = uobj->ufile;
+ 
+ 	spin_lock(&ufile->idr_lock);
+ 	/*
+ 	 * We already allocated this IDR with a NULL object, so
+ 	 * this shouldn't fail.
+ 	 *
+ 	 * NOTE: Once we set the IDR we loose ownership of our kref on uobj.
+ 	 * It will be put by remove_commit_idr_uobject()
+ 	 */
+ 	WARN_ON(idr_replace(&ufile->idr, uobj, uobj->id));
+ 	spin_unlock(&ufile->idr_lock);
+ 
+ 	return 0;
+ }
+ 
+ static int alloc_commit_fd_uobject(struct ib_uobject *uobj)
+ {
+ 	const struct uverbs_obj_fd_type *fd_type =
+ 		container_of(uobj->type, struct uverbs_obj_fd_type, type);
+ 	int fd = uobj->id;
+ 	struct file *filp;
+ 
+ 	/*
+ 	 * The kref for uobj is moved into filp->private data and put in
+ 	 * uverbs_close_fd(). Once alloc_commit() succeeds uverbs_close_fd()
+ 	 * must be guaranteed to be called from the provided fops release
+ 	 * callback.
+ 	 */
+ 	filp = anon_inode_getfile(fd_type->name,
+ 				  fd_type->fops,
+ 				  uobj,
+ 				  fd_type->flags);
+ 	if (IS_ERR(filp))
+ 		return PTR_ERR(filp);
+ 
+ 	uobj->object = filp;
+ 
+ 	/* Matching put will be done in uverbs_close_fd() */
+ 	kref_get(&uobj->ufile->ref);
+ 
+ 	/* This shouldn't be used anymore. Use the file object instead */
+ 	uobj->id = 0;
+ 
+ 	/*
+ 	 * NOTE: Once we install the file we loose ownership of our kref on
+ 	 * uobj. It will be put by uverbs_close_fd()
+ 	 */
+ 	fd_install(fd, filp);
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * In all cases rdma_alloc_commit_uobject() consumes the kref to uobj and the
+  * caller can no longer assume uobj is valid. If this function fails it
+  * destroys the uboject, including the attached HW object.
+  */
+ int __must_check rdma_alloc_commit_uobject(struct ib_uobject *uobj)
+ {
+ 	struct ib_uverbs_file *ufile = uobj->ufile;
+ 	int ret;
+ 
+ 	/* alloc_commit consumes the uobj kref */
+ 	ret = uobj->type->type_class->alloc_commit(uobj);
+ 	if (ret) {
+ 		uverbs_destroy_uobject(uobj, RDMA_REMOVE_ABORT);
+ 		up_read(&ufile->hw_destroy_rwsem);
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  		return ret;
  	}
  
@@@ -728,14 -988,16 +979,15 @@@ const struct uverbs_obj_type_class uver
  	.alloc_commit = alloc_commit_fd_uobject,
  	.alloc_abort = alloc_abort_fd_uobject,
  	.lookup_put = lookup_put_fd_uobject,
- 	.remove_commit = remove_commit_fd_uobject,
+ 	.destroy_hw = destroy_hw_fd_uobject,
+ 	.remove_handle = remove_handle_fd_uobject,
  	.needs_kfree_rcu = false,
  };
 -EXPORT_SYMBOL(uverbs_fd_class);
 -
 -struct ib_uobject *
 -uverbs_get_uobject_from_file(const struct uverbs_obj_type *type_attrs,
 -			     struct ib_uverbs_file *ufile,
 -			     enum uverbs_obj_access access, s64 id)
 + 
 +struct ib_uobject *uverbs_get_uobject_from_context(const struct uverbs_obj_type *type_attrs,
 +						   struct ib_ucontext *ucontext,
 +						   enum uverbs_obj_access access,
 +						   int id)
  {
  	switch (access) {
  	case UVERBS_ACCESS_READ:
diff --cc drivers/infiniband/core/uverbs_main.c
index 9b53f7b4a4a8,6f62146e9738..000000000000
--- a/drivers/infiniband/core/uverbs_main.c
+++ b/drivers/infiniband/core/uverbs_main.c
@@@ -882,13 -869,12 +884,16 @@@ static int ib_uverbs_open(struct inode 
  	}
  
  	file->device	 = dev;
++<<<<<<< HEAD
 +	spin_lock_init(&file->idr_lock);
 +	idr_init(&file->idr);
 +	file->ucontext	 = NULL;
 +	file->async_file = NULL;
++=======
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  	kref_init(&file->ref);
 -	mutex_init(&file->ucontext_lock);
 -
 -	spin_lock_init(&file->uobjects_lock);
 -	INIT_LIST_HEAD(&file->uobjects);
 -	init_rwsem(&file->hw_destroy_rwsem);
 +	mutex_init(&file->mutex);
 +	mutex_init(&file->cleanup_mutex);
  
  	filp->private_data = file;
  	kobject_get(&dev->kobj);
@@@ -896,6 -882,11 +901,14 @@@
  	mutex_unlock(&dev->lists_mutex);
  	srcu_read_unlock(&dev->disassociate_srcu, srcu_key);
  
++<<<<<<< HEAD
++=======
+ 	file->uverbs_cmd_mask = ib_dev->uverbs_cmd_mask;
+ 	file->uverbs_ex_cmd_mask = ib_dev->uverbs_ex_cmd_mask;
+ 
+ 	setup_ufile_idr_uobject(file);
+ 
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  	return nonseekable_open(inode, filp);
  
  err_module:
@@@ -914,13 -905,7 +927,17 @@@ static int ib_uverbs_close(struct inod
  {
  	struct ib_uverbs_file *file = filp->private_data;
  
++<<<<<<< HEAD
 +	mutex_lock(&file->cleanup_mutex);
 +	if (file->ucontext) {
 +		ib_uverbs_cleanup_ucontext(file, file->ucontext, false);
 +		file->ucontext = NULL;
 +	}
 +	mutex_unlock(&file->cleanup_mutex);
 +	idr_destroy(&file->idr);
++=======
+ 	uverbs_destroy_ufile_hw(file, RDMA_REMOVE_CLOSE);
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  
  	mutex_lock(&file->device->lists_mutex);
  	if (!file->is_closed) {
diff --cc include/rdma/uverbs_types.h
index cc04ec65588d,1ab9a85eebd9..000000000000
--- a/include/rdma/uverbs_types.h
+++ b/include/rdma/uverbs_types.h
@@@ -38,55 -38,64 +38,110 @@@
  
  struct uverbs_obj_type;
  
++<<<<<<< HEAD
++=======
+ enum rdma_lookup_mode {
+ 	UVERBS_LOOKUP_READ,
+ 	UVERBS_LOOKUP_WRITE,
+ 	/*
+ 	 * Destroy is like LOOKUP_WRITE, except that the uobject is not
+ 	 * locked.  uobj_destroy is used to convert a LOOKUP_DESTROY lock into
+ 	 * a LOOKUP_WRITE lock.
+ 	 */
+ 	UVERBS_LOOKUP_DESTROY,
+ };
+ 
+ /*
+  * The following sequences are valid:
+  * Success flow:
+  *   alloc_begin
+  *   alloc_commit
+  *    [..]
+  * Access flow:
+  *   lookup_get(exclusive=false) & uverbs_try_lock_object
+  *   lookup_put(exclusive=false) via rdma_lookup_put_uobject
+  * Destruction flow:
+  *   lookup_get(exclusive=true) & uverbs_try_lock_object
+  *   remove_commit
+  *   remove_handle (optional)
+  *   lookup_put(exclusive=true) via rdma_lookup_put_uobject
+  *
+  * Allocate Error flow #1
+  *   alloc_begin
+  *   alloc_abort
+  * Allocate Error flow #2
+  *   alloc_begin
+  *   remove_commit
+  *   alloc_abort
+  * Allocate Error flow #3
+  *   alloc_begin
+  *   alloc_commit (fails)
+  *   remove_commit
+  *   alloc_abort
+  *
+  * In all cases the caller must hold the ufile kref until alloc_commit or
+  * alloc_abort returns.
+  */
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  struct uverbs_obj_type_class {
 +	/*
 +	 * Get an ib_uobject that corresponds to the given id from ucontext,
 +	 * These functions could create or destroy objects if required.
 +	 * The action will be finalized only when commit, abort or put fops are
 +	 * called.
 +	 * The flow of the different actions is:
 +	 * [alloc]:	 Starts with alloc_begin. The handlers logic is than
 +	 *		 executed. If the handler is successful, alloc_commit
 +	 *		 is called and the object is inserted to the repository.
 +	 *		 Once alloc_commit completes the object is visible to
 +	 *		 other threads and userspace.
 +	 e		 Otherwise, alloc_abort is called and the object is
 +	 *		 destroyed.
 +	 * [lookup]:	 Starts with lookup_get which fetches and locks the
 +	 *		 object. After the handler finished using the object, it
 +	 *		 needs to call lookup_put to unlock it. The exclusive
 +	 *		 flag indicates if the object is locked for exclusive
 +	 *		 access.
 +	 * [remove]:	 Starts with lookup_get with exclusive flag set. This
 +	 *		 locks the object for exclusive access. If the handler
 +	 *		 code completed successfully, remove_commit is called
 +	 *		 and the ib_uobject is removed from the context's
 +	 *		 uobjects repository and put. The object itself is
 +	 *		 destroyed as well. Once remove succeeds new krefs to
 +	 *		 the object cannot be acquired by other threads or
 +	 *		 userspace and the hardware driver is removed from the
 +	 *		 object. Other krefs on the object may still exist.
 +	 *		 If the handler code failed, lookup_put should be
 +	 *		 called. This callback is used when the context
 +	 *		 is destroyed as well (process termination,
 +	 *		 reset flow).
 +	 */
  	struct ib_uobject *(*alloc_begin)(const struct uverbs_obj_type *type,
 -					  struct ib_uverbs_file *ufile);
 -	/* This consumes the kref on uobj */
 -	int (*alloc_commit)(struct ib_uobject *uobj);
 -	/* This does not consume the kref on uobj */
 +					  struct ib_ucontext *ucontext);
 +	void (*alloc_commit)(struct ib_uobject *uobj);
  	void (*alloc_abort)(struct ib_uobject *uobj);
  
  	struct ib_uobject *(*lookup_get)(const struct uverbs_obj_type *type,
++<<<<<<< HEAD
 +					 struct ib_ucontext *ucontext, int id,
 +					 bool exclusive);
 +	void (*lookup_put)(struct ib_uobject *uobj, bool exclusive);
 +	/*
 +	 * Must be called with the exclusive lock held. If successful uobj is
 +	 * invalid on return. On failure uobject is left completely
 +	 * unchanged
 +	 */
 +	int __must_check (*remove_commit)(struct ib_uobject *uobj,
 +					  enum rdma_remove_reason why);
++=======
+ 					 struct ib_uverbs_file *ufile, s64 id,
+ 					 enum rdma_lookup_mode mode);
+ 	void (*lookup_put)(struct ib_uobject *uobj, enum rdma_lookup_mode mode);
+ 	/* This does not consume the kref on uobj */
+ 	int __must_check (*destroy_hw)(struct ib_uobject *uobj,
+ 				       enum rdma_remove_reason why);
+ 	void (*remove_handle)(struct ib_uobject *uobj);
++>>>>>>> 0f50d88a6e9a (IB/uverbs: Allow all DESTROY commands to succeed after disassociate)
  	u8    needs_kfree_rcu;
  };
  
* Unmerged path drivers/infiniband/core/rdma_core.c
diff --git a/drivers/infiniband/core/rdma_core.h b/drivers/infiniband/core/rdma_core.h
index a243cc2a59f7..ea24dfa09c2c 100644
--- a/drivers/infiniband/core/rdma_core.h
+++ b/drivers/infiniband/core/rdma_core.h
@@ -113,4 +113,7 @@ int uverbs_finalize_object(struct ib_uobject *uobj,
 			   enum uverbs_obj_access access,
 			   bool commit);
 
+void setup_ufile_idr_uobject(struct ib_uverbs_file *ufile);
+void release_ufile_idr_uobject(struct ib_uverbs_file *ufile);
+
 #endif /* RDMA_CORE_H */
* Unmerged path drivers/infiniband/core/uverbs_main.c
* Unmerged path include/rdma/uverbs_types.h
