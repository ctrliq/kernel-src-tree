IB/uverbs: Rework the locking for cleaning up the ucontext

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Jason Gunthorpe <jgg@mellanox.com>
commit e951747a087a8655f467833bb367ebf53d57527c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/e951747a.failed

The locking here has always been a bit crazy and spread out, upon some
careful analysis we can simplify things.

Create a single function uverbs_destroy_ufile_hw() that internally handles
all locking. This pulls together pieces of this process that were
sprinkled all over the places into one place, and covers them with one
lock.

This eliminates several duplicate/confusing locks and makes the control
flow in ib_uverbs_close() and ib_uverbs_free_hw_resources() extremely
simple.

Unfortunately we have to keep an extra mutex, ucontext_lock.  This lock is
logically part of the rwsem and provides the 'down write, fail if write
locked, wait if read locked' semantic we require.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit e951747a087a8655f467833bb367ebf53d57527c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/rdma_core.c
#	drivers/infiniband/core/rdma_core.h
#	drivers/infiniband/core/uverbs.h
#	drivers/infiniband/core/uverbs_main.c
diff --cc drivers/infiniband/core/rdma_core.c
index 586f179a9de6,eeed6374134c..000000000000
--- a/drivers/infiniband/core/rdma_core.c
+++ b/drivers/infiniband/core/rdma_core.c
@@@ -285,11 -285,8 +286,14 @@@ struct ib_uobject *rdma_lookup_get_uobj
  	}
  
  	ret = uverbs_try_lock_object(uobj, exclusive);
++<<<<<<< HEAD
 +	if (ret) {
 +		WARN(ucontext->cleanup_reason,
 +		     "ib_uverbs: Trying to lookup_get while cleanup context\n");
++=======
+ 	if (ret)
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  		goto free;
- 	}
  
  	return uobj;
  free:
@@@ -648,80 -676,188 +652,244 @@@ unlock
  
  void uverbs_close_fd(struct file *f)
  {
 -	struct ib_uobject *uobj = f->private_data;
 -	struct ib_uverbs_file *ufile = uobj->ufile;
 -
 -	if (down_read_trylock(&ufile->hw_destroy_rwsem)) {
 -		_uverbs_close_fd(uobj);
 -		up_read(&ufile->hw_destroy_rwsem);
 -	}
 +	struct ib_uobject_file *uobj_file = f->private_data;
 +	struct kref *uverbs_file_ref = &uobj_file->ufile->ref;
  
 -	uobj->object = NULL;
 -	/* Matches the get in alloc_begin_fd_uobject */
 -	kref_put(&ufile->ref, ib_uverbs_release_file);
 -
 -	/* Pairs with filp->private_data in alloc_begin_fd_uobject */
 -	uverbs_uobject_put(uobj);
 +	_uverbs_close_fd(uobj_file);
 +	uverbs_uobject_put(&uobj_file->uobj);
 +	kref_put(uverbs_file_ref, ib_uverbs_release_file);
  }
  
++<<<<<<< HEAD
 +void uverbs_cleanup_ucontext(struct ib_ucontext *ucontext, bool device_removed)
 +{
 +	enum rdma_remove_reason reason = device_removed ?
 +		RDMA_REMOVE_DRIVER_REMOVE : RDMA_REMOVE_CLOSE;
 +	unsigned int cur_order = 0;
++=======
+ static void ufile_disassociate_ucontext(struct ib_ucontext *ibcontext)
+ {
+ 	struct ib_device *ib_dev = ibcontext->device;
+ 	struct task_struct *owning_process  = NULL;
+ 	struct mm_struct   *owning_mm       = NULL;
+ 
+ 	owning_process = get_pid_task(ibcontext->tgid, PIDTYPE_PID);
+ 	if (!owning_process)
+ 		return;
+ 
+ 	owning_mm = get_task_mm(owning_process);
+ 	if (!owning_mm) {
+ 		pr_info("no mm, disassociate ucontext is pending task termination\n");
+ 		while (1) {
+ 			put_task_struct(owning_process);
+ 			usleep_range(1000, 2000);
+ 			owning_process = get_pid_task(ibcontext->tgid,
+ 						      PIDTYPE_PID);
+ 			if (!owning_process ||
+ 			    owning_process->state == TASK_DEAD) {
+ 				pr_info("disassociate ucontext done, task was terminated\n");
+ 				/* in case task was dead need to release the
+ 				 * task struct.
+ 				 */
+ 				if (owning_process)
+ 					put_task_struct(owning_process);
+ 				return;
+ 			}
+ 		}
+ 	}
+ 
+ 	down_write(&owning_mm->mmap_sem);
+ 	ib_dev->disassociate_ucontext(ibcontext);
+ 	up_write(&owning_mm->mmap_sem);
+ 	mmput(owning_mm);
+ 	put_task_struct(owning_process);
+ }
+ 
+ /*
+  * Drop the ucontext off the ufile and completely disconnect it from the
+  * ib_device
+  */
+ static void ufile_destroy_ucontext(struct ib_uverbs_file *ufile,
+ 				   enum rdma_remove_reason reason)
+ {
+ 	struct ib_ucontext *ucontext = ufile->ucontext;
+ 	int ret;
+ 
+ 	if (reason == RDMA_REMOVE_DRIVER_REMOVE)
+ 		ufile_disassociate_ucontext(ucontext);
+ 
+ 	put_pid(ucontext->tgid);
+ 	ib_rdmacg_uncharge(&ucontext->cg_obj, ucontext->device,
+ 			   RDMACG_RESOURCE_HCA_HANDLE);
+ 
+ 	/*
+ 	 * FIXME: Drivers are not permitted to fail dealloc_ucontext, remove
+ 	 * the error return.
+ 	 */
+ 	ret = ucontext->device->dealloc_ucontext(ufile->ucontext);
+ 	WARN_ON(ret);
+ 
+ 	ufile->ucontext = NULL;
+ }
+ 
+ static int __uverbs_cleanup_ufile(struct ib_uverbs_file *ufile,
+ 				  enum rdma_remove_reason reason)
+ {
+ 	struct ib_uobject *obj, *next_obj;
+ 	int ret = -EINVAL;
+ 	int err = 0;
+ 
+ 	/*
+ 	 * This shouldn't run while executing other commands on this
+ 	 * context. Thus, the only thing we should take care of is
+ 	 * releasing a FD while traversing this list. The FD could be
+ 	 * closed and released from the _release fop of this FD.
+ 	 * In order to mitigate this, we add a lock.
+ 	 * We take and release the lock per traversal in order to let
+ 	 * other threads (which might still use the FDs) chance to run.
+ 	 */
+ 	list_for_each_entry_safe(obj, next_obj, &ufile->uobjects, list) {
+ 		/*
+ 		 * if we hit this WARN_ON, that means we are
+ 		 * racing with a lookup_get.
+ 		 */
+ 		WARN_ON(uverbs_try_lock_object(obj, true));
+ 		err = obj->type->type_class->remove_commit(obj, reason);
+ 
+ 		if (ib_is_destroy_retryable(err, reason, obj)) {
+ 			pr_debug("ib_uverbs: failed to remove uobject id %d err %d\n",
+ 				 obj->id, err);
+ 			atomic_set(&obj->usecnt, 0);
+ 			continue;
+ 		}
+ 
+ 		if (err)
+ 			pr_err("ib_uverbs: unable to remove uobject id %d err %d\n",
+ 				obj->id, err);
+ 
+ 		list_del(&obj->list);
+ 		/* Pairs with the get in rdma_alloc_commit_uobject() */
+ 		uverbs_uobject_put(obj);
+ 		ret = 0;
+ 	}
+ 	return ret;
+ }
+ 
+ /*
+  * Destroy the uncontext and every uobject associated with it. If called with
+  * reason != RDMA_REMOVE_CLOSE this will not return until the destruction has
+  * been completed and ufile->ucontext is NULL.
+  *
+  * This is internally locked and can be called in parallel from multiple
+  * contexts.
+  */
+ void uverbs_destroy_ufile_hw(struct ib_uverbs_file *ufile,
+ 			     enum rdma_remove_reason reason)
+ {
+ 	if (reason == RDMA_REMOVE_CLOSE) {
+ 		/*
+ 		 * During destruction we might trigger something that
+ 		 * synchronously calls release on any file descriptor. For
+ 		 * this reason all paths that come from file_operations
+ 		 * release must use try_lock. They can progress knowing that
+ 		 * there is an ongoing uverbs_destroy_ufile_hw that will clean
+ 		 * up the driver resources.
+ 		 */
+ 		if (!mutex_trylock(&ufile->ucontext_lock))
+ 			return;
+ 
+ 	} else {
+ 		mutex_lock(&ufile->ucontext_lock);
+ 	}
+ 
+ 	down_write(&ufile->hw_destroy_rwsem);
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  
 +	ucontext->cleanup_reason = reason;
  	/*
- 	 * Waits for all remove_commit and alloc_commit to finish. Logically, We
- 	 * want to hold this forever as the context is going to be destroyed,
- 	 * but we'll release it since it causes a "held lock freed" BUG message.
+ 	 * If a ucontext was never created then we can't have any uobjects to
+ 	 * cleanup, nothing to do.
  	 */
++<<<<<<< HEAD
 +	down_write(&ucontext->cleanup_rwsem);
 +
 +	while (!list_empty(&ucontext->uobjects)) {
 +		struct ib_uobject *obj, *next_obj;
 +		unsigned int next_order = UINT_MAX;
 +
 +		/*
 +		 * This shouldn't run while executing other commands on this
 +		 * context. Thus, the only thing we should take care of is
 +		 * releasing a FD while traversing this list. The FD could be
 +		 * closed and released from the _release fop of this FD.
 +		 * In order to mitigate this, we add a lock.
 +		 * We take and release the lock per order traversal in order
 +		 * to let other threads (which might still use the FDs) chance
 +		 * to run.
 +		 */
 +		mutex_lock(&ucontext->uobjects_lock);
 +		list_for_each_entry_safe(obj, next_obj, &ucontext->uobjects,
 +					 list) {
 +			if (obj->type->destroy_order == cur_order) {
 +				int ret;
 +
 +				/*
 +				 * if we hit this WARN_ON, that means we are
 +				 * racing with a lookup_get.
 +				 */
 +				WARN_ON(uverbs_try_lock_object(obj, true));
 +				ret = obj->type->type_class->remove_commit(obj,
 +									   reason);
 +				list_del(&obj->list);
 +				if (ret)
 +					pr_warn("ib_uverbs: failed to remove uobject id %d order %u\n",
 +						obj->id, cur_order);
 +				/* put the ref we took when we created the object */
 +				uverbs_uobject_put(obj);
 +			} else {
 +				next_order = min(next_order,
 +						 obj->type->destroy_order);
 +			}
 +		}
 +		mutex_unlock(&ucontext->uobjects_lock);
 +		cur_order = next_order;
 +	}
 +	up_write(&ucontext->cleanup_rwsem);
++=======
+ 	if (!ufile->ucontext)
+ 		goto done;
+ 
+ 	ufile->ucontext->closing = true;
+ 	ufile->ucontext->cleanup_retryable = true;
+ 	while (!list_empty(&ufile->uobjects))
+ 		if (__uverbs_cleanup_ufile(ufile, reason)) {
+ 			/*
+ 			 * No entry was cleaned-up successfully during this
+ 			 * iteration
+ 			 */
+ 			break;
+ 		}
+ 
+ 	ufile->ucontext->cleanup_retryable = false;
+ 	if (!list_empty(&ufile->uobjects))
+ 		__uverbs_cleanup_ufile(ufile, reason);
+ 
+ 	ufile_destroy_ucontext(ufile, reason);
+ 
+ done:
+ 	up_write(&ufile->hw_destroy_rwsem);
+ 	mutex_unlock(&ufile->ucontext_lock);
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  }
  
 +void uverbs_initialize_ucontext(struct ib_ucontext *ucontext)
 +{
 +	ucontext->cleanup_reason = 0;
 +	mutex_init(&ucontext->uobjects_lock);
 +	INIT_LIST_HEAD(&ucontext->uobjects);
 +	init_rwsem(&ucontext->cleanup_rwsem);
 +}
 + 
  const struct uverbs_obj_type_class uverbs_fd_class = {
  	.alloc_begin = alloc_begin_fd_uobject,
  	.lookup_get = lookup_get_fd_uobject,
diff --cc drivers/infiniband/core/rdma_core.h
index a243cc2a59f7,a736b46d18e3..000000000000
--- a/drivers/infiniband/core/rdma_core.h
+++ b/drivers/infiniband/core/rdma_core.h
@@@ -48,15 -48,9 +48,21 @@@ const struct uverbs_object_spec *uverbs
  						   uint16_t object);
  const struct uverbs_method_spec *uverbs_get_method(const struct uverbs_object_spec *object,
  						   uint16_t method);
++<<<<<<< HEAD
 +/*
 + * These functions initialize the context and cleanups its uobjects.
 + * The context has a list of objects which is protected by a mutex
 + * on the context. initialize_ucontext should be called when we create
 + * a context.
 + * cleanup_ucontext removes all uobjects from the context and puts them.
 + */
 +void uverbs_cleanup_ucontext(struct ib_ucontext *ucontext, bool device_removed);
 +void uverbs_initialize_ucontext(struct ib_ucontext *ucontext);
++=======
+ 
+ void uverbs_destroy_ufile_hw(struct ib_uverbs_file *ufile,
+ 			     enum rdma_remove_reason reason);
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  
  /*
   * uverbs_uobject_get is called in order to increase the reference count on
diff --cc drivers/infiniband/core/uverbs.h
index cbf36c75d546,ca9b0450d3f9..000000000000
--- a/drivers/infiniband/core/uverbs.h
+++ b/drivers/infiniband/core/uverbs.h
@@@ -145,6 -145,16 +145,19 @@@ struct ib_uverbs_file 
  	struct list_head			list;
  	int					is_closed;
  
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * To access the uobjects list hw_destroy_rwsem must be held for write
+ 	 * OR hw_destroy_rwsem held for read AND uobjects_lock held.
+ 	 * hw_destroy_rwsem should be called across any destruction of the HW
+ 	 * object of an associated uobject.
+ 	 */
+ 	struct rw_semaphore	hw_destroy_rwsem;
+ 	spinlock_t		uobjects_lock;
+ 	struct list_head	uobjects;
+ 
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  	struct idr		idr;
  	/* spinlock protects write access to idr */
  	spinlock_t		idr_lock;
diff --cc drivers/infiniband/core/uverbs_main.c
index 9b53f7b4a4a8,78d79020ea5c..000000000000
--- a/drivers/infiniband/core/uverbs_main.c
+++ b/drivers/infiniband/core/uverbs_main.c
@@@ -226,17 -225,6 +224,20 @@@ void ib_uverbs_detach_umcast(struct ib_
  	}
  }
  
++<<<<<<< HEAD
 +static int ib_uverbs_cleanup_ucontext(struct ib_uverbs_file *file,
 +				      struct ib_ucontext *context,
 +				      bool device_removed)
 +{
 +	context->closing = 1;
 +	uverbs_cleanup_ucontext(context, device_removed);
 +	put_pid(context->tgid);
 +
 +	return context->device->dealloc_ucontext(context);
 +}
 +
++=======
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  static void ib_uverbs_comp_dev(struct ib_uverbs_device *dev)
  {
  	complete(&dev->comp);
@@@ -884,12 -868,13 +885,11 @@@ static int ib_uverbs_open(struct inode 
  	file->device	 = dev;
  	spin_lock_init(&file->idr_lock);
  	idr_init(&file->idr);
 +	file->ucontext	 = NULL;
 +	file->async_file = NULL;
  	kref_init(&file->ref);
- 	mutex_init(&file->mutex);
- 	mutex_init(&file->cleanup_mutex);
+ 	mutex_init(&file->ucontext_lock);
  
 -	spin_lock_init(&file->uobjects_lock);
 -	INIT_LIST_HEAD(&file->uobjects);
 -	init_rwsem(&file->hw_destroy_rwsem);
 -
  	filp->private_data = file;
  	kobject_get(&dev->kobj);
  	list_add_tail(&file->list, &dev->uverbs_file_list);
@@@ -914,12 -899,7 +914,16 @@@ static int ib_uverbs_close(struct inod
  {
  	struct ib_uverbs_file *file = filp->private_data;
  
++<<<<<<< HEAD
 +	mutex_lock(&file->cleanup_mutex);
 +	if (file->ucontext) {
 +		ib_uverbs_cleanup_ucontext(file, file->ucontext, false);
 +		file->ucontext = NULL;
 +	}
 +	mutex_unlock(&file->cleanup_mutex);
++=======
+ 	uverbs_destroy_ufile_hw(file, RDMA_REMOVE_CLOSE);
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  	idr_destroy(&file->idr);
  
  	mutex_lock(&file->device->lists_mutex);
@@@ -1160,33 -1106,19 +1125,44 @@@ static void ib_uverbs_free_hw_resources
  		file->is_closed = 1;
  		list_del(&file->list);
  		kref_get(&file->ref);
+ 
+ 		/* We must release the mutex before going ahead and calling
+ 		 * uverbs_cleanup_ufile, as it might end up indirectly calling
+ 		 * uverbs_close, for example due to freeing the resources (e.g
+ 		 * mmput).
+ 		 */
  		mutex_unlock(&uverbs_dev->lists_mutex);
  
++<<<<<<< HEAD
 +
 +		mutex_lock(&file->cleanup_mutex);
 +		ucontext = file->ucontext;
 +		file->ucontext = NULL;
 +		mutex_unlock(&file->cleanup_mutex);
 +
 +		/* At this point ib_uverbs_close cannot be running
 +		 * ib_uverbs_cleanup_ucontext
 +		 */
 +		if (ucontext) {
 +			/* We must release the mutex before going ahead and
 +			 * calling disassociate_ucontext. disassociate_ucontext
 +			 * might end up indirectly calling uverbs_close,
 +			 * for example due to freeing the resources
 +			 * (e.g mmput).
 +			 */
 +			ib_uverbs_event_handler(&file->event_handler, &event);
 +			ib_uverbs_disassociate_ucontext(ucontext);
 +			mutex_lock(&file->cleanup_mutex);
 +			ib_uverbs_cleanup_ucontext(file, ucontext, true);
 +			mutex_unlock(&file->cleanup_mutex);
 +		}
++=======
+ 		ib_uverbs_event_handler(&file->event_handler, &event);
+ 		uverbs_destroy_ufile_hw(file, RDMA_REMOVE_DRIVER_REMOVE);
+ 		kref_put(&file->ref, ib_uverbs_release_file);
++>>>>>>> e951747a087a (IB/uverbs: Rework the locking for cleaning up the ucontext)
  
  		mutex_lock(&uverbs_dev->lists_mutex);
- 		kref_put(&file->ref, ib_uverbs_release_file);
  	}
  
  	while (!list_empty(&uverbs_dev->uverbs_events_file_list)) {
* Unmerged path drivers/infiniband/core/rdma_core.c
* Unmerged path drivers/infiniband/core/rdma_core.h
* Unmerged path drivers/infiniband/core/uverbs.h
diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c
index f1558e6f86c4..09b1fa24c4a0 100644
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@ -83,7 +83,7 @@ ssize_t ib_uverbs_get_context(struct ib_uverbs_file *file,
 	if (copy_from_user(&cmd, buf, sizeof cmd))
 		return -EFAULT;
 
-	mutex_lock(&file->mutex);
+	mutex_lock(&file->ucontext_lock);
 
 	if (file->ucontext) {
 		ret = -EINVAL;
@@ -144,7 +144,7 @@ ssize_t ib_uverbs_get_context(struct ib_uverbs_file *file,
 
 	fd_install(resp.async_fd, filp);
 
-	mutex_unlock(&file->mutex);
+	mutex_unlock(&file->ucontext_lock);
 
 	return in_len;
 
@@ -160,7 +160,7 @@ err_free:
 	ib_dev->dealloc_ucontext(ucontext);
 
 err:
-	mutex_unlock(&file->mutex);
+	mutex_unlock(&file->ucontext_lock);
 	return ret;
 }
 
* Unmerged path drivers/infiniband/core/uverbs_main.c
diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h
index f069d7abc349..56a32b21fcde 100644
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@ -1456,6 +1456,11 @@ enum rdma_remove_reason {
 struct ib_ucontext {
 	struct ib_device       *device;
 	struct ib_uverbs_file  *ufile;
+	/*
+	 * 'closing' can be read by the driver only during a destroy callback,
+	 * it is set when we are closing the file descriptor and indicates
+	 * that mm_sem may be locked.
+	 */
 	int			closing;
 
 	/* locking the uobjects_list */
