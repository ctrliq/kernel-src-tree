x86/bugs: Make sure MSR_SPEC_CTRL is updated properly upon resume from S3

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-486.el8
commit-author Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
commit 66065157420c5b9b3f078f43d313c153e1ff7f83
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-486.el8/66065157.failed

The "force" argument to write_spec_ctrl_current() is currently ambiguous
as it does not guarantee the MSR write. This is due to the optimization
that writes to the MSR happen only when the new value differs from the
cached value.

This is fine in most cases, but breaks for S3 resume when the cached MSR
value gets out of sync with the hardware MSR value due to S3 resetting
it.

When x86_spec_ctrl_current is same as x86_spec_ctrl_base, the MSR write
is skipped. Which results in SPEC_CTRL mitigations not getting restored.

Move the MSR write from write_spec_ctrl_current() to a new function that
unconditionally writes to the MSR. Update the callers accordingly and
rename functions.

  [ bp: Rework a bit. ]

Fixes: caa0ff24d5d0 ("x86/bugs: Keep a per-CPU IA32_SPEC_CTRL value")
	Suggested-by: Borislav Petkov <bp@alien8.de>
	Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: <stable@kernel.org>
Link: https://lore.kernel.org/r/806d39b0bfec2fe8f50dc5446dff20f5bb24a959.1669821572.git.pawan.kumar.gupta@linux.intel.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 66065157420c5b9b3f078f43d313c153e1ff7f83)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
diff --cc arch/x86/kernel/cpu/bugs.c
index 848a0cce2243,6daf84229548..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -72,11 -80,9 +79,15 @@@ void update_spec_ctrl_cond(u64 val
  
  	/*
  	 * When KERNEL_IBRS this MSR is written on return-to-user, unless
 -	 * forced the update can be delayed until that time.
 +	 * forced or the exit MSR write is skipped the update can be delayed
 +	 * until that time.
  	 */
++<<<<<<< HEAD
 +	if (force || !cpu_feature_enabled(X86_FEATURE_KERNEL_IBRS) ||
 +	    cpu_feature_enabled(X86_FEATURE_IBRS_EXIT_SKIP))
++=======
+ 	if (!cpu_feature_enabled(X86_FEATURE_KERNEL_IBRS))
++>>>>>>> 66065157420c (x86/bugs: Make sure MSR_SPEC_CTRL is updated properly upon resume from S3)
  		wrmsrl(MSR_IA32_SPEC_CTRL, val);
  }
  
diff --git a/arch/x86/include/asm/nospec-branch.h b/arch/x86/include/asm/nospec-branch.h
index 442e62e7be47..53e56fc9cf70 100644
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@ -318,7 +318,7 @@ static inline void indirect_branch_prediction_barrier(void)
 /* The Intel SPEC CTRL MSR base value cache */
 extern u64 x86_spec_ctrl_base;
 DECLARE_PER_CPU(u64, x86_spec_ctrl_current);
-extern void write_spec_ctrl_current(u64 val, bool force);
+extern void update_spec_ctrl_cond(u64 val);
 extern u64 spec_ctrl_current(void);
 
 /*
* Unmerged path arch/x86/kernel/cpu/bugs.c
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index 87bcb25ff8b2..a62f200aa736 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -583,7 +583,7 @@ static __always_inline void __speculation_ctrl_update(unsigned long tifp,
 	}
 
 	if (updmsr)
-		write_spec_ctrl_current(msr, false);
+		update_spec_ctrl_cond(msr);
 }
 
 static unsigned long speculation_ctrl_update_tif(struct task_struct *tsk)
