iomap: pass an iomap_iter to various buffered I/O helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-492.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 1b5c1e36dc0e0f15de9717e81508934cbc3daf15
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-492.el8/1b5c1e36.failed

Pass the iomap_iter structure instead of individual parameters to
various internal helpers for buffered I/O.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Darrick J. Wong <djwong@kernel.org>
	Signed-off-by: Darrick J. Wong <djwong@kernel.org>
(cherry picked from commit 1b5c1e36dc0e0f15de9717e81508934cbc3daf15)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/iomap/buffered-io.c
diff --cc fs/iomap/buffered-io.c
index a9fecbda715a,d6d1fd0208a9..000000000000
--- a/fs/iomap/buffered-io.c
+++ b/fs/iomap/buffered-io.c
@@@ -238,46 -224,48 +239,56 @@@ static loff_t iomap_read_inline_data(st
  	if (WARN_ON_ONCE(size > iomap->length))
  		return -EIO;
  	if (poff > 0)
- 		iomap_page_create(inode, page);
+ 		iomap_page_create(iter->inode, page);
  
 -	addr = kmap_local_page(page) + poff;
 +	addr = kmap_atomic(page) + poff;
  	memcpy(addr, iomap->inline_data, size);
  	memset(addr + size, 0, PAGE_SIZE - poff - size);
 -	kunmap_local(addr);
 +	kunmap_atomic(addr);
  	iomap_set_range_uptodate(page, poff, PAGE_SIZE - poff);
  	return PAGE_SIZE - poff;
  }
  
- static inline bool iomap_block_needs_zeroing(struct inode *inode,
- 		struct iomap *iomap, loff_t pos)
+ static inline bool iomap_block_needs_zeroing(struct iomap_iter *iter,
+ 		loff_t pos)
  {
- 	return iomap->type != IOMAP_MAPPED ||
- 		(iomap->flags & IOMAP_F_NEW) ||
- 		pos >= i_size_read(inode);
+ 	struct iomap *srcmap = iomap_iter_srcmap(iter);
+ 
+ 	return srcmap->type != IOMAP_MAPPED ||
+ 		(srcmap->flags & IOMAP_F_NEW) ||
+ 		pos >= i_size_read(iter->inode);
  }
  
 -static loff_t iomap_readpage_iter(struct iomap_iter *iter,
 -		struct iomap_readpage_ctx *ctx, loff_t offset)
 +static loff_t
 +iomap_readpage_actor(struct inode *inode, loff_t pos, loff_t length, void *data,
 +		struct iomap *iomap, struct iomap *srcmap)
  {
 -	struct iomap *iomap = &iter->iomap;
 -	loff_t pos = iter->pos + offset;
 -	loff_t length = iomap_length(iter) - offset;
 +	struct iomap_readpage_ctx *ctx = data;
  	struct page *page = ctx->cur_page;
  	struct iomap_page *iop;
 +	bool is_contig = false;
  	loff_t orig_pos = pos;
  	unsigned poff, plen;
  	sector_t sector;
  
  	if (iomap->type == IOMAP_INLINE)
++<<<<<<< HEAD
 +		return min(iomap_read_inline_data(inode, page, iomap), length);
++=======
+ 		return min(iomap_read_inline_data(iter, page), length);
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  
  	/* zero post-eof blocks as the page may be mapped */
 -	iop = iomap_page_create(iter->inode, page);
 -	iomap_adjust_read_range(iter->inode, iop, &pos, length, &poff, &plen);
 +	iop = iomap_page_create(inode, page);
 +	iomap_adjust_read_range(inode, iop, &pos, length, &poff, &plen);
  	if (plen == 0)
  		goto done;
  
++<<<<<<< HEAD
 +	if (iomap_block_needs_zeroing(inode, iomap, pos)) {
++=======
+ 	if (iomap_block_needs_zeroing(iter, pos)) {
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  		zero_user(page, poff, plen);
  		iomap_set_range_uptodate(page, poff, plen);
  		goto done;
@@@ -622,21 -581,8 +633,26 @@@ static int __iomap_write_begin(struct i
  	return 0;
  }
  
++<<<<<<< HEAD
 +static void __iomap_put_folio(struct iomap *iomap, struct inode *inode,
 +			      loff_t pos, size_t ret, struct page *page)
 +{
 +	const struct iomap_page_ops *page_ops = iomap->page_ops;
 +
 +	if (page_ops && page_ops->page_done)
 +		page_ops->page_done(inode, pos, ret, page);
 +	else if (page) {
 +		unlock_page(page);
 +		put_page(page);
 +	}
 +}
 +
 +static int iomap_write_begin_inline(struct inode *inode,
 +		struct page *page, struct iomap *srcmap)
++=======
+ static int iomap_write_begin_inline(struct iomap_iter *iter,
+ 		struct page *page)
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  {
  	int ret;
  
@@@ -670,12 -616,11 +686,12 @@@ static int iomap_write_begin(struct iom
  			return status;
  	}
  
- 	page = grab_cache_page_write_begin(inode->i_mapping, pos >> PAGE_SHIFT,
- 			AOP_FLAG_NOFS);
+ 	page = grab_cache_page_write_begin(iter->inode->i_mapping,
+ 				pos >> PAGE_SHIFT, AOP_FLAG_NOFS);
  	if (!page) {
  		status = -ENOMEM;
 -		goto out_no_page;
 +		__iomap_put_folio(iomap, inode, pos, 0, NULL);
 +		return status;
  	}
  
  	if (srcmap->type == IOMAP_INLINE)
@@@ -693,9 -637,13 +708,19 @@@
  	return 0;
  
  out_unlock:
++<<<<<<< HEAD
 +	__iomap_put_folio(iomap, inode, pos, 0, page);
 +	iomap_write_failed(inode, pos, len);
 +
++=======
+ 	unlock_page(page);
+ 	put_page(page);
+ 	iomap_write_failed(iter->inode, pos, len);
+ 
+ out_no_page:
+ 	if (page_ops && page_ops->page_done)
+ 		page_ops->page_done(iter->inode, pos, 0, NULL);
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  	return status;
  }
  
@@@ -756,20 -680,21 +782,25 @@@ static size_t iomap_write_end_inline(st
  	BUG_ON(!iomap_inline_data_valid(iomap));
  
  	flush_dcache_page(page);
 -	addr = kmap_local_page(page) + pos;
 -	memcpy(iomap_inline_data(iomap, pos), addr, copied);
 -	kunmap_local(addr);
 +	addr = kmap_atomic(page);
 +	memcpy(iomap_inline_data(iomap, pos), addr + pos, copied);
 +	kunmap_atomic(addr);
  
- 	mark_inode_dirty(inode);
+ 	mark_inode_dirty(iter->inode);
  	return copied;
  }
  
  /* Returns the number of bytes copied.  May be 0.  Cannot be an errno. */
- static size_t iomap_write_end(struct inode *inode, loff_t pos, size_t len,
- 		size_t copied, struct page *page, struct iomap *iomap,
- 		struct iomap *srcmap)
+ static size_t iomap_write_end(struct iomap_iter *iter, loff_t pos, size_t len,
+ 		size_t copied, struct page *page)
  {
++<<<<<<< HEAD
 +	loff_t old_size = inode->i_size;
++=======
+ 	const struct iomap_page_ops *page_ops = iter->iomap.page_ops;
+ 	struct iomap *srcmap = iomap_iter_srcmap(iter);
+ 	loff_t old_size = iter->inode->i_size;
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  	size_t ret;
  
  	if (srcmap->type == IOMAP_INLINE) {
@@@ -787,16 -712,19 +818,26 @@@
  	 * preferably after I/O completion so that no stale data is exposed.
  	 */
  	if (pos + ret > old_size) {
- 		i_size_write(inode, pos + ret);
- 		iomap->flags |= IOMAP_F_SIZE_CHANGED;
+ 		i_size_write(iter->inode, pos + ret);
+ 		iter->iomap.flags |= IOMAP_F_SIZE_CHANGED;
  	}
 -	unlock_page(page);
 +	__iomap_put_folio(iomap, inode, pos, ret, page);
  
  	if (old_size < pos)
++<<<<<<< HEAD
 +		pagecache_isize_extended(inode, old_size, pos);
 +
 +	if (ret < len)
 +		iomap_write_failed(inode, pos + ret, len - ret);
++=======
+ 		pagecache_isize_extended(iter->inode, old_size, pos);
+ 	if (page_ops && page_ops->page_done)
+ 		page_ops->page_done(iter->inode, pos, ret, page);
+ 	put_page(page);
+ 
+ 	if (ret < len)
+ 		iomap_write_failed(iter->inode, pos, len);
++>>>>>>> 1b5c1e36dc0e (iomap: pass an iomap_iter to various buffered I/O helpers)
  	return ret;
  }
  
@@@ -841,13 -766,14 +879,12 @@@ again
  		if (mapping_writably_mapped(iter->inode->i_mapping))
  			flush_dcache_page(page);
  
 -		copied = copy_page_from_iter_atomic(page, offset, bytes, i);
 +		copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
  
- 		status = iomap_write_end(iter->inode, pos, bytes, copied, page,
- 					 iomap, srcmap);
+ 		status = iomap_write_end(iter, pos, bytes, copied, page);
  
 -		if (unlikely(copied != status))
 -			iov_iter_revert(i, copied - status);
 -
  		cond_resched();
 +
  		if (unlikely(status == 0)) {
  			/*
  			 * A short copy made iomap_write_end() reject the
* Unmerged path fs/iomap/buffered-io.c
