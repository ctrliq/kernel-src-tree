mm/userfaultfd: don't consider uffd-wp bit of writable migration entries

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-514.el8
commit-author David Hildenbrand <david@redhat.com>
commit 27da93d8e6d5633ac065c9316afc0f0240303c0a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-514.el8/27da93d8.failed

If we end up with a writable migration entry that has the uffd-wp bit set,
we already messed up: the source PTE/PMD was writable, which means we
could have modified the page without notifying uffd first.  Setting the
uffd-wp bit always implies converting migration entries to !writable
migration entries.

Commit 8f34f1eac382 ("mm/userfaultfd: fix uffd-wp special cases for
fork()") documents that "3.  Forget to carry over uffd-wp bit for a write
migration huge pmd entry", but it doesn't really say why that should be
relevant.

So let's remove that code to avoid hiding an eventual underlying issue (in
the future, we might want to warn when creating writable migration entries
that have the uffd-wp bit set -- or even better when turning a PTE
writable that still has the uffd-wp bit set).

This now matches the handling for hugetlb migration entries in
hugetlb_change_protection().

In copy_huge_pmd()/copy_nonpresent_pte()/copy_hugetlb_page_range(), we
still transfer the uffd-bit also for writable migration entries, but
simply because we have unified handling for "writable" and
"readable-exclusive" migration entries, and we care about transferring the
uffd-wp bit for the latter.

Link: https://lkml.kernel.org/r/20230405160236.587705-3-david@redhat.com
	Signed-off-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: Peter Xu <peterx@redhat.com>
	Cc: Muhammad Usama Anjum <usama.anjum@collabora.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
(cherry picked from commit 27da93d8e6d5633ac065c9316afc0f0240303c0a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/huge_memory.c
#	mm/mprotect.c
diff --cc mm/huge_memory.c
index 90eefa9de607,0dbce09916c4..000000000000
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@@ -1847,8 -1845,16 +1847,20 @@@ int change_huge_pmd(struct vm_area_stru
  			newpmd = swp_entry_to_pmd(entry);
  			if (pmd_swp_soft_dirty(*pmd))
  				newpmd = pmd_swp_mksoft_dirty(newpmd);
++<<<<<<< HEAD
++=======
+ 		} else {
+ 			newpmd = *pmd;
+ 		}
+ 
+ 		if (uffd_wp)
+ 			newpmd = pmd_swp_mkuffd_wp(newpmd);
+ 		else if (uffd_wp_resolve)
+ 			newpmd = pmd_swp_clear_uffd_wp(newpmd);
+ 		if (!pmd_same(*pmd, newpmd))
++>>>>>>> 27da93d8e6d5 (mm/userfaultfd: don't consider uffd-wp bit of writable migration entries)
  			set_pmd_at(mm, addr, pmd, newpmd);
 +		}
  		goto unlock;
  	}
  #endif
diff --cc mm/mprotect.c
index 87f0e57bbe11,92d3d3ca390a..000000000000
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@@ -152,9 -223,7 +152,13 @@@ static unsigned long change_pte_range(s
  				newpte = swp_entry_to_pte(entry);
  				if (pte_swp_soft_dirty(oldpte))
  					newpte = pte_swp_mksoft_dirty(newpte);
++<<<<<<< HEAD
 +				if (pte_swp_uffd_wp(oldpte))
 +					newpte = pte_swp_mkuffd_wp(newpte);
 +			} else if (is_write_device_private_entry(entry)) {
++=======
+ 			} else if (is_writable_device_private_entry(entry)) {
++>>>>>>> 27da93d8e6d5 (mm/userfaultfd: don't consider uffd-wp bit of writable migration entries)
  				/*
  				 * We do not preserve soft-dirtiness. See
  				 * copy_one_pte() for explanation.
* Unmerged path mm/huge_memory.c
* Unmerged path mm/mprotect.c
