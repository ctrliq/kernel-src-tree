KVM: arm64: Move vGIC v4 handling for WFI out arch callback hook

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-512.el8
commit-author Sean Christopherson <seanjc@google.com>
commit 6109c5a6ab7f38ed8e1beb06a90aa83884c18700
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-512.el8/6109c5a6.failed

Move the put and reload of the vGIC out of the block/unblock callbacks
and into a dedicated WFI helper.  Functionally, this is nearly a nop as
the block hook is called at the very beginning of kvm_vcpu_block(), and
the only code in kvm_vcpu_block() after the unblock hook is to update the
halt-polling controls, i.e. can only affect the next WFI.

Back when the arch (un)blocking hooks were added by commits 3217f7c25bca
("KVM: Add kvm_arch_vcpu_{un}blocking callbacks) and d35268da6687
("arm/arm64: KVM: arch_timer: Only schedule soft timer on vcpu_block"),
the hooks were invoked only when KVM was about to "block", i.e. schedule
out the vCPU.  The use case at the time was to schedule a timer in the
host based on the earliest timer in the guest in order to wake the
blocking vCPU when the emulated guest timer fired.  Commit accb99bcd0ca
("KVM: arm/arm64: Simplify bg_timer programming") reworked the timer
logic to be even more precise, by waiting until the vCPU was actually
scheduled out, and so move the timer logic from the (un)blocking hooks to
vcpu_load/put.

In the meantime, the hooks gained usage for enabling vGIC v4 doorbells in
commit df9ba95993b9 ("KVM: arm/arm64: GICv4: Use the doorbell interrupt
as an unblocking source"), and added related logic for the VMCR in commit
5eeaf10eec39 ("KVM: arm/arm64: Sync ICH_VMCR_EL2 back when about to block").

Finally, commit 07ab0f8d9a12 ("KVM: Call kvm_arch_vcpu_blocking early
into the blocking sequence") hoisted the (un)blocking hooks so that they
wrapped KVM's halt-polling logic in addition to the core "block" logic.

In other words, the original need for arch hooks to take action _only_
in the block path is long since gone.

	Cc: Oliver Upton <oupton@google.com>
	Cc: Marc Zyngier <maz@kernel.org>
	Signed-off-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20211009021236.4122790-11-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 6109c5a6ab7f38ed8e1beb06a90aa83884c18700)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/kvm_emulate.h
#	arch/arm64/kvm/arm.c
#	arch/arm64/kvm/handle_exit.c
diff --cc arch/arm64/include/asm/kvm_emulate.h
index 3f6b515df977,28acc65ccb17..000000000000
--- a/arch/arm64/include/asm/kvm_emulate.h
+++ b/arch/arm64/include/asm/kvm_emulate.h
@@@ -43,12 -40,9 +43,17 @@@ void kvm_inject_undefined(struct kvm_vc
  void kvm_inject_vabt(struct kvm_vcpu *vcpu);
  void kvm_inject_dabt(struct kvm_vcpu *vcpu, unsigned long addr);
  void kvm_inject_pabt(struct kvm_vcpu *vcpu, unsigned long addr);
 -
 +void kvm_inject_undef32(struct kvm_vcpu *vcpu);
 +void kvm_inject_dabt32(struct kvm_vcpu *vcpu, unsigned long addr);
 +void kvm_inject_pabt32(struct kvm_vcpu *vcpu, unsigned long addr);
 +void kvm_inject_size_fault(struct kvm_vcpu *vcpu);
 +
++<<<<<<< HEAD
 +#if defined(__KVM_VHE_HYPERVISOR__) || defined(__KVM_NVHE_HYPERVISOR__)
++=======
+ void kvm_vcpu_wfi(struct kvm_vcpu *vcpu);
+ 
++>>>>>>> 6109c5a6ab7f (KVM: arm64: Move vGIC v4 handling for WFI out arch callback hook)
  static __always_inline bool vcpu_el1_is_32bit(struct kvm_vcpu *vcpu)
  {
  	return !(vcpu->arch.hcr_el2 & HCR_RW);
diff --cc arch/arm64/kvm/arm.c
index ec388a03f14c,ced54a3a3db0..000000000000
--- a/arch/arm64/kvm/arm.c
+++ b/arch/arm64/kvm/arm.c
@@@ -638,6 -656,44 +623,47 @@@ static void vcpu_req_sleep(struct kvm_v
  	smp_rmb();
  }
  
++<<<<<<< HEAD
++=======
+ /**
+  * kvm_vcpu_wfi - emulate Wait-For-Interrupt behavior
+  * @vcpu:	The VCPU pointer
+  *
+  * Suspend execution of a vCPU until a valid wake event is detected, i.e. until
+  * the vCPU is runnable.  The vCPU may or may not be scheduled out, depending
+  * on when a wake event arrives, e.g. there may already be a pending wake event.
+  */
+ void kvm_vcpu_wfi(struct kvm_vcpu *vcpu)
+ {
+ 	/*
+ 	 * Sync back the state of the GIC CPU interface so that we have
+ 	 * the latest PMR and group enables. This ensures that
+ 	 * kvm_arch_vcpu_runnable has up-to-date data to decide whether
+ 	 * we have pending interrupts, e.g. when determining if the
+ 	 * vCPU should block.
+ 	 *
+ 	 * For the same reason, we want to tell GICv4 that we need
+ 	 * doorbells to be signalled, should an interrupt become pending.
+ 	 */
+ 	preempt_disable();
+ 	kvm_vgic_vmcr_sync(vcpu);
+ 	vgic_v4_put(vcpu, true);
+ 	preempt_enable();
+ 
+ 	kvm_vcpu_block(vcpu);
+ 	kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+ 
+ 	preempt_disable();
+ 	vgic_v4_load(vcpu);
+ 	preempt_enable();
+ }
+ 
+ static int kvm_vcpu_initialized(struct kvm_vcpu *vcpu)
+ {
+ 	return vcpu->arch.target >= 0;
+ }
+ 
++>>>>>>> 6109c5a6ab7f (KVM: arm64: Move vGIC v4 handling for WFI out arch callback hook)
  static void check_vcpu_requests(struct kvm_vcpu *vcpu)
  {
  	if (kvm_request_pending(vcpu)) {
diff --cc arch/arm64/kvm/handle_exit.c
index 5bc737ece4f7,4794563a506b..000000000000
--- a/arch/arm64/kvm/handle_exit.c
+++ b/arch/arm64/kvm/handle_exit.c
@@@ -107,11 -95,10 +107,15 @@@ static int kvm_handle_wfx(struct kvm_vc
  	} else {
  		trace_kvm_wfx_arm64(*vcpu_pc(vcpu), false);
  		vcpu->stat.wfi_exit_stat++;
++<<<<<<< HEAD
 +		kvm_vcpu_halt(vcpu);
 +		kvm_clear_request(KVM_REQ_UNHALT, vcpu);
++=======
+ 		kvm_vcpu_wfi(vcpu);
++>>>>>>> 6109c5a6ab7f (KVM: arm64: Move vGIC v4 handling for WFI out arch callback hook)
  	}
  
 -	kvm_incr_pc(vcpu);
 +	kvm_skip_instr(vcpu, kvm_vcpu_trap_il_is32bit(vcpu));
  
  	return 1;
  }
* Unmerged path arch/arm64/include/asm/kvm_emulate.h
* Unmerged path arch/arm64/kvm/arm.c
* Unmerged path arch/arm64/kvm/handle_exit.c
