net/mlx5: Lock mlx5 devlink reload callbacks

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-477.10.1.el8_8
commit-author Moshe Shemesh <moshe@nvidia.com>
commit 84a433a40d0ebf3bbf36b8bfa58c6f45dc782344
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-477.10.1.el8_8/84a433a4.failed

Change devlink instance locks in mlx5 driver to have devlink reload
callbacks locked, while keeping all driver paths which lead to devl_ API
functions called by the driver locked.

Add mlx5_load_one_devl_locked() and mlx5_unload_one_devl_locked() which
are used by the paths which are already locked such as devlink reload
callbacks.

This patch makes the driver use devl_ API also for traps register as
these functions are called from the driver paths parallel to reload that
requires locking now.

	Signed-off-by: Moshe Shemesh <moshe@nvidia.com>
	Reviewed-by: Jiri Pirko <jiri@nvidia.com>
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 84a433a40d0ebf3bbf36b8bfa58c6f45dc782344)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/dev.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/dev.c
index 50422b56a64d,0571e40c6ee5..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/dev.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/dev.c
@@@ -340,8 -340,10 +340,12 @@@ int mlx5_attach_device(struct mlx5_core
  	struct auxiliary_driver *adrv;
  	int ret = 0, i;
  
++<<<<<<< HEAD
++=======
+ 	devl_assert_locked(priv_to_devlink(dev));
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  	mutex_lock(&mlx5_intf_mutex);
  	priv->flags &= ~MLX5_PRIV_FLAGS_DETACH;
 -	priv->flags |= MLX5_PRIV_FLAGS_MLX5E_LOCKED_FLOW;
  	for (i = 0; i < ARRAY_SIZE(mlx5_adev_devices); i++) {
  		if (!priv->adev[i]) {
  			bool is_supported = false;
@@@ -401,7 -404,9 +405,11 @@@ void mlx5_detach_device(struct mlx5_cor
  	pm_message_t pm = {};
  	int i;
  
++<<<<<<< HEAD
++=======
+ 	devl_assert_locked(priv_to_devlink(dev));
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  	mutex_lock(&mlx5_intf_mutex);
 -	priv->flags |= MLX5_PRIV_FLAGS_MLX5E_LOCKED_FLOW;
  	for (i = ARRAY_SIZE(mlx5_adev_devices) - 1; i >= 0; i--) {
  		if (!priv->adev[i])
  			continue;
@@@ -438,6 -444,7 +446,10 @@@ int mlx5_register_device(struct mlx5_co
  {
  	int ret;
  
++<<<<<<< HEAD
++=======
+ 	devl_assert_locked(priv_to_devlink(dev));
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  	mutex_lock(&mlx5_intf_mutex);
  	dev->priv.flags &= ~MLX5_PRIV_FLAGS_DISABLE_ALL_ADEV;
  	ret = mlx5_rescan_drivers_locked(dev);
@@@ -450,6 -457,7 +462,10 @@@
  
  void mlx5_unregister_device(struct mlx5_core_dev *dev)
  {
++<<<<<<< HEAD
++=======
+ 	devl_assert_locked(priv_to_devlink(dev));
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  	mutex_lock(&mlx5_intf_mutex);
  	dev->priv.flags = MLX5_PRIV_FLAGS_DISABLE_ALL_ADEV;
  	mlx5_rescan_drivers_locked(dev);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index b4f03e2a26bb,6aa58044b949..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1314,7 -1306,9 +1314,13 @@@ int mlx5_eswitch_enable(struct mlx5_esw
  	if (!mlx5_esw_allowed(esw))
  		return 0;
  
++<<<<<<< HEAD
 +	toggle_lag = esw->mode == MLX5_ESWITCH_NONE;
++=======
+ 	devl_assert_locked(priv_to_devlink(esw->dev));
+ 
+ 	toggle_lag = !mlx5_esw_is_fdb_created(esw);
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  
  	if (toggle_lag)
  		mlx5_lag_disable_change(esw->dev);
@@@ -1339,15 -1333,56 +1345,59 @@@
  	return ret;
  }
  
++<<<<<<< HEAD
 +void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw, bool clear_vf)
++=======
+ /* When disabling sriov, free driver level resources. */
+ void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw, bool clear_vf)
+ {
+ 	if (!mlx5_esw_allowed(esw))
+ 		return;
+ 
+ 	devl_assert_locked(priv_to_devlink(esw->dev));
+ 	down_write(&esw->mode_lock);
+ 	/* If driver is unloaded, this function is called twice by remove_one()
+ 	 * and mlx5_unload(). Prevent the second call.
+ 	 */
+ 	if (!esw->esw_funcs.num_vfs && !clear_vf)
+ 		goto unlock;
+ 
+ 	esw_info(esw->dev, "Unload vfs: mode(%s), nvfs(%d), active vports(%d)\n",
+ 		 esw->mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
+ 		 esw->esw_funcs.num_vfs, esw->enabled_vports);
+ 
+ 	mlx5_eswitch_unload_vf_vports(esw, esw->esw_funcs.num_vfs);
+ 	if (clear_vf)
+ 		mlx5_eswitch_clear_vf_vports_info(esw);
+ 	/* If disabling sriov in switchdev mode, free meta rules here
+ 	 * because it depends on num_vfs.
+ 	 */
+ 	if (esw->mode == MLX5_ESWITCH_OFFLOADS) {
+ 		struct devlink *devlink = priv_to_devlink(esw->dev);
+ 
+ 		esw_offloads_del_send_to_vport_meta_rules(esw);
+ 		devl_rate_nodes_destroy(devlink);
+ 	}
+ 
+ 	esw->esw_funcs.num_vfs = 0;
+ 
+ unlock:
+ 	up_write(&esw->mode_lock);
+ }
+ 
+ /* Free resources for corresponding eswitch mode. It is called by devlink
+  * when changing eswitch mode or modprobe when unloading driver.
+  */
+ void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw)
++>>>>>>> 84a433a40d0e (net/mlx5: Lock mlx5 devlink reload callbacks)
  {
  	struct devlink *devlink = priv_to_devlink(esw->dev);
 +	int old_mode;
  
 -	/* Notify eswitch users that it is exiting from current mode.
 -	 * So that it can do necessary cleanup before the eswitch is disabled.
 -	 */
 -	mlx5_esw_mode_change_notify(esw, MLX5_ESWITCH_LEGACY);
 +	lockdep_assert_held_exclusive(&esw->mode_lock);
  
 -	mlx5_eswitch_event_handlers_unregister(esw);
 +	if (esw->mode == MLX5_ESWITCH_NONE)
 +		return;
  
  	esw_info(esw->dev, "Disable: mode(%s), nvfs(%d), active vports(%d)\n",
  		 esw->mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
@@@ -1384,10 -1404,10 +1434,11 @@@ void mlx5_eswitch_disable(struct mlx5_e
  	if (!mlx5_esw_allowed(esw))
  		return;
  
+ 	devl_assert_locked(priv_to_devlink(esw->dev));
  	mlx5_lag_disable_change(esw->dev);
  	down_write(&esw->mode_lock);
 -	mlx5_eswitch_disable_locked(esw);
 +	mlx5_eswitch_disable_locked(esw, clear_vf);
 +	esw->esw_funcs.num_vfs = 0;
  	up_write(&esw->mode_lock);
  	mlx5_lag_enable_change(esw->dev);
  }
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/dev.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/devlink.c b/drivers/net/ethernet/mellanox/mlx5/core/devlink.c
index 41bb50d94caa..1c05a7091698 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/devlink.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/devlink.c
@@ -108,7 +108,7 @@ static int mlx5_devlink_reload_fw_activate(struct devlink *devlink, struct netli
 	if (err)
 		return err;
 
-	mlx5_unload_one(dev);
+	mlx5_unload_one_devl_locked(dev);
 	err = mlx5_health_wait_pci_up(dev);
 	if (err)
 		NL_SET_ERR_MSG_MOD(extack, "FW activate aborted, PCI reads fail after reset");
@@ -143,6 +143,7 @@ static int mlx5_devlink_reload_down(struct devlink *devlink, bool netns_change,
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct pci_dev *pdev = dev->pdev;
 	bool sf_dev_allocated;
+	int ret = 0;
 
 	sf_dev_allocated = mlx5_sf_dev_allocated(dev);
 	if (sf_dev_allocated) {
@@ -163,19 +164,25 @@ static int mlx5_devlink_reload_down(struct devlink *devlink, bool netns_change,
 		NL_SET_ERR_MSG_MOD(extack, "reload while VFs are present is unfavorable");
 	}
 
+	devl_lock(devlink);
 	switch (action) {
 	case DEVLINK_RELOAD_ACTION_DRIVER_REINIT:
-		mlx5_unload_one(dev);
-		return 0;
+		mlx5_unload_one_devl_locked(dev);
+		break;
 	case DEVLINK_RELOAD_ACTION_FW_ACTIVATE:
 		if (limit == DEVLINK_RELOAD_LIMIT_NO_RESET)
-			return mlx5_devlink_trigger_fw_live_patch(devlink, extack);
-		return mlx5_devlink_reload_fw_activate(devlink, extack);
+			ret = mlx5_devlink_trigger_fw_live_patch(devlink, extack);
+		else
+			ret = mlx5_devlink_reload_fw_activate(devlink, extack);
+		break;
 	default:
 		/* Unsupported action should not get to this function */
 		WARN_ON(1);
-		return -EOPNOTSUPP;
+		ret = -EOPNOTSUPP;
 	}
+
+	devl_unlock(devlink);
+	return ret;
 }
 
 static int mlx5_devlink_reload_up(struct devlink *devlink, enum devlink_reload_action action,
@@ -183,24 +190,29 @@ static int mlx5_devlink_reload_up(struct devlink *devlink, enum devlink_reload_a
 				  struct netlink_ext_ack *extack)
 {
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
+	int ret = 0;
 
+	devl_lock(devlink);
 	*actions_performed = BIT(action);
 	switch (action) {
 	case DEVLINK_RELOAD_ACTION_DRIVER_REINIT:
-		return mlx5_load_one(dev, false);
+		ret = mlx5_load_one_devl_locked(dev, false);
+		break;
 	case DEVLINK_RELOAD_ACTION_FW_ACTIVATE:
 		if (limit == DEVLINK_RELOAD_LIMIT_NO_RESET)
 			break;
 		/* On fw_activate action, also driver is reloaded and reinit performed */
 		*actions_performed |= BIT(DEVLINK_RELOAD_ACTION_DRIVER_REINIT);
-		return mlx5_load_one(dev, false);
+		ret = mlx5_load_one_devl_locked(dev, false);
+		break;
 	default:
 		/* Unsupported action should not get to this function */
 		WARN_ON(1);
-		return -EOPNOTSUPP;
+		ret = -EOPNOTSUPP;
 	}
 
-	return 0;
+	devl_unlock(devlink);
+	return ret;
 }
 
 static struct mlx5_devlink_trap *mlx5_find_trap_by_id(struct mlx5_core_dev *dev, int trap_id)
@@ -837,28 +849,28 @@ static int mlx5_devlink_traps_register(struct devlink *devlink)
 	struct mlx5_core_dev *core_dev = devlink_priv(devlink);
 	int err;
 
-	err = devlink_trap_groups_register(devlink, mlx5_trap_groups_arr,
-					   ARRAY_SIZE(mlx5_trap_groups_arr));
+	err = devl_trap_groups_register(devlink, mlx5_trap_groups_arr,
+					ARRAY_SIZE(mlx5_trap_groups_arr));
 	if (err)
 		return err;
 
-	err = devlink_traps_register(devlink, mlx5_traps_arr, ARRAY_SIZE(mlx5_traps_arr),
-				     &core_dev->priv);
+	err = devl_traps_register(devlink, mlx5_traps_arr, ARRAY_SIZE(mlx5_traps_arr),
+				  &core_dev->priv);
 	if (err)
 		goto err_trap_group;
 	return 0;
 
 err_trap_group:
-	devlink_trap_groups_unregister(devlink, mlx5_trap_groups_arr,
-				       ARRAY_SIZE(mlx5_trap_groups_arr));
+	devl_trap_groups_unregister(devlink, mlx5_trap_groups_arr,
+				    ARRAY_SIZE(mlx5_trap_groups_arr));
 	return err;
 }
 
 static void mlx5_devlink_traps_unregister(struct devlink *devlink)
 {
-	devlink_traps_unregister(devlink, mlx5_traps_arr, ARRAY_SIZE(mlx5_traps_arr));
-	devlink_trap_groups_unregister(devlink, mlx5_trap_groups_arr,
-				       ARRAY_SIZE(mlx5_trap_groups_arr));
+	devl_traps_unregister(devlink, mlx5_traps_arr, ARRAY_SIZE(mlx5_traps_arr));
+	devl_trap_groups_unregister(devlink, mlx5_trap_groups_arr,
+				    ARRAY_SIZE(mlx5_trap_groups_arr));
 }
 
 int mlx5_devlink_register(struct devlink *devlink)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/main.c b/drivers/net/ethernet/mellanox/mlx5/core/main.c
index 7115a1abd474..a8b01cd3de0a 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@ -1324,8 +1324,10 @@ static void mlx5_unload(struct mlx5_core_dev *dev)
 
 int mlx5_init_one(struct mlx5_core_dev *dev)
 {
+	struct devlink *devlink = priv_to_devlink(dev);
 	int err = 0;
 
+	devl_lock(devlink);
 	mutex_lock(&dev->intf_state_mutex);
 	dev->state = MLX5_DEVICE_STATE_UP;
 
@@ -1354,6 +1356,7 @@ int mlx5_init_one(struct mlx5_core_dev *dev)
 		goto err_register;
 
 	mutex_unlock(&dev->intf_state_mutex);
+	devl_unlock(devlink);
 	return 0;
 
 err_register:
@@ -1368,11 +1371,15 @@ int mlx5_init_one(struct mlx5_core_dev *dev)
 err_function:
 	dev->state = MLX5_DEVICE_STATE_INTERNAL_ERROR;
 	mutex_unlock(&dev->intf_state_mutex);
+	devl_unlock(devlink);
 	return err;
 }
 
 void mlx5_uninit_one(struct mlx5_core_dev *dev)
 {
+	struct devlink *devlink = priv_to_devlink(dev);
+
+	devl_lock(devlink);
 	mutex_lock(&dev->intf_state_mutex);
 
 	mlx5_unregister_device(dev);
@@ -1391,13 +1398,15 @@ void mlx5_uninit_one(struct mlx5_core_dev *dev)
 	mlx5_function_teardown(dev, true);
 out:
 	mutex_unlock(&dev->intf_state_mutex);
+	devl_unlock(devlink);
 }
 
-int mlx5_load_one(struct mlx5_core_dev *dev, bool recovery)
+int mlx5_load_one_devl_locked(struct mlx5_core_dev *dev, bool recovery)
 {
 	int err = 0;
 	u64 timeout;
 
+	devl_assert_locked(priv_to_devlink(dev));
 	mutex_lock(&dev->intf_state_mutex);
 	if (test_bit(MLX5_INTERFACE_STATE_UP, &dev->intf_state)) {
 		mlx5_core_warn(dev, "interface is up, NOP\n");
@@ -1439,8 +1448,20 @@ int mlx5_load_one(struct mlx5_core_dev *dev, bool recovery)
 	return err;
 }
 
-void mlx5_unload_one(struct mlx5_core_dev *dev)
+int mlx5_load_one(struct mlx5_core_dev *dev, bool recovery)
 {
+	struct devlink *devlink = priv_to_devlink(dev);
+	int ret;
+
+	devl_lock(devlink);
+	ret = mlx5_load_one_devl_locked(dev, recovery);
+	devl_unlock(devlink);
+	return ret;
+}
+
+void mlx5_unload_one_devl_locked(struct mlx5_core_dev *dev)
+{
+	devl_assert_locked(priv_to_devlink(dev));
 	mutex_lock(&dev->intf_state_mutex);
 
 	mlx5_detach_device(dev);
@@ -1458,6 +1479,15 @@ void mlx5_unload_one(struct mlx5_core_dev *dev)
 	mutex_unlock(&dev->intf_state_mutex);
 }
 
+void mlx5_unload_one(struct mlx5_core_dev *dev)
+{
+	struct devlink *devlink = priv_to_devlink(dev);
+
+	devl_lock(devlink);
+	mlx5_unload_one_devl_locked(dev);
+	devl_unlock(devlink);
+}
+
 static const int types[] = {
 	MLX5_CAP_GENERAL,
 	MLX5_CAP_GENERAL_2,
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
index b0b468ba768d..6334743c46ef 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
@@ -273,7 +273,9 @@ void mlx5_mdev_uninit(struct mlx5_core_dev *dev);
 int mlx5_init_one(struct mlx5_core_dev *dev);
 void mlx5_uninit_one(struct mlx5_core_dev *dev);
 void mlx5_unload_one(struct mlx5_core_dev *dev);
+void mlx5_unload_one_devl_locked(struct mlx5_core_dev *dev);
 int mlx5_load_one(struct mlx5_core_dev *dev, bool recovery);
+int mlx5_load_one_devl_locked(struct mlx5_core_dev *dev, bool recovery);
 
 int mlx5_vport_get_other_func_cap(struct mlx5_core_dev *dev, u16 function_id, void *out);
 
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/sriov.c b/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
index 2935614f6fa9..1e61d0497465 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/sriov.c
@@ -155,13 +155,16 @@ mlx5_device_disable_sriov(struct mlx5_core_dev *dev, int num_vfs, bool clear_vf)
 static int mlx5_sriov_enable(struct pci_dev *pdev, int num_vfs)
 {
 	struct mlx5_core_dev *dev  = pci_get_drvdata(pdev);
+	struct devlink *devlink = priv_to_devlink(dev);
 	int err;
 
+	devl_lock(devlink);
 	err = mlx5_device_enable_sriov(dev, num_vfs);
 	if (err) {
 		mlx5_core_warn(dev, "mlx5_device_enable_sriov failed : %d\n", err);
 		return err;
 	}
+	devl_unlock(devlink);
 
 	err = pci_enable_sriov(pdev, num_vfs);
 	if (err) {
@@ -174,10 +177,13 @@ static int mlx5_sriov_enable(struct pci_dev *pdev, int num_vfs)
 void mlx5_sriov_disable(struct pci_dev *pdev)
 {
 	struct mlx5_core_dev *dev  = pci_get_drvdata(pdev);
+	struct devlink *devlink = priv_to_devlink(dev);
 	int num_vfs = pci_num_vf(dev->pdev);
 
 	pci_disable_sriov(pdev);
+	devl_lock(devlink);
 	mlx5_device_disable_sriov(dev, num_vfs, true);
+	devl_unlock(devlink);
 }
 
 int mlx5_core_sriov_configure(struct pci_dev *pdev, int num_vfs)
