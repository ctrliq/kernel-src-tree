scsi: fnic: Code cleanup

jira LE-4311
Rebuild_History Non-Buildable kernel-5.14.0-570.46.1.el9_6
commit-author Karan Tilak Kumar <kartilak@cisco.com>
commit 7e6886b705fd8b338dbd4b7492bd45f0259cc55f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-5.14.0-570.46.1.el9_6/7e6886b7.failed

Replace existing host structure with fnic host.

Add headers from scsi to support new functionality.

Remove unused code and declarations.

	Reviewed-by: Sesidhar Baddela <sebaddel@cisco.com>
	Reviewed-by: Arulprabhu Ponnusamy <arulponn@cisco.com>
	Reviewed-by: Gian Carlo Boffa <gcboffa@cisco.com>
	Signed-off-by: Karan Tilak Kumar <kartilak@cisco.com>
Link: https://lore.kernel.org/r/20241212020312.4786-14-kartilak@cisco.com
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 7e6886b705fd8b338dbd4b7492bd45f0259cc55f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/fnic/fdls_disc.c
#	drivers/scsi/fnic/fip.c
#	drivers/scsi/fnic/fip.h
#	drivers/scsi/fnic/fnic.h
#	drivers/scsi/fnic/fnic_fcs.c
#	drivers/scsi/fnic/fnic_main.c
#	drivers/scsi/fnic/fnic_scsi.c
diff --cc drivers/scsi/fnic/fnic.h
index 73fb8245c7b7,b02459b6ec2f..000000000000
--- a/drivers/scsi/fnic/fnic.h
+++ b/drivers/scsi/fnic/fnic.h
@@@ -22,8 -10,10 +22,15 @@@
  #include <linux/netdevice.h>
  #include <linux/workqueue.h>
  #include <linux/bitops.h>
++<<<<<<< HEAD
 +#include <scsi/libfc.h>
 +#include <scsi/libfcoe.h>
++=======
+ #include <scsi/scsi_cmnd.h>
+ #include <scsi/scsi_transport.h>
+ #include <scsi/scsi_transport_fc.h>
+ #include <scsi/fc_frame.h>
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  #include "fnic_io.h"
  #include "fnic_res.h"
  #include "fnic_trace.h"
@@@ -229,8 -341,9 +236,14 @@@ struct fnic_cpy_wq 
  /* Per-instance private data structure */
  struct fnic {
  	int fnic_num;
++<<<<<<< HEAD
 +	struct fc_lport *lport;
 +	struct fcoe_ctlr ctlr;		/* FIP FCoE controller structure */
++=======
+ 	enum fnic_role_e role;
+ 	struct fnic_iport_s iport;
+ 	struct Scsi_Host *host;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	struct vnic_dev_bar bar0;
  
  	struct fnic_msix_entry msix[FNIC_MSIX_INTR_MAX];
@@@ -259,10 -376,9 +272,7 @@@
  	u32 vlan_hw_insert:1;	        /* let hw insert the tag */
  	u32 in_remove:1;                /* fnic device in removal */
  	u32 stop_rx_link_events:1;      /* stop proc. rx frames, link events */
- 	u32 link_events:1;              /* set when we get any link event*/
- 
- 	struct completion *remove_wait; /* device remove thread blocks */
  
 -	struct completion *fw_reset_done;
 -	u32 reset_in_progress;
  	atomic_t in_flight;		/* io counter */
  	bool internal_reset_inprogress;
  	u32 _reserved;			/* fill hole */
@@@ -398,4 -519,90 +408,93 @@@ fnic_chk_state_flags_locked(struct fni
  }
  void __fnic_set_state_flags(struct fnic *, unsigned long, unsigned long);
  void fnic_dump_fchost_stats(struct Scsi_Host *, struct fc_host_statistics *);
++<<<<<<< HEAD
++=======
+ void fnic_free_txq(struct list_head *head);
+ int fnic_get_desc_by_devid(struct pci_dev *pdev, char **desc,
+ 						   char **subsys_desc);
+ void fnic_fdls_link_status_change(struct fnic *fnic, int linkup);
+ void fnic_delete_fcp_tports(struct fnic *fnic);
+ void fnic_flush_tport_event_list(struct fnic *fnic);
+ int fnic_count_ioreqs_wq(struct fnic *fnic, u32 hwq, u32 portid);
+ unsigned int fnic_count_ioreqs(struct fnic *fnic, u32 portid);
+ unsigned int fnic_count_all_ioreqs(struct fnic *fnic);
+ unsigned int fnic_count_lun_ioreqs_wq(struct fnic *fnic, u32 hwq,
+ 						  struct scsi_device *device);
+ unsigned int fnic_count_lun_ioreqs(struct fnic *fnic,
+ 					   struct scsi_device *device);
+ void fnic_scsi_unload(struct fnic *fnic);
+ void fnic_scsi_unload_cleanup(struct fnic *fnic);
+ int fnic_get_debug_info(struct stats_debug_info *info,
+ 			struct fnic *fnic);
+ 
+ struct fnic_scsi_iter_data {
+ 	struct fnic *fnic;
+ 	void *data1;
+ 	void *data2;
+ 	bool (*fn)(struct fnic *fnic, struct scsi_cmnd *sc,
+ 			void *data1, void *data2);
+ };
+ 
+ static inline bool
+ fnic_io_iter_handler(struct scsi_cmnd *sc, void *iter_data)
+ {
+ 	struct fnic_scsi_iter_data *iter = iter_data;
+ 
+ 	return iter->fn(iter->fnic, sc, iter->data1, iter->data2);
+ }
+ 
+ static inline void
+ fnic_scsi_io_iter(struct fnic *fnic,
+ 		bool (*fn)(struct fnic *fnic, struct scsi_cmnd *sc,
+ 				void *data1, void *data2),
+ 		void *data1, void *data2)
+ {
+ 	struct fnic_scsi_iter_data iter_data = {
+ 		.fn = fn,
+ 		.fnic = fnic,
+ 		.data1 = data1,
+ 		.data2 = data2,
+ 	};
+ 	scsi_host_busy_iter(fnic->host, fnic_io_iter_handler, &iter_data);
+ }
+ 
+ #ifdef FNIC_DEBUG
+ static inline void
+ fnic_debug_dump(struct fnic *fnic, uint8_t *u8arr, int len)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < len; i = i+8) {
+ 		FNIC_FCS_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		    "%d: %02x %02x %02x %02x %02x %02x %02x %02x", i / 8,
+ 		    u8arr[i + 0], u8arr[i + 1], u8arr[i + 2], u8arr[i + 3],
+ 		    u8arr[i + 4], u8arr[i + 5], u8arr[i + 6], u8arr[i + 7]);
+ 	}
+ }
+ 
+ static inline void
+ fnic_debug_dump_fc_frame(struct fnic *fnic, struct fc_frame_header *fchdr,
+ 				int len, char *pfx)
+ {
+ 	uint32_t s_id, d_id;
+ 
+ 	s_id = ntoh24(fchdr->fh_s_id);
+ 	d_id = ntoh24(fchdr->fh_d_id);
+ 	FNIC_FCS_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		"%s packet contents: sid/did/type/oxid = 0x%x/0x%x/0x%x/0x%x (len = %d)\n",
+ 		pfx, s_id, d_id, fchdr->fh_type,
+ 		FNIC_STD_GET_OX_ID(fchdr), len);
+ 
+ 	fnic_debug_dump(fnic, (uint8_t *)fchdr, len);
+ 
+ }
+ #else /* FNIC_DEBUG */
+ static inline void
+ fnic_debug_dump(struct fnic *fnic, uint8_t *u8arr, int len) {}
+ static inline void
+ fnic_debug_dump_fc_frame(struct fnic *fnic, struct fc_frame_header *fchdr,
+ 				uint32_t len, char *pfx) {}
+ #endif /* FNIC_DEBUG */
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  #endif /* _FNIC_H_ */
diff --cc drivers/scsi/fnic/fnic_fcs.c
index 8c3b350695e3,086b92578624..000000000000
--- a/drivers/scsi/fnic/fnic_fcs.c
+++ b/drivers/scsi/fnic/fnic_fcs.c
@@@ -26,40 -14,183 +26,203 @@@
  #include <linux/workqueue.h>
  #include <scsi/fc/fc_fip.h>
  #include <scsi/fc/fc_els.h>
 +#include <scsi/fc/fc_fcoe.h>
  #include <scsi/fc_frame.h>
++<<<<<<< HEAD
 +#include <scsi/libfc.h>
++=======
+ #include <linux/etherdevice.h>
+ #include <scsi/scsi_transport_fc.h>
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  #include "fnic_io.h"
  #include "fnic.h"
 -#include "fnic_fdls.h"
 -#include "fdls_fc.h"
 +#include "fnic_fip.h"
  #include "cq_enet_desc.h"
  #include "cq_exch_desc.h"
 -#include "fip.h"
 -
 -#define MAX_RESET_WAIT_COUNT    64
  
 -extern struct workqueue_struct *fnic_fip_queue;
 +static u8 fcoe_all_fcfs[ETH_ALEN] = FIP_ALL_FCF_MACS;
 +struct workqueue_struct *fnic_fip_queue;
  struct workqueue_struct *fnic_event_queue;
  
++<<<<<<< HEAD
 +static void fnic_set_eth_mode(struct fnic *);
 +static void fnic_fcoe_send_vlan_req(struct fnic *fnic);
 +static void fnic_fcoe_start_fcf_disc(struct fnic *fnic);
 +static void fnic_fcoe_process_vlan_resp(struct fnic *fnic, struct sk_buff *);
 +static int fnic_fcoe_vlan_check(struct fnic *fnic, u16 flag);
 +static int fnic_fcoe_handle_fip_frame(struct fnic *fnic, struct sk_buff *skb);
++=======
+ static uint8_t FCOE_ALL_FCF_MAC[6] = FC_FCOE_FLOGI_MAC;
+ 
+ /*
+  * Internal Functions
+  * This function will initialize the src_mac address to be
+  * used in outgoing frames
+  */
+ static inline void fnic_fdls_set_fcoe_srcmac(struct fnic *fnic,
+ 							 uint8_t *src_mac)
+ {
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Setting src mac: %02x:%02x:%02x:%02x:%02x:%02x",
+ 				 src_mac[0], src_mac[1], src_mac[2], src_mac[3],
+ 				 src_mac[4], src_mac[5]);
+ 
+ 	memcpy(fnic->iport.fpma, src_mac, 6);
+ }
+ 
+ /*
+  * This function will initialize the dst_mac address to be
+  * used in outgoing frames
+  */
+ static inline  void fnic_fdls_set_fcoe_dstmac(struct fnic *fnic,
+ 							 uint8_t *dst_mac)
+ {
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Setting dst mac: %02x:%02x:%02x:%02x:%02x:%02x",
+ 				 dst_mac[0], dst_mac[1], dst_mac[2], dst_mac[3],
+ 				 dst_mac[4], dst_mac[5]);
+ 
+ 	memcpy(fnic->iport.fcfmac, dst_mac, 6);
+ }
+ 
+ void fnic_get_host_port_state(struct Scsi_Host *shost)
+ {
+ 	struct fnic *fnic = *((struct fnic **) shost_priv(shost));
+ 	struct fnic_iport_s *iport = &fnic->iport;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	if (!fnic->link_status)
+ 		fc_host_port_state(shost) = FC_PORTSTATE_LINKDOWN;
+ 	else if (iport->state == FNIC_IPORT_STATE_READY)
+ 		fc_host_port_state(shost) = FC_PORTSTATE_ONLINE;
+ 	else
+ 		fc_host_port_state(shost) = FC_PORTSTATE_OFFLINE;
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ }
+ 
+ void fnic_fdls_link_status_change(struct fnic *fnic, int linkup)
+ {
+ 	struct fnic_iport_s *iport = &fnic->iport;
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "link up: %d, usefip: %d", linkup, iport->usefip);
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
+ 
+ 	if (linkup) {
+ 		if (iport->usefip) {
+ 			iport->state = FNIC_IPORT_STATE_FIP;
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "link up: %d, usefip: %d", linkup, iport->usefip);
+ 			fnic_fcoe_send_vlan_req(fnic);
+ 		} else {
+ 			iport->state = FNIC_IPORT_STATE_FABRIC_DISC;
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "iport->state: %d", iport->state);
+ 			fnic_fdls_disc_start(iport);
+ 		}
+ 	} else {
+ 		iport->state = FNIC_IPORT_STATE_LINK_WAIT;
+ 		if (!is_zero_ether_addr(iport->fpma))
+ 			vnic_dev_del_addr(fnic->vdev, iport->fpma);
+ 		fnic_common_fip_cleanup(fnic);
+ 		fnic_fdls_link_down(iport);
+ 
+ 	}
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ }
+ 
+ 
+ /*
+  * FPMA can be either taken from ethhdr(dst_mac) or flogi resp
+  * or derive from FC_MAP and FCID combination. While it should be
+  * same, revisit this if there is any possibility of not-correct.
+  */
+ void fnic_fdls_learn_fcoe_macs(struct fnic_iport_s *iport, void *rx_frame,
+ 							   uint8_t *fcid)
+ {
+ 	struct fnic *fnic = iport->fnic;
+ 	struct ethhdr *ethhdr = (struct ethhdr *) rx_frame;
+ 	uint8_t fcmac[6] = { 0x0E, 0xFC, 0x00, 0x00, 0x00, 0x00 };
+ 
+ 	memcpy(&fcmac[3], fcid, 3);
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "learn fcoe: dst_mac: %02x:%02x:%02x:%02x:%02x:%02x",
+ 				 ethhdr->h_dest[0], ethhdr->h_dest[1],
+ 				 ethhdr->h_dest[2], ethhdr->h_dest[3],
+ 				 ethhdr->h_dest[4], ethhdr->h_dest[5]);
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "learn fcoe: fc_mac: %02x:%02x:%02x:%02x:%02x:%02x",
+ 				 fcmac[0], fcmac[1], fcmac[2], fcmac[3], fcmac[4],
+ 				 fcmac[5]);
+ 
+ 	fnic_fdls_set_fcoe_srcmac(fnic, fcmac);
+ 	fnic_fdls_set_fcoe_dstmac(fnic, ethhdr->h_source);
+ }
+ 
+ void fnic_fdls_init(struct fnic *fnic, int usefip)
+ {
+ 	struct fnic_iport_s *iport = &fnic->iport;
+ 
+ 	/* Initialize iPort structure */
+ 	iport->state = FNIC_IPORT_STATE_INIT;
+ 	iport->fnic = fnic;
+ 	iport->usefip = usefip;
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "iportsrcmac: %02x:%02x:%02x:%02x:%02x:%02x",
+ 				 iport->hwmac[0], iport->hwmac[1], iport->hwmac[2],
+ 				 iport->hwmac[3], iport->hwmac[4], iport->hwmac[5]);
+ 
+ 	INIT_LIST_HEAD(&iport->tport_list);
+ 	INIT_LIST_HEAD(&iport->tport_list_pending_del);
+ 
+ 	fnic_fdls_disc_init(iport);
+ }
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  void fnic_handle_link(struct work_struct *work)
  {
  	struct fnic *fnic = container_of(work, struct fnic, link_work);
 +	unsigned long flags;
  	int old_link_status;
  	u32 old_link_down_cnt;
 -	int max_count = 0;
 +	u64 old_port_speed, new_port_speed;
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
++=======
+ 	if (vnic_dev_get_intr_mode(fnic->vdev) != VNIC_DEV_INTR_MODE_MSI)
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "Interrupt mode is not MSI\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
 -	spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
 +	fnic->link_events = 1;      /* less work to just set everytime*/
  
  	if (fnic->stop_rx_link_events) {
++<<<<<<< HEAD
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++=======
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "Stop link rx events\n");
+ 		return;
+ 	}
+ 
+ 	/* Do not process if the fnic is already in transitional state */
+ 	if ((fnic->state != FNIC_IN_ETH_MODE)
+ 		&& (fnic->state != FNIC_IN_FC_MODE)) {
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			 "fnic in transitional state: %d. link up: %d ignored",
+ 			 fnic->state, vnic_dev_link_status(fnic->vdev));
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			 "Current link status: %d iport state: %d\n",
+ 			 fnic->link_status, fnic->iport.state);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return;
  	}
  
@@@ -71,206 -199,113 +234,290 @@@
  	fnic->link_status = vnic_dev_link_status(fnic->vdev);
  	fnic->link_down_cnt = vnic_dev_link_down_cnt(fnic->vdev);
  
++<<<<<<< HEAD
 +	new_port_speed = vnic_dev_port_speed(fnic->vdev);
 +	atomic64_set(&fnic->fnic_stats.misc_stats.current_port_speed,
 +			new_port_speed);
 +	if (old_port_speed != new_port_speed)
 +		FNIC_MAIN_DBG(KERN_INFO, fnic->lport->host,
 +				"Current vnic speed set to :  %llu\n",
 +				new_port_speed);
 +
 +	switch (vnic_dev_port_speed(fnic->vdev)) {
 +	case DCEM_PORTSPEED_10G:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_10GBIT;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_10GBIT;
 +		break;
 +	case DCEM_PORTSPEED_20G:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_20GBIT;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_20GBIT;
 +		break;
 +	case DCEM_PORTSPEED_25G:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_25GBIT;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_25GBIT;
 +		break;
 +	case DCEM_PORTSPEED_40G:
 +	case DCEM_PORTSPEED_4x10G:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_40GBIT;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_40GBIT;
 +		break;
 +	case DCEM_PORTSPEED_100G:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_100GBIT;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_100GBIT;
 +		break;
 +	default:
 +		fc_host_speed(fnic->lport->host)   = FC_PORTSPEED_UNKNOWN;
 +		fnic->lport->link_supported_speeds = FC_PORTSPEED_UNKNOWN;
 +		break;
++=======
+ 	while (fnic->reset_in_progress == IN_PROGRESS) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			 "fnic reset in progress. Link event needs to wait\n");
+ 
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "waiting for reset completion\n");
+ 		wait_for_completion_timeout(&fnic->reset_completion_wait,
+ 									msecs_to_jiffies(5000));
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "woken up from reset completion wait\n");
+ 		spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
+ 
+ 		max_count++;
+ 		if (max_count >= MAX_RESET_WAIT_COUNT) {
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Rstth waited for too long. Skipping handle link event\n");
+ 			spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 			return;
+ 		}
+ 	}
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Marking fnic reset in progress\n");
+ 	fnic->reset_in_progress = IN_PROGRESS;
+ 
+ 	if ((vnic_dev_get_intr_mode(fnic->vdev) != VNIC_DEV_INTR_MODE_MSI) ||
+ 		(fnic->link_status != old_link_status)) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "old link status: %d link status: %d\n",
+ 					 old_link_status, (int) fnic->link_status);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "old down count %d down count: %d\n",
+ 					 old_link_down_cnt, (int) fnic->link_down_cnt);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
  	if (old_link_status == fnic->link_status) {
  		if (!fnic->link_status) {
  			/* DOWN -> DOWN */
++<<<<<<< HEAD
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +			fnic_fc_trace_set_data(fnic->lport->host->host_no,
 +				FNIC_FC_LE, "Link Status: DOWN->DOWN",
 +				strlen("Link Status: DOWN->DOWN"));
 +		} else {
 +			if (old_link_down_cnt != fnic->link_down_cnt) {
 +				/* UP -> DOWN -> UP */
 +				fnic->lport->host_stats.link_failure_count++;
 +				spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +				fnic_fc_trace_set_data(
 +					fnic->lport->host->host_no,
 +					FNIC_FC_LE,
 +					"Link Status:UP_DOWN_UP",
 +					strlen("Link_Status:UP_DOWN_UP")
 +					);
 +				FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +					     "link down\n");
 +				fcoe_ctlr_link_down(&fnic->ctlr);
 +				if (fnic->config.flags & VFCF_FIP_CAPABLE) {
 +					/* start FCoE VLAN discovery */
 +					fnic_fc_trace_set_data(
 +						fnic->lport->host->host_no,
 +						FNIC_FC_LE,
 +						"Link Status: UP_DOWN_UP_VLAN",
 +						strlen(
 +						"Link Status: UP_DOWN_UP_VLAN")
 +						);
 +					fnic_fcoe_send_vlan_req(fnic);
 +					return;
 +				}
 +				FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +					     "link up\n");
 +				fcoe_ctlr_link_up(&fnic->ctlr);
 +			} else {
 +				/* UP -> UP */
 +				spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +				fnic_fc_trace_set_data(
 +					fnic->lport->host->host_no, FNIC_FC_LE,
 +					"Link Status: UP_UP",
 +					strlen("Link Status: UP_UP"));
++=======
+ 			spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "down->down\n");
+ 		} else {
+ 			if (old_link_down_cnt != fnic->link_down_cnt) {
+ 				/* UP -> DOWN -> UP */
+ 				spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 				FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 							 "up->down. Link down\n");
+ 				fnic_fdls_link_status_change(fnic, 0);
+ 
+ 				FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 							 "down->up. Link up\n");
+ 				fnic_fdls_link_status_change(fnic, 1);
+ 			} else {
+ 				/* UP -> UP */
+ 				spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 				FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 							 "up->up\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			}
  		}
  	} else if (fnic->link_status) {
  		/* DOWN -> UP */
++<<<<<<< HEAD
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		if (fnic->config.flags & VFCF_FIP_CAPABLE) {
 +			/* start FCoE VLAN discovery */
 +			fnic_fc_trace_set_data(fnic->lport->host->host_no,
 +					       FNIC_FC_LE, "Link Status: DOWN_UP_VLAN",
 +					       strlen("Link Status: DOWN_UP_VLAN"));
 +			fnic_fcoe_send_vlan_req(fnic);
 +
 +			return;
 +		}
 +
 +		FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "link up\n");
 +		fnic_fc_trace_set_data(fnic->lport->host->host_no, FNIC_FC_LE,
 +				       "Link Status: DOWN_UP", strlen("Link Status: DOWN_UP"));
 +		fcoe_ctlr_link_up(&fnic->ctlr);
 +	} else {
 +		/* UP -> DOWN */
 +		fnic->lport->host_stats.link_failure_count++;
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "link down\n");
 +		fnic_fc_trace_set_data(
 +			fnic->lport->host->host_no, FNIC_FC_LE,
 +			"Link Status: UP_DOWN",
 +			strlen("Link Status: UP_DOWN"));
 +		if (fnic->config.flags & VFCF_FIP_CAPABLE) {
 +			FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +				"deleting fip-timer during link-down\n");
 +			del_timer_sync(&fnic->fip_timer);
 +		}
 +		fcoe_ctlr_link_down(&fnic->ctlr);
 +	}
 +
++=======
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "down->up. Link up\n");
+ 		fnic_fdls_link_status_change(fnic, 1);
+ 	} else {
+ 		/* UP -> DOWN */
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "up->down. Link down\n");
+ 		fnic_fdls_link_status_change(fnic, 0);
+ 	}
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
+ 	fnic->reset_in_progress = NOT_IN_PROGRESS;
+ 	complete(&fnic->reset_completion_wait);
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Marking fnic reset completion\n");
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
- /*
-  * This function passes incoming fabric frames to libFC
-  */
  void fnic_handle_frame(struct work_struct *work)
  {
  	struct fnic *fnic = container_of(work, struct fnic, frame_work);
 -	struct fnic_frame_list *cur_frame, *next;
 -	int fchdr_offset = 0;
 +	struct fc_lport *lp = fnic->lport;
 +	unsigned long flags;
 +	struct sk_buff *skb;
 +	struct fc_frame *fp;
  
 -	spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
 -	list_for_each_entry_safe(cur_frame, next, &fnic->frame_queue, links) {
 +	while ((skb = skb_dequeue(&fnic->frame_queue))) {
 +
 +		spin_lock_irqsave(&fnic->fnic_lock, flags);
  		if (fnic->stop_rx_link_events) {
 -			list_del(&cur_frame->links);
 -			spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
 -			kfree(cur_frame->fp);
 -			mempool_free(cur_frame, fnic->frame_elem_pool);
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +			dev_kfree_skb(skb);
 +			return;
 +		}
 +		fp = (struct fc_frame *)skb;
 +
 +		/*
 +		 * If we're in a transitional state, just re-queue and return.
 +		 * The queue will be serviced when we get to a stable state.
 +		 */
 +		if (fnic->state != FNIC_IN_FC_MODE &&
++<<<<<<< HEAD
 +		    fnic->state != FNIC_IN_ETH_MODE) {
 +			skb_queue_head(&fnic->frame_queue, skb);
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  			return;
  		}
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
 +		fc_exch_recv(lp, fp);
 +	}
 +}
 +
 +void fnic_fcoe_evlist_free(struct fnic *fnic)
 +{
 +	struct fnic_event *fevt = NULL;
 +	struct fnic_event *next = NULL;
 +	unsigned long flags;
 +
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	if (list_empty(&fnic->evlist)) {
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		return;
 +	}
 +
 +	list_for_each_entry_safe(fevt, next, &fnic->evlist, list) {
 +		list_del(&fevt->list);
 +		kfree(fevt);
 +	}
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +}
 +
 +void fnic_handle_event(struct work_struct *work)
 +{
 +	struct fnic *fnic = container_of(work, struct fnic, event_work);
 +	struct fnic_event *fevt = NULL;
 +	struct fnic_event *next = NULL;
 +	unsigned long flags;
 +
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	if (list_empty(&fnic->evlist)) {
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		return;
 +	}
  
 +	list_for_each_entry_safe(fevt, next, &fnic->evlist, list) {
 +		if (fnic->stop_rx_link_events) {
 +			list_del(&fevt->list);
 +			kfree(fevt);
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +			return;
 +		}
  		/*
  		 * If we're in a transitional state, just re-queue and return.
  		 * The queue will be serviced when we get to a stable state.
  		 */
  		if (fnic->state != FNIC_IN_FC_MODE &&
 +		    fnic->state != FNIC_IN_ETH_MODE) {
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++=======
+ 			fnic->state != FNIC_IN_ETH_MODE) {
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Cannot process frame in transitional state\n");
+ 			spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			return;
  		}
  
@@@ -605,19 -326,23 +852,28 @@@ drop
  
  void fnic_handle_fip_frame(struct work_struct *work)
  {
 -	struct fnic_frame_list *cur_frame, *next;
  	struct fnic *fnic = container_of(work, struct fnic, fip_frame_work);
 +	struct fnic_stats *fnic_stats = &fnic->fnic_stats;
 +	unsigned long flags;
 +	struct sk_buff *skb;
 +	struct ethhdr *eh;
  
++<<<<<<< HEAD
 +	while ((skb = skb_dequeue(&fnic->fip_frame_queue))) {
 +		spin_lock_irqsave(&fnic->fnic_lock, flags);
++=======
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Processing FIP frame\n");
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, fnic->lock_flags);
+ 	list_for_each_entry_safe(cur_frame, next, &fnic->fip_frame_queue,
+ 							 links) {
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		if (fnic->stop_rx_link_events) {
 -			list_del(&cur_frame->links);
 -			spin_unlock_irqrestore(&fnic->fnic_lock, fnic->lock_flags);
 -			kfree(cur_frame->fp);
 -			kfree(cur_frame);
 +			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +			dev_kfree_skb(skb);
  			return;
  		}
 -
  		/*
  		 * If we're in a transitional state, just re-queue and return.
  		 * The queue will be serviced when we get to a stable state.
@@@ -733,9 -407,13 +989,16 @@@ void fnic_update_mac_locked(struct fni
  		new = ctl;
  	if (ether_addr_equal(data, new))
  		return;
++<<<<<<< HEAD
 +	FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "update_mac %pM\n", new);
++=======
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Update MAC: %u\n", *new);
+ 
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	if (!is_zero_ether_addr(data) && !ether_addr_equal(data, ctl))
  		vnic_dev_del_addr(fnic->vdev, data);
 -
  	memcpy(data, new, ETH_ALEN);
  	if (!ether_addr_equal(new, ctl))
  		vnic_dev_add_addr(fnic->vdev, new);
@@@ -856,75 -454,92 +1119,118 @@@ static void fnic_rq_cmpl_frame_recv(str
  
  	cq_desc_dec(cq_desc, &type, &color, &q_number, &completed_index);
  	if (type == CQ_DESC_TYPE_RQ_FCP) {
 -		cq_fcp_rq_desc_dec((struct cq_fcp_rq_desc *) cq_desc, &type,
 -						   &color, &q_number, &completed_index, &eop, &sop,
 -						   &fcoe_fnic_crc_ok, &exchange_id, &tmpl,
 -						   &fcp_bytes_written, &sof, &eof, &ingress_port,
 -						   &packet_error, &fcoe_enc_error, &fcs_ok,
 -						   &vlan_stripped, &vlan);
 -		ethhdr_stripped = 1;
 -		bytes_written = fcp_bytes_written;
 -	} else if (type == CQ_DESC_TYPE_RQ_ENET) {
 -		cq_enet_rq_desc_dec((struct cq_enet_rq_desc *) cq_desc, &type,
 -					&color, &q_number, &completed_index,
 -					&ingress_port, &fcoe, &eop, &sop, &rss_type,
 -					&csum_not_calc, &rss_hash, &enet_bytes_written,
 -					&packet_error, &vlan_stripped, &vlan,
 -					&checksum, &fcoe_sof, &fcoe_fnic_crc_ok,
 -					&fcoe_enc_error, &fcoe_eof, &tcp_udp_csum_ok,
 -					&udp, &tcp, &ipv4_csum_ok, &ipv6, &ipv4,
 -					&ipv4_fragment, &fcs_ok);
 -
 -		ethhdr_stripped = 0;
 -		bytes_written = enet_bytes_written;
 +		cq_fcp_rq_desc_dec((struct cq_fcp_rq_desc *)cq_desc,
 +				   &type, &color, &q_number, &completed_index,
 +				   &eop, &sop, &fcoe_fc_crc_ok, &exchange_id,
 +				   &tmpl, &fcp_bytes_written, &sof, &eof,
 +				   &ingress_port, &packet_error,
 +				   &fcoe_enc_error, &fcs_ok, &vlan_stripped,
 +				   &vlan);
 +		skb_trim(skb, fcp_bytes_written);
 +		fr_sof(fp) = sof;
 +		fr_eof(fp) = eof;
  
 +	} else if (type == CQ_DESC_TYPE_RQ_ENET) {
 +		cq_enet_rq_desc_dec((struct cq_enet_rq_desc *)cq_desc,
 +				    &type, &color, &q_number, &completed_index,
 +				    &ingress_port, &fcoe, &eop, &sop,
 +				    &rss_type, &csum_not_calc, &rss_hash,
 +				    &bytes_written, &packet_error,
 +				    &vlan_stripped, &vlan, &checksum,
 +				    &fcoe_sof, &fcoe_fc_crc_ok,
 +				    &fcoe_enc_error, &fcoe_eof,
 +				    &tcp_udp_csum_ok, &udp, &tcp,
 +				    &ipv4_csum_ok, &ipv6, &ipv4,
 +				    &ipv4_fragment, &fcs_ok);
 +		skb_trim(skb, bytes_written);
  		if (!fcs_ok) {
  			atomic64_inc(&fnic_stats->misc_stats.frame_errors);
++<<<<<<< HEAD
 +			FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +				     "fcs error.  dropping packet.\n");
++=======
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "fnic 0x%p fcs error.  Dropping packet.\n", fnic);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			goto drop;
  		}
 -		eh = (struct ethhdr *) fp;
 -		if (eh->h_proto != cpu_to_be16(ETH_P_FCOE)) {
 +		if (fnic_import_rq_eth_pkt(fnic, skb))
 +			return;
  
++<<<<<<< HEAD
 +	} else {
 +		/* wrong CQ type*/
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			     "fnic rq_cmpl wrong cq type x%x\n", type);
++=======
+ 			if (fnic_import_rq_eth_pkt(fnic, fp))
+ 				return;
+ 
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 							 "Dropping h_proto 0x%x",
+ 							 be16_to_cpu(eh->h_proto));
+ 			goto drop;
+ 		}
+ 	} else {
+ 		/* wrong CQ type */
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "fnic rq_cmpl wrong cq type x%x\n", type);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		goto drop;
  	}
  
 -	if (!fcs_ok || packet_error || !fcoe_fnic_crc_ok || fcoe_enc_error) {
 +	if (!fcs_ok || packet_error || !fcoe_fc_crc_ok || fcoe_enc_error) {
  		atomic64_inc(&fnic_stats->misc_stats.frame_errors);
++<<<<<<< HEAD
 +		FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +			     "fnic rq_cmpl fcoe x%x fcsok x%x"
 +			     " pkterr x%x fcoe_fc_crc_ok x%x, fcoe_enc_err"
 +			     " x%x\n",
 +			     fcoe, fcs_ok, packet_error,
 +			     fcoe_fc_crc_ok, fcoe_enc_error);
++=======
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			 "fcoe %x fcsok %x pkterr %x ffco %x fee %x\n",
+ 			 fcoe, fcs_ok, packet_error,
+ 			 fcoe_fnic_crc_ok, fcoe_enc_error);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		goto drop;
  	}
  
  	spin_lock_irqsave(&fnic->fnic_lock, flags);
  	if (fnic->stop_rx_link_events) {
  		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++<<<<<<< HEAD
++=======
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "fnic->stop_rx_link_events: %d\n",
+ 					 fnic->stop_rx_link_events);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		goto drop;
  	}
 -
 +	fr_dev(fp) = fnic->lport;
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++<<<<<<< HEAD
 +	if ((fnic_fc_trace_set_data(fnic->lport->host->host_no, FNIC_FC_RECV,
 +					(char *)skb->data, skb->len)) != 0) {
 +		printk(KERN_ERR "fnic ctlr frame trace error!!!");
++=======
+ 
+ 	frame_elem = mempool_alloc(fnic->frame_elem_pool,
+ 					GFP_ATOMIC | __GFP_ZERO);
+ 	if (!frame_elem) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Failed to allocate memory for frame elem");
+ 		goto drop;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
 -	frame_elem->fp = fp;
 -	frame_elem->rx_ethhdr_stripped = ethhdr_stripped;
 -	frame_elem->frame_len = bytes_written;
 -
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	list_add_tail(&frame_elem->links, &fnic->frame_queue);
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  
 +	skb_queue_tail(&fnic->frame_queue, skb);
  	queue_work(fnic_event_queue, &fnic->frame_work);
 -	return;
  
 +	return;
  drop:
 -	kfree(fp);
 +	dev_kfree_skb_irq(skb);
  }
  
  static int fnic_rq_cmpl_handler_cont(struct vnic_dev *vdev,
@@@ -950,10 -565,10 +1256,10 @@@ int fnic_rq_cmpl_handler(struct fnic *f
  		cur_work_done = vnic_cq_service(&fnic->cq[i], rq_work_to_do,
  						fnic_rq_cmpl_handler_cont,
  						NULL);
 -		if (cur_work_done && fnic->stop_rx_link_events != 1) {
 +		if (cur_work_done) {
  			err = vnic_rq_fill(&fnic->rq[i], fnic_alloc_rq_frame);
  			if (err)
- 				shost_printk(KERN_ERR, fnic->lport->host,
+ 				shost_printk(KERN_ERR, fnic->host,
  					     "fnic_alloc_rq_frame can't alloc"
  					     " frame\n");
  		}
@@@ -971,35 -586,32 +1277,50 @@@
  int fnic_alloc_rq_frame(struct vnic_rq *rq)
  {
  	struct fnic *fnic = vnic_dev_priv(rq->vdev);
 -	void *buf;
 +	struct sk_buff *skb;
  	u16 len;
  	dma_addr_t pa;
 -	int ret;
 -
 +	int r;
 +
++<<<<<<< HEAD
 +	len = FC_FRAME_HEADROOM + FC_MAX_FRAME + FC_FRAME_TAILROOM;
 +	skb = dev_alloc_skb(len);
 +	if (!skb) {
 +		FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +			     "Unable to allocate RQ sk_buff\n");
++=======
+ 	len = FNIC_FRAME_HT_ROOM;
+ 	buf = kmalloc(len, GFP_ATOMIC);
+ 	if (!buf) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "Unable to allocate RQ buffer of size: %d\n", len);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return -ENOMEM;
  	}
 -
 -	pa = dma_map_single(&fnic->pdev->dev, buf, len, DMA_FROM_DEVICE);
 +	skb_reset_mac_header(skb);
 +	skb_reset_transport_header(skb);
 +	skb_reset_network_header(skb);
 +	skb_put(skb, len);
 +	pa = dma_map_single(&fnic->pdev->dev, skb->data, len, DMA_FROM_DEVICE);
  	if (dma_mapping_error(&fnic->pdev->dev, pa)) {
++<<<<<<< HEAD
 +		r = -ENOMEM;
 +		printk(KERN_ERR "PCI mapping failed with error %d\n", r);
 +		goto free_skb;
++=======
+ 		ret = -ENOMEM;
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "PCI mapping failed with error %d\n", ret);
+ 		goto free_buf;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
 -	fnic_queue_rq_desc(rq, buf, pa, len);
 +	fnic_queue_rq_desc(rq, skb, pa, len);
  	return 0;
 -free_buf:
 -	kfree(buf);
 -	return ret;
 +
 +free_skb:
 +	kfree_skb(skb);
 +	return r;
  }
  
  void fnic_free_rq_buf(struct vnic_rq *rq, struct vnic_rq_buf *buf)
@@@ -1086,103 -636,129 +1407,147 @@@ static int fnic_send_frame(struct fnic 
  	int ret = 0;
  	unsigned long flags;
  
 -	pa = dma_map_single(&fnic->pdev->dev, frame, frame_len, DMA_TO_DEVICE);
 +	fh = fc_frame_header_get(fp);
 +	skb = fp_skb(fp);
 +
++<<<<<<< HEAD
 +	if (unlikely(fh->fh_r_ctl == FC_RCTL_ELS_REQ) &&
 +	    fcoe_ctlr_els_send(&fnic->ctlr, fnic->lport, skb))
 +		return 0;
 +
 +	if (!fnic->vlan_hw_insert) {
 +		eth_hdr_len = sizeof(*vlan_hdr) + sizeof(*fcoe_hdr);
 +		vlan_hdr = skb_push(skb, eth_hdr_len);
 +		eth_hdr = (struct ethhdr *)vlan_hdr;
 +		vlan_hdr->h_vlan_proto = htons(ETH_P_8021Q);
 +		vlan_hdr->h_vlan_encapsulated_proto = htons(ETH_P_FCOE);
 +		vlan_hdr->h_vlan_TCI = htons(fnic->vlan_id);
 +		fcoe_hdr = (struct fcoe_hdr *)(vlan_hdr + 1);
 +	} else {
 +		eth_hdr_len = sizeof(*eth_hdr) + sizeof(*fcoe_hdr);
 +		eth_hdr = skb_push(skb, eth_hdr_len);
 +		eth_hdr->h_proto = htons(ETH_P_FCOE);
 +		fcoe_hdr = (struct fcoe_hdr *)(eth_hdr + 1);
 +	}
 +
 +	if (fnic->ctlr.map_dest)
 +		fc_fcoe_set_mac(eth_hdr->h_dest, fh->fh_d_id);
 +	else
 +		memcpy(eth_hdr->h_dest, fnic->ctlr.dest_addr, ETH_ALEN);
 +	memcpy(eth_hdr->h_source, fnic->data_src_addr, ETH_ALEN);
 +
 +	tot_len = skb->len;
 +	BUG_ON(tot_len % 4);
 +
 +	memset(fcoe_hdr, 0, sizeof(*fcoe_hdr));
 +	fcoe_hdr->fcoe_sof = fr_sof(fp);
 +	if (FC_FCOE_VER)
 +		FC_FCOE_ENCAPS_VER(fcoe_hdr, FC_FCOE_VER);
 +
 +	pa = dma_map_single(&fnic->pdev->dev, eth_hdr, tot_len, DMA_TO_DEVICE);
 +	if (dma_mapping_error(&fnic->pdev->dev, pa)) {
 +		ret = -ENOMEM;
 +		printk(KERN_ERR "DMA map failed with error %d\n", ret);
 +		goto free_skb_on_err;
 +	}
  
 +	if ((fnic_fc_trace_set_data(fnic->lport->host->host_no, FNIC_FC_SEND,
 +				(char *)eth_hdr, tot_len)) != 0) {
 +		printk(KERN_ERR "fnic ctlr frame trace error!!!");
++=======
+ 	if ((fnic_fc_trace_set_data(fnic->fnic_num,
+ 				FNIC_FC_SEND | 0x80, (char *) frame,
+ 				frame_len)) != 0) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "fnic ctlr frame trace error");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
  	spin_lock_irqsave(&fnic->wq_lock[0], flags);
  
  	if (!vnic_wq_desc_avail(wq)) {
++<<<<<<< HEAD
 +		dma_unmap_single(&fnic->pdev->dev, pa, tot_len, DMA_TO_DEVICE);
++=======
+ 		dma_unmap_single(&fnic->pdev->dev, pa, frame_len, DMA_TO_DEVICE);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "vnic work queue descriptor is not available");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		ret = -1;
 -		goto fnic_send_frame_end;
 +		goto irq_restore;
  	}
  
 -	/* hw inserts cos value */
 -	fnic_queue_wq_desc(wq, frame, pa, frame_len, FC_EOF_T,
 -					   0, fnic->vlan_id, 1, 1, 1);
 +	fnic_queue_wq_desc(wq, skb, pa, tot_len, fr_eof(fp),
 +			   0 /* hw inserts cos value */,
 +			   fnic->vlan_id, 1, 1, 1);
  
 -fnic_send_frame_end:
 +irq_restore:
  	spin_unlock_irqrestore(&fnic->wq_lock[0], flags);
 +
 +free_skb_on_err:
 +	if (ret)
 +		dev_kfree_skb_any(fp_skb(fp));
 +
  	return ret;
  }
  
 -/**
 - * fdls_send_fcoe_frame - send a filled-in FC frame, filling in eth and FCoE
 - *	info. This interface is used only in the non fast path. (login, fabric
 - *	registrations etc.)
 - *
 - * @fnic:	fnic instance
 - * @frame:	frame structure with FC payload filled in
 - * @frame_size:	length of the frame to be sent
 - * @srcmac:	source mac address
 - * @dstmac:	destination mac address
 - *
 - * Called with the fnic lock held.
 +/*
 + * fnic_send
 + * Routine to send a raw frame
   */
 -static int
 -fdls_send_fcoe_frame(struct fnic *fnic, void *frame, int frame_size,
 -					 uint8_t *srcmac, uint8_t *dstmac)
 +int fnic_send(struct fc_lport *lp, struct fc_frame *fp)
  {
 -	struct ethhdr *pethhdr;
 -	struct fcoe_hdr *pfcoe_hdr;
 -	struct fnic_frame_list *frame_elem;
 -	int len = frame_size;
 -	int ret;
 -	struct fc_frame_header *fchdr = (struct fc_frame_header *) (frame +
 -			FNIC_ETH_FCOE_HDRS_OFFSET);
 +	struct fnic *fnic = lport_priv(lp);
 +	unsigned long flags;
  
++<<<<<<< HEAD
 +	if (fnic->in_remove) {
 +		dev_kfree_skb(fp_skb(fp));
 +		return -1;
 +	}
++=======
+ 	pethhdr = (struct ethhdr *) frame;
+ 	pethhdr->h_proto = cpu_to_be16(ETH_P_FCOE);
+ 	memcpy(pethhdr->h_source, srcmac, ETH_ALEN);
+ 	memcpy(pethhdr->h_dest, dstmac, ETH_ALEN);
+ 
+ 	pfcoe_hdr = (struct fcoe_hdr *) (frame + sizeof(struct ethhdr));
+ 	pfcoe_hdr->fcoe_sof = FC_SOF_I3;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/*
  	 * Queue frame if in a transitional state.
  	 * This occurs while registering the Port_ID / MAC address after FLOGI.
  	 */
++<<<<<<< HEAD
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	if (fnic->state != FNIC_IN_FC_MODE && fnic->state != FNIC_IN_ETH_MODE) {
 +		skb_queue_tail(&fnic->tx_queue, fp_skb(fp));
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++=======
+ 	if ((fnic->state != FNIC_IN_FC_MODE)
+ 		&& (fnic->state != FNIC_IN_ETH_MODE)) {
+ 		frame_elem = mempool_alloc(fnic->frame_elem_pool,
+ 						GFP_ATOMIC | __GFP_ZERO);
+ 		if (!frame_elem) {
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Failed to allocate memory for frame elem");
+ 			return -ENOMEM;
+ 		}
+ 
+ 		FNIC_FCS_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 			"Queueing FC frame: sid/did/type/oxid = 0x%x/0x%x/0x%x/0x%x\n",
+ 			ntoh24(fchdr->fh_s_id), ntoh24(fchdr->fh_d_id),
+ 			fchdr->fh_type, FNIC_STD_GET_OX_ID(fchdr));
+ 		frame_elem->fp = frame;
+ 		frame_elem->frame_len = len;
+ 		list_add_tail(&frame_elem->links, &fnic->tx_queue);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return 0;
  	}
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  
 -	fnic_debug_dump_fc_frame(fnic, fchdr, frame_size, "Outgoing");
 -
 -	ret = fnic_send_frame(fnic, frame, len);
 -	return ret;
 -}
 -
 -void fnic_send_fcoe_frame(struct fnic_iport_s *iport, void *frame,
 -						 int frame_size)
 -{
 -	struct fnic *fnic = iport->fnic;
 -	uint8_t *dstmac, *srcmac;
 -
 -	/* If module unload is in-progress, don't send */
 -	if (fnic->in_remove)
 -		return;
 -
 -	if (iport->fabric.flags & FNIC_FDLS_FPMA_LEARNT) {
 -		srcmac = iport->fpma;
 -		dstmac = iport->fcfmac;
 -	} else {
 -		srcmac = iport->hwmac;
 -		dstmac = FCOE_ALL_FCF_MAC;
 -	}
 -
 -	fdls_send_fcoe_frame(fnic, frame, frame_size, srcmac, dstmac);
 -}
 -
 -int
 -fnic_send_fip_frame(struct fnic_iport_s *iport, void *frame,
 -					int frame_size)
 -{
 -	struct fnic *fnic = iport->fnic;
 -
 -	if (fnic->in_remove)
 -		return -1;
 -
 -	fnic_debug_dump_fip_frame(fnic, frame, frame_size, "Outgoing");
 -	return fnic_send_frame(fnic, frame, frame_size);
 +	return fnic_send_frame(fnic, fp);
  }
  
  /**
@@@ -1198,51 -774,76 +1563,112 @@@
  void fnic_flush_tx(struct work_struct *work)
  {
  	struct fnic *fnic = container_of(work, struct fnic, flush_work);
 +	struct sk_buff *skb;
  	struct fc_frame *fp;
 -	struct fnic_frame_list *cur_frame, *next;
  
++<<<<<<< HEAD
 +	while ((skb = skb_dequeue(&fnic->tx_queue))) {
 +		fp = (struct fc_frame *)skb;
 +		fnic_send_frame(fnic, fp);
++=======
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Flush queued frames");
+ 
+ 	list_for_each_entry_safe(cur_frame, next, &fnic->tx_queue, links) {
+ 		fp = cur_frame->fp;
+ 		list_del(&cur_frame->links);
+ 		fnic_send_frame(fnic, fp, cur_frame->frame_len);
+ 		mempool_free(cur_frame, fnic->frame_elem_pool);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  }
  
 -int
 -fnic_fdls_register_portid(struct fnic_iport_s *iport, u32 port_id,
 -						  void *fp)
 +/**
 + * fnic_set_eth_mode() - put fnic into ethernet mode.
 + * @fnic: fnic device
 + *
 + * Called without fnic lock held.
 + */
 +static void fnic_set_eth_mode(struct fnic *fnic)
  {
 -	struct fnic *fnic = iport->fnic;
 -	struct ethhdr *ethhdr;
 +	unsigned long flags;
 +	enum fnic_state old_state;
  	int ret;
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +again:
 +	old_state = fnic->state;
 +	switch (old_state) {
 +	case FNIC_IN_FC_MODE:
 +	case FNIC_IN_ETH_TRANS_FC_MODE:
 +	default:
 +		fnic->state = FNIC_IN_FC_TRANS_ETH_MODE;
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
 +		ret = fnic_fw_reset_handler(fnic);
 +
 +		spin_lock_irqsave(&fnic->fnic_lock, flags);
 +		if (fnic->state != FNIC_IN_FC_TRANS_ETH_MODE)
 +			goto again;
 +		if (ret)
 +			fnic->state = old_state;
 +		break;
 +
 +	case FNIC_IN_FC_TRANS_ETH_MODE:
 +	case FNIC_IN_ETH_MODE:
 +		break;
++=======
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Setting port id: 0x%x fp: 0x%p fnic state: %d", port_id,
+ 				 fp, fnic->state);
+ 
+ 	if (fp) {
+ 		ethhdr = (struct ethhdr *) fp;
+ 		vnic_dev_add_addr(fnic->vdev, ethhdr->h_dest);
+ 	}
+ 
+ 	/* Change state to reflect transition to FC mode */
+ 	if (fnic->state == FNIC_IN_ETH_MODE || fnic->state == FNIC_IN_FC_MODE)
+ 		fnic->state = FNIC_IN_ETH_TRANS_FC_MODE;
+ 	else {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			 "Unexpected fnic state while processing FLOGI response\n");
+ 		return -1;
+ 	}
+ 
+ 	/*
+ 	 * Send FLOGI registration to firmware to set up FC mode.
+ 	 * The new address will be set up when registration completes.
+ 	 */
+ 	ret = fnic_flogi_reg_handler(fnic, port_id);
+ 	if (ret < 0) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "FLOGI registration error ret: %d fnic state: %d\n",
+ 					 ret, fnic->state);
+ 		if (fnic->state == FNIC_IN_ETH_TRANS_FC_MODE)
+ 			fnic->state = FNIC_IN_ETH_MODE;
+ 
+ 		return -1;
+ 	}
+ 	iport->fabric.flags |= FNIC_FDLS_FPMA_LEARNT;
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "FLOGI registration success\n");
+ 	return 0;
+ }
+ 
+ void fnic_free_txq(struct list_head *head)
+ {
+ 	struct fnic_frame_list *cur_frame, *next;
+ 
+ 	list_for_each_entry_safe(cur_frame, next, head, links) {
+ 		list_del(&cur_frame->links);
+ 		kfree(cur_frame->fp);
+ 		kfree(cur_frame);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  }
  
  static void fnic_wq_complete_frame_send(struct vnic_wq *wq,
@@@ -1303,109 -901,173 +1729,260 @@@ void fnic_free_wq_buf(struct vnic_wq *w
  	buf->os_buf = NULL;
  }
  
 -void
 -fnic_fdls_add_tport(struct fnic_iport_s *iport, struct fnic_tport_s *tport,
 -					unsigned long flags)
 +void fnic_fcoe_reset_vlans(struct fnic *fnic)
  {
++<<<<<<< HEAD
++=======
+ 	struct fnic *fnic = iport->fnic;
+ 	struct fc_rport *rport;
+ 	struct fc_rport_identifiers ids;
+ 	struct rport_dd_data_s *rdd_data;
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Adding rport fcid: 0x%x", tport->fcid);
+ 
+ 	ids.node_name = tport->wwnn;
+ 	ids.port_name = tport->wwpn;
+ 	ids.port_id = tport->fcid;
+ 	ids.roles = FC_RPORT_ROLE_FCP_TARGET;
+ 
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 	rport = fc_remote_port_add(fnic->host, 0, &ids);
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	if (!rport) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "Failed to add rport for tport: 0x%x", tport->fcid);
+ 		return;
+ 	}
+ 
+ 	FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				 "Added rport fcid: 0x%x", tport->fcid);
+ 
+ 	/* Mimic these assignments in queuecommand to avoid timing issues */
+ 	rport->maxframe_size = FNIC_FC_MAX_PAYLOAD_LEN;
+ 	rport->supported_classes = FC_COS_CLASS3 | FC_RPORT_ROLE_FCP_TARGET;
+ 	rdd_data = rport->dd_data;
+ 	rdd_data->tport = tport;
+ 	rdd_data->iport = iport;
+ 	tport->rport = rport;
+ 	tport->flags |= FNIC_FDLS_SCSI_REGISTERED;
+ }
+ 
+ void
+ fnic_fdls_remove_tport(struct fnic_iport_s *iport,
+ 					   struct fnic_tport_s *tport, unsigned long flags)
+ {
+ 	struct fnic *fnic = iport->fnic;
+ 	struct rport_dd_data_s *rdd_data;
+ 
+ 	struct fc_rport *rport;
+ 
+ 	if (!tport)
+ 		return;
+ 
+ 	fdls_set_tport_state(tport, FDLS_TGT_STATE_OFFLINE);
+ 	rport = tport->rport;
+ 
+ 	if (rport) {
+ 		/* tport resource release will be done
+ 		 * after fnic_terminate_rport_io()
+ 		 */
+ 		tport->flags |= FNIC_FDLS_TPORT_DELETED;
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 
+ 		/* Interface to scsi_fc_transport  */
+ 		fc_remote_port_delete(rport);
+ 
+ 		spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 		 "Deregistered and freed tport fcid: 0x%x from scsi transport fc",
+ 		 tport->fcid);
+ 
+ 		/*
+ 		 * the dd_data is allocated by fc transport
+ 		 * of size dd_fcrport_size
+ 		 */
+ 		rdd_data = rport->dd_data;
+ 		rdd_data->tport = NULL;
+ 		rdd_data->iport = NULL;
+ 		list_del(&tport->links);
+ 		kfree(tport);
+ 	} else {
+ 		fnic_del_tport_timer_sync(fnic, tport);
+ 		list_del(&tport->links);
+ 		kfree(tport);
+ 	}
+ }
+ 
+ void fnic_delete_fcp_tports(struct fnic *fnic)
+ {
+ 	struct fnic_tport_s *tport, *next;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	unsigned long flags;
 +	struct fcoe_vlan *vlan;
 +	struct fcoe_vlan *next;
  
++<<<<<<< HEAD
 +	/*
 +	 * indicate a link down to fcoe so that all fcf's are free'd
 +	 * might not be required since we did this before sending vlan
 +	 * discovery request
 +	 */
 +	spin_lock_irqsave(&fnic->vlans_lock, flags);
 +	if (!list_empty(&fnic->vlans)) {
 +		list_for_each_entry_safe(vlan, next, &fnic->vlans, list) {
 +			list_del(&vlan->list);
 +			kfree(vlan);
++=======
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	list_for_each_entry_safe(tport, next, &fnic->iport.tport_list, links) {
+ 		FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "removing fcp rport fcid: 0x%x", tport->fcid);
+ 		fdls_set_tport_state(tport, FDLS_TGT_STATE_OFFLINING);
+ 		fnic_del_tport_timer_sync(fnic, tport);
+ 		fnic_fdls_remove_tport(&fnic->iport, tport, flags);
+ 	}
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ }
+ 
+ /**
+  * fnic_tport_event_handler() - Handler for remote port events
+  * in the tport_event_queue.
+  *
+  * @work: Handle to the remote port being dequeued
+  */
+ void fnic_tport_event_handler(struct work_struct *work)
+ {
+ 	struct fnic *fnic = container_of(work, struct fnic, tport_work);
+ 	struct fnic_tport_event_s *cur_evt, *next;
+ 	unsigned long flags;
+ 	struct fnic_tport_s *tport;
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	list_for_each_entry_safe(cur_evt, next, &fnic->tport_event_list, links) {
+ 		tport = cur_evt->arg1;
+ 		switch (cur_evt->event) {
+ 		case TGT_EV_RPORT_ADD:
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "Add rport event");
+ 			if (tport->state == FDLS_TGT_STATE_READY) {
+ 				fnic_fdls_add_tport(&fnic->iport,
+ 					(struct fnic_tport_s *) cur_evt->arg1, flags);
+ 			} else {
+ 				FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					 "Target not ready. Add rport event dropped: 0x%x",
+ 					 tport->fcid);
+ 			}
+ 			break;
+ 		case TGT_EV_RPORT_DEL:
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "Remove rport event");
+ 			if (tport->state == FDLS_TGT_STATE_OFFLINING) {
+ 				fnic_fdls_remove_tport(&fnic->iport,
+ 					   (struct fnic_tport_s *) cur_evt->arg1, flags);
+ 			} else {
+ 				FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 							 "remove rport event dropped tport fcid: 0x%x",
+ 							 tport->fcid);
+ 			}
+ 			break;
+ 		case TGT_EV_TPORT_DELETE:
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "Delete tport event");
+ 			fdls_delete_tport(tport->iport, tport);
+ 			break;
+ 		default:
+ 			FNIC_FCS_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 						 "Unknown tport event");
+ 			break;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		}
 -		list_del(&cur_evt->links);
 -		kfree(cur_evt);
  	}
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	spin_unlock_irqrestore(&fnic->vlans_lock, flags);
  }
  
 -void fnic_flush_tport_event_list(struct fnic *fnic)
 +void fnic_handle_fip_timer(struct fnic *fnic)
  {
 -	struct fnic_tport_event_s *cur_evt, *next;
  	unsigned long flags;
 +	struct fcoe_vlan *vlan;
 +	struct fnic_stats *fnic_stats = &fnic->fnic_stats;
 +	u64 sol_time;
  
  	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	list_for_each_entry_safe(cur_evt, next, &fnic->tport_event_list, links) {
 -		list_del(&cur_evt->links);
 -		kfree(cur_evt);
 +	if (fnic->stop_rx_link_events) {
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		return;
  	}
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
 +	if (fnic->ctlr.mode == FIP_MODE_NON_FIP)
 +		return;
 +
 +	spin_lock_irqsave(&fnic->vlans_lock, flags);
 +	if (list_empty(&fnic->vlans)) {
 +		spin_unlock_irqrestore(&fnic->vlans_lock, flags);
 +		/* no vlans available, try again */
 +		if (unlikely(fnic_log_level & FNIC_FCS_LOGGING))
 +			if (printk_ratelimit())
 +				shost_printk(KERN_DEBUG, fnic->lport->host,
 +						"Start VLAN Discovery\n");
 +		fnic_event_enq(fnic, FNIC_EVT_START_VLAN_DISC);
 +		return;
 +	}
 +
 +	vlan = list_first_entry(&fnic->vlans, struct fcoe_vlan, list);
 +	FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +		  "fip_timer: vlan %d state %d sol_count %d\n",
 +		  vlan->vid, vlan->state, vlan->sol_count);
 +	switch (vlan->state) {
 +	case FIP_VLAN_USED:
 +		FNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,
 +			  "FIP VLAN is selected for FC transaction\n");
 +		spin_unlock_irqrestore(&fnic->vlans_lock, flags);
 +		break;
 +	case FIP_VLAN_FAILED:
 +		spin_unlock_irqrestore(&fnic->vlans_lock, flags);
 +		/* if all vlans are in failed state, restart vlan disc */
 +		if (unlikely(fnic_log_level & FNIC_FCS_LOGGING))
 +			if (printk_ratelimit())
 +				shost_printk(KERN_DEBUG, fnic->lport->host,
 +					  "Start VLAN Discovery\n");
 +		fnic_event_enq(fnic, FNIC_EVT_START_VLAN_DISC);
 +		break;
 +	case FIP_VLAN_SENT:
 +		if (vlan->sol_count >= FCOE_CTLR_MAX_SOL) {
 +			/*
 +			 * no response on this vlan, remove  from the list.
 +			 * Try the next vlan
 +			 */
 +			FNIC_FCS_DBG(KERN_INFO, fnic->lport->host,
 +				  "Dequeue this VLAN ID %d from list\n",
 +				  vlan->vid);
 +			list_del(&vlan->list);
 +			kfree(vlan);
 +			vlan = NULL;
 +			if (list_empty(&fnic->vlans)) {
 +				/* we exhausted all vlans, restart vlan disc */
 +				spin_unlock_irqrestore(&fnic->vlans_lock,
 +							flags);
 +				FNIC_FCS_DBG(KERN_INFO, fnic->lport->host,
 +					  "fip_timer: vlan list empty, "
 +					  "trigger vlan disc\n");
 +				fnic_event_enq(fnic, FNIC_EVT_START_VLAN_DISC);
 +				return;
 +			}
 +			/* check the next vlan */
 +			vlan = list_first_entry(&fnic->vlans, struct fcoe_vlan,
 +							list);
 +			fnic->set_vlan(fnic, vlan->vid);
 +			vlan->state = FIP_VLAN_SENT; /* sent now */
 +		}
 +		spin_unlock_irqrestore(&fnic->vlans_lock, flags);
 +		atomic64_inc(&fnic_stats->vlan_stats.sol_expiry_count);
 +		vlan->sol_count++;
 +		sol_time = jiffies + msecs_to_jiffies
 +					(FCOE_CTLR_START_DELAY);
 +		mod_timer(&fnic->fip_timer, round_jiffies(sol_time));
 +		break;
 +	}
  }
diff --cc drivers/scsi/fnic/fnic_main.c
index 06fd7b543b33,fe8816feb247..000000000000
--- a/drivers/scsi/fnic/fnic_main.c
+++ b/drivers/scsi/fnic/fnic_main.c
@@@ -175,9 -171,13 +174,17 @@@ static struct fc_function_template fnic
  
  static void fnic_get_host_speed(struct Scsi_Host *shost)
  {
 -	struct fnic *fnic = *((struct fnic **) shost_priv(shost));
 +	struct fc_lport *lp = shost_priv(shost);
 +	struct fnic *fnic = lport_priv(lp);
  	u32 port_speed = vnic_dev_port_speed(fnic->vdev);
++<<<<<<< HEAD
++=======
+ 	struct fnic_stats *fnic_stats = &fnic->fnic_stats;
+ 
+ 	FNIC_MAIN_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "port_speed: %d Mbps", port_speed);
+ 	atomic64_set(&fnic_stats->misc_stats.port_speed_in_mbps, port_speed);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/* Add in other values as they get defined in fw */
  	switch (port_speed) {
@@@ -197,7 -215,18 +204,12 @@@
  	case DCEM_PORTSPEED_100G:
  		fc_host_speed(shost) = FC_PORTSPEED_100GBIT;
  		break;
 -	case DCEM_PORTSPEED_128G:
 -		fc_host_speed(shost) = FC_PORTSPEED_128GBIT;
 -		break;
  	default:
++<<<<<<< HEAD
++=======
+ 		FNIC_MAIN_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "Unknown FC speed: %d Mbps", port_speed);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		fc_host_speed(shost) = FC_PORTSPEED_UNKNOWN;
  		break;
  	}
@@@ -221,9 -251,8 +233,14 @@@ static struct fc_host_statistics *fnic_
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  
  	if (ret) {
++<<<<<<< HEAD
 +		FNIC_MAIN_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "fnic: Get vnic stats failed"
 +			      " 0x%x", ret);
++=======
+ 		FNIC_MAIN_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 					  "fnic: Get vnic stats failed: 0x%x", ret);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return stats;
  	}
  	vs = fnic->stats;
@@@ -333,7 -360,7 +350,11 @@@ static void fnic_reset_host_stats(struc
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  
  	if (ret) {
++<<<<<<< HEAD
 +		FNIC_MAIN_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_MAIN_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				"fnic: Reset vnic stats failed"
  				" 0x%x", ret);
  		return;
@@@ -558,9 -562,23 +579,29 @@@ static void fnic_set_vlan(struct fnic *
  	vnic_dev_set_default_vlan(fnic->vdev, vlan_id);
  }
  
++<<<<<<< HEAD
 +static int fnic_scsi_drv_init(struct fnic *fnic)
 +{
 +	struct Scsi_Host *host = fnic->lport->host;
++=======
+ static void fnic_scsi_init(struct fnic *fnic)
+ {
+ 	struct Scsi_Host *host = fnic->host;
+ 
+ 	snprintf(fnic->name, sizeof(fnic->name) - 1, "%s%d", DRV_NAME,
+ 			 host->host_no);
+ 
+ 	host->transportt = fnic_fc_transport;
+ }
+ 
+ static int fnic_scsi_drv_init(struct fnic *fnic)
+ {
+ 	struct Scsi_Host *host = fnic->host;
+ 	int err;
+ 	struct pci_dev *pdev = fnic->pdev;
+ 	struct fnic_iport_s *iport = &fnic->iport;
+ 	int hwq;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/* Configure maximum outstanding IO reqs*/
  	if (fnic->config.io_throttle_count != FNIC_UCSM_DFLT_THROTTLE_CNT_BLD)
@@@ -571,32 -589,100 +612,113 @@@
  	fnic->fnic_max_tag_id = host->can_queue;
  	host->max_lun = fnic->config.luns_per_tgt;
  	host->max_id = FNIC_MAX_FCP_TARGET;
 -	host->max_cmd_len = FNIC_FCOE_MAX_CMD_LEN;
 +	host->max_cmd_len = FCOE_MAX_CMD_LEN;
  
  	host->nr_hw_queues = fnic->wq_copy_count;
 +	if (host->nr_hw_queues > 1)
 +		shost_printk(KERN_ERR, host,
 +				"fnic: blk-mq is not supported");
  
 -	dev_info(&fnic->pdev->dev, "fnic: can_queue: %d max_lun: %llu",
 +	host->nr_hw_queues = fnic->wq_copy_count = 1;
 +
 +	shost_printk(KERN_INFO, host,
 +			"fnic: can_queue: %d max_lun: %llu",
  			host->can_queue, host->max_lun);
  
 -	dev_info(&fnic->pdev->dev, "fnic: max_id: %d max_cmd_len: %d nr_hw_queues: %d",
 +	shost_printk(KERN_INFO, host,
 +			"fnic: max_id: %d max_cmd_len: %d nr_hw_queues: %d",
  			host->max_id, host->max_cmd_len, host->nr_hw_queues);
  
++<<<<<<< HEAD
++	return 0;
++}
++
++=======
+ 	for (hwq = 0; hwq < fnic->wq_copy_count; hwq++) {
+ 		fnic->sw_copy_wq[hwq].ioreq_table_size = fnic->fnic_max_tag_id;
+ 		fnic->sw_copy_wq[hwq].io_req_table =
+ 			kzalloc((fnic->sw_copy_wq[hwq].ioreq_table_size + 1) *
+ 					sizeof(struct fnic_io_req *), GFP_KERNEL);
+ 	}
+ 
+ 	dev_info(&fnic->pdev->dev, "fnic copy wqs: %d, Q0 ioreq table size: %d\n",
+ 			fnic->wq_copy_count, fnic->sw_copy_wq[0].ioreq_table_size);
+ 
+ 	fnic_scsi_init(fnic);
+ 
+ 	err = scsi_add_host(fnic->host, &pdev->dev);
+ 	if (err) {
+ 		dev_err(&fnic->pdev->dev, "fnic: scsi add host failed: aborting\n");
+ 		return -1;
+ 	}
+ 	fc_host_maxframe_size(fnic->host) = iport->max_payload_size;
+ 	fc_host_dev_loss_tmo(fnic->host) =
+ 		fnic->config.port_down_timeout / 1000;
+ 	sprintf(fc_host_symbolic_name(fnic->host),
+ 			DRV_NAME " v" DRV_VERSION " over %s", fnic->name);
+ 	fc_host_port_type(fnic->host) = FC_PORTTYPE_NPORT;
+ 	fc_host_node_name(fnic->host) = iport->wwnn;
+ 	fc_host_port_name(fnic->host) = iport->wwpn;
+ 	fc_host_supported_classes(fnic->host) = FC_COS_CLASS3;
+ 	memset(fc_host_supported_fc4s(fnic->host), 0,
+ 		   sizeof(fc_host_supported_fc4s(fnic->host)));
+ 	fc_host_supported_fc4s(fnic->host)[2] = 1;
+ 	fc_host_supported_fc4s(fnic->host)[7] = 1;
+ 	fc_host_supported_speeds(fnic->host) = 0;
+ 	fc_host_supported_speeds(fnic->host) |= FC_PORTSPEED_8GBIT;
+ 
+ 	dev_info(&fnic->pdev->dev, "shost_data: 0x%p\n", fnic->host->shost_data);
+ 	if (fnic->host->shost_data != NULL) {
+ 		if (fnic_tgt_id_binding == 0) {
+ 			dev_info(&fnic->pdev->dev, "Setting target binding to NONE\n");
+ 			fc_host_tgtid_bind_type(fnic->host) = FC_TGTID_BIND_NONE;
+ 		} else {
+ 			dev_info(&fnic->pdev->dev, "Setting target binding to WWPN\n");
+ 			fc_host_tgtid_bind_type(fnic->host) = FC_TGTID_BIND_BY_WWPN;
+ 		}
+ 	}
+ 
+ 	fnic->io_req_pool = mempool_create_slab_pool(2, fnic_io_req_cache);
+ 	if (!fnic->io_req_pool) {
+ 		scsi_remove_host(fnic->host);
+ 		return -ENOMEM;
+ 	}
+ 
  	return 0;
  }
  
+ void fnic_mq_map_queues_cpus(struct Scsi_Host *host)
+ {
+ 	struct fnic *fnic = *((struct fnic **) shost_priv(host));
+ 	struct pci_dev *l_pdev = fnic->pdev;
+ 	int intr_mode = fnic->config.intr_mode;
+ 	struct blk_mq_queue_map *qmap = &host->tag_set.map[HCTX_TYPE_DEFAULT];
+ 
+ 	if (intr_mode == VNIC_DEV_INTR_MODE_MSI || intr_mode == VNIC_DEV_INTR_MODE_INTX) {
+ 		FNIC_MAIN_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"intr_mode is not msix\n");
+ 		return;
+ 	}
+ 
+ 	FNIC_MAIN_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			"qmap->nr_queues: %d\n", qmap->nr_queues);
+ 
+ 	if (l_pdev == NULL) {
+ 		FNIC_MAIN_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 						"l_pdev is null\n");
+ 		return;
+ 	}
+ 
+ 	blk_mq_pci_map_queues(qmap, l_pdev, FNIC_PCI_OFFSET);
+ }
+ 
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  static int fnic_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
  {
 -	struct Scsi_Host *host = NULL;
 +	struct Scsi_Host *host;
 +	struct fc_lport *lp;
  	struct fnic *fnic;
  	mempool_t *pool;
 -	struct fnic_iport_s *iport;
  	int err = 0;
  	int fnic_id = 0;
  	int i;
@@@ -734,13 -813,38 +856,43 @@@
  	/* Get vNIC configuration */
  	err = fnic_get_vnic_config(fnic);
  	if (err) {
 -		dev_err(&fnic->pdev->dev, "Get vNIC configuration failed, "
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			     "Get vNIC configuration failed, "
  			     "aborting.\n");
 -		goto err_out_fnic_get_config;
 +		goto err_out_dev_close;
  	}
  
++<<<<<<< HEAD
 +	fnic_scsi_drv_init(fnic);
++=======
+ 	switch (fnic->config.flags & 0xff0) {
+ 	case VFCF_FC_INITIATOR:
+ 		{
+ 			host =
+ 				scsi_host_alloc(&fnic_host_template,
+ 								sizeof(struct fnic *));
+ 			if (!host) {
+ 				dev_err(&fnic->pdev->dev, "Unable to allocate scsi host\n");
+ 				err = -ENOMEM;
+ 				goto err_out_scsi_host_alloc;
+ 			}
+ 			*((struct fnic **) shost_priv(host)) = fnic;
+ 
+ 			fnic->host = host;
+ 			fnic->role = FNIC_ROLE_FCP_INITIATOR;
+ 			dev_info(&fnic->pdev->dev, "fnic: %d is scsi initiator\n",
+ 					fnic->fnic_num);
+ 		}
+ 		break;
+ 	default:
+ 		dev_info(&fnic->pdev->dev, "fnic: %d has no role defined\n", fnic->fnic_num);
+ 		err = -EINVAL;
+ 		goto err_out_fnic_role;
+ 	}
+ 
+ 	/* Setup PCI resources */
+ 	pci_set_drvdata(pdev, fnic);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	fnic_get_res_counts(fnic);
  
@@@ -941,42 -1039,56 +1093,66 @@@
  
  	return 0;
  
++<<<<<<< HEAD
 +err_out_free_exch_mgr:
 +	fc_exch_mgr_free(lp);
 +err_out_remove_scsi_host:
 +	fc_remove_host(lp->host);
 +	scsi_remove_host(lp->host);
 +err_out_free_rq_buf:
 +	for (i = 0; i < fnic->rq_count; i++)
++=======
+ err_out_free_stats_debugfs:
+ 	fnic_stats_debugfs_remove(fnic);
+ 	scsi_remove_host(fnic->host);
+ err_out_scsi_drv_init:
+ 	fnic_free_intr(fnic);
+ err_out_fnic_request_intr:
+ err_out_alloc_rq_buf:
+ 	for (i = 0; i < fnic->rq_count; i++) {
+ 		if (ioread32(&fnic->rq[i].ctrl->enable))
+ 			vnic_rq_disable(&fnic->rq[i]);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		vnic_rq_clean(&fnic->rq[i], fnic_free_rq_buf);
 -	}
  	vnic_dev_notify_unset(fnic->vdev);
 -err_out_fnic_notify_set:
 -	mempool_destroy(fnic->frame_elem_pool);
 -err_out_fdls_frame_elem_pool:
 -	mempool_destroy(fnic->frame_pool);
 -err_out_fdls_frame_pool:
 +err_out_free_max_pool:
  	mempool_destroy(fnic->io_sgl_pool[FNIC_SGL_CACHE_MAX]);
  err_out_free_dflt_pool:
  	mempool_destroy(fnic->io_sgl_pool[FNIC_SGL_CACHE_DFLT]);
 +err_out_free_ioreq_pool:
 +	mempool_destroy(fnic->io_req_pool);
  err_out_free_resources:
  	fnic_free_vnic_resources(fnic);
 -err_out_fnic_alloc_vnic_res:
 +err_out_clear_intr:
  	fnic_clear_intr_mode(fnic);
++<<<<<<< HEAD
 +err_out_dev_close:
++=======
+ err_out_fnic_set_intr_mode:
+ 	if (IS_FNIC_FCP_INITIATOR(fnic))
+ 		scsi_host_put(fnic->host);
+ err_out_fnic_role:
+ err_out_scsi_host_alloc:
+ err_out_fnic_get_config:
+ err_out_dev_mac_addr:
+ err_out_dev_init:
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	vnic_dev_close(fnic->vdev);
 -err_out_dev_open:
 -err_out_dev_cmd_init:
 +err_out_dev_cmd_deinit:
 +err_out_vnic_unregister:
  	vnic_dev_unregister(fnic->vdev);
 -err_out_dev_register:
 +err_out_iounmap:
  	fnic_iounmap(fnic);
 -err_out_fnic_map_bar:
 -err_out_map_bar:
 -err_out_set_dma_mask:
 +err_out_release_regions:
  	pci_release_regions(pdev);
 -err_out_pci_request_regions:
 +err_out_disable_device:
  	pci_disable_device(pdev);
 -err_out_pci_enable_device:
 +err_out_free_hba:
 +	fnic_stats_debugfs_remove(fnic);
  	ida_free(&fnic_ida, fnic->fnic_num);
  err_out_ida_alloc:
 -	kfree(fnic);
 -err_out_fnic_alloc:
 +	scsi_host_put(lp->host);
 +err_out:
  	return err;
  }
  
@@@ -1055,8 -1159,13 +1231,16 @@@ static void fnic_remove(struct pci_dev 
  	fnic_iounmap(fnic);
  	pci_release_regions(pdev);
  	pci_disable_device(pdev);
 -	pci_set_drvdata(pdev, NULL);
  	ida_free(&fnic_ida, fnic->fnic_num);
++<<<<<<< HEAD
 +	scsi_host_put(lp->host);
++=======
+ 	if (IS_FNIC_FCP_INITIATOR(fnic)) {
+ 		fnic_scsi_unload_cleanup(fnic);
+ 		scsi_host_put(fnic->host);
+ 	}
+ 	kfree(fnic);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
  static struct pci_driver fnic_driver = {
diff --cc drivers/scsi/fnic/fnic_scsi.c
index 321954ca143f,7133b254cbe4..000000000000
--- a/drivers/scsi/fnic/fnic_scsi.c
+++ b/drivers/scsi/fnic/fnic_scsi.c
@@@ -35,8 -23,8 +35,7 @@@
  #include <scsi/scsi_tcq.h>
  #include <scsi/fc/fc_els.h>
  #include <scsi/fc/fc_fcoe.h>
- #include <scsi/libfc.h>
  #include <scsi/fc_frame.h>
 -#include <scsi/scsi_transport_fc.h>
  #include "fnic_io.h"
  #include "fnic.h"
  
@@@ -140,11 -126,70 +139,73 @@@ static void fnic_release_ioreq_buf(stru
  				 SCSI_SENSE_BUFFERSIZE, DMA_FROM_DEVICE);
  }
  
++<<<<<<< HEAD
++=======
+ static bool
+ fnic_count_portid_ioreqs_iter(struct fnic *fnic, struct scsi_cmnd *sc,
+ 				void *data1, void *data2)
+ {
+ 	u32 *portid = data1;
+ 	unsigned int *count = data2;
+ 	struct fnic_io_req *io_req = fnic_priv(sc)->io_req;
+ 
+ 	if (!io_req || (*portid && (io_req->port_id != *portid)))
+ 		return true;
+ 
+ 	*count += 1;
+ 	return true;
+ }
+ 
+ unsigned int fnic_count_ioreqs(struct fnic *fnic, u32 portid)
+ {
+ 	unsigned int count = 0;
+ 
+ 	fnic_scsi_io_iter(fnic, fnic_count_portid_ioreqs_iter,
+ 				&portid, &count);
+ 
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		      "portid = 0x%x count = %u\n", portid, count);
+ 	return count;
+ }
+ 
+ unsigned int fnic_count_all_ioreqs(struct fnic *fnic)
+ {
+ 	return fnic_count_ioreqs(fnic, 0);
+ }
+ 
+ static bool
+ fnic_count_lun_ioreqs_iter(struct fnic *fnic, struct scsi_cmnd *sc,
+ 				void *data1, void *data2)
+ {
+ 	struct scsi_device *scsi_device = data1;
+ 	unsigned int *count = data2;
+ 
+ 	if (sc->device != scsi_device || !fnic_priv(sc)->io_req)
+ 		return true;
+ 
+ 	*count += 1;
+ 	return true;
+ }
+ 
+ unsigned int
+ fnic_count_lun_ioreqs(struct fnic *fnic, struct scsi_device *scsi_device)
+ {
+ 	unsigned int count = 0;
+ 
+ 	fnic_scsi_io_iter(fnic, fnic_count_lun_ioreqs_iter,
+ 				scsi_device, &count);
+ 
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		      "lun = %p count = %u\n", scsi_device, count);
+ 	return count;
+ }
+ 
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  /* Free up Copy Wq descriptors. Called with copy_wq lock held */
 -static int free_wq_copy_descs(struct fnic *fnic, struct vnic_wq_copy *wq, unsigned int hwq)
 +static int free_wq_copy_descs(struct fnic *fnic, struct vnic_wq_copy *wq)
  {
  	/* if no Ack received from firmware, then nothing to clean */
 -	if (!fnic->fw_ack_recd[hwq])
 +	if (!fnic->fw_ack_recd[0])
  		return 1;
  
  	/*
@@@ -227,6 -268,8 +288,11 @@@ int fnic_fw_reset_handler(struct fnic *
  	if (!vnic_wq_copy_desc_avail(wq))
  		ret = -EAGAIN;
  	else {
++<<<<<<< HEAD
++=======
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			  "ioreq_count: %u\n", ioreq_count);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		fnic_queue_wq_copy_desc_fw_reset(wq, SCSI_NO_TAG);
  		atomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);
  		if (atomic64_read(&fnic->fnic_stats.fw_stats.active_fw_reqs) >
@@@ -240,12 -283,12 +306,21 @@@
  
  	if (!ret) {
  		atomic64_inc(&fnic->fnic_stats.reset_stats.fw_resets);
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "Issued fw reset\n");
 +	} else {
 +		fnic_clear_state_flags(fnic, FNIC_FLAGS_FWRESET);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "Failed to issue fw reset\n");
++=======
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				"Issued fw reset\n");
+ 	} else {
+ 		fnic_clear_state_flags(fnic, FNIC_FLAGS_FWRESET);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 				"Failed to issue fw reset\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
  	return ret;
@@@ -275,28 -318,23 +350,42 @@@ int fnic_flogi_reg_handler(struct fnic 
  		goto flogi_reg_ioreq_end;
  	}
  
 -	memcpy(gw_mac, fnic->iport.fcfmac, ETH_ALEN);
 -	format = FCPIO_FLOGI_REG_GW_DEST;
 +	if (fnic->ctlr.map_dest) {
 +		eth_broadcast_addr(gw_mac);
 +		format = FCPIO_FLOGI_REG_DEF_DEST;
 +	} else {
 +		memcpy(gw_mac, fnic->ctlr.dest_addr, ETH_ALEN);
 +		format = FCPIO_FLOGI_REG_GW_DEST;
 +	}
  
 -	if (fnic->config.flags & VFCF_FIP_CAPABLE) {
 +	if ((fnic->config.flags & VFCF_FIP_CAPABLE) && !fnic->ctlr.map_dest) {
  		fnic_queue_wq_copy_desc_fip_reg(wq, SCSI_NO_TAG,
  						fc_id, gw_mac,
++<<<<<<< HEAD
 +						fnic->data_src_addr,
 +						lp->r_a_tov, lp->e_d_tov);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "FLOGI FIP reg issued fcid %x src %pM dest %pM\n",
 +			      fc_id, fnic->data_src_addr, gw_mac);
 +	} else {
 +		fnic_queue_wq_copy_desc_flogi_reg(wq, SCSI_NO_TAG,
 +						  format, fc_id, gw_mac);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "FLOGI reg issued fcid %x map %d dest %pM\n",
 +			      fc_id, fnic->ctlr.map_dest, gw_mac);
++=======
+ 						fnic->iport.fpma,
+ 						iport->r_a_tov, iport->e_d_tov);
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			      "FLOGI FIP reg issued fcid: 0x%x src %p dest %p\n",
+ 				  fc_id, fnic->iport.fpma, gw_mac);
+ 	} else {
+ 		fnic_queue_wq_copy_desc_flogi_reg(wq, SCSI_NO_TAG,
+ 						  format, fc_id, gw_mac);
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			"FLOGI reg issued fcid 0x%x dest %p\n",
+ 			fc_id, gw_mac);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
  	atomic64_inc(&fnic->fnic_stats.fw_stats.active_fw_reqs);
@@@ -366,14 -409,11 +455,18 @@@ static inline int fnic_queue_wq_copy_de
  	int_to_scsilun(sc->device->lun, &fc_lun);
  
  	/* Enqueue the descriptor in the Copy WQ */
 -	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[hwq])
 -		free_wq_copy_descs(fnic, wq, hwq);
 +	spin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);
 +
 +	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])
 +		free_wq_copy_descs(fnic, wq);
  
  	if (unlikely(!vnic_wq_copy_desc_avail(wq))) {
++<<<<<<< HEAD
 +		spin_unlock_irqrestore(&fnic->wq_copy_lock[0], intr_flags);
 +		FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "fnic_queue_wq_copy_desc failure - no descriptors\n");
  		atomic64_inc(&misc_stats->io_cpwq_alloc_failures);
  		return SCSI_MLQUEUE_HOST_BUSY;
@@@ -446,7 -478,7 +539,11 @@@ static int fnic_queuecommand_lck(struc
  
  	rport = starget_to_rport(scsi_target(sc->device));
  	if (!rport) {
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				"returning DID_NO_CONNECT for IO as rport is NULL\n");
  		sc->result = DID_NO_CONNECT << 16;
  		done(sc);
@@@ -455,49 -487,98 +552,131 @@@
  
  	ret = fc_remote_port_chkready(rport);
  	if (ret) {
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				"rport is not ready\n");
 -		atomic64_inc(&fnic_stats->misc_stats.tport_not_ready);
 +		atomic64_inc(&fnic_stats->misc_stats.rport_not_ready);
  		sc->result = ret;
  		done(sc);
  		return 0;
  	}
  
 -	mqtag = blk_mq_unique_tag(rq);
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	iport = &fnic->iport;
 +	rp = rport->dd_data;
 +	if (!rp || rp->rp_state == RPORT_ST_DELETE) {
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			"rport 0x%x removed, returning DID_NO_CONNECT\n",
 +			rport->port_id);
  
++<<<<<<< HEAD
 +		atomic64_inc(&fnic_stats->misc_stats.rport_not_ready);
 +		sc->result = DID_NO_CONNECT<<16;
++=======
+ 	if (iport->state != FNIC_IPORT_STATE_READY) {
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "returning DID_NO_CONNECT for IO as iport state: %d\n",
+ 					  iport->state);
+ 		sc->result = DID_NO_CONNECT << 16;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		done(sc);
  		return 0;
  	}
  
++<<<<<<< HEAD
 +	if (rp->rp_state != RPORT_ST_READY) {
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			"rport 0x%x in state 0x%x, returning DID_IMM_RETRY\n",
 +			rport->port_id, rp->rp_state);
 +
 +		sc->result = DID_IMM_RETRY << 16;
++=======
+ 	/* fc_remote_port_add() may have added the tport to
+ 	 * fc_transport but dd_data not yet set
+ 	 */
+ 	rdd_data = rport->dd_data;
+ 	tport = rdd_data->tport;
+ 	if (!tport || (rdd_data->iport != iport)) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "dd_data not yet set in SCSI for rport portid: 0x%x\n",
+ 					  rport->port_id);
+ 		tport = fnic_find_tport_by_fcid(iport, rport->port_id);
+ 		if (!tport) {
+ 			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 			FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 						  "returning DID_BUS_BUSY for IO as tport not found for: 0x%x\n",
+ 						  rport->port_id);
+ 			sc->result = DID_BUS_BUSY << 16;
+ 			done(sc);
+ 			return 0;
+ 		}
+ 
+ 		/* Re-assign same params as in fnic_fdls_add_tport */
+ 		rport->maxframe_size = FNIC_FC_MAX_PAYLOAD_LEN;
+ 		rport->supported_classes =
+ 			FC_COS_CLASS3 | FC_RPORT_ROLE_FCP_TARGET;
+ 		/* the dd_data is allocated by fctransport of size dd_fcrport_size */
+ 		rdd_data = rport->dd_data;
+ 		rdd_data->tport = tport;
+ 		rdd_data->iport = iport;
+ 		tport->rport = rport;
+ 		tport->flags |= FNIC_FDLS_SCSI_REGISTERED;
+ 	}
+ 
+ 	if ((tport->state != FDLS_TGT_STATE_READY)
+ 		&& (tport->state != FDLS_TGT_STATE_ADISC)) {
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "returning DID_NO_CONNECT for IO as tport state: %d\n",
+ 					  tport->state);
+ 		sc->result = DID_NO_CONNECT << 16;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		done(sc);
  		return 0;
  	}
  
 +	if (lp->state != LPORT_ST_READY || !(lp->link_up))
 +		return SCSI_MLQUEUE_HOST_BUSY;
 +
  	atomic_inc(&fnic->in_flight);
 -	atomic_inc(&tport->in_flight);
  
++<<<<<<< HEAD
 +	/*
 +	 * Release host lock, use driver resource specific locks from here.
 +	 * Don't re-enable interrupts in case they were disabled prior to the
 +	 * caller disabling them.
 +	 */
 +	spin_unlock(lp->host->host_lock);
 +	CMD_STATE(sc) = FNIC_IOREQ_NOT_INITED;
 +	CMD_FLAGS(sc) = FNIC_NO_FLAGS;
++=======
+ 	if (unlikely(fnic_chk_state_flags_locked(fnic, FNIC_FLAGS_IO_BLOCKED))) {
+ 		atomic_dec(&fnic->in_flight);
+ 		atomic_dec(&tport->in_flight);
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		return SCSI_MLQUEUE_HOST_BUSY;
+ 	}
+ 
+ 	if (unlikely(fnic_chk_state_flags_locked(fnic, FNIC_FLAGS_FWRESET))) {
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 		  "fnic flags FW reset: 0x%lx. Returning SCSI_MLQUEUE_HOST_BUSY\n",
+ 		  fnic->state_flags);
+ 		return SCSI_MLQUEUE_HOST_BUSY;
+ 	}
+ 
+ 	if (!tport->lun0_delay) {
+ 		lun0_delay = 1;
+ 		tport->lun0_delay++;
+ 	}
+ 
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 
+ 	fnic_priv(sc)->state = FNIC_IOREQ_NOT_INITED;
+ 	fnic_priv(sc)->flags = FNIC_NO_FLAGS;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/* Get a new io_req for this SCSI IO */
  	io_req = mempool_alloc(fnic->io_req_pool, GFP_ATOMIC);
@@@ -608,11 -700,17 +787,22 @@@ out
  
  	/* if only we issued IO, will we have the io lock */
  	if (io_lock_acquired)
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(io_lock, flags);
  
  	atomic_dec(&fnic->in_flight);
++<<<<<<< HEAD
 +	/* acquire host lock before returning to SCSI */
 +	spin_lock(lp->host->host_lock);
++=======
+ 	atomic_dec(&tport->in_flight);
+ 
+ 	if (lun0_delay) {
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "LUN0 delay\n");
+ 		mdelay(LUN0_DELAY_TIME);
+ 	}
+ 
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	return ret;
  }
  
@@@ -649,31 -746,23 +839,48 @@@ static int fnic_fcpio_fw_reset_cmpl_han
  	if (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE) {
  		/* Check status of reset completion */
  		if (!hdr_status) {
++<<<<<<< HEAD
 +			FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				      "reset cmpl success\n");
 +			/* Ready to send flogi out */
 +			fnic->state = FNIC_IN_ETH_MODE;
 +		} else {
 +			FNIC_SCSI_DBG(KERN_DEBUG,
 +				      fnic->lport->host,
 +				      "fnic fw_reset : failed %s\n",
 +				      fnic_fcpio_status_to_str(hdr_status));
++=======
+ 			FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					"reset cmpl success\n");
+ 			/* Ready to send flogi out */
+ 			fnic->state = FNIC_IN_ETH_MODE;
+ 		} else {
+ 			FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 				"reset failed with header status: %s\n",
+ 				fnic_fcpio_status_to_str(hdr_status));
 -
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
 +
 +			/*
 +			 * Unable to change to eth mode, cannot send out flogi
 +			 * Change state to fc mode, so that subsequent Flogi
 +			 * requests from libFC will cause more attempts to
 +			 * reset the firmware. Free the cached flogi
 +			 */
  			fnic->state = FNIC_IN_FC_MODE;
  			atomic64_inc(&reset_stats->fw_reset_failures);
  			ret = -1;
  		}
  	} else {
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG,
 +			      fnic->lport->host,
 +			      "Unexpected state %s while processing"
 +			      " reset cmpl\n", fnic_state_to_str(fnic->state));
++=======
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"Unexpected state while processing reset completion: %s\n",
+ 			fnic_state_to_str(fnic->state));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		atomic64_inc(&reset_stats->fw_reset_failures);
  		ret = -1;
  	}
@@@ -724,19 -812,19 +931,33 @@@ static int fnic_fcpio_flogi_reg_cmpl_ha
  
  		/* Check flogi registration completion status */
  		if (!hdr_status) {
++<<<<<<< HEAD
 +			FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				      "flog reg succeeded\n");
 +			fnic->state = FNIC_IN_FC_MODE;
 +		} else {
 +			FNIC_SCSI_DBG(KERN_DEBUG,
 +				      fnic->lport->host,
 +				      "fnic flogi reg :failed %s\n",
++=======
+ 			FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				      "FLOGI reg succeeded\n");
+ 			fnic->state = FNIC_IN_FC_MODE;
+ 		} else {
+ 			FNIC_SCSI_DBG(KERN_DEBUG,
+ 				      fnic->host, fnic->fnic_num,
+ 				      "fnic flogi reg failed: %s\n",
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				      fnic_fcpio_status_to_str(hdr_status));
  			fnic->state = FNIC_IN_ETH_MODE;
  			ret = -1;
  		}
  	} else {
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			      "Unexpected fnic state %s while"
  			      " processing flogi reg completion\n",
  			      fnic_state_to_str(fnic->state));
@@@ -806,9 -895,9 +1027,9 @@@ static inline void fnic_fcpio_ack_handl
  		atomic64_inc(
  			&fnic->fnic_stats.misc_stats.ack_index_out_of_range);
  
 -	spin_unlock_irqrestore(&fnic->wq_copy_lock[wq_index], flags);
 +	spin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);
  	FNIC_TRACE(fnic_fcpio_ack_handler,
- 		  fnic->lport->host->host_no, 0, 0, ox_id_tag[2], ox_id_tag[3],
+ 		  fnic->host->host_no, 0, 0, ox_id_tag[2], ox_id_tag[3],
  		  ox_id_tag[4], ox_id_tag[5]);
  }
  
@@@ -833,24 -921,45 +1054,52 @@@ static void fnic_fcpio_icmnd_cmpl_handl
  	u64 cmd_trace;
  	unsigned long start_time;
  	unsigned long io_duration_time;
 -	unsigned int hwq = 0;
 -	unsigned int mqtag = 0;
 -	unsigned int tag = 0;
  
  	/* Decode the cmpl description to get the io_req id */
 -	fcpio_header_dec(&desc->hdr, &type, &hdr_status, &ftag);
 -	fcpio_tag_id_dec(&ftag, &id);
 +	fcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);
 +	fcpio_tag_id_dec(&tag, &id);
  	icmnd_cmpl = &desc->u.icmnd_cmpl;
  
++<<<<<<< HEAD
 +	if (id >= fnic->fnic_max_tag_id) {
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			"Tag out of range tag %x hdr status = %s\n",
 +			     id, fnic_fcpio_status_to_str(hdr_status));
++=======
+ 	mqtag = id;
+ 	tag = blk_mq_unique_tag_to_tag(mqtag);
+ 	hwq = blk_mq_unique_tag_to_hwq(mqtag);
+ 
+ 	if (hwq != cq_index) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x cq index: %d ",
+ 			hwq, mqtag, tag, cq_index);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hdr status: %s icmnd completion on the wrong queue\n",
+ 			fnic_fcpio_status_to_str(hdr_status));
+ 	}
+ 
+ 	if (tag >= fnic->fnic_max_tag_id) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x cq index: %d ",
+ 			hwq, mqtag, tag, cq_index);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hdr status: %s Out of range tag\n",
+ 			fnic_fcpio_status_to_str(hdr_status));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return;
  	}
 -	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
  
- 	sc = scsi_host_find_tag(fnic->lport->host, id);
+ 	sc = scsi_host_find_tag(fnic->host, id);
  	WARN_ON_ONCE(!sc);
  	if (!sc) {
  		atomic64_inc(&fnic_stats->io_stats.sc_null);
++<<<<<<< HEAD
 +		shost_printk(KERN_ERR, fnic->lport->host,
++=======
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		shost_printk(KERN_ERR, fnic->host,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "icmnd_cmpl sc is null - "
  			  "hdr status = %s tag = 0x%x desc = 0x%p\n",
  			  fnic_fcpio_status_to_str(hdr_status), id, desc);
@@@ -871,9 -985,9 +1120,15 @@@
  	WARN_ON_ONCE(!io_req);
  	if (!io_req) {
  		atomic64_inc(&fnic_stats->io_stats.ioreq_null);
++<<<<<<< HEAD
 +		CMD_FLAGS(sc) |= FNIC_IO_REQ_NULL;
 +		spin_unlock_irqrestore(io_lock, flags);
 +		shost_printk(KERN_ERR, fnic->lport->host,
++=======
+ 		fnic_priv(sc)->flags |= FNIC_IO_REQ_NULL;
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		shost_printk(KERN_ERR, fnic->host,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "icmnd_cmpl io_req is null - "
  			  "hdr status = %s tag = 0x%x sc 0x%p\n",
  			  fnic_fcpio_status_to_str(hdr_status), id, sc);
@@@ -894,13 -1008,13 +1149,17 @@@
  		 * set the FNIC_IO_DONE so that this doesn't get
  		 * flagged as 'out of order' if it was not aborted
  		 */
 -		fnic_priv(sc)->flags |= FNIC_IO_DONE;
 -		fnic_priv(sc)->flags |= FNIC_IO_ABTS_PENDING;
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		CMD_FLAGS(sc) |= FNIC_IO_DONE;
 +		CMD_FLAGS(sc) |= FNIC_IO_ABTS_PENDING;
 +		spin_unlock_irqrestore(io_lock, flags);
  		if(FCPIO_ABORTED == hdr_status)
 -			fnic_priv(sc)->flags |= FNIC_IO_ABORTED;
 +			CMD_FLAGS(sc) |= FNIC_IO_ABORTED;
  
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			"icmnd_cmpl abts pending "
  			  "hdr status = %s tag = 0x%x sc = 0x%p "
  			  "scsi_status = %x residual = %d\n",
@@@ -931,6 -1045,9 +1190,12 @@@
  
  		if (icmnd_cmpl->scsi_status == SAM_STAT_TASK_SET_FULL)
  			atomic64_inc(&fnic_stats->misc_stats.queue_fulls);
++<<<<<<< HEAD
++=======
+ 
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				"xfer_len: %llu", xfer_len);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		break;
  
  	case FCPIO_TIMEOUT:          /* request was timed out */
@@@ -1071,40 -1189,78 +1336,98 @@@ static void fnic_fcpio_itmf_cmpl_handle
  	struct terminate_stats *term_stats = &fnic->fnic_stats.term_stats;
  	struct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;
  	unsigned long flags;
 +	spinlock_t *io_lock;
  	unsigned long start_time;
 -	unsigned int hwq = cq_index;
 -	unsigned int mqtag;
 -	unsigned int tag;
  
 -	fcpio_header_dec(&desc->hdr, &type, &hdr_status, &ftag);
 -	fcpio_tag_id_dec(&ftag, &id);
 +	fcpio_header_dec(&desc->hdr, &type, &hdr_status, &tag);
 +	fcpio_tag_id_dec(&tag, &id);
  
++<<<<<<< HEAD
 +	if ((id & FNIC_TAG_MASK) >= fnic->fnic_max_tag_id) {
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +		"Tag out of range tag %x hdr status = %s\n",
 +		id, fnic_fcpio_status_to_str(hdr_status));
 +		return;
 +	}
 +
 +	sc = scsi_host_find_tag(fnic->lport->host, id & FNIC_TAG_MASK);
 +	WARN_ON_ONCE(!sc);
 +	if (!sc) {
 +		atomic64_inc(&fnic_stats->io_stats.sc_null);
 +		shost_printk(KERN_ERR, fnic->lport->host,
++=======
+ 	mqtag = id & FNIC_TAG_MASK;
+ 	tag = blk_mq_unique_tag_to_tag(id & FNIC_TAG_MASK);
+ 	hwq = blk_mq_unique_tag_to_hwq(id & FNIC_TAG_MASK);
+ 
+ 	if (hwq != cq_index) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x cq index: %d ",
+ 			hwq, mqtag, tag, cq_index);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hdr status: %s ITMF completion on the wrong queue\n",
+ 			fnic_fcpio_status_to_str(hdr_status));
+ 	}
+ 
+ 	if (tag > fnic->fnic_max_tag_id) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x cq index: %d ",
+ 			hwq, mqtag, tag, cq_index);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hdr status: %s Tag out of range\n",
+ 			fnic_fcpio_status_to_str(hdr_status));
+ 		return;
+ 	}  else if ((tag == fnic->fnic_max_tag_id) && !(id & FNIC_TAG_DEV_RST)) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x cq index: %d ",
+ 			hwq, mqtag, tag, cq_index);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hdr status: %s Tag out of range\n",
+ 			fnic_fcpio_status_to_str(hdr_status));
+ 		return;
+ 	}
+ 
+ 	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
+ 
+ 	/* If it is sg3utils allocated SC then tag_id
+ 	 * is max_tag_id and SC is retrieved from io_req
+ 	 */
+ 	if ((mqtag == fnic->fnic_max_tag_id) && (id & FNIC_TAG_DEV_RST)) {
+ 		io_req = fnic->sw_copy_wq[hwq].io_req_table[tag];
+ 		if (io_req)
+ 			sc = io_req->sc;
+ 	} else {
+ 		sc = scsi_host_find_tag(fnic->host, id & FNIC_TAG_MASK);
+ 	}
+ 
+ 	WARN_ON_ONCE(!sc);
+ 	if (!sc) {
+ 		atomic64_inc(&fnic_stats->io_stats.sc_null);
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		shost_printk(KERN_ERR, fnic->host,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "itmf_cmpl sc is null - hdr status = %s tag = 0x%x\n",
 -			  fnic_fcpio_status_to_str(hdr_status), tag);
 +			  fnic_fcpio_status_to_str(hdr_status), id);
  		return;
  	}
 -
 -	io_req = fnic_priv(sc)->io_req;
 +	io_lock = fnic_io_lock_hash(fnic, sc);
 +	spin_lock_irqsave(io_lock, flags);
 +	io_req = (struct fnic_io_req *)CMD_SP(sc);
  	WARN_ON_ONCE(!io_req);
  	if (!io_req) {
  		atomic64_inc(&fnic_stats->io_stats.ioreq_null);
++<<<<<<< HEAD
 +		spin_unlock_irqrestore(io_lock, flags);
 +		CMD_FLAGS(sc) |= FNIC_IO_ABT_TERM_REQ_NULL;
 +		shost_printk(KERN_ERR, fnic->lport->host,
++=======
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		fnic_priv(sc)->flags |= FNIC_IO_ABT_TERM_REQ_NULL;
+ 		shost_printk(KERN_ERR, fnic->host,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "itmf_cmpl io_req is null - "
  			  "hdr status = %s tag = 0x%x sc 0x%p\n",
 -			  fnic_fcpio_status_to_str(hdr_status), tag, sc);
 +			  fnic_fcpio_status_to_str(hdr_status), id, sc);
  		return;
  	}
  	start_time = io_req->start_time;
@@@ -1112,17 -1268,22 +1435,34 @@@
  	if ((id & FNIC_TAG_ABORT) && (id & FNIC_TAG_DEV_RST)) {
  		/* Abort and terminate completion of device reset req */
  		/* REVISIT : Add asserts about various flags */
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "dev reset abts cmpl recd. id %x status %s\n",
 +			      id, fnic_fcpio_status_to_str(hdr_status));
 +		CMD_STATE(sc) = FNIC_IOREQ_ABTS_COMPLETE;
 +		CMD_ABTS_STATUS(sc) = hdr_status;
 +		CMD_FLAGS(sc) |= FNIC_DEV_RST_DONE;
++=======
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s Abt/term completion received\n",
+ 			hwq, mqtag, tag,
+ 			fnic_fcpio_status_to_str(hdr_status));
+ 		fnic_priv(sc)->state = FNIC_IOREQ_ABTS_COMPLETE;
+ 		fnic_priv(sc)->abts_status = hdr_status;
+ 		fnic_priv(sc)->flags |= FNIC_DEV_RST_DONE;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		if (io_req->abts_done)
  			complete(io_req->abts_done);
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(io_lock, flags);
  	} else if (id & FNIC_TAG_ABORT) {
  		/* Completion of abort cmd */
++<<<<<<< HEAD
++=======
+ 		shost_printk(KERN_DEBUG, fnic->host,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x Abort header status: %s\n",
+ 			hwq, mqtag, tag,
+ 			fnic_fcpio_status_to_str(hdr_status));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		switch (hdr_status) {
  		case FCPIO_SUCCESS:
  			break;
@@@ -1134,7 -1295,7 +1474,11 @@@
  					&term_stats->terminate_fw_timeouts);
  			break;
  		case FCPIO_ITMF_REJECTED:
++<<<<<<< HEAD
 +			FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
++=======
+ 			FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				"abort reject recd. id %d\n",
  				(int)(id & FNIC_TAG_MASK));
  			break;
@@@ -1164,12 -1325,12 +1508,16 @@@
  
  		/* If the status is IO not found consider it as success */
  		if (hdr_status == FCPIO_IO_NOT_FOUND)
 -			fnic_priv(sc)->abts_status = FCPIO_SUCCESS;
 +			CMD_ABTS_STATUS(sc) = FCPIO_SUCCESS;
  
 -		if (!(fnic_priv(sc)->flags & (FNIC_IO_ABORTED | FNIC_IO_DONE)))
 +		if (!(CMD_FLAGS(sc) & (FNIC_IO_ABORTED | FNIC_IO_DONE)))
  			atomic64_inc(&misc_stats->no_icmnd_itmf_cmpls);
  
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			      "abts cmpl recd. id %d status %s\n",
  			      (int)(id & FNIC_TAG_MASK),
  			      fnic_fcpio_status_to_str(hdr_status));
@@@ -1181,87 -1342,89 +1529,140 @@@
  		 */
  		if (io_req->abts_done) {
  			complete(io_req->abts_done);
++<<<<<<< HEAD
 +			spin_unlock_irqrestore(io_lock, flags);
 +		} else {
 +			FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				      "abts cmpl, completing IO\n");
 +			CMD_SP(sc) = NULL;
++=======
+ 			spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 			shost_printk(KERN_INFO, fnic->host,
+ 					"hwq: %d mqtag: 0x%x tag: 0x%x Waking up abort thread\n",
+ 					hwq, mqtag, tag);
+ 		} else {
+ 			FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s Completing IO\n",
+ 				hwq, mqtag,
+ 				tag, fnic_fcpio_status_to_str(hdr_status));
+ 			fnic_priv(sc)->io_req = NULL;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			sc->result = (DID_ERROR << 16);
 -			fnic->sw_copy_wq[hwq].io_req_table[tag] = NULL;
 -			spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +
 +			spin_unlock_irqrestore(io_lock, flags);
  
  			fnic_release_ioreq_buf(fnic, io_req, sc);
  			mempool_free(io_req, fnic->io_req_pool);
 -			FNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,
 -				   sc->device->host->host_no, id,
 -				   sc,
 -				   jiffies_to_msecs(jiffies - start_time),
 -				   desc,
 -				   (((u64)hdr_status << 40) |
 -				    (u64)sc->cmnd[0] << 32 |
 -				    (u64)sc->cmnd[2] << 24 |
 -				    (u64)sc->cmnd[3] << 16 |
 -				    (u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 -				   fnic_flags_and_state(sc));
 -			scsi_done(sc);
 -			atomic64_dec(&fnic_stats->io_stats.active_ios);
 -			if (atomic64_read(&fnic->io_cmpl_skip))
 -				atomic64_dec(&fnic->io_cmpl_skip);
 -			else
 -				atomic64_inc(&fnic_stats->io_stats.io_completions);
 +			if (sc->scsi_done) {
 +				FNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,
 +					sc->device->host->host_no, id,
 +					sc,
 +					jiffies_to_msecs(jiffies - start_time),
 +					desc,
 +					(((u64)hdr_status << 40) |
 +					(u64)sc->cmnd[0] << 32 |
 +					(u64)sc->cmnd[2] << 24 |
 +					(u64)sc->cmnd[3] << 16 |
 +					(u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 +					(((u64)CMD_FLAGS(sc) << 32) |
 +					CMD_STATE(sc)));
 +				sc->scsi_done(sc);
 +				atomic64_dec(&fnic_stats->io_stats.active_ios);
 +				if (atomic64_read(&fnic->io_cmpl_skip))
 +					atomic64_dec(&fnic->io_cmpl_skip);
 +				else
 +					atomic64_inc(&fnic_stats->io_stats.io_completions);
 +			}
  		}
 +
  	} else if (id & FNIC_TAG_DEV_RST) {
  		/* Completion of device reset */
++<<<<<<< HEAD
 +		CMD_LR_STATUS(sc) = hdr_status;
 +		if (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {
 +			spin_unlock_irqrestore(io_lock, flags);
 +			CMD_FLAGS(sc) |= FNIC_DEV_RST_ABTS_PENDING;
 +			FNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,
 +				  sc->device->host->host_no, id, sc,
 +				  jiffies_to_msecs(jiffies - start_time),
 +				  desc, 0,
 +				  (((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));
 +			FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				"Terminate pending "
 +				"dev reset cmpl recd. id %d status %s\n",
 +				(int)(id & FNIC_TAG_MASK),
 +				fnic_fcpio_status_to_str(hdr_status));
++=======
+ 		shost_printk(KERN_INFO, fnic->host,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x DR hst: %s\n",
+ 			hwq, mqtag,
+ 			tag, fnic_fcpio_status_to_str(hdr_status));
+ 		fnic_priv(sc)->lr_status = hdr_status;
+ 		if (fnic_priv(sc)->state == FNIC_IOREQ_ABTS_PENDING) {
+ 			spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 			fnic_priv(sc)->flags |= FNIC_DEV_RST_ABTS_PENDING;
+ 			FNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,
+ 				  sc->device->host->host_no, id, sc,
+ 				  jiffies_to_msecs(jiffies - start_time),
+ 				  desc, 0, fnic_flags_and_state(sc));
+ 			FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s Terminate pending\n",
+ 				hwq, mqtag,
+ 				tag, fnic_fcpio_status_to_str(hdr_status));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			return;
  		}
 -		if (fnic_priv(sc)->flags & FNIC_DEV_RST_TIMED_OUT) {
 +		if (CMD_FLAGS(sc) & FNIC_DEV_RST_TIMED_OUT) {
  			/* Need to wait for terminate completion */
 -			spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +			spin_unlock_irqrestore(io_lock, flags);
  			FNIC_TRACE(fnic_fcpio_itmf_cmpl_handler,
  				  sc->device->host->host_no, id, sc,
  				  jiffies_to_msecs(jiffies - start_time),
++<<<<<<< HEAD
 +				  desc, 0,
 +				  (((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));
 +			FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 				  desc, 0, fnic_flags_and_state(sc));
+ 			FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  				"dev reset cmpl recd after time out. "
  				"id %d status %s\n",
  				(int)(id & FNIC_TAG_MASK),
  				fnic_fcpio_status_to_str(hdr_status));
  			return;
  		}
++<<<<<<< HEAD
 +		CMD_STATE(sc) = FNIC_IOREQ_CMD_COMPLETE;
 +		CMD_FLAGS(sc) |= FNIC_DEV_RST_DONE;
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "dev reset cmpl recd. id %d status %s\n",
 +			      (int)(id & FNIC_TAG_MASK),
 +			      fnic_fcpio_status_to_str(hdr_status));
++=======
+ 		fnic_priv(sc)->state = FNIC_IOREQ_CMD_COMPLETE;
+ 		fnic_priv(sc)->flags |= FNIC_DEV_RST_DONE;
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x hst: %s DR completion received\n",
+ 			hwq, mqtag,
+ 			tag, fnic_fcpio_status_to_str(hdr_status));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		if (io_req->dr_done)
  			complete(io_req->dr_done);
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(io_lock, flags);
  
  	} else {
++<<<<<<< HEAD
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			     "Unexpected itmf io state %s tag %x\n",
 +			     fnic_ioreq_state_to_str(CMD_STATE(sc)), id);
 +		spin_unlock_irqrestore(io_lock, flags);
++=======
+ 		shost_printk(KERN_ERR, fnic->host,
+ 			"%s: Unexpected itmf io state: hwq: %d tag 0x%x %s\n",
+ 			__func__, hwq, id, fnic_ioreq_state_to_str(fnic_priv(sc)->state));
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
  }
@@@ -1311,7 -1476,7 +1712,11 @@@ static int fnic_fcpio_cmpl_handler(stru
  		break;
  
  	default:
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			      "firmware completion type %d\n",
  			      desc->hdr.type);
  		break;
@@@ -1351,20 -1516,35 +1756,38 @@@ int fnic_wq_copy_cmpl_handler(struct fn
  
  static bool fnic_cleanup_io_iter(struct scsi_cmnd *sc, void *data)
  {
 -	struct request *const rq = scsi_cmd_to_rq(sc);
 +	const int tag = scsi_cmd_to_rq(sc)->tag;
  	struct fnic *fnic = data;
  	struct fnic_io_req *io_req;
 +	unsigned long flags = 0;
 +	spinlock_t *io_lock;
  	unsigned long start_time = 0;
 -	unsigned long flags;
  	struct fnic_stats *fnic_stats = &fnic->fnic_stats;
 -	uint16_t hwq = 0;
 -	int tag;
 -	int mqtag;
  
 -	mqtag = blk_mq_unique_tag(rq);
 -	hwq = blk_mq_unique_tag_to_hwq(mqtag);
 -	tag = blk_mq_unique_tag_to_tag(mqtag);
 +	io_lock = fnic_io_lock_tag(fnic, tag);
 +	spin_lock_irqsave(io_lock, flags);
  
++<<<<<<< HEAD
 +	io_req = (struct fnic_io_req *)CMD_SP(sc);
 +	if ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&
 +	    !(CMD_FLAGS(sc) & FNIC_DEV_RST_DONE)) {
++=======
+ 	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
+ 
+ 	fnic->sw_copy_wq[hwq].io_req_table[tag] = NULL;
+ 
+ 	io_req = fnic_priv(sc)->io_req;
+ 	if (!io_req) {
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d mqtag: 0x%x tag: 0x%x flags: 0x%x No ioreq. Returning\n",
+ 			hwq, mqtag, tag, fnic_priv(sc)->flags);
+ 		return true;
+ 	}
+ 
+ 	if ((fnic_priv(sc)->flags & FNIC_DEVICE_RESET) &&
+ 		!(fnic_priv(sc)->flags & FNIC_DEV_RST_DONE)) {
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		/*
  		 * We will be here only when FW completes reset
  		 * without sending completions for outstanding ios.
@@@ -1397,11 -1574,10 +1820,17 @@@
  	fnic_release_ioreq_buf(fnic, io_req, sc);
  	mempool_free(io_req, fnic->io_req_pool);
  
 +cleanup_scsi_cmd:
  	sc->result = DID_TRANSPORT_DISRUPTED << 16;
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "fnic_cleanup_io: tag:0x%x : sc:0x%p duration = %lu DID_TRANSPORT_DISRUPTED\n",
 +		      tag, sc, jiffies - start_time);
++=======
+ 	FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 	"mqtag: 0x%x tag: 0x%x sc: 0x%p duration = %lu DID_TRANSPORT_DISRUPTED\n",
+ 		mqtag, tag, sc, (jiffies - start_time));
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	if (atomic64_read(&fnic->io_cmpl_skip))
  		atomic64_dec(&fnic->io_cmpl_skip);
@@@ -1429,10 -1599,46 +1858,51 @@@
  	return true;
  }
  
 -static void fnic_cleanup_io(struct fnic *fnic, int exclude_id)
 +static void fnic_cleanup_io(struct fnic *fnic)
  {
++<<<<<<< HEAD
 +	scsi_host_busy_iter(fnic->lport->host,
 +			    fnic_cleanup_io_iter, fnic);
++=======
+ 	unsigned int io_count = 0;
+ 	unsigned long flags;
+ 	struct fnic_io_req *io_req = NULL;
+ 	struct scsi_cmnd *sc = NULL;
+ 
+ 	io_count = fnic_count_all_ioreqs(fnic);
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				  "Outstanding ioreq count: %d active io count: %lld Waiting\n",
+ 				  io_count,
+ 				  atomic64_read(&fnic->fnic_stats.io_stats.active_ios));
+ 
+ 	scsi_host_busy_iter(fnic->host,
+ 						fnic_cleanup_io_iter, fnic);
+ 
+ 	/* with sg3utils device reset, SC needs to be retrieved from ioreq */
+ 	spin_lock_irqsave(&fnic->wq_copy_lock[0], flags);
+ 	io_req = fnic->sw_copy_wq[0].io_req_table[fnic->fnic_max_tag_id];
+ 	if (io_req) {
+ 		sc = io_req->sc;
+ 		if (sc) {
+ 			if ((fnic_priv(sc)->flags & FNIC_DEVICE_RESET)
+ 				&& !(fnic_priv(sc)->flags & FNIC_DEV_RST_DONE)) {
+ 				fnic_priv(sc)->flags |= FNIC_DEV_RST_DONE;
+ 				if (io_req && io_req->dr_done)
+ 					complete(io_req->dr_done);
+ 			}
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);
+ 
+ 	while ((io_count = fnic_count_all_ioreqs(fnic))) {
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		  "Outstanding ioreq count: %d active io count: %lld Waiting\n",
+ 		  io_count,
+ 		  atomic64_read(&fnic->fnic_stats.io_stats.active_ios));
+ 
+ 		schedule_timeout(msecs_to_jiffies(100));
+ 	}
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
  void fnic_wq_copy_cleanup_handler(struct vnic_wq_copy *wq,
@@@ -1480,20 -1688,18 +1950,24 @@@
  
  wq_copy_cleanup_scsi_cmd:
  	sc->result = DID_NO_CONNECT << 16;
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "wq_copy_cleanup_handler:"
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num, "wq_copy_cleanup_handler:"
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		      " DID_NO_CONNECT\n");
  
 -	FNIC_TRACE(fnic_wq_copy_cleanup_handler,
 -		   sc->device->host->host_no, id, sc,
 -		   jiffies_to_msecs(jiffies - start_time),
 -		   0, ((u64)sc->cmnd[0] << 32 |
 -		       (u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |
 -		       (u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 -		   fnic_flags_and_state(sc));
 +	if (sc->scsi_done) {
 +		FNIC_TRACE(fnic_wq_copy_cleanup_handler,
 +			  sc->device->host->host_no, id, sc,
 +			  jiffies_to_msecs(jiffies - start_time),
 +			  0, ((u64)sc->cmnd[0] << 32 |
 +			  (u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |
 +			  (u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 +			  (((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));
  
 -	scsi_done(sc);
 +		sc->scsi_done(sc);
 +	}
  }
  
  static inline int fnic_queue_abort_io_req(struct fnic *fnic, int tag,
@@@ -1512,17 -1721,18 +1986,22 @@@
  		return 1;
  	} else
  		atomic_inc(&fnic->in_flight);
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	spin_unlock_irqrestore(host->host_lock, flags);
  
 -	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 +	spin_lock_irqsave(&fnic->wq_copy_lock[0], flags);
  
 -	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[hwq])
 -		free_wq_copy_descs(fnic, wq, hwq);
 +	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])
 +		free_wq_copy_descs(fnic, wq);
  
  	if (!vnic_wq_copy_desc_avail(wq)) {
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(&fnic->wq_copy_lock[0], flags);
  		atomic_dec(&fnic->in_flight);
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		atomic_dec(&tport->in_flight);
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			"fnic_queue_abort_io_req: failure: no descriptors\n");
  		atomic64_inc(&misc_stats->abts_cpwq_alloc_failures);
  		return 1;
@@@ -1561,23 -1770,31 +2040,40 @@@ static bool fnic_rport_abort_io_iter(st
  	struct terminate_stats *term_stats = &fnic->fnic_stats.term_stats;
  	struct scsi_lun fc_lun;
  	enum fnic_ioreq_state old_ioreq_state;
 -	uint16_t hwq = 0;
 -	unsigned long flags;
  
 -	abt_tag = blk_mq_unique_tag(rq);
 -	hwq = blk_mq_unique_tag_to_hwq(abt_tag);
 +	io_lock = fnic_io_lock_tag(fnic, abt_tag);
 +	spin_lock_irqsave(io_lock, flags);
  
++<<<<<<< HEAD
 +	io_req = (struct fnic_io_req *)CMD_SP(sc);
++=======
+ 	if (!sc) {
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 					  "sc is NULL abt_tag: 0x%x hwq: %d\n", abt_tag, hwq);
+ 		return true;
+ 	}
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
 -	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 -	io_req = fnic_priv(sc)->io_req;
  	if (!io_req || io_req->port_id != iter_data->port_id) {
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(io_lock, flags);
  		return true;
  	}
  
++<<<<<<< HEAD
 +	if ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&
 +	    (!(CMD_FLAGS(sc) & FNIC_DEV_RST_ISSUED))) {
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			"fnic_rport_exch_reset dev rst not pending sc 0x%p\n",
 +			sc);
 +		spin_unlock_irqrestore(io_lock, flags);
++=======
+ 	if ((fnic_priv(sc)->flags & FNIC_DEVICE_RESET) &&
+ 	    !(fnic_priv(sc)->flags & FNIC_DEV_RST_ISSUED)) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d abt_tag: 0x%x flags: 0x%x Device reset is not pending\n",
+ 			hwq, abt_tag, fnic_priv(sc)->flags);
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return true;
  	}
  
@@@ -1585,41 -1802,44 +2081,65 @@@
  	 * Found IO that is still pending with firmware and
  	 * belongs to rport that went away
  	 */
 -	if (fnic_priv(sc)->state == FNIC_IOREQ_ABTS_PENDING) {
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +	if (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {
 +		spin_unlock_irqrestore(io_lock, flags);
  		return true;
  	}
 -
  	if (io_req->abts_done) {
++<<<<<<< HEAD
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			"fnic_rport_exch_reset: io_req->abts_done is set "
 +			"state is %s\n",
 +			fnic_ioreq_state_to_str(CMD_STATE(sc)));
 +	}
 +
 +	if (!(CMD_FLAGS(sc) & FNIC_IO_ISSUED)) {
 +		shost_printk(KERN_ERR, fnic->lport->host,
 +			     "rport_exch_reset "
 +			     "IO not yet issued %p tag 0x%x flags "
 +			     "%x state %d\n",
 +			     sc, abt_tag, CMD_FLAGS(sc), CMD_STATE(sc));
++=======
+ 		shost_printk(KERN_ERR, fnic->host,
+ 			"fnic_rport_exch_reset: io_req->abts_done is set state is %s\n",
+ 			fnic_ioreq_state_to_str(fnic_priv(sc)->state));
+ 	}
+ 
+ 	if (!(fnic_priv(sc)->flags & FNIC_IO_ISSUED)) {
+ 		shost_printk(KERN_ERR, fnic->host,
+ 			"rport_exch_reset IO not yet issued %p abt_tag 0x%x",
+ 			sc, abt_tag);
+ 		shost_printk(KERN_ERR, fnic->host,
+ 			"flags %x state %d\n", fnic_priv(sc)->flags,
+ 			fnic_priv(sc)->state);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
 -	old_ioreq_state = fnic_priv(sc)->state;
 -	fnic_priv(sc)->state = FNIC_IOREQ_ABTS_PENDING;
 -	fnic_priv(sc)->abts_status = FCPIO_INVALID_CODE;
 -
 -	if (fnic_priv(sc)->flags & FNIC_DEVICE_RESET) {
 +	old_ioreq_state = CMD_STATE(sc);
 +	CMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;
 +	CMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;
 +	if (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {
  		atomic64_inc(&reset_stats->device_reset_terminates);
  		abt_tag |= FNIC_TAG_DEV_RST;
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 					  "dev reset sc 0x%p\n", sc);
  	}
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "fnic_rport_exch_reset dev rst sc 0x%p\n", sc);
 +	BUG_ON(io_req->abts_done);
 +
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		      "fnic_rport_exch_reset: dev rst sc 0x%p\n", sc);
+ 	WARN_ON_ONCE(io_req->abts_done);
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		      "fnic_rport_reset_exch: Issuing abts\n");
  
 -	spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +	spin_unlock_irqrestore(io_lock, flags);
  
 -	/* Queue the abort command to firmware */
 +	/* Now queue the abort command to firmware */
  	int_to_scsilun(sc->device->lun, &fc_lun);
  
  	if (fnic_queue_abort_io_req(fnic, abt_tag,
@@@ -1631,17 -1851,20 +2151,27 @@@
  		 * aborted later by scsi_eh, or cleaned up during
  		 * lun reset
  		 */
++<<<<<<< HEAD
 +		spin_lock_irqsave(io_lock, flags);
 +		if (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)
 +			CMD_STATE(sc) = old_ioreq_state;
 +		spin_unlock_irqrestore(io_lock, flags);
++=======
+ 		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d abt_tag: 0x%x flags: 0x%x Queuing abort failed\n",
+ 			hwq, abt_tag, fnic_priv(sc)->flags);
+ 		if (fnic_priv(sc)->state == FNIC_IOREQ_ABTS_PENDING)
+ 			fnic_priv(sc)->state = old_ioreq_state;
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	} else {
 -		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 -		if (fnic_priv(sc)->flags & FNIC_DEVICE_RESET)
 -			fnic_priv(sc)->flags |= FNIC_DEV_RST_TERM_ISSUED;
 +		spin_lock_irqsave(io_lock, flags);
 +		if (CMD_FLAGS(sc) & FNIC_DEVICE_RESET)
 +			CMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;
  		else
 -			fnic_priv(sc)->flags |= FNIC_IO_INTERNAL_TERM_ISSUED;
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +			CMD_FLAGS(sc) |= FNIC_IO_INTERNAL_TERM_ISSUED;
 +		spin_unlock_irqrestore(io_lock, flags);
  		atomic64_inc(&term_stats->terminates);
  		iter_data->term_cnt++;
  	}
@@@ -1657,54 -1883,115 +2187,113 @@@ static void fnic_rport_exch_reset(struc
  		.term_cnt = 0,
  	};
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG,
 +		      fnic->lport->host,
 +		      "fnic_rport_exch_reset called portid 0x%06x\n",
 +		      port_id);
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				  "fnic rport exchange reset for tport: 0x%06x\n",
+ 				  port_id);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	if (fnic->in_remove)
  		return;
  
++<<<<<<< HEAD
 +	scsi_host_busy_iter(fnic->lport->host, fnic_rport_abort_io_iter,
++=======
+ 	io_count = fnic_count_ioreqs(fnic, port_id);
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				  "Starting terminates: rport:0x%x  portid-io-count: %d active-io-count: %lld\n",
+ 				  port_id, io_count,
+ 				  atomic64_read(&fnic->fnic_stats.io_stats.active_ios));
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	/* Bump in_flight counter to hold off fnic_fw_reset_handler. */
+ 	atomic_inc(&fnic->in_flight);
+ 	if (unlikely(fnic_chk_state_flags_locked(fnic, FNIC_FLAGS_IO_BLOCKED))) {
+ 		atomic_dec(&fnic->in_flight);
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		return;
+ 	}
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 
+ 	scsi_host_busy_iter(fnic->host, fnic_rport_abort_io_iter,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			    &iter_data);
 -
  	if (iter_data.term_cnt > atomic64_read(&term_stats->max_terminates))
  		atomic64_set(&term_stats->max_terminates, iter_data.term_cnt);
  
++<<<<<<< HEAD
++=======
+ 	atomic_dec(&fnic->in_flight);
+ 
+ 	while ((io_count = fnic_count_ioreqs(fnic, port_id)))
+ 		schedule_timeout(msecs_to_jiffies(1000));
+ 
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				  "rport: 0x%x remaining portid-io-count: %d ",
+ 				  port_id, io_count);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
  void fnic_terminate_rport_io(struct fc_rport *rport)
  {
 -	struct fnic_tport_s *tport;
 -	struct rport_dd_data_s *rdd_data;
 -	struct fnic_iport_s *iport = NULL;
 -	struct fnic *fnic = NULL;
 +	struct fc_rport_libfc_priv *rdata;
 +	struct fc_lport *lport;
 +	struct fnic *fnic;
  
  	if (!rport) {
 -		pr_err("rport is NULL\n");
 +		printk(KERN_ERR "fnic_terminate_rport_io: rport is NULL\n");
  		return;
  	}
 +	rdata = rport->dd_data;
  
 -	rdd_data = rport->dd_data;
 -	if (rdd_data) {
 -		tport = rdd_data->tport;
 -		if (!tport) {
 -			pr_err(
 -			"term rport io called after tport is deleted. Returning 0x%8x\n",
 -		   rport->port_id);
 -		} else {
 -			pr_err(
 -			   "term rport io called after tport is set 0x%8x\n",
 -			   rport->port_id);
 -			pr_err(
 -			   "tport maybe rediscovered\n");
 -
 -			iport = (struct fnic_iport_s *) tport->iport;
 -			fnic = iport->fnic;
 -			fnic_rport_exch_reset(fnic, rport->port_id);
 -		}
 +	if (!rdata) {
 +		printk(KERN_ERR "fnic_terminate_rport_io: rdata is NULL\n");
 +		return;
  	}
 -}
 +	lport = rdata->local_port;
  
 -/*
 - * FCP-SCSI specific handling for module unload
 - *
 - */
 -void fnic_scsi_unload(struct fnic *fnic)
 -{
 -	unsigned long flags;
 +	if (!lport) {
 +		printk(KERN_ERR "fnic_terminate_rport_io: lport is NULL\n");
 +		return;
 +	}
 +	fnic = lport_priv(lport);
 +	FNIC_SCSI_DBG(KERN_DEBUG,
 +		      fnic->lport->host, "fnic_terminate_rport_io called"
 +		      " wwpn 0x%llx, wwnn0x%llx, rport 0x%p, portid 0x%06x\n",
 +		      rport->port_name, rport->node_name, rport,
 +		      rport->port_id);
  
 -	/*
 -	 * Mark state so that the workqueue thread stops forwarding
 -	 * received frames and link events to the local port. ISR and
 -	 * other threads that can queue work items will also stop
 -	 * creating work items on the fnic workqueue
 -	 */
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	fnic->iport.state = FNIC_IPORT_STATE_LINK_WAIT;
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	if (fnic->in_remove)
 +		return;
  
++<<<<<<< HEAD
 +	fnic_rport_exch_reset(fnic, rport->port_id);
++=======
+ 	if (fdls_get_state(&fnic->iport.fabric) != FDLS_STATE_INIT)
+ 		fnic_scsi_fcpio_reset(fnic);
+ 
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	fnic->in_remove = 1;
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 
+ 	fnic_flush_tport_event_list(fnic);
+ 	fnic_delete_fcp_tports(fnic);
+ }
+ 
+ void fnic_scsi_unload_cleanup(struct fnic *fnic)
+ {
+ 	int hwq = 0;
+ 
+ 	fc_remove_host(fnic->host);
+ 	scsi_remove_host(fnic->host);
+ 	for (hwq = 0; hwq < fnic->wq_copy_count; hwq++)
+ 		kfree(fnic->sw_copy_wq[hwq].io_req_table);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
  /*
@@@ -1745,18 -2037,55 +2334,63 @@@ int fnic_abort_cmd(struct scsi_cmnd *sc
  	term_stats = &fnic->fnic_stats.term_stats;
  
  	rport = starget_to_rport(scsi_target(sc->device));
 -	mqtag = blk_mq_unique_tag(rq);
 -	hwq = blk_mq_unique_tag_to_hwq(mqtag);
 +	FNIC_SCSI_DBG(KERN_DEBUG,
 +		fnic->lport->host,
 +		"Abort Cmd called FCID 0x%x, LUN 0x%llx TAG %x flags %x\n",
 +		rport->port_id, sc->device->lun, tag, CMD_FLAGS(sc));
  
 -	fnic_priv(sc)->flags = FNIC_NO_FLAGS;
 +	CMD_FLAGS(sc) = FNIC_NO_FLAGS;
  
++<<<<<<< HEAD
 +	if (lp->state != LPORT_ST_READY || !(lp->link_up)) {
++=======
+ 	rdd_data = rport->dd_data;
+ 	tport = rdd_data->tport;
+ 
+ 	if (!tport) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			  "Abort cmd called after tport delete! rport fcid: 0x%x",
+ 			  rport->port_id);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			  "lun: %llu hwq: 0x%x mqtag: 0x%x Op: 0x%x flags: 0x%x\n",
+ 			  sc->device->lun, hwq, mqtag,
+ 			  sc->cmnd[0], fnic_priv(sc)->flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
+ 		ret = FAILED;
 -		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		goto fnic_abort_cmd_end;
+ 	}
+ 
++<<<<<<< HEAD
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 	  "Abort cmd called rport fcid: 0x%x lun: %llu hwq: 0x%x mqtag: 0x%x",
+ 	  rport->port_id, sc->device->lun, hwq, mqtag);
+ 
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "Op: 0x%x flags: 0x%x\n",
+ 				  sc->cmnd[0],
+ 				  fnic_priv(sc)->flags);
+ 
+ 	if (iport->state != FNIC_IPORT_STATE_READY) {
+ 		atomic64_inc(&fnic_stats->misc_stats.iport_not_ready);
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "iport NOT in READY state");
  		ret = FAILED;
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  		goto fnic_abort_cmd_end;
  	}
  
+ 	if ((tport->state != FDLS_TGT_STATE_READY) &&
+ 		(tport->state != FDLS_TGT_STATE_ADISC)) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "tport state: %d\n", tport->state);
+ 		ret = FAILED;
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		goto fnic_abort_cmd_end;
+ 	}
+ 
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	/*
  	 * Avoid a race between SCSI issuing the abort and the device
  	 * completing the command.
@@@ -1800,8 -2129,9 +2434,14 @@@
  	else
  		atomic64_inc(&abts_stats->abort_issued_greater_than_60_sec);
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
 +		"CBD Opcode: %02x Abort issued time: %lu msec\n", sc->cmnd[0], abt_issued_time);
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		"CDB Opcode: 0x%02x Abort issued time: %lu msec\n",
+ 		sc->cmnd[0], abt_issued_time);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	/*
  	 * Command is still pending, need to abort it
  	 * If the firmware completes the command after this point,
@@@ -1888,10 -2218,10 +2528,17 @@@
  
  	/* IO out of order */
  
++<<<<<<< HEAD
 +	if (!(CMD_FLAGS(sc) & (FNIC_IO_ABORTED | FNIC_IO_DONE))) {
 +		spin_unlock_irqrestore(io_lock, flags);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			"Issuing Host reset due to out of order IO\n");
++=======
+ 	if (!(fnic_priv(sc)->flags & (FNIC_IO_ABORTED | FNIC_IO_DONE))) {
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			      "Issuing host reset due to out of order IO\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  		ret = FAILED;
  		goto fnic_abort_cmd_end;
@@@ -1935,9 -2266,9 +2582,13 @@@ fnic_abort_cmd_end
  		  0, ((u64)sc->cmnd[0] << 32 |
  		  (u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |
  		  (u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 -		  fnic_flags_and_state(sc));
 +		  (((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		      "Returning from abort cmd type %x %s\n", task_req,
  		      (ret == SUCCESS) ?
  		      "SUCCESS" : "FAILED");
@@@ -1953,24 -2283,33 +2604,28 @@@ static inline int fnic_queue_dr_io_req(
  	struct misc_stats *misc_stats = &fnic->fnic_stats.misc_stats;
  	struct scsi_lun fc_lun;
  	int ret = 0;
 -	unsigned long flags;
 -	uint16_t hwq = 0;
 -	uint32_t tag = 0;
 -	struct fnic_tport_s *tport = io_req->tport;
 -
 -	tag = io_req->tag;
 -	hwq = blk_mq_unique_tag_to_hwq(tag);
 -	wq = &fnic->hw_copy_wq[hwq];
 +	unsigned long intr_flags;
  
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	spin_lock_irqsave(host->host_lock, intr_flags);
  	if (unlikely(fnic_chk_state_flags_locked(fnic,
  						FNIC_FLAGS_IO_BLOCKED))) {
 -		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		spin_unlock_irqrestore(host->host_lock, intr_flags);
  		return FAILED;
 -	} else {
 +	} else
  		atomic_inc(&fnic->in_flight);
 -		atomic_inc(&tport->in_flight);
 -	}
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	spin_unlock_irqrestore(host->host_lock, intr_flags);
  
 -	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 +	spin_lock_irqsave(&fnic->wq_copy_lock[0], intr_flags);
  
 -	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[hwq])
 -		free_wq_copy_descs(fnic, wq, hwq);
 +	if (vnic_wq_copy_desc_avail(wq) <= fnic->wq_copy_desc_low[0])
 +		free_wq_copy_descs(fnic, wq);
  
  	if (!vnic_wq_copy_desc_avail(wq)) {
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			  "queue_dr_io_req failure - no descriptors\n");
  		atomic64_inc(&misc_stats->devrst_cpwq_alloc_failures);
  		ret = -EAGAIN;
@@@ -2033,28 -2377,27 +2688,40 @@@ static bool fnic_pending_aborts_iter(st
  	 * Found IO that is still pending with firmware and
  	 * belongs to the LUN that we are resetting
  	 */
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		      "Found IO in %s on lun\n",
 -		      fnic_ioreq_state_to_str(fnic_priv(sc)->state));
 +		      fnic_ioreq_state_to_str(CMD_STATE(sc)));
  
 -	if (fnic_priv(sc)->state == FNIC_IOREQ_ABTS_PENDING) {
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +	if (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING) {
 +		spin_unlock_irqrestore(io_lock, flags);
  		return true;
  	}
++<<<<<<< HEAD
 +	if ((CMD_FLAGS(sc) & FNIC_DEVICE_RESET) &&
 +	    (!(CMD_FLAGS(sc) & FNIC_DEV_RST_ISSUED))) {
 +		FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
 +			      "%s dev rst not pending sc 0x%p\n", __func__,
 +			      sc);
 +		spin_unlock_irqrestore(io_lock, flags);
++=======
+ 	if ((fnic_priv(sc)->flags & FNIC_DEVICE_RESET) &&
+ 	    (!(fnic_priv(sc)->flags & FNIC_DEV_RST_ISSUED))) {
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			      "dev rst not pending sc 0x%p\n", sc);
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return true;
  	}
  
  	if (io_req->abts_done)
- 		shost_printk(KERN_ERR, fnic->lport->host,
+ 		shost_printk(KERN_ERR, fnic->host,
  			     "%s: io_req->abts_done is set state is %s\n",
 -			     __func__, fnic_ioreq_state_to_str(fnic_priv(sc)->state));
 -	old_ioreq_state = fnic_priv(sc)->state;
 +			     __func__, fnic_ioreq_state_to_str(CMD_STATE(sc)));
 +	old_ioreq_state = CMD_STATE(sc);
  	/*
  	 * Any pending IO issued prior to reset is expected to be
  	 * in abts pending state, if not we need to set
@@@ -2066,38 -2409,40 +2733,50 @@@
  
  	BUG_ON(io_req->abts_done);
  
++<<<<<<< HEAD
 +	if (CMD_FLAGS(sc) & FNIC_DEVICE_RESET) {
 +		abt_tag |= FNIC_TAG_DEV_RST;
 +		FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
 +			      "%s: dev rst sc 0x%p\n", __func__, sc);
++=======
+ 	if (fnic_priv(sc)->flags & FNIC_DEVICE_RESET) {
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			      "dev rst sc 0x%p\n", sc);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  
 -	fnic_priv(sc)->abts_status = FCPIO_INVALID_CODE;
 +	CMD_ABTS_STATUS(sc) = FCPIO_INVALID_CODE;
  	io_req->abts_done = &tm_done;
 -	spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +	spin_unlock_irqrestore(io_lock, flags);
  
  	/* Now queue the abort command to firmware */
  	int_to_scsilun(sc->device->lun, &fc_lun);
  
  	if (fnic_queue_abort_io_req(fnic, abt_tag,
  				    FCPIO_ITMF_ABT_TASK_TERM,
 -				    fc_lun.scsi_lun, io_req, hwq)) {
 -		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 -		io_req = fnic_priv(sc)->io_req;
 +				    fc_lun.scsi_lun, io_req)) {
 +		spin_lock_irqsave(io_lock, flags);
 +		io_req = (struct fnic_io_req *)CMD_SP(sc);
  		if (io_req)
  			io_req->abts_done = NULL;
 -		if (fnic_priv(sc)->state == FNIC_IOREQ_ABTS_PENDING)
 -			fnic_priv(sc)->state = old_ioreq_state;
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		if (CMD_STATE(sc) == FNIC_IOREQ_ABTS_PENDING)
 +			CMD_STATE(sc) = old_ioreq_state;
 +		spin_unlock_irqrestore(io_lock, flags);
  		iter_data->ret = FAILED;
++<<<<<<< HEAD
++=======
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 			"hwq: %d abt_tag: 0x%lx Abort could not be queued\n",
+ 			hwq, abt_tag);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		return false;
  	} else {
 -		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 -		if (fnic_priv(sc)->flags & FNIC_DEVICE_RESET)
 -			fnic_priv(sc)->flags |= FNIC_DEV_RST_TERM_ISSUED;
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_lock_irqsave(io_lock, flags);
 +		if (CMD_FLAGS(sc) & FNIC_DEVICE_RESET)
 +			CMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;
 +		spin_unlock_irqrestore(io_lock, flags);
  	}
 -	fnic_priv(sc)->flags |= FNIC_IO_INTERNAL_TERM_ISSUED;
 +	CMD_FLAGS(sc) |= FNIC_IO_INTERNAL_TERM_ISSUED;
  
  	wait_for_completion_timeout(&tm_done, msecs_to_jiffies
  				    (fnic->config.ed_tov));
@@@ -2163,10 -2509,9 +2842,10 @@@ static int fnic_clean_pending_aborts(st
  		.ret = SUCCESS,
  	};
  
 -	iter_data.lr_sc = lr_sc;
 +	if (new_sc)
 +		iter_data.lr_sc = lr_sc;
  
- 	scsi_host_busy_iter(fnic->lport->host,
+ 	scsi_host_busy_iter(fnic->host,
  			    fnic_pending_aborts_iter, &iter_data);
  	if (iter_data.ret == FAILED) {
  		ret = iter_data.ret;
@@@ -2179,8 -2524,8 +2858,13 @@@
  		ret = 1;
  
  clean_pending_aborts_end:
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
 +			"%s: exit status: %d\n", __func__, ret);
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			"exit status: %d\n", ret);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	return ret;
  }
  
@@@ -2222,12 -2572,39 +2906,47 @@@ int fnic_device_reset(struct scsi_cmnd 
  	atomic64_inc(&reset_stats->device_resets);
  
  	rport = starget_to_rport(scsi_target(sc->device));
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "Device reset called FCID 0x%x, LUN 0x%llx sc 0x%p\n",
 +		      rport->port_id, sc->device->lun, sc);
  
++<<<<<<< HEAD
 +	if (lp->state != LPORT_ST_READY || !(lp->link_up))
 +		goto fnic_device_reset_end;
++=======
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 		"fcid: 0x%x lun: %llu hwq: %d mqtag: 0x%x flags: 0x%x Device reset\n",
+ 		rport->port_id, sc->device->lun, hwq, mqtag,
+ 		fnic_priv(sc)->flags);
+ 
+ 	rdd_data = rport->dd_data;
+ 	tport = rdd_data->tport;
+ 	if (!tport) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 		  "Dev rst called after tport delete! rport fcid: 0x%x lun: %llu\n",
+ 		  rport->port_id, sc->device->lun);
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		goto fnic_device_reset_end;
+ 	}
+ 
+ 	if (iport->state != FNIC_IPORT_STATE_READY) {
+ 		atomic64_inc(&fnic_stats->misc_stats.iport_not_ready);
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "iport NOT in READY state");
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		goto fnic_device_reset_end;
+ 	}
+ 
+ 	if ((tport->state != FDLS_TGT_STATE_READY) &&
+ 		(tport->state != FDLS_TGT_STATE_ADISC)) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "tport state: %d\n", tport->state);
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		goto fnic_device_reset_end;
+ 	}
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/* Check if remote port up */
  	if (fc_remote_port_chkready(rport)) {
@@@ -2265,14 -2645,24 +2984,18 @@@
  		}
  		memset(io_req, 0, sizeof(*io_req));
  		io_req->port_id = rport->port_id;
 -		io_req->tag = mqtag;
 -		fnic_priv(sc)->io_req = io_req;
 -		io_req->tport = tport;
 -		io_req->sc = sc;
 -
 -		if (fnic->sw_copy_wq[hwq].io_req_table[blk_mq_unique_tag_to_tag(mqtag)] != NULL)
 -			WARN(1, "fnic<%d>: %s: tag 0x%x already exists\n",
 -					fnic->fnic_num, __func__, blk_mq_unique_tag_to_tag(mqtag));
 -
 -		fnic->sw_copy_wq[hwq].io_req_table[blk_mq_unique_tag_to_tag(mqtag)] =
 -				io_req;
 +		CMD_SP(sc) = (char *)io_req;
  	}
  	io_req->dr_done = &tm_done;
 -	fnic_priv(sc)->state = FNIC_IOREQ_CMD_PENDING;
 -	fnic_priv(sc)->lr_status = FCPIO_INVALID_CODE;
 -	spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +	CMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;
 +	CMD_LR_STATUS(sc) = FCPIO_INVALID_CODE;
 +	spin_unlock_irqrestore(io_lock, flags);
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host, "TAG %x\n", tag);
++=======
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num, "TAG %x\n", mqtag);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	/*
  	 * issue the device reset, if enqueue failed, clean up the ioreq
@@@ -2296,17 -2691,42 +3019,32 @@@
  	wait_for_completion_timeout(&tm_done,
  				    msecs_to_jiffies(FNIC_LUN_RESET_TIMEOUT));
  
 -	/*
 -	 * Wake up can be due to the following reasons:
 -	 * 1) The device reset completed from target.
 -	 * 2) Device reset timed out.
 -	 * 3) A link-down/host_reset may have happened in between.
 -	 * 4) The device reset was aborted and io_req->dr_done was called.
 -	 */
 -
 -	exit_dr = 0;
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	if ((old_link_down_cnt != fnic->link_down_cnt) ||
 -		(fnic->reset_in_progress) ||
 -		(fnic->soft_reset_count != old_soft_reset_count) ||
 -		(iport->state != FNIC_IPORT_STATE_READY))
 -		exit_dr = 1;
 -
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 -
 -	spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 -	io_req = fnic_priv(sc)->io_req;
 +	spin_lock_irqsave(io_lock, flags);
 +	io_req = (struct fnic_io_req *)CMD_SP(sc);
  	if (!io_req) {
++<<<<<<< HEAD
 +		spin_unlock_irqrestore(io_lock, flags);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				"io_req is null tag 0x%x sc 0x%p\n", tag, sc);
 +		goto fnic_device_reset_end;
 +	}
++=======
+ 		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 				"io_req is null mqtag 0x%x sc 0x%p\n", mqtag, sc);
+ 		goto fnic_device_reset_end;
+ 	}
+ 
+ 	if (exit_dr) {
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "Host reset called for fnic. Exit device reset\n");
+ 		io_req->dr_done = NULL;
+ 		goto fnic_device_reset_clean;
+ 	}
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	io_req->dr_done = NULL;
  
 -	status = fnic_priv(sc)->lr_status;
 +	status = CMD_LR_STATUS(sc);
  
  	/*
  	 * If lun reset not completed, bail out with failed. io_req
@@@ -2314,64 -2734,22 +3052,72 @@@
  	 */
  	if (status == FCPIO_INVALID_CODE) {
  		atomic64_inc(&reset_stats->device_reset_timeouts);
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			      "Device reset timed out\n");
 -		fnic_priv(sc)->flags |= FNIC_DEV_RST_TIMED_OUT;
 +		CMD_FLAGS(sc) |= FNIC_DEV_RST_TIMED_OUT;
 +		spin_unlock_irqrestore(io_lock, flags);
  		int_to_scsilun(sc->device->lun, &fc_lun);
 -		goto fnic_device_reset_clean;
 +		/*
 +		 * Issue abort and terminate on device reset request.
 +		 * If q'ing of terminate fails, retry it after a delay.
 +		 */
 +		while (1) {
 +			spin_lock_irqsave(io_lock, flags);
 +			if (CMD_FLAGS(sc) & FNIC_DEV_RST_TERM_ISSUED) {
 +				spin_unlock_irqrestore(io_lock, flags);
 +				break;
 +			}
 +			spin_unlock_irqrestore(io_lock, flags);
 +			if (fnic_queue_abort_io_req(fnic,
 +				tag | FNIC_TAG_DEV_RST,
 +				FCPIO_ITMF_ABT_TASK_TERM,
 +				fc_lun.scsi_lun, io_req)) {
 +				wait_for_completion_timeout(&tm_done,
 +				msecs_to_jiffies(FNIC_ABT_TERM_DELAY_TIMEOUT));
 +			} else {
 +				spin_lock_irqsave(io_lock, flags);
 +				CMD_FLAGS(sc) |= FNIC_DEV_RST_TERM_ISSUED;
 +				CMD_STATE(sc) = FNIC_IOREQ_ABTS_PENDING;
 +				io_req->abts_done = &tm_done;
 +				spin_unlock_irqrestore(io_lock, flags);
 +				FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +				"Abort and terminate issued on Device reset "
 +				"tag 0x%x sc 0x%p\n", tag, sc);
 +				break;
 +			}
 +		}
 +		while (1) {
 +			spin_lock_irqsave(io_lock, flags);
 +			if (!(CMD_FLAGS(sc) & FNIC_DEV_RST_DONE)) {
 +				spin_unlock_irqrestore(io_lock, flags);
 +				wait_for_completion_timeout(&tm_done,
 +				msecs_to_jiffies(FNIC_LUN_RESET_TIMEOUT));
 +				break;
 +			} else {
 +				io_req = (struct fnic_io_req *)CMD_SP(sc);
 +				io_req->abts_done = NULL;
 +				goto fnic_device_reset_clean;
 +			}
 +		}
  	} else {
 -		spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
 +		spin_unlock_irqrestore(io_lock, flags);
  	}
  
  	/* Completed, but not successful, clean up the io_req, return fail */
  	if (status != FCPIO_SUCCESS) {
 -		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
 +		spin_lock_irqsave(io_lock, flags);
  		FNIC_SCSI_DBG(KERN_DEBUG,
++<<<<<<< HEAD
 +			      fnic->lport->host,
++=======
+ 			      fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  			      "Device reset completed - failed\n");
 -		io_req = fnic_priv(sc)->io_req;
 +		io_req = (struct fnic_io_req *)CMD_SP(sc);
  		goto fnic_device_reset_clean;
  	}
  
@@@ -2383,11 -2761,10 +3129,18 @@@
  	 * succeeds
  	 */
  	if (fnic_clean_pending_aborts(fnic, sc, new_sc)) {
++<<<<<<< HEAD
 +		spin_lock_irqsave(io_lock, flags);
 +		io_req = (struct fnic_io_req *)CMD_SP(sc);
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			      "Device reset failed"
 +			      " since could not abort all IOs\n");
++=======
+ 		spin_lock_irqsave(&fnic->wq_copy_lock[hwq], flags);
+ 		io_req = fnic_priv(sc)->io_req;
+ 		FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
+ 					  "Device reset failed: Cannot abort all IOs\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		goto fnic_device_reset_clean;
  	}
  
@@@ -2416,13 -2805,25 +3169,28 @@@ fnic_device_reset_end
  		  0, ((u64)sc->cmnd[0] << 32 |
  		  (u64)sc->cmnd[2] << 24 | (u64)sc->cmnd[3] << 16 |
  		  (u64)sc->cmnd[4] << 8 | sc->cmnd[5]),
 -		  fnic_flags_and_state(sc));
 +		  (((u64)CMD_FLAGS(sc) << 32) | CMD_STATE(sc)));
  
 -	if (new_sc) {
 -		fnic->sgreset_sc = NULL;
 -		mutex_unlock(&fnic->sgreset_mutex);
 -	}
 +	/* free tag if it is allocated */
 +	if (unlikely(tag_gen_flag))
 +		fnic_scsi_host_end_tag(fnic, sc);
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
++=======
+ 	while ((ret == SUCCESS) && fnic_count_lun_ioreqs(fnic, sc->device)) {
+ 		if (count >= 2) {
+ 			ret = FAILED;
+ 			break;
+ 		}
+ 		FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 					  "Cannot clean up all IOs for the LUN\n");
+ 		schedule_timeout(msecs_to_jiffies(1000));
+ 		count++;
+ 	}
+ 
+ 	FNIC_SCSI_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  		      "Returning from device reset %s\n",
  		      (ret == SUCCESS) ?
  		      "SUCCESS" : "FAILED");
@@@ -2433,68 -2834,78 +3201,99 @@@
  	return ret;
  }
  
 -static void fnic_post_flogo_linkflap(struct fnic *fnic)
 -{
 -	unsigned long flags;
 -
 -	fnic_fdls_link_status_change(fnic, 0);
 -	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -
 -	if (fnic->link_status) {
 -		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 -		fnic_fdls_link_status_change(fnic, 1);
 -		return;
 -	}
 -	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 -}
 -
 -/* Logout from all the targets and simulate link flap */
 -void fnic_reset(struct Scsi_Host *shost)
 +/* Clean up all IOs, clean up libFC local port */
 +int fnic_reset(struct Scsi_Host *shost)
  {
 +	struct fc_lport *lp;
  	struct fnic *fnic;
 +	int ret = 0;
  	struct reset_stats *reset_stats;
  
 -	fnic = *((struct fnic **) shost_priv(shost));
 +	lp = shost_priv(shost);
 +	fnic = lport_priv(lp);
  	reset_stats = &fnic->fnic_stats.reset_stats;
  
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "fnic_reset called\n");
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "Issuing fnic reset\n");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
  	atomic64_inc(&reset_stats->fnic_resets);
 -	fnic_post_flogo_linkflap(fnic);
  
++<<<<<<< HEAD
 +	/*
 +	 * Reset local port, this will clean up libFC exchanges,
 +	 * reset remote port sessions, and if link is up, begin flogi
 +	 */
 +	ret = fc_lport_reset(lp);
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "Returning from fnic reset");
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  
 -	atomic64_inc(&reset_stats->fnic_reset_completions);
 -}
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "Returning from fnic reset %s\n",
 +		      (ret == 0) ?
 +		      "SUCCESS" : "FAILED");
  
 -int fnic_issue_fc_host_lip(struct Scsi_Host *shost)
 -{
 -	int ret = 0;
 -	struct fnic *fnic = *((struct fnic **) shost_priv(shost));
 +	if (ret == 0)
 +		atomic64_inc(&reset_stats->fnic_reset_completions);
 +	else
 +		atomic64_inc(&reset_stats->fnic_reset_failures);
  
++<<<<<<< HEAD
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "FC host lip issued");
+ 
+ 	ret = fnic_host_reset(shost);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	return ret;
  }
  
 -int fnic_host_reset(struct Scsi_Host *shost)
 +/*
 + * SCSI Error handling calls driver's eh_host_reset if all prior
 + * error handling levels return FAILED. If host reset completes
 + * successfully, and if link is up, then Fabric login begins.
 + *
 + * Host Reset is the highest level of error recovery. If this fails, then
 + * host is offlined by SCSI.
 + *
 + */
 +int fnic_host_reset(struct scsi_cmnd *sc)
  {
 -	int ret = SUCCESS;
 +	int ret;
  	unsigned long wait_host_tmo;
 -	struct fnic *fnic = *((struct fnic **) shost_priv(shost));
 +	struct Scsi_Host *shost = sc->device->host;
 +	struct fc_lport *lp = shost_priv(shost);
 +	struct fnic *fnic = lport_priv(lp);
  	unsigned long flags;
 -	struct fnic_iport_s *iport = &fnic->iport;
  
  	spin_lock_irqsave(&fnic->fnic_lock, flags);
 -	if (fnic->reset_in_progress == NOT_IN_PROGRESS) {
 -		fnic->reset_in_progress = IN_PROGRESS;
 +	if (!fnic->internal_reset_inprogress) {
 +		fnic->internal_reset_inprogress = true;
  	} else {
  		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
++<<<<<<< HEAD
 +		FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +			"host reset in progress skipping another host reset\n");
 +		return SUCCESS;
++=======
+ 		wait_for_completion_timeout(&fnic->reset_completion_wait,
+ 									msecs_to_jiffies(10000));
+ 
+ 		spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 		if (fnic->reset_in_progress == IN_PROGRESS) {
+ 			spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 			FNIC_SCSI_DBG(KERN_WARNING, fnic->host, fnic->fnic_num,
+ 			  "Firmware reset in progress. Skipping another host reset\n");
+ 			return SUCCESS;
+ 		}
+ 		fnic->reset_in_progress = IN_PROGRESS;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	}
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
  
@@@ -2513,130 -2935,13 +3312,136 @@@
  				ret = SUCCESS;
  				break;
  			}
 +			ssleep(1);
  		}
  	}
 +
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	fnic->internal_reset_inprogress = false;
  	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	return ret;
 +}
 +
 +/*
 + * This fxn is called from libFC when host is removed
 + */
 +void fnic_scsi_abort_io(struct fc_lport *lp)
 +{
 +	int err = 0;
 +	unsigned long flags;
 +	enum fnic_state old_state;
 +	struct fnic *fnic = lport_priv(lp);
 +	DECLARE_COMPLETION_ONSTACK(remove_wait);
  
 +	/* Issue firmware reset for fnic, wait for reset to complete */
 +retry_fw_reset:
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	if (unlikely(fnic->state == FNIC_IN_FC_TRANS_ETH_MODE) &&
 +		     fnic->link_events) {
 +		/* fw reset is in progress, poll for its completion */
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		schedule_timeout(msecs_to_jiffies(100));
 +		goto retry_fw_reset;
 +	}
 +
 +	fnic->remove_wait = &remove_wait;
 +	old_state = fnic->state;
 +	fnic->state = FNIC_IN_FC_TRANS_ETH_MODE;
 +	fnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
++<<<<<<< HEAD
 +	err = fnic_fw_reset_handler(fnic);
 +	if (err) {
 +		spin_lock_irqsave(&fnic->fnic_lock, flags);
 +		if (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)
 +			fnic->state = old_state;
 +		fnic->remove_wait = NULL;
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		return;
 +	}
 +
 +	/* Wait for firmware reset to complete */
 +	wait_for_completion_timeout(&remove_wait,
 +				    msecs_to_jiffies(FNIC_RMDEVICE_TIMEOUT));
 +
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	fnic->remove_wait = NULL;
 +	FNIC_SCSI_DBG(KERN_DEBUG, fnic->lport->host,
 +		      "fnic_scsi_abort_io %s\n",
 +		      (fnic->state == FNIC_IN_ETH_MODE) ?
 +		      "SUCCESS" : "FAILED");
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
 +}
 +
 +/*
 + * This fxn called from libFC to clean up driver IO state on link down
 + */
 +void fnic_scsi_cleanup(struct fc_lport *lp)
 +{
 +	unsigned long flags;
 +	enum fnic_state old_state;
 +	struct fnic *fnic = lport_priv(lp);
 +
 +	/* issue fw reset */
 +retry_fw_reset:
 +	spin_lock_irqsave(&fnic->fnic_lock, flags);
 +	if (unlikely(fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)) {
 +		/* fw reset is in progress, poll for its completion */
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +		schedule_timeout(msecs_to_jiffies(100));
 +		goto retry_fw_reset;
 +	}
 +	old_state = fnic->state;
 +	fnic->state = FNIC_IN_FC_TRANS_ETH_MODE;
 +	fnic_update_mac_locked(fnic, fnic->ctlr.ctl_src_addr);
 +	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +
 +	if (fnic_fw_reset_handler(fnic)) {
 +		spin_lock_irqsave(&fnic->fnic_lock, flags);
 +		if (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)
 +			fnic->state = old_state;
 +		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
 +	}
 +
 +}
 +
 +void fnic_empty_scsi_cleanup(struct fc_lport *lp)
 +{
 +}
 +
 +void fnic_exch_mgr_reset(struct fc_lport *lp, u32 sid, u32 did)
 +{
 +	struct fnic *fnic = lport_priv(lp);
 +
 +	/* Non-zero sid, nothing to do */
 +	if (sid)
 +		goto call_fc_exch_mgr_reset;
 +
 +	if (did) {
 +		fnic_rport_exch_reset(fnic, did);
 +		goto call_fc_exch_mgr_reset;
 +	}
 +
 +	/*
 +	 * sid = 0, did = 0
 +	 * link down or device being removed
 +	 */
 +	if (!fnic->in_remove)
 +		fnic_scsi_cleanup(lp);
 +	else
 +		fnic_scsi_abort_io(lp);
 +
 +	/* call libFC exch mgr reset to reset its exchanges */
 +call_fc_exch_mgr_reset:
 +	fc_exch_mgr_reset(lp, sid, did);
 +
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "host reset return status: %d\n", ret);
+ 	return ret;
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  }
  
  static bool fnic_abts_pending_iter(struct scsi_cmnd *sc, void *data)
@@@ -2670,11 -2979,12 +3475,20 @@@
  	 * Found IO that is still pending with firmware and
  	 * belongs to the LUN that we are resetting
  	 */
++<<<<<<< HEAD
 +	FNIC_SCSI_DBG(KERN_INFO, fnic->lport->host,
 +		      "Found IO in %s on lun\n",
 +		      fnic_ioreq_state_to_str(CMD_STATE(sc)));
 +	cmd_state = CMD_STATE(sc);
 +	spin_unlock_irqrestore(io_lock, flags);
++=======
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 		"hwq: %d tag: 0x%x Found IO in state: %s on lun\n",
+ 		hwq, tag,
+ 		fnic_ioreq_state_to_str(fnic_priv(sc)->state));
+ 	cmd_state = fnic_priv(sc)->state;
+ 	spin_unlock_irqrestore(&fnic->wq_copy_lock[hwq], flags);
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
  	if (cmd_state == FNIC_IOREQ_ABTS_PENDING)
  		iter_data->ret = 1;
  
@@@ -2707,3 -3017,76 +3521,79 @@@ int fnic_is_abts_pending(struct fnic *f
  
  	return iter_data.ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * SCSI Error handling calls driver's eh_host_reset if all prior
+  * error handling levels return FAILED. If host reset completes
+  * successfully, and if link is up, then Fabric login begins.
+  *
+  * Host Reset is the highest level of error recovery. If this fails, then
+  * host is offlined by SCSI.
+  *
+  */
+ int fnic_eh_host_reset_handler(struct scsi_cmnd *sc)
+ {
+ 	int ret = 0;
+ 	struct Scsi_Host *shost = sc->device->host;
+ 	struct fnic *fnic = *((struct fnic **) shost_priv(shost));
+ 
+ 	FNIC_SCSI_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
+ 				  "SCSI error handling: fnic host reset");
+ 
+ 	ret = fnic_host_reset(shost);
+ 	return ret;
+ }
+ 
+ 
+ void fnic_scsi_fcpio_reset(struct fnic *fnic)
+ {
+ 	unsigned long flags;
+ 	enum fnic_state old_state;
+ 	struct fnic_iport_s *iport = &fnic->iport;
+ 	DECLARE_COMPLETION_ONSTACK(fw_reset_done);
+ 	int time_remain;
+ 
+ 	/* issue fw reset */
+ 	spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 	if (unlikely(fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)) {
+ 		/* fw reset is in progress, poll for its completion */
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 			  "fnic is in unexpected state: %d for fw_reset\n",
+ 			  fnic->state);
+ 		return;
+ 	}
+ 
+ 	old_state = fnic->state;
+ 	fnic->state = FNIC_IN_FC_TRANS_ETH_MODE;
+ 
+ 	fnic_update_mac_locked(fnic, iport->hwmac);
+ 	fnic->fw_reset_done = &fw_reset_done;
+ 	spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 
+ 	FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "Issuing fw reset\n");
+ 	if (fnic_fw_reset_handler(fnic)) {
+ 		spin_lock_irqsave(&fnic->fnic_lock, flags);
+ 		if (fnic->state == FNIC_IN_FC_TRANS_ETH_MODE)
+ 			fnic->state = old_state;
+ 		spin_unlock_irqrestore(&fnic->fnic_lock, flags);
+ 	} else {
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "Waiting for fw completion\n");
+ 		time_remain = wait_for_completion_timeout(&fw_reset_done,
+ 						  msecs_to_jiffies(FNIC_FW_RESET_TIMEOUT));
+ 		FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 					  "Woken up after fw completion timeout\n");
+ 		if (time_remain == 0) {
+ 			FNIC_SCSI_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
+ 				  "FW reset completion timed out after %d ms)\n",
+ 				  FNIC_FW_RESET_TIMEOUT);
+ 		}
+ 		atomic64_inc(&fnic->fnic_stats.reset_stats.fw_reset_timeouts);
+ 	}
+ 	fnic->fw_reset_done = NULL;
+ }
++>>>>>>> 7e6886b705fd (scsi: fnic: Code cleanup)
* Unmerged path drivers/scsi/fnic/fdls_disc.c
* Unmerged path drivers/scsi/fnic/fip.c
* Unmerged path drivers/scsi/fnic/fip.h
* Unmerged path drivers/scsi/fnic/fdls_disc.c
* Unmerged path drivers/scsi/fnic/fip.c
* Unmerged path drivers/scsi/fnic/fip.h
* Unmerged path drivers/scsi/fnic/fnic.h
diff --git a/drivers/scsi/fnic/fnic_debugfs.c b/drivers/scsi/fnic/fnic_debugfs.c
index 1a4151ef90c1..a024556836d4 100644
--- a/drivers/scsi/fnic/fnic_debugfs.c
+++ b/drivers/scsi/fnic/fnic_debugfs.c
@@ -691,7 +691,7 @@ void fnic_stats_debugfs_init(struct fnic *fnic)
 {
 	char name[16];
 
-	snprintf(name, sizeof(name), "host%d", fnic->lport->host->host_no);
+	snprintf(name, sizeof(name), "host%d", fnic->host->host_no);
 
 	fnic->fnic_stats_debugfs_host = debugfs_create_dir(name,
 						fnic_stats_debugfs_root);
* Unmerged path drivers/scsi/fnic/fnic_fcs.c
diff --git a/drivers/scsi/fnic/fnic_isr.c b/drivers/scsi/fnic/fnic_isr.c
index 8ce488a5e6ee..74e72f196511 100644
--- a/drivers/scsi/fnic/fnic_isr.c
+++ b/drivers/scsi/fnic/fnic_isr.c
@@ -19,7 +19,7 @@
 #include <linux/errno.h>
 #include <linux/pci.h>
 #include <linux/interrupt.h>
-#include <scsi/libfc.h>
+#include <scsi/scsi_transport_fc.h>
 #include <scsi/fc_frame.h>
 #include "vnic_dev.h"
 #include "vnic_intr.h"
@@ -234,7 +234,7 @@ int fnic_request_intr(struct fnic *fnic)
 							fnic->msix[i].devname,
 							fnic->msix[i].devid);
 			if (err) {
-				FNIC_ISR_DBG(KERN_ERR, fnic->lport->host, fnic->fnic_num,
+				FNIC_ISR_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
 							"request_irq failed with error: %d\n",
 							err);
 				fnic_free_intr(fnic);
@@ -262,10 +262,10 @@ int fnic_set_intr_mode_msix(struct fnic *fnic)
 	 * We need n RQs, m WQs, o Copy WQs, n+m+o CQs, and n+m+o+1 INTRs
 	 * (last INTR is used for WQ/RQ errors and notification area)
 	 */
-	FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+	FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 		"rq-array size: %d wq-array size: %d copy-wq array size: %d\n",
 		n, m, o);
-	FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+	FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 		"rq_count: %d raw_wq_count: %d wq_copy_count: %d cq_count: %d\n",
 		fnic->rq_count, fnic->raw_wq_count,
 		fnic->wq_copy_count, fnic->cq_count);
@@ -277,17 +277,17 @@ int fnic_set_intr_mode_msix(struct fnic *fnic)
 
 		vec_count = pci_alloc_irq_vectors(fnic->pdev, min_irqs, vecs,
 					PCI_IRQ_MSIX | PCI_IRQ_AFFINITY);
-		FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+		FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 					"allocated %d MSI-X vectors\n",
 					vec_count);
 
 		if (vec_count > 0) {
 			if (vec_count < vecs) {
-				FNIC_ISR_DBG(KERN_ERR, fnic->lport->host, fnic->fnic_num,
+				FNIC_ISR_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
 				"interrupts number mismatch: vec_count: %d vecs: %d\n",
 				vec_count, vecs);
 				if (vec_count < min_irqs) {
-					FNIC_ISR_DBG(KERN_ERR, fnic->lport->host, fnic->fnic_num,
+					FNIC_ISR_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
 								"no interrupts for copy wq\n");
 					return 1;
 				}
@@ -299,7 +299,7 @@ int fnic_set_intr_mode_msix(struct fnic *fnic)
 			fnic->wq_copy_count = vec_count - n - m - 1;
 			fnic->wq_count = fnic->raw_wq_count + fnic->wq_copy_count;
 			if (fnic->cq_count != vec_count - 1) {
-				FNIC_ISR_DBG(KERN_ERR, fnic->lport->host, fnic->fnic_num,
+				FNIC_ISR_DBG(KERN_ERR, fnic->host, fnic->fnic_num,
 				"CQ count: %d does not match MSI-X vector count: %d\n",
 				fnic->cq_count, vec_count);
 				fnic->cq_count = vec_count - 1;
@@ -307,23 +307,23 @@ int fnic_set_intr_mode_msix(struct fnic *fnic)
 			fnic->intr_count = vec_count;
 			fnic->err_intr_offset = fnic->rq_count + fnic->wq_count;
 
-			FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+			FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 				"rq_count: %d raw_wq_count: %d copy_wq_base: %d\n",
 				fnic->rq_count,
 				fnic->raw_wq_count, fnic->copy_wq_base);
 
-			FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+			FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 				"wq_copy_count: %d wq_count: %d cq_count: %d\n",
 				fnic->wq_copy_count,
 				fnic->wq_count, fnic->cq_count);
 
-			FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+			FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 				"intr_count: %d err_intr_offset: %u",
 				fnic->intr_count,
 				fnic->err_intr_offset);
 
 			vnic_dev_set_intr_mode(fnic->vdev, VNIC_DEV_INTR_MODE_MSIX);
-			FNIC_ISR_DBG(KERN_INFO, fnic->lport->host, fnic->fnic_num,
+			FNIC_ISR_DBG(KERN_INFO, fnic->host, fnic->fnic_num,
 					"fnic using MSI-X\n");
 			return 0;
 		}
@@ -363,7 +363,7 @@ int fnic_set_intr_mode(struct fnic *fnic)
 		fnic->intr_count = 1;
 		fnic->err_intr_offset = 0;
 
-		FNIC_ISR_DBG(KERN_DEBUG, fnic->lport->host, fnic->fnic_num,
+		FNIC_ISR_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
 			     "Using MSI Interrupts\n");
 		vnic_dev_set_intr_mode(fnic->vdev, VNIC_DEV_INTR_MODE_MSI);
 
@@ -389,7 +389,7 @@ int fnic_set_intr_mode(struct fnic *fnic)
 		fnic->cq_count = 3;
 		fnic->intr_count = 3;
 
-		FNIC_ISR_DBG(KERN_DEBUG, fnic->lport->host, fnic->fnic_num,
+		FNIC_ISR_DBG(KERN_DEBUG, fnic->host, fnic->fnic_num,
 			     "Using Legacy Interrupts\n");
 		vnic_dev_set_intr_mode(fnic->vdev, VNIC_DEV_INTR_MODE_INTX);
 
* Unmerged path drivers/scsi/fnic/fnic_main.c
* Unmerged path drivers/scsi/fnic/fnic_scsi.c
