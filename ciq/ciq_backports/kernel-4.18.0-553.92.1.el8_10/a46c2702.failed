blk-mq: don't schedule block kworker on isolated CPUs

jira KERNEL-428
Rebuild_History Non-Buildable kernel-4.18.0-553.92.1.el8_10
commit-author Ming Lei <ming.lei@redhat.com>
commit a46c27026da10a126dd870f7b65380010bd20db5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.92.1.el8_10/a46c2702.failed

Kernel parameter of `isolcpus=` or 'nohz_full=' are used to isolate CPUs
for specific task, and it isn't expected to let block IO disturb these CPUs.
blk-mq kworker shouldn't be scheduled on isolated CPUs. Also if isolated
CPUs is run for blk-mq kworker, long block IO latency can be caused.

Kernel workqueue only respects CPU isolation for WQ_UNBOUND, for bound
WQ, the responsibility is on user because CPU is specified as WQ API
parameter, such as mod_delayed_work_on(cpu), queue_delayed_work_on(cpu)
and queue_work_on(cpu).

So not run blk-mq kworker on isolated CPUs by removing isolated CPUs
from hctx->cpumask. Meantime use queue map to check if all CPUs in this
hw queue are offline instead of hctx->cpumask, this way can avoid any
cost in fast IO code path, and is safe since hctx->cpumask are only
used in the two cases.

	Cc: Tim Chen <tim.c.chen@linux.intel.com>
	Cc: Juri Lelli <juri.lelli@redhat.com>
	Cc: Andrew Theurer <atheurer@redhat.com>
	Cc: Joe Mario <jmario@redhat.com>
	Cc: Sebastian Jug <sejug@redhat.com>
	Cc: Frederic Weisbecker <frederic@kernel.org>
	Cc: Bart Van Assche <bvanassche@acm.org>
	Cc: Tejun Heo <tj@kernel.org>
Tesed-by: Joe Mario <jmario@redhat.com>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Ewan D. Milne <emilne@redhat.com>
Link: https://lore.kernel.org/r/20240322021244.1056223-1-ming.lei@redhat.com
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit a46c27026da10a126dd870f7b65380010bd20db5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index b5962859601b,b8dbfed8b28b..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -25,6 -26,9 +25,12 @@@
  #include <linux/delay.h>
  #include <linux/crash_dump.h>
  #include <linux/prefetch.h>
++<<<<<<< HEAD
++=======
+ #include <linux/blk-crypto.h>
+ #include <linux/part_stat.h>
+ #include <linux/sched/isolation.h>
++>>>>>>> a46c27026da1 (blk-mq: don't schedule block kworker on isolated CPUs)
  
  #include <trace/events/block.h>
  
@@@ -2648,14 -3494,30 +2664,38 @@@ static bool blk_mq_hctx_has_requests(st
  	return data.has_rq;
  }
  
- static inline bool blk_mq_last_cpu_in_hctx(unsigned int cpu,
- 		struct blk_mq_hw_ctx *hctx)
+ static bool blk_mq_hctx_has_online_cpu(struct blk_mq_hw_ctx *hctx,
+ 		unsigned int this_cpu)
  {
++<<<<<<< HEAD
 +	if (cpumask_next_and(-1, hctx->cpumask, cpu_online_mask) != cpu)
 +		return false;
 +	if (cpumask_next_and(cpu, hctx->cpumask, cpu_online_mask) < nr_cpu_ids)
 +		return false;
 +	return true;
++=======
+ 	enum hctx_type type = hctx->type;
+ 	int cpu;
+ 
+ 	/*
+ 	 * hctx->cpumask has to rule out isolated CPUs, but userspace still
+ 	 * might submit IOs on these isolated CPUs, so use the queue map to
+ 	 * check if all CPUs mapped to this hctx are offline
+ 	 */
+ 	for_each_online_cpu(cpu) {
+ 		struct blk_mq_hw_ctx *h = blk_mq_map_queue_type(hctx->queue,
+ 				type, cpu);
+ 
+ 		if (h != hctx)
+ 			continue;
+ 
+ 		/* this hctx has at least one online CPU */
+ 		if (this_cpu != cpu)
+ 			return true;
+ 	}
+ 
+ 	return false;
++>>>>>>> a46c27026da1 (blk-mq: don't schedule block kworker on isolated CPUs)
  }
  
  static int blk_mq_hctx_notify_offline(unsigned int cpu, struct hlist_node *node)
* Unmerged path block/blk-mq.c
