s390/mm: check 2KB-fragment page on release

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Alexander Gordeev <agordeev@linux.ibm.com>
commit 4c88bb96e40b757f4796f70a4a7507df554467c4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/4c88bb96.failed

When CONFIG_DEBUG_VM is defined check that pending remove
and tracking nibbles (bits 31-24 of the page refcount) are
cleared. Should the earlier stages of the page lifespan
have a race or logical error, such check could help in
exposing the issue.

	Signed-off-by: Alexander Gordeev <agordeev@linux.ibm.com>
	Reviewed-by: Gerald Schaefer <gerald.schaefer@linux.ibm.com>
	Signed-off-by: Heiko Carstens <hca@linux.ibm.com>
(cherry picked from commit 4c88bb96e40b757f4796f70a4a7507df554467c4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/mm/pgalloc.c
diff --cc arch/s390/mm/pgalloc.c
index 195c1827361f,fd35c1a0213b..000000000000
--- a/arch/s390/mm/pgalloc.c
+++ b/arch/s390/mm/pgalloc.c
@@@ -265,13 -348,17 +278,24 @@@ void page_table_free(struct mm_struct *
  		spin_unlock_bh(&mm->context.lock);
  		mask = atomic_xor_bits(&page->_refcount, 0x10U << (bit + 24));
  		mask >>= 24;
 -		if (mask != 0x00U)
 +		if (mask != 0)
  			return;
+ 		half = 0x01U << bit;
  	} else {
++<<<<<<< HEAD
 +		atomic_xor_bits(&page->_refcount, 3U << 24);
 +	}
 +
 +	pgtable_page_dtor(page);
++=======
+ 		half = 0x03U;
+ 		mask = atomic_xor_bits(&page->_refcount, 0x03U << 24);
+ 		mask >>= 24;
+ 	}
+ 
+ 	page_table_release_check(page, table, half, mask);
+ 	pgtable_pte_page_dtor(page);
++>>>>>>> 4c88bb96e40b (s390/mm: check 2KB-fragment page on release)
  	__free_page(page);
  }
  
@@@ -305,28 -397,30 +329,53 @@@ void page_table_free_rcu(struct mmu_gat
  
  void __tlb_remove_table(void *_table)
  {
++<<<<<<< HEAD
 +	unsigned int mask = (unsigned long) _table & 3;
 +	void *table = (void *)((unsigned long) _table ^ mask);
 +	struct page *page = virt_to_page(table);
 +
 +	switch (mask) {
 +	case 0:		/* pmd, pud, or p4d */
 +		free_pages((unsigned long) table, 2);
 +		break;
 +	case 1:		/* lower 2K of a 4K page table */
 +	case 2:		/* higher 2K of a 4K page table */
 +		mask = atomic_xor_bits(&page->_refcount, mask << (4 + 24));
 +		mask >>= 24;
 +		if (mask != 0)
 +			break;
 +		/* fallthrough */
 +	case 3:		/* 4K page table with pgstes */
 +		if (mask & 3)
 +			atomic_xor_bits(&page->_refcount, 3 << 24);
 +		pgtable_page_dtor(page);
 +		__free_page(page);
++=======
+ 	unsigned int mask = (unsigned long) _table & 0x03U, half = mask;
+ 	void *table = (void *)((unsigned long) _table ^ mask);
+ 	struct page *page = virt_to_page(table);
+ 
+ 	switch (half) {
+ 	case 0x00U:	/* pmd, pud, or p4d */
+ 		free_pages((unsigned long) table, 2);
+ 		return;
+ 	case 0x01U:	/* lower 2K of a 4K page table */
+ 	case 0x02U:	/* higher 2K of a 4K page table */
+ 		mask = atomic_xor_bits(&page->_refcount, mask << (4 + 24));
+ 		mask >>= 24;
+ 		if (mask != 0x00U)
+ 			return;
+ 		break;
+ 	case 0x03U:	/* 4K page table with pgstes */
+ 		mask = atomic_xor_bits(&page->_refcount, 0x03U << 24);
+ 		mask >>= 24;
++>>>>>>> 4c88bb96e40b (s390/mm: check 2KB-fragment page on release)
  		break;
  	}
+ 
+ 	page_table_release_check(page, table, half, mask);
+ 	pgtable_pte_page_dtor(page);
+ 	__free_page(page);
  }
  
  /*
* Unmerged path arch/s390/mm/pgalloc.c
