arm64: mte: CPU feature detection and initial sysreg configuration

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Vincenzo Frascino <vincenzo.frascino@arm.com>
commit 3b714d24ef173f81c78af16f73dcc9b40428c803
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/3b714d24.failed

Add the cpufeature and hwcap entries to detect the presence of MTE. Any
secondary CPU not supporting the feature, if detected on the boot CPU,
will be parked.

Add the minimum SCTLR_EL1 and HCR_EL2 bits for enabling MTE. The Normal
Tagged memory type is configured in MAIR_EL1 before the MMU is enabled
in order to avoid disrupting other CPUs in the CnP domain.

	Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
Co-developed-by: Catalin Marinas <catalin.marinas@arm.com>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will@kernel.org>
	Cc: Suzuki K Poulose <Suzuki.Poulose@arm.com>
(cherry picked from commit 3b714d24ef173f81c78af16f73dcc9b40428c803)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/include/asm/hwcap.h
#	arch/arm64/include/uapi/asm/hwcap.h
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/kernel/cpuinfo.c
#	arch/arm64/mm/proc.S
diff --cc arch/arm64/include/asm/cpucaps.h
index 7115f7a85078,1937653b05a3..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -61,18 -50,22 +61,38 @@@
  #define ARM64_HAS_GENERIC_AUTH_ARCH		40
  #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		41
  #define ARM64_HAS_IRQ_PRIO_MASKING		42
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	43
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	44
 +#define ARM64_WORKAROUND_1463225		45
 +#define ARM64_WORKAROUND_1542419		46
 +#define ARM64_HAS_32BIT_EL1			47
 +#define ARM64_WORKAROUND_NVIDIA_CARMEL_CNP	48
 +#define ARM64_HAS_ARMv8_4_TTL			49
 +#define ARM64_HAS_TLB_RANGE			50
 +#define ARM64_HAS_DCPODP			51
 +#define ARM64_HAS_E0PD				52
 +#define ARM64_HAS_RNG				53
 +
 +#define ARM64_NCAPS				54
++=======
+ #define ARM64_HAS_DCPODP			43
+ #define ARM64_WORKAROUND_1463225		44
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	45
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	46
+ #define ARM64_WORKAROUND_1542419		47
+ #define ARM64_HAS_E0PD				48
+ #define ARM64_HAS_RNG				49
+ #define ARM64_HAS_AMU_EXTN			50
+ #define ARM64_HAS_ADDRESS_AUTH			51
+ #define ARM64_HAS_GENERIC_AUTH			52
+ #define ARM64_HAS_32BIT_EL1			53
+ #define ARM64_BTI				54
+ #define ARM64_HAS_ARMv8_4_TTL			55
+ #define ARM64_HAS_TLB_RANGE			56
+ #define ARM64_MTE				57
+ 
+ #define ARM64_NCAPS				58
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/include/asm/hwcap.h
index 8793fb43c406,0d4a6741b6a5..000000000000
--- a/arch/arm64/include/asm/hwcap.h
+++ b/arch/arm64/include/asm/hwcap.h
@@@ -105,6 -94,8 +105,11 @@@
  #define KERNEL_HWCAP_BF16		__khwcap2_feature(BF16)
  #define KERNEL_HWCAP_DGH		__khwcap2_feature(DGH)
  #define KERNEL_HWCAP_RNG		__khwcap2_feature(RNG)
++<<<<<<< HEAD
++=======
+ #define KERNEL_HWCAP_BTI		__khwcap2_feature(BTI)
+ #define KERNEL_HWCAP_MTE		__khwcap2_feature(MTE)
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  
  /*
   * This yields a mask that user programs can use to figure out what
diff --cc arch/arm64/include/uapi/asm/hwcap.h
index 7752d93bb50f,b8f41aa234ee..000000000000
--- a/arch/arm64/include/uapi/asm/hwcap.h
+++ b/arch/arm64/include/uapi/asm/hwcap.h
@@@ -73,5 -73,7 +73,10 @@@
  #define HWCAP2_BF16		(1 << 14)
  #define HWCAP2_DGH		(1 << 15)
  #define HWCAP2_RNG		(1 << 16)
++<<<<<<< HEAD
++=======
+ #define HWCAP2_BTI		(1 << 17)
+ #define HWCAP2_MTE		(1 << 18)
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  
  #endif /* _UAPI__ASM_HWCAP_H */
diff --cc arch/arm64/kernel/cpufeature.c
index 976fb30e87c8,fabc8a237223..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -193,7 -227,11 +193,9 @@@ static const struct arm64_ftr_bits ftr_
  static const struct arm64_ftr_bits ftr_id_aa64pfr1[] = {
  	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64PFR1_MPAMFRAC_SHIFT, 4, 0),
  	ARM64_FTR_BITS(FTR_HIDDEN, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64PFR1_RASFRAC_SHIFT, 4, 0),
+ 	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_MTE),
+ 		       FTR_STRICT, FTR_LOWER_SAFE, ID_AA64PFR1_MTE_SHIFT, 4, ID_AA64PFR1_MTE_NI),
  	ARM64_FTR_BITS(FTR_VISIBLE, FTR_STRICT, FTR_LOWER_SAFE, ID_AA64PFR1_SSBS_SHIFT, 4, ID_AA64PFR1_SSBS_PSTATE_NI),
 -	ARM64_FTR_BITS(FTR_VISIBLE_IF_IS_ENABLED(CONFIG_ARM64_BTI),
 -				    FTR_STRICT, FTR_LOWER_SAFE, ID_AA64PFR1_BT_SHIFT, 4, 0),
  	ARM64_FTR_END,
  };
  
@@@ -1962,6 -2106,35 +1964,38 @@@ static const struct arm64_cpu_capabilit
  		.min_field_value = 1,
  	},
  #endif
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ARM64_BTI
+ 	{
+ 		.desc = "Branch Target Identification",
+ 		.capability = ARM64_BTI,
+ #ifdef CONFIG_ARM64_BTI_KERNEL
+ 		.type = ARM64_CPUCAP_STRICT_BOOT_CPU_FEATURE,
+ #else
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ #endif
+ 		.matches = has_cpuid_feature,
+ 		.cpu_enable = bti_enable,
+ 		.sys_reg = SYS_ID_AA64PFR1_EL1,
+ 		.field_pos = ID_AA64PFR1_BT_SHIFT,
+ 		.min_field_value = ID_AA64PFR1_BT_BTI,
+ 		.sign = FTR_UNSIGNED,
+ 	},
+ #endif
+ #ifdef CONFIG_ARM64_MTE
+ 	{
+ 		.desc = "Memory Tagging Extension",
+ 		.capability = ARM64_MTE,
+ 		.type = ARM64_CPUCAP_STRICT_BOOT_CPU_FEATURE,
+ 		.matches = has_cpuid_feature,
+ 		.sys_reg = SYS_ID_AA64PFR1_EL1,
+ 		.field_pos = ID_AA64PFR1_MTE_SHIFT,
+ 		.min_field_value = ID_AA64PFR1_MTE,
+ 		.sign = FTR_UNSIGNED,
+ 	},
+ #endif /* CONFIG_ARM64_MTE */
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  	{},
  };
  
diff --cc arch/arm64/kernel/cpuinfo.c
index a60acf140f50,6104b87f021d..000000000000
--- a/arch/arm64/kernel/cpuinfo.c
+++ b/arch/arm64/kernel/cpuinfo.c
@@@ -102,6 -92,8 +102,11 @@@ static const char *const hwcap_str[] = 
  	"bf16",
  	"dgh",
  	"rng",
++<<<<<<< HEAD
++=======
+ 	"bti",
+ 	"mte",
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  	NULL
  };
  
diff --cc arch/arm64/mm/proc.S
index 768b1405972d,23c326a06b2d..000000000000
--- a/arch/arm64/mm/proc.S
+++ b/arch/arm64/mm/proc.S
@@@ -27,6 -17,8 +27,11 @@@
  #include <asm/pgtable-hwdef.h>
  #include <asm/cpufeature.h>
  #include <asm/alternative.h>
++<<<<<<< HEAD
++=======
+ #include <asm/smp.h>
+ #include <asm/sysreg.h>
++>>>>>>> 3b714d24ef17 (arm64: mte: CPU feature detection and initial sysreg configuration)
  
  #ifdef CONFIG_ARM64_64K_PAGES
  #define TCR_TG_FLAGS	TCR_TG0_64K | TCR_TG1_64K
@@@ -441,11 -426,30 +446,34 @@@ ENTRY(__cpu_setup
  	 * Memory region attributes
  	 */
  	mov_q	x5, MAIR_EL1_SET
+ #ifdef CONFIG_ARM64_MTE
+ 	/*
+ 	 * Update MAIR_EL1, GCR_EL1 and TFSR*_EL1 if MTE is supported
+ 	 * (ID_AA64PFR1_EL1[11:8] > 1).
+ 	 */
+ 	mrs	x10, ID_AA64PFR1_EL1
+ 	ubfx	x10, x10, #ID_AA64PFR1_MTE_SHIFT, #4
+ 	cmp	x10, #ID_AA64PFR1_MTE
+ 	b.lt	1f
+ 
+ 	/* Normal Tagged memory type at the corresponding MAIR index */
+ 	mov	x10, #MAIR_ATTR_NORMAL_TAGGED
+ 	bfi	x5, x10, #(8 *  MT_NORMAL_TAGGED), #8
+ 
+ 	/* initialize GCR_EL1: all non-zero tags excluded by default */
+ 	mov	x10, #(SYS_GCR_EL1_RRND | SYS_GCR_EL1_EXCL_MASK)
+ 	msr_s	SYS_GCR_EL1, x10
+ 
+ 	/* clear any pending tag check faults in TFSR*_EL1 */
+ 	msr_s	SYS_TFSR_EL1, xzr
+ 	msr_s	SYS_TFSRE0_EL1, xzr
+ 1:
+ #endif
  	msr	mair_el1, x5
 +	/*
 +	 * Prepare SCTLR
 +	 */
 +	mov_q	x0, SCTLR_EL1_SET
  	/*
  	 * Set/prepare TCR and TTBR. We use 512GB (39-bit) address range for
  	 * both user and kernel.
* Unmerged path arch/arm64/include/asm/cpucaps.h
diff --git a/arch/arm64/include/asm/cpufeature.h b/arch/arm64/include/asm/cpufeature.h
index 5af39db67149..225e1e2dafee 100644
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@ -683,6 +683,12 @@ static __always_inline bool system_uses_irq_prio_masking(void)
 	       cpus_have_const_cap(ARM64_HAS_IRQ_PRIO_MASKING);
 }
 
+static inline bool system_supports_mte(void)
+{
+	return IS_ENABLED(CONFIG_ARM64_MTE) &&
+		cpus_have_const_cap(ARM64_MTE);
+}
+
 static inline bool system_has_prio_mask_debugging(void)
 {
 	return IS_ENABLED(CONFIG_ARM64_DEBUG_PRIORITY_MASKING) &&
* Unmerged path arch/arm64/include/asm/hwcap.h
diff --git a/arch/arm64/include/asm/kvm_arm.h b/arch/arm64/include/asm/kvm_arm.h
index b947bc51487a..7c09f460c5a8 100644
--- a/arch/arm64/include/asm/kvm_arm.h
+++ b/arch/arm64/include/asm/kvm_arm.h
@@ -90,7 +90,7 @@
 			 HCR_AMO | HCR_SWIO | HCR_TIDCP | HCR_RW | HCR_TLOR | \
 			 HCR_FMO | HCR_IMO | HCR_PTW )
 #define HCR_VIRT_EXCP_MASK (HCR_VSE | HCR_VI | HCR_VF)
-#define HCR_HOST_NVHE_FLAGS (HCR_RW | HCR_API | HCR_APK)
+#define HCR_HOST_NVHE_FLAGS (HCR_RW | HCR_API | HCR_APK | HCR_ATA)
 #define HCR_HOST_VHE_FLAGS (HCR_RW | HCR_TGE | HCR_E2H)
 
 /* TCR_EL2 Registers bits */
diff --git a/arch/arm64/include/asm/sysreg.h b/arch/arm64/include/asm/sysreg.h
index 7b11f3be556e..f0bf4ed13151 100644
--- a/arch/arm64/include/asm/sysreg.h
+++ b/arch/arm64/include/asm/sysreg.h
@@ -655,6 +655,7 @@
 			 SCTLR_EL1_SA0  | SCTLR_EL1_SED  | SCTLR_ELx_I    |\
 			 SCTLR_EL1_DZE  | SCTLR_EL1_UCT                   |\
 			 SCTLR_EL1_NTWE | SCTLR_ELx_IESB | SCTLR_EL1_SPAN |\
+			 SCTLR_ELx_ITFSB| SCTLR_ELx_ATA  | SCTLR_EL1_ATA0 |\
 			 ENDIAN_SET_EL1 | SCTLR_EL1_UCI  | SCTLR_EL1_RES1)
 #define SCTLR_EL1_CLEAR	(SCTLR_ELx_A   | SCTLR_EL1_CP15BEN | SCTLR_EL1_ITD    |\
 			 SCTLR_EL1_UMA | SCTLR_ELx_WXN     | ENDIAN_CLEAR_EL1 |\
* Unmerged path arch/arm64/include/uapi/asm/hwcap.h
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/kernel/cpuinfo.c
* Unmerged path arch/arm64/mm/proc.S
