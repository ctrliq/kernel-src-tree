arm64: enable ptrauth earlier

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Kristina Martsenko <kristina.martsenko@arm.com>
commit 6982934e19f8ebb4152ba77308facdb1a38533f9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/6982934e.failed

When the kernel is compiled with pointer auth instructions, the boot CPU
needs to start using address auth very early, so change the cpucap to
account for this.

Pointer auth must be enabled before we call C functions, because it is
not possible to enter a function with pointer auth disabled and exit it
with pointer auth enabled. Note, mismatches between architected and
IMPDEF algorithms will still be caught by the cpufeature framework (the
separate *_ARCH and *_IMP_DEF cpucaps).

Note the change in behavior: if the boot CPU has address auth and a
late CPU does not, then the late CPU is parked by the cpufeature
framework. This is possible as kernel will only have NOP space intructions
for PAC so such mismatched late cpu will silently ignore those
instructions in C functions. Also, if the boot CPU does not have address
auth and the late CPU has then the late cpu will still boot but with
ptrauth feature disabled.

Leave generic authentication as a "system scope" cpucap for now, since
initially the kernel will only use address authentication.

	Reviewed-by: Kees Cook <keescook@chromium.org>
	Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
	Reviewed-by: Vincenzo Frascino <Vincenzo.Frascino@arm.com>
	Signed-off-by: Kristina Martsenko <kristina.martsenko@arm.com>
[Amit: Re-worked ptrauth setup logic, comments]
	Signed-off-by: Amit Daniel Kachhap <amit.kachhap@arm.com>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
(cherry picked from commit 6982934e19f8ebb4152ba77308facdb1a38533f9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/Kconfig
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/mm/proc.S
diff --cc arch/arm64/Kconfig
index e2a64679ab25,87e2cbb76930..000000000000
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@@ -1425,19 -1515,11 +1425,27 @@@ config ARM64_PTR_AUT
  	  be enabled. However, KVM guest also require VHE mode and hence
  	  CONFIG_ARM64_VHE=y option to use this feature.
  
++<<<<<<< HEAD
 +config AS_HAS_ARMV8_4
 +	def_bool $(cc-option,-Wa$(comma)-march=armv8.4-a)
 +
 +config ARM64_TLB_RANGE
 +	bool "Enable support for tlbi range feature"
 +	default y
 +	depends on AS_HAS_ARMV8_4
 +	help
 +	  ARMv8.4-TLBI provides TLBI invalidation instruction that apply to a
 +	  range of input addresses.
 +
 +	  The feature introduces new assembly instructions, and they were
 +	  support when binutils >= 2.30.
++=======
+ 	  If the feature is present on the boot CPU but not on a late CPU, then
+ 	  the late CPU will be parked. Also, if the boot CPU does not have
+ 	  address auth and the late CPU has then the late CPU will still boot
+ 	  but with the feature disabled. On such a system, this option should
+ 	  not be selected.
++>>>>>>> 6982934e19f8 (arm64: enable ptrauth earlier)
  
  endmenu
  
diff --cc arch/arm64/kernel/cpufeature.c
index 23e372cfd69d,f6c0cb755107..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -1353,10 -1318,18 +1353,25 @@@ static void cpu_clear_disr(const struc
  #endif /* CONFIG_ARM64_RAS_EXTN */
  
  #ifdef CONFIG_ARM64_PTR_AUTH
++<<<<<<< HEAD
 +static void cpu_enable_address_auth(struct arm64_cpu_capabilities const *cap)
 +{
 +	sysreg_clear_set(sctlr_el1, 0, SCTLR_ELx_ENIA | SCTLR_ELx_ENIB |
 +				       SCTLR_ELx_ENDA | SCTLR_ELx_ENDB);
++=======
+ static bool has_address_auth(const struct arm64_cpu_capabilities *entry,
+ 			     int __unused)
+ {
+ 	return __system_matches_cap(ARM64_HAS_ADDRESS_AUTH_ARCH) ||
+ 	       __system_matches_cap(ARM64_HAS_ADDRESS_AUTH_IMP_DEF);
+ }
+ 
+ static bool has_generic_auth(const struct arm64_cpu_capabilities *entry,
+ 			     int __unused)
+ {
+ 	return __system_matches_cap(ARM64_HAS_GENERIC_AUTH_ARCH) ||
+ 	       __system_matches_cap(ARM64_HAS_GENERIC_AUTH_IMP_DEF);
++>>>>>>> 6982934e19f8 (arm64: enable ptrauth earlier)
  }
  #endif /* CONFIG_ARM64_PTR_AUTH */
  
@@@ -1697,7 -1637,11 +1712,15 @@@ static const struct arm64_cpu_capabilit
  		.field_pos = ID_AA64ISAR1_API_SHIFT,
  		.min_field_value = ID_AA64ISAR1_API_IMP_DEF,
  		.matches = has_cpuid_feature,
++<<<<<<< HEAD
 +		.cpu_enable = cpu_enable_address_auth,
++=======
+ 	},
+ 	{
+ 		.capability = ARM64_HAS_ADDRESS_AUTH,
+ 		.type = ARM64_CPUCAP_BOOT_CPU_FEATURE,
+ 		.matches = has_address_auth,
++>>>>>>> 6982934e19f8 (arm64: enable ptrauth earlier)
  	},
  	{
  		.desc = "Generic authentication (architected algorithm)",
diff --cc arch/arm64/mm/proc.S
index 768b1405972d,4cf19a26af2d..000000000000
--- a/arch/arm64/mm/proc.S
+++ b/arch/arm64/mm/proc.S
@@@ -482,5 -469,39 +483,42 @@@ ENTRY(__cpu_setup
  1:
  #endif	/* CONFIG_ARM64_HW_AFDBM */
  	msr	tcr_el1, x10
++<<<<<<< HEAD
++=======
+ 	mov	x1, x0
+ 	/*
+ 	 * Prepare SCTLR
+ 	 */
+ 	mov_q	x0, SCTLR_EL1_SET
+ 
+ #ifdef CONFIG_ARM64_PTR_AUTH
+ 	/* No ptrauth setup for run time cpus */
+ 	cmp	x1, #ARM64_CPU_RUNTIME
+ 	b.eq	3f
+ 
+ 	/* Check if the CPU supports ptrauth */
+ 	mrs	x2, id_aa64isar1_el1
+ 	ubfx	x2, x2, #ID_AA64ISAR1_APA_SHIFT, #8
+ 	cbz	x2, 3f
+ 
+ 	msr_s	SYS_APIAKEYLO_EL1, xzr
+ 	msr_s	SYS_APIAKEYHI_EL1, xzr
+ 
+ 	/* Just enable ptrauth for primary cpu */
+ 	cmp	x1, #ARM64_CPU_BOOT_PRIMARY
+ 	b.eq	2f
+ 
+ 	/* if !system_supports_address_auth() then skip enable */
+ alternative_if_not ARM64_HAS_ADDRESS_AUTH
+ 	b	3f
+ alternative_else_nop_endif
+ 
+ 2:	/* Enable ptrauth instructions */
+ 	ldr	x2, =SCTLR_ELx_ENIA | SCTLR_ELx_ENIB | \
+ 		     SCTLR_ELx_ENDA | SCTLR_ELx_ENDB
+ 	orr	x0, x0, x2
+ 3:
+ #endif
++>>>>>>> 6982934e19f8 (arm64: enable ptrauth earlier)
  	ret					// return to head.S
 -SYM_FUNC_END(__cpu_setup)
 +ENDPROC(__cpu_setup)
* Unmerged path arch/arm64/Kconfig
diff --git a/arch/arm64/include/asm/cpufeature.h b/arch/arm64/include/asm/cpufeature.h
index 41fe5b1ea3d0..d3960eb2ba31 100644
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@ -294,6 +294,15 @@ extern struct arm64_ftr_reg arm64_ftr_reg_ctrel0;
 #define ARM64_CPUCAP_STRICT_BOOT_CPU_FEATURE		\
 	(ARM64_CPUCAP_SCOPE_BOOT_CPU | ARM64_CPUCAP_PANIC_ON_CONFLICT)
 
+/*
+ * CPU feature used early in the boot based on the boot CPU. It is safe for a
+ * late CPU to have this feature even though the boot CPU hasn't enabled it,
+ * although the feature will not be used by Linux in this case. If the boot CPU
+ * has enabled this feature already, then every late CPU must have it.
+ */
+#define ARM64_CPUCAP_BOOT_CPU_FEATURE                  \
+	(ARM64_CPUCAP_SCOPE_BOOT_CPU | ARM64_CPUCAP_PERMITTED_FOR_LATE_CPU)
+
 struct arm64_cpu_capabilities {
 	const char *desc;
 	u16 capability;
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/mm/proc.S
