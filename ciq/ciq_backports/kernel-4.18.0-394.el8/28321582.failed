arm64: initialize ptrauth keys for kernel booting task

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Amit Daniel Kachhap <amit.kachhap@arm.com>
commit 28321582334c261c13b20d7efe634e610b4c100b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/28321582.failed

This patch uses the existing boot_init_stack_canary arch function
to initialize the ptrauth keys for the booting task in the primary
core. The requirement here is that it should be always inline and
the caller must never return.

As pointer authentication too detects a subset of stack corruption
so it makes sense to place this code here.

Both pointer authentication and stack canary codes are protected
by their respective config option.

	Suggested-by: Ard Biesheuvel <ardb@kernel.org>
	Signed-off-by: Amit Daniel Kachhap <amit.kachhap@arm.com>
	Reviewed-by: Vincenzo Frascino <Vincenzo.Frascino@arm.com>
	Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
(cherry picked from commit 28321582334c261c13b20d7efe634e610b4c100b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/pointer_auth.h
diff --cc arch/arm64/include/asm/pointer_auth.h
index 1e1215eb8d01,833d3f948de0..000000000000
--- a/arch/arm64/include/asm/pointer_auth.h
+++ b/arch/arm64/include/asm/pointer_auth.h
@@@ -50,19 -54,18 +50,29 @@@ do {								
  	write_sysreg_s(__pki_v.hi, SYS_ ## k ## KEYHI_EL1);	\
  } while (0)
  
++<<<<<<< HEAD
 +static inline void ptrauth_keys_switch_user(struct ptrauth_keys_user *keys)
++=======
+ static __always_inline void ptrauth_keys_init_kernel(struct ptrauth_keys_kernel *keys)
++>>>>>>> 28321582334c (arm64: initialize ptrauth keys for kernel booting task)
  {
 -	if (system_supports_address_auth())
 -		get_random_bytes(&keys->apia, sizeof(keys->apia));
 +	if (system_supports_address_auth()) {
 +		__ptrauth_key_install(APIA, keys->apia);
 +		__ptrauth_key_install(APIB, keys->apib);
 +		__ptrauth_key_install(APDA, keys->apda);
 +		__ptrauth_key_install(APDB, keys->apdb);
 +	}
 +
 +	if (system_supports_generic_auth())
 +		__ptrauth_key_install(APGA, keys->apga);
  }
  
+ static __always_inline void ptrauth_keys_switch_kernel(struct ptrauth_keys_kernel *keys)
+ {
+ 	if (system_supports_address_auth())
+ 		__ptrauth_key_install(APIA, keys->apia);
+ }
+ 
  extern int ptrauth_prctl_reset_keys(struct task_struct *tsk, unsigned long arg);
  
  /*
@@@ -78,20 -81,18 +88,33 @@@ static inline unsigned long ptrauth_str
  }
  
  #define ptrauth_thread_init_user(tsk)					\
++<<<<<<< HEAD
 +do {									\
 +	struct task_struct *__ptiu_tsk = (tsk);				\
 +	ptrauth_keys_init_user(&__ptiu_tsk->thread.keys_user);		\
 +	ptrauth_keys_switch_user(&__ptiu_tsk->thread.keys_user);		\
 +} while (0)
 +
 +#define ptrauth_thread_switch(tsk)	\
 +	ptrauth_keys_switch_user(&(tsk)->thread.keys_user)
++=======
+ 	ptrauth_keys_init_user(&(tsk)->thread.keys_user)
+ #define ptrauth_thread_init_kernel(tsk)					\
+ 	ptrauth_keys_init_kernel(&(tsk)->thread.keys_kernel)
+ #define ptrauth_thread_switch_kernel(tsk)				\
+ 	ptrauth_keys_switch_kernel(&(tsk)->thread.keys_kernel)
++>>>>>>> 28321582334c (arm64: initialize ptrauth keys for kernel booting task)
  
  #else /* CONFIG_ARM64_PTR_AUTH */
  #define ptrauth_prctl_reset_keys(tsk, arg)	(-EINVAL)
  #define ptrauth_strip_insn_pac(lr)	(lr)
  #define ptrauth_thread_init_user(tsk)
++<<<<<<< HEAD
 +#define ptrauth_thread_switch(tsk)
++=======
+ #define ptrauth_thread_init_kernel(tsk)
+ #define ptrauth_thread_switch_kernel(tsk)
++>>>>>>> 28321582334c (arm64: initialize ptrauth keys for kernel booting task)
  #endif /* CONFIG_ARM64_PTR_AUTH */
  
  #endif /* __ASM_POINTER_AUTH_H */
* Unmerged path arch/arm64/include/asm/pointer_auth.h
diff --git a/arch/arm64/include/asm/stackprotector.h b/arch/arm64/include/asm/stackprotector.h
index 5884a2b02827..7263e0bac680 100644
--- a/arch/arm64/include/asm/stackprotector.h
+++ b/arch/arm64/include/asm/stackprotector.h
@@ -15,6 +15,7 @@
 
 #include <linux/random.h>
 #include <linux/version.h>
+#include <asm/pointer_auth.h>
 
 extern unsigned long __stack_chk_guard;
 
@@ -26,6 +27,7 @@ extern unsigned long __stack_chk_guard;
  */
 static __always_inline void boot_init_stack_canary(void)
 {
+#if defined(CONFIG_STACKPROTECTOR)
 	unsigned long canary;
 
 	/* Try to get a semi random initial value. */
@@ -36,6 +38,9 @@ static __always_inline void boot_init_stack_canary(void)
 	current->stack_canary = canary;
 	if (!IS_ENABLED(CONFIG_STACKPROTECTOR_PER_TASK))
 		__stack_chk_guard = current->stack_canary;
+#endif
+	ptrauth_thread_init_kernel(current);
+	ptrauth_thread_switch_kernel(current);
 }
 
 #endif	/* _ASM_STACKPROTECTOR_H */
diff --git a/include/linux/stackprotector.h b/include/linux/stackprotector.h
index 6b792d080eee..4c678c4fec58 100644
--- a/include/linux/stackprotector.h
+++ b/include/linux/stackprotector.h
@@ -6,7 +6,7 @@
 #include <linux/sched.h>
 #include <linux/random.h>
 
-#ifdef CONFIG_STACKPROTECTOR
+#if defined(CONFIG_STACKPROTECTOR) || defined(CONFIG_ARM64_PTR_AUTH)
 # include <asm/stackprotector.h>
 #else
 static inline void boot_init_stack_canary(void)
