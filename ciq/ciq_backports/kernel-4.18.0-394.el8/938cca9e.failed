sock: fix /proc/net/sockstat underflow in sk_clone_lock()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>
commit 938cca9e4109b30ee1d476904538225a825e54eb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/938cca9e.failed

sk_clone_lock() needs to call sock_inuse_add(1) before entering the
sk_free_unlock_clone() error path, for __sk_free() from sk_free() from
sk_free_unlock_clone() calls sock_inuse_add(-1).

	Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Fixes: 648845ab7e200993 ("sock: Move the socket inuse to namespace.")
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 938cca9e4109b30ee1d476904538225a825e54eb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/sock.c
diff --cc net/core/sock.c
index cfe2b9cc6fa7,41e91d0f7061..000000000000
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@@ -1872,121 -2111,121 +1872,182 @@@ static void sk_init_common(struct sock 
  struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority)
  {
  	struct proto *prot = READ_ONCE(sk->sk_prot);
 -	struct sk_filter *filter;
 -	bool is_charged = true;
  	struct sock *newsk;
 +	bool is_charged = true;
  
  	newsk = sk_prot_alloc(prot, priority, sk->sk_family);
 -	if (!newsk)
 -		goto out;
 -
 -	sock_copy(newsk, sk);
 -
 -	newsk->sk_prot_creator = prot;
 -
 +	if (newsk != NULL) {
 +		struct sk_filter *filter;
 +
 +		sock_copy(newsk, sk);
 +
 +		newsk->sk_prot_creator = prot;
 +
++<<<<<<< HEAD
 +		/* SANITY */
 +		if (likely(newsk->sk_net_refcnt))
 +			get_net(sock_net(newsk));
 +		sk_node_init(&newsk->sk_node);
 +		sock_lock_init(newsk);
 +		bh_lock_sock(newsk);
 +		newsk->sk_backlog.head	= newsk->sk_backlog.tail = NULL;
 +		newsk->sk_backlog.len = 0;
++=======
+ 	/* SANITY */
+ 	if (likely(newsk->sk_net_refcnt)) {
+ 		get_net(sock_net(newsk));
+ 		sock_inuse_add(sock_net(newsk), 1);
+ 	}
+ 	sk_node_init(&newsk->sk_node);
+ 	sock_lock_init(newsk);
+ 	bh_lock_sock(newsk);
+ 	newsk->sk_backlog.head	= newsk->sk_backlog.tail = NULL;
+ 	newsk->sk_backlog.len = 0;
++>>>>>>> 938cca9e4109 (sock: fix /proc/net/sockstat underflow in sk_clone_lock())
  
 -	atomic_set(&newsk->sk_rmem_alloc, 0);
 -
 -	/* sk_wmem_alloc set to one (see sk_free() and sock_wfree()) */
 -	refcount_set(&newsk->sk_wmem_alloc, 1);
 +		atomic_set(&newsk->sk_rmem_alloc, 0);
 +		/*
 +		 * sk_wmem_alloc set to one (see sk_free() and sock_wfree())
 +		 */
 +		refcount_set(&newsk->sk_wmem_alloc, 1);
 +		atomic_set(&newsk->sk_omem_alloc, 0);
 +		sk_init_common(newsk);
 +
 +		newsk->sk_dst_cache	= NULL;
 +		newsk->sk_dst_pending_confirm = 0;
 +		newsk->sk_wmem_queued	= 0;
 +		newsk->sk_forward_alloc = 0;
 +		atomic_set(&newsk->sk_drops, 0);
 +		newsk->sk_send_head	= NULL;
 +		newsk->sk_userlocks	= sk->sk_userlocks & ~SOCK_BINDPORT_LOCK;
 +		atomic_set(&newsk->sk_zckey, 0);
 +
 +		sock_reset_flag(newsk, SOCK_DONE);
 +		mem_cgroup_sk_alloc(newsk);
 +		cgroup_sk_clone(&newsk->sk_cgrp_data);
  
 -	atomic_set(&newsk->sk_omem_alloc, 0);
 -	sk_init_common(newsk);
 +		rcu_read_lock();
 +		filter = rcu_dereference(sk->sk_filter);
 +		if (filter != NULL)
 +			/* though it's an empty new sock, the charging may fail
 +			 * if sysctl_optmem_max was changed between creation of
 +			 * original socket and cloning
 +			 */
 +			is_charged = sk_filter_charge(newsk, filter);
 +		RCU_INIT_POINTER(newsk->sk_filter, filter);
 +		rcu_read_unlock();
  
 -	newsk->sk_dst_cache	= NULL;
 -	newsk->sk_dst_pending_confirm = 0;
 -	newsk->sk_wmem_queued	= 0;
 -	newsk->sk_forward_alloc = 0;
 -	newsk->sk_reserved_mem  = 0;
 -	atomic_set(&newsk->sk_drops, 0);
 -	newsk->sk_send_head	= NULL;
 -	newsk->sk_userlocks	= sk->sk_userlocks & ~SOCK_BINDPORT_LOCK;
 -	atomic_set(&newsk->sk_zckey, 0);
 +		if (unlikely(!is_charged || xfrm_sk_clone_policy(newsk, sk))) {
 +			/* We need to make sure that we don't uncharge the new
 +			 * socket if we couldn't charge it in the first place
 +			 * as otherwise we uncharge the parent's filter.
 +			 */
 +			if (!is_charged)
 +				RCU_INIT_POINTER(newsk->sk_filter, NULL);
 +			sk_free_unlock_clone(newsk);
 +			newsk = NULL;
 +			goto out;
 +		}
 +		RCU_INIT_POINTER(newsk->sk_reuseport_cb, NULL);
  
 -	sock_reset_flag(newsk, SOCK_DONE);
 +		if (bpf_sk_storage_clone(sk, newsk)) {
 +			sk_free_unlock_clone(newsk);
 +			newsk = NULL;
 +			goto out;
 +		}
  
 -	/* sk->sk_memcg will be populated at accept() time */
 -	newsk->sk_memcg = NULL;
 +		/* Clear sk_user_data if parent had the pointer tagged
 +		 * as not suitable for copying when cloning.
 +		 */
 +		if (sk_user_data_is_nocopy(newsk))
 +			newsk->sk_user_data = NULL;
  
 -	cgroup_sk_clone(&newsk->sk_cgrp_data);
 +		newsk->sk_err	   = 0;
 +		newsk->sk_err_soft = 0;
 +		newsk->sk_priority = 0;
 +		newsk->sk_incoming_cpu = raw_smp_processor_id();
 +		atomic64_set(&newsk->sk_cookie, 0);
 +		if (likely(newsk->sk_net_refcnt))
 +			sock_inuse_add(sock_net(newsk), 1);
  
 -	rcu_read_lock();
 -	filter = rcu_dereference(sk->sk_filter);
 -	if (filter != NULL)
 -		/* though it's an empty new sock, the charging may fail
 -		 * if sysctl_optmem_max was changed between creation of
 -		 * original socket and cloning
 +		/*
 +		 * Before updating sk_refcnt, we must commit prior changes to memory
 +		 * (Documentation/RCU/rculist_nulls.rst for details)
  		 */
 -		is_charged = sk_filter_charge(newsk, filter);
 -	RCU_INIT_POINTER(newsk->sk_filter, filter);
 -	rcu_read_unlock();
 +		smp_wmb();
 +		refcount_set(&newsk->sk_refcnt, 2);
  
 -	if (unlikely(!is_charged || xfrm_sk_clone_policy(newsk, sk))) {
 -		/* We need to make sure that we don't uncharge the new
 -		 * socket if we couldn't charge it in the first place
 -		 * as otherwise we uncharge the parent's filter.
 +		/*
 +		 * Increment the counter in the same struct proto as the master
 +		 * sock (sk_refcnt_debug_inc uses newsk->sk_prot->socks, that
 +		 * is the same as sk->sk_prot->socks, as this field was copied
 +		 * with memcpy).
 +		 *
 +		 * This _changes_ the previous behaviour, where
 +		 * tcp_create_openreq_child always was incrementing the
 +		 * equivalent to tcp_prot->socks (inet_sock_nr), so this have
 +		 * to be taken into account in all callers. -acme
  		 */
 -		if (!is_charged)
 -			RCU_INIT_POINTER(newsk->sk_filter, NULL);
 -		sk_free_unlock_clone(newsk);
 -		newsk = NULL;
 -		goto out;
 +		sk_refcnt_debug_inc(newsk);
 +		sk_set_socket(newsk, NULL);
 +		sk_tx_queue_clear(newsk);
 +		RCU_INIT_POINTER(newsk->sk_wq, NULL);
 +
 +		if (newsk->sk_prot->sockets_allocated)
 +			sk_sockets_allocated_inc(newsk);
 +
 +		if (sock_needs_netstamp(sk) &&
 +		    newsk->sk_flags & SK_FLAGS_TIMESTAMP)
 +			net_enable_timestamp();
  	}
++<<<<<<< HEAD
++=======
+ 	RCU_INIT_POINTER(newsk->sk_reuseport_cb, NULL);
+ 
+ 	if (bpf_sk_storage_clone(sk, newsk)) {
+ 		sk_free_unlock_clone(newsk);
+ 		newsk = NULL;
+ 		goto out;
+ 	}
+ 
+ 	/* Clear sk_user_data if parent had the pointer tagged
+ 	 * as not suitable for copying when cloning.
+ 	 */
+ 	if (sk_user_data_is_nocopy(newsk))
+ 		newsk->sk_user_data = NULL;
+ 
+ 	newsk->sk_err	   = 0;
+ 	newsk->sk_err_soft = 0;
+ 	newsk->sk_priority = 0;
+ 	newsk->sk_incoming_cpu = raw_smp_processor_id();
+ 
+ 	/* Before updating sk_refcnt, we must commit prior changes to memory
+ 	 * (Documentation/RCU/rculist_nulls.rst for details)
+ 	 */
+ 	smp_wmb();
+ 	refcount_set(&newsk->sk_refcnt, 2);
+ 
+ 	/* Increment the counter in the same struct proto as the master
+ 	 * sock (sk_refcnt_debug_inc uses newsk->sk_prot->socks, that
+ 	 * is the same as sk->sk_prot->socks, as this field was copied
+ 	 * with memcpy).
+ 	 *
+ 	 * This _changes_ the previous behaviour, where
+ 	 * tcp_create_openreq_child always was incrementing the
+ 	 * equivalent to tcp_prot->socks (inet_sock_nr), so this have
+ 	 * to be taken into account in all callers. -acme
+ 	 */
+ 	sk_refcnt_debug_inc(newsk);
+ 	sk_set_socket(newsk, NULL);
+ 	sk_tx_queue_clear(newsk);
+ 	RCU_INIT_POINTER(newsk->sk_wq, NULL);
+ 
+ 	if (newsk->sk_prot->sockets_allocated)
+ 		sk_sockets_allocated_inc(newsk);
+ 
+ 	if (sock_needs_netstamp(sk) && newsk->sk_flags & SK_FLAGS_TIMESTAMP)
+ 		net_enable_timestamp();
++>>>>>>> 938cca9e4109 (sock: fix /proc/net/sockstat underflow in sk_clone_lock())
  out:
  	return newsk;
  }
* Unmerged path net/core/sock.c
