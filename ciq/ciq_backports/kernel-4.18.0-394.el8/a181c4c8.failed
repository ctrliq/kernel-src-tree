RDMA/rxe: Collect cleanup mca code in a subroutine

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Bob Pearson <rpearsonhpe@gmail.com>
commit a181c4c81a7104370c6144df5daf914780f8e89e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/a181c4c8.failed

Collect cleanup code for struct rxe_mca into a subroutine,
__rxe_cleanup_mca() called in rxe_detach_mcg() in rxe_mcast.c.

Link: https://lore.kernel.org/r/20220223230706.50332-4-rpearsonhpe@gmail.com
	Signed-off-by: Bob Pearson <rpearsonhpe@gmail.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit a181c4c81a7104370c6144df5daf914780f8e89e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/sw/rxe/rxe_mcast.c
diff --cc drivers/infiniband/sw/rxe/rxe_mcast.c
index 5f1c72c1473c,66c1ae703976..000000000000
--- a/drivers/infiniband/sw/rxe/rxe_mcast.c
+++ b/drivers/infiniband/sw/rxe/rxe_mcast.c
@@@ -126,38 -339,62 +126,94 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
 +int rxe_mcast_drop_grp_elem(struct rxe_dev *rxe, struct rxe_qp *qp,
 +			    union ib_gid *mgid)
 +{
 +	struct rxe_mc_grp *grp;
 +	struct rxe_mc_elem *elem, *tmp;
++=======
+ /**
+  * __rxe_cleanup_mca - cleanup mca object holding lock
+  * @mca: mca object
+  * @mcg: mcg object
+  *
+  * Context: caller must hold a reference to mcg and rxe->mcg_lock
+  */
+ static void __rxe_cleanup_mca(struct rxe_mca *mca, struct rxe_mcg *mcg)
+ {
+ 	list_del(&mca->qp_list);
+ 
+ 	atomic_dec(&mcg->qp_num);
+ 	atomic_dec(&mcg->rxe->mcg_attach);
+ 	atomic_dec(&mca->qp->mcg_num);
+ 	rxe_drop_ref(mca->qp);
+ 
+ 	kfree(mca);
+ }
+ 
+ static int rxe_detach_mcg(struct rxe_dev *rxe, struct rxe_qp *qp,
+ 				   union ib_gid *mgid)
+ {
+ 	struct rxe_mcg *mcg;
+ 	struct rxe_mca *mca, *tmp;
+ 	unsigned long flags;
 -
 -	mcg = rxe_lookup_mcg(rxe, mgid);
 -	if (!mcg)
 -		return -EINVAL;
 -
++>>>>>>> a181c4c81a71 (RDMA/rxe: Collect cleanup mca code in a subroutine)
 +
 +	grp = rxe_pool_get_key(&rxe->mc_grp_pool, mgid);
 +	if (!grp)
 +		goto err1;
 +
++<<<<<<< HEAD
 +	spin_lock_bh(&qp->grp_lock);
 +	spin_lock_bh(&grp->mcg_lock);
 +
 +	list_for_each_entry_safe(elem, tmp, &grp->qp_list, qp_list) {
 +		if (elem->qp == qp) {
 +			list_del(&elem->qp_list);
 +			list_del(&elem->grp_list);
 +			grp->num_qp--;
 +
 +			spin_unlock_bh(&grp->mcg_lock);
 +			spin_unlock_bh(&qp->grp_lock);
 +			rxe_drop_ref(elem);
 +			rxe_drop_ref(grp);	/* ref held by QP */
 +			rxe_drop_ref(grp);	/* ref from get_key */
++=======
+ 	spin_lock_irqsave(&rxe->mcg_lock, flags);
+ 	list_for_each_entry_safe(mca, tmp, &mcg->qp_list, qp_list) {
+ 		if (mca->qp == qp) {
+ 			__rxe_cleanup_mca(mca, mcg);
+ 
+ 			/* if the number of qp's attached to the
+ 			 * mcast group falls to zero go ahead and
+ 			 * tear it down. This will not free the
+ 			 * object since we are still holding a ref
+ 			 * from the get key above
+ 			 */
+ 			if (atomic_read(&mcg->qp_num) <= 0)
+ 				__rxe_destroy_mcg(mcg);
+ 
+ 			/* drop the ref from get key. This will free the
+ 			 * object if qp_num is zero.
+ 			 */
+ 			kref_put(&mcg->ref_cnt, rxe_cleanup_mcg);
+ 
+ 			spin_unlock_irqrestore(&rxe->mcg_lock, flags);
++>>>>>>> a181c4c81a71 (RDMA/rxe: Collect cleanup mca code in a subroutine)
  			return 0;
  		}
  	}
  
++<<<<<<< HEAD
 +	spin_unlock_bh(&grp->mcg_lock);
 +	spin_unlock_bh(&qp->grp_lock);
 +	rxe_drop_ref(grp);			/* ref from get_key */
 +err1:
++=======
+ 	/* we didn't find the qp on the list */
+ 	spin_unlock_irqrestore(&rxe->mcg_lock, flags);
++>>>>>>> a181c4c81a71 (RDMA/rxe: Collect cleanup mca code in a subroutine)
  	return -EINVAL;
  }
  
* Unmerged path drivers/infiniband/sw/rxe/rxe_mcast.c
