IB/hfi1: Remove atomic completion count

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-394.el8
commit-author Mike Marciniszyn <mike.marciniszyn@cornelisnetworks.com>
commit b4b90a50cbb97f327b9231bd61d6592296093309
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-394.el8/b4b90a50.failed

The atomic is not needed.

Fixes: d99dc602e2a5 ("IB/hfi1: Add functions to transmit datagram ipoib packets")
Link: https://lore.kernel.org/r/20210913132847.131370.54250.stgit@awfm-01.cornelisnetworks.com
	Reviewed-by: Dennis Dalessandro <dennis.dalessandro@cornelisnetworks.com>
	Signed-off-by: Mike Marciniszyn <mike.marciniszyn@cornelisnetworks.com>
	Signed-off-by: Dennis Dalessandro <dennis.dalessandro@cornelisnetworks.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit b4b90a50cbb97f327b9231bd61d6592296093309)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/hfi1/ipoib.h
#	drivers/infiniband/hw/hfi1/ipoib_tx.c
#	drivers/infiniband/hw/hfi1/trace_tx.h
diff --cc drivers/infiniband/hw/hfi1/ipoib.h
index 71b102d2f7b6,eb5c25199ad3..000000000000
--- a/drivers/infiniband/hw/hfi1/ipoib.h
+++ b/drivers/infiniband/hw/hfi1/ipoib.h
@@@ -54,10 -59,18 +54,23 @@@ union hfi1_ipoib_flow 
  struct ipoib_txreq;
  struct hfi1_ipoib_circ_buf {
  	void *items;
 +	u32 head;
 +	u32 tail;
  	u32 max_items;
  	u32 shift;
++<<<<<<< HEAD
++=======
+ 	/* consumer cache line */
+ 	u64 ____cacheline_aligned_in_smp sent_txreqs;
+ 	u32 avail;
+ 	u32 tail;
+ 	atomic_t stops;
+ 	atomic_t ring_full;
+ 	atomic_t no_desc;
+ 	/* producer cache line */
+ 	u64 ____cacheline_aligned_in_smp complete_txreqs;
+ 	u32 head;
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  };
  
  /**
diff --cc drivers/infiniband/hw/hfi1/ipoib_tx.c
index 27b2816b7c41,1a7a8372d8c8..000000000000
--- a/drivers/infiniband/hw/hfi1/ipoib_tx.c
+++ b/drivers/infiniband/hw/hfi1/ipoib_tx.c
@@@ -66,8 -66,8 +66,13 @@@ static u32 hfi1_ipoib_txreqs(const u64 
  
  static u64 hfi1_ipoib_used(struct hfi1_ipoib_txq *txq)
  {
++<<<<<<< HEAD
 +	return hfi1_ipoib_txreqs(txq->sent_txreqs,
 +				 atomic64_read(&txq->complete_txreqs));
++=======
+ 	return hfi1_ipoib_txreqs(txq->tx_ring.sent_txreqs,
+ 				 txq->tx_ring.complete_txreqs);
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  }
  
  static void hfi1_ipoib_stop_txq(struct hfi1_ipoib_txq *txq)
@@@ -166,8 -166,9 +171,14 @@@ static void hfi1_ipoib_drain_tx_ring(st
  	}
  	tx_ring->head = 0;
  	tx_ring->tail = 0;
++<<<<<<< HEAD
 +	atomic64_set(&txq->complete_txreqs, 0);
 +	txq->sent_txreqs = 0;
++=======
+ 	tx_ring->complete_txreqs = 0;
+ 	tx_ring->sent_txreqs = 0;
+ 	tx_ring->avail = hfi1_ipoib_ring_hwat(txq);
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  }
  
  static int hfi1_ipoib_poll_tx_ring(struct napi_struct *napi, int budget)
@@@ -190,7 -191,7 +201,11 @@@
  		head = CIRC_NEXT(head, max_tx);
  		tx =  hfi1_txreq_from_idx(tx_ring, head);
  	}
++<<<<<<< HEAD
 +	atomic64_add(work_done, &txq->complete_txreqs);
++=======
+ 	tx_ring->complete_txreqs += work_done;
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  
  	/* Finished freeing tx items so store the head value. */
  	smp_store_release(&tx_ring->head, head);
@@@ -720,10 -730,9 +735,16 @@@ int hfi1_ipoib_txreq_init(struct hfi1_i
  		txq->priv = priv;
  		txq->sde = NULL;
  		INIT_LIST_HEAD(&txq->tx_list);
++<<<<<<< HEAD
 +		atomic64_set(&txq->complete_txreqs, 0);
 +		atomic_set(&txq->stops, 0);
 +		atomic_set(&txq->ring_full, 0);
 +		atomic_set(&txq->no_desc, 0);
++=======
+ 		atomic_set(&txq->tx_ring.stops, 0);
+ 		atomic_set(&txq->tx_ring.ring_full, 0);
+ 		atomic_set(&txq->tx_ring.no_desc, 0);
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  		txq->q_idx = i;
  		txq->flow.tx_queue = 0xff;
  		txq->flow.sc5 = 0xff;
@@@ -765,7 -775,6 +786,10 @@@ static void hfi1_ipoib_drain_tx_list(st
  {
  	struct sdma_txreq *txreq;
  	struct sdma_txreq *txreq_tmp;
++<<<<<<< HEAD
 +	atomic64_t *complete_txreqs = &txq->complete_txreqs;
++=======
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  
  	list_for_each_entry_safe(txreq, txreq_tmp, &txq->tx_list, list) {
  		struct ipoib_txreq *tx =
@@@ -782,8 -791,8 +806,13 @@@
  		dd_dev_warn(txq->priv->dd,
  			    "txq %d not empty found %u requests\n",
  			    txq->q_idx,
++<<<<<<< HEAD
 +			    hfi1_ipoib_txreqs(txq->sent_txreqs,
 +					      atomic64_read(complete_txreqs)));
++=======
+ 			    hfi1_ipoib_txreqs(txq->tx_ring.sent_txreqs,
+ 					      txq->tx_ring.complete_txreqs));
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  }
  
  void hfi1_ipoib_txreq_deinit(struct hfi1_ipoib_dev_priv *priv)
@@@ -834,20 -843,20 +863,28 @@@ void hfi1_ipoib_tx_timeout(struct net_d
  {
  	struct hfi1_ipoib_dev_priv *priv = hfi1_ipoib_priv(dev);
  	struct hfi1_ipoib_txq *txq = &priv->txqs[q];
++<<<<<<< HEAD
 +	u64 completed = atomic64_read(&txq->complete_txreqs);
++=======
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  
 -	dd_dev_info(priv->dd, "timeout txq %llx q %u stopped %u stops %d no_desc %d ring_full %d\n",
 -		    (unsigned long long)txq, q,
 +	dd_dev_info(priv->dd, "timeout txq %p q %u stopped %u stops %d no_desc %d ring_full %d\n",
 +		    txq, q,
  		    __netif_subqueue_stopped(dev, txq->q_idx),
 -		    atomic_read(&txq->tx_ring.stops),
 -		    atomic_read(&txq->tx_ring.no_desc),
 -		    atomic_read(&txq->tx_ring.ring_full));
 -	dd_dev_info(priv->dd, "sde %llx engine %u\n",
 -		    (unsigned long long)txq->sde,
 +		    atomic_read(&txq->stops),
 +		    atomic_read(&txq->no_desc),
 +		    atomic_read(&txq->ring_full));
 +	dd_dev_info(priv->dd, "sde %p engine %u\n",
 +		    txq->sde,
  		    txq->sde ? txq->sde->this_idx : 0);
  	dd_dev_info(priv->dd, "flow %x\n", txq->flow.as_int);
  	dd_dev_info(priv->dd, "sent %llu completed %llu used %llu\n",
++<<<<<<< HEAD
 +		    txq->sent_txreqs, completed, hfi1_ipoib_used(txq));
++=======
+ 		    txq->tx_ring.sent_txreqs, txq->tx_ring.complete_txreqs,
+ 		    hfi1_ipoib_used(txq));
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  	dd_dev_info(priv->dd, "tx_queue_len %u max_items %u\n",
  		    dev->tx_queue_len, txq->tx_ring.max_items);
  	dd_dev_info(priv->dd, "head %u tail %u\n",
diff --cc drivers/infiniband/hw/hfi1/trace_tx.h
index e8b6069c9bfb,f00696f89652..000000000000
--- a/drivers/infiniband/hw/hfi1/trace_tx.h
+++ b/drivers/infiniband/hw/hfi1/trace_tx.h
@@@ -842,11 -917,11 +842,16 @@@ DECLARE_EVENT_CLASS(/* AIP  *
  		__entry->tail = txq->tx_ring.tail;
  		__entry->idx = txq->q_idx;
  		__entry->used =
++<<<<<<< HEAD
 +			txq->sent_txreqs -
 +			atomic64_read(&txq->complete_txreqs);
++=======
+ 			txq->tx_ring.sent_txreqs -
+ 			txq->tx_ring.complete_txreqs;
++>>>>>>> b4b90a50cbb9 (IB/hfi1: Remove atomic completion count)
  		__entry->flow = txq->flow.as_int;
 -		__entry->stops = atomic_read(&txq->tx_ring.stops);
 -		__entry->no_desc = atomic_read(&txq->tx_ring.no_desc);
 +		__entry->stops = atomic_read(&txq->stops);
 +		__entry->no_desc = atomic_read(&txq->no_desc);
  		__entry->stopped =
  		 __netif_subqueue_stopped(txq->priv->netdev, txq->q_idx);
  	),
* Unmerged path drivers/infiniband/hw/hfi1/ipoib.h
* Unmerged path drivers/infiniband/hw/hfi1/ipoib_tx.c
* Unmerged path drivers/infiniband/hw/hfi1/trace_tx.h
