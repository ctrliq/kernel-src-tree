watchdog: export lockup_detector_reconfigure

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-488.el8
commit-author Laurent Dufour <ldufour@linux.ibm.com>
commit 7c56a8733d0a2a4be2438a7512566e5ce552fccf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-488.el8/7c56a873.failed

In some circumstances it may be interesting to reconfigure the watchdog
from inside the kernel.

On PowerPC, this may helpful before and after a LPAR migration (LPM) is
initiated, because it implies some latencies, watchdog, and especially NMI
watchdog is expected to be triggered during this operation. Reconfiguring
the watchdog with a factor, would prevent it to happen too frequently
during LPM.

Rename lockup_detector_reconfigure() as __lockup_detector_reconfigure() and
create a new function lockup_detector_reconfigure() calling
__lockup_detector_reconfigure() under the protection of watchdog_mutex.

	Signed-off-by: Laurent Dufour <ldufour@linux.ibm.com>
[mpe: Squash in build fix from Laurent, reported by Sachin]
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/20220713154729.80789-3-ldufour@linux.ibm.com
(cherry picked from commit 7c56a8733d0a2a4be2438a7512566e5ce552fccf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/watchdog.c
diff --cc kernel/watchdog.c
index 8839d8ac2dd5,41596c415111..000000000000
--- a/kernel/watchdog.c
+++ b/kernel/watchdog.c
@@@ -489,71 -490,58 +489,71 @@@ static void watchdog_disable(unsigned i
  	 */
  	watchdog_nmi_disable(cpu);
  	hrtimer_cancel(hrtimer);
 -	wait_for_completion(this_cpu_ptr(&softlockup_completion));
  }
  
 -static int softlockup_stop_fn(void *data)
 +static void watchdog_cleanup(unsigned int cpu, bool online)
  {
 -	watchdog_disable(smp_processor_id());
 -	return 0;
 +	watchdog_disable(cpu);
  }
  
 -static void softlockup_stop_all(void)
 +static int watchdog_should_run(unsigned int cpu)
  {
 -	int cpu;
 -
 -	if (!softlockup_initialized)
 -		return;
 -
 -	for_each_cpu(cpu, &watchdog_allowed_mask)
 -		smp_call_on_cpu(cpu, softlockup_stop_fn, NULL, false);
 -
 -	cpumask_clear(&watchdog_allowed_mask);
 +	return __this_cpu_read(hrtimer_interrupts) !=
 +		__this_cpu_read(soft_lockup_hrtimer_cnt);
  }
  
 -static int softlockup_start_fn(void *data)
 -{
 -	watchdog_enable(smp_processor_id());
 -	return 0;
 -}
 +/*
 + * The watchdog thread function - touches the timestamp.
 + *
 + * It only runs once every sample_period seconds (4 seconds by
 + * default) to reset the softlockup timestamp. If this gets delayed
 + * for more than 2*watchdog_thresh seconds then the debug-printout
 + * triggers in watchdog_timer_fn().
 + */
 +static void watchdog(unsigned int cpu)
 +{
 +	__this_cpu_write(soft_lockup_hrtimer_cnt,
 +			 __this_cpu_read(hrtimer_interrupts));
 +	__touch_watchdog();
 +}
 +
 +static struct smp_hotplug_thread watchdog_threads = {
 +	.store			= &softlockup_watchdog,
 +	.thread_should_run	= watchdog_should_run,
 +	.thread_fn		= watchdog,
 +	.thread_comm		= "watchdog/%u",
 +	.setup			= watchdog_enable,
 +	.cleanup		= watchdog_cleanup,
 +	.park			= watchdog_disable,
 +	.unpark			= watchdog_enable,
 +};
  
 -static void softlockup_start_all(void)
 +static void softlockup_update_smpboot_threads(void)
  {
 -	int cpu;
 +	lockdep_assert_held(&watchdog_mutex);
  
 -	cpumask_copy(&watchdog_allowed_mask, &watchdog_cpumask);
 -	for_each_cpu(cpu, &watchdog_allowed_mask)
 -		smp_call_on_cpu(cpu, softlockup_start_fn, NULL, false);
 +	if (!softlockup_threads_initialized)
 +		return;
 +
 +	smpboot_update_cpumask_percpu_thread(&watchdog_threads,
 +					     &watchdog_allowed_mask);
  }
  
 -int lockup_detector_online_cpu(unsigned int cpu)
 +/* Temporarily park all watchdog threads */
 +static void softlockup_park_all_threads(void)
  {
 -	if (cpumask_test_cpu(cpu, &watchdog_allowed_mask))
 -		watchdog_enable(cpu);
 -	return 0;
 +	cpumask_clear(&watchdog_allowed_mask);
 +	softlockup_update_smpboot_threads();
  }
  
 -int lockup_detector_offline_cpu(unsigned int cpu)
 +/* Unpark enabled threads */
 +static void softlockup_unpark_threads(void)
  {
 -	if (cpumask_test_cpu(cpu, &watchdog_allowed_mask))
 -		watchdog_disable(cpu);
 -	return 0;
 +	cpumask_copy(&watchdog_allowed_mask, &watchdog_cpumask);
 +	softlockup_update_smpboot_threads();
  }
  
- static void lockup_detector_reconfigure(void)
+ static void __lockup_detector_reconfigure(void)
  {
  	cpus_read_lock();
  	watchdog_nmi_stop();
@@@ -571,12 -561,15 +571,19 @@@
  	__lockup_detector_cleanup();
  }
  
+ void lockup_detector_reconfigure(void)
+ {
+ 	mutex_lock(&watchdog_mutex);
+ 	__lockup_detector_reconfigure();
+ 	mutex_unlock(&watchdog_mutex);
+ }
+ 
  /*
 - * Create the watchdog infrastructure and configure the detector(s).
 + * Create the watchdog thread infrastructure and configure the detector(s).
 + *
 + * The threads are not unparked as watchdog_allowed_mask is empty.  When
 + * the threads are sucessfully initialized, take the proper locks and
 + * unpark the threads in the watchdog_cpumask if the watchdog is enabled.
   */
  static __init void lockup_detector_setup(void)
  {
@@@ -592,25 -583,14 +599,34 @@@
  	    !(watchdog_enabled && watchdog_thresh))
  		return;
  
 +	ret = smpboot_register_percpu_thread_cpumask(&watchdog_threads,
 +						     &watchdog_allowed_mask);
 +	if (ret) {
 +		pr_err("Failed to initialize soft lockup detector threads\n");
 +		return;
 +	}
 +
  	mutex_lock(&watchdog_mutex);
++<<<<<<< HEAD
 +	softlockup_threads_initialized = true;
 +	lockup_detector_reconfigure();
++=======
+ 	__lockup_detector_reconfigure();
+ 	softlockup_initialized = true;
++>>>>>>> 7c56a8733d0a (watchdog: export lockup_detector_reconfigure)
  	mutex_unlock(&watchdog_mutex);
  }
  
  #else /* CONFIG_SOFTLOCKUP_DETECTOR */
++<<<<<<< HEAD
 +static inline int watchdog_park_threads(void) { return 0; }
 +static inline void watchdog_unpark_threads(void) { }
 +static inline int watchdog_enable_all_cpus(void) { return 0; }
 +static inline void watchdog_disable_all_cpus(void) { }
 +static void lockup_detector_reconfigure(void)
++=======
+ static void __lockup_detector_reconfigure(void)
++>>>>>>> 7c56a8733d0a (watchdog: export lockup_detector_reconfigure)
  {
  	cpus_read_lock();
  	watchdog_nmi_stop();
diff --git a/include/linux/nmi.h b/include/linux/nmi.h
index 50d143995338..2bc6396d9292 100644
--- a/include/linux/nmi.h
+++ b/include/linux/nmi.h
@@ -116,6 +116,8 @@ int watchdog_nmi_probe(void);
 int watchdog_nmi_enable(unsigned int cpu);
 void watchdog_nmi_disable(unsigned int cpu);
 
+void lockup_detector_reconfigure(void);
+
 /**
  * touch_nmi_watchdog - restart NMI watchdog timeout.
  *
* Unmerged path kernel/watchdog.c
