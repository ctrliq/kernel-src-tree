iommu/amd: Add support for IOMMU default DMA mode build options

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Zhen Lei <thunder.leizhen@huawei.com>
commit 02252b3bfe9f98770a8d902925711676ff5bd766
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/02252b3b.failed

Make IOMMU_DEFAULT_LAZY default for when AMD_IOMMU config is set, which
matches current behaviour.

For "fullflush" param, just call iommu_set_dma_strict(true) directly.

Since we get a strict vs lazy mode print already in iommu_subsys_init(),
and maintain a deprecation print when "fullflush" param is passed, drop the
prints in amd_iommu_init_dma_ops().

Finally drop global flag amd_iommu_unmap_flush, as it has no longer has any
purpose.

[jpg: Rebase for relocated file and drop amd_iommu_unmap_flush]

	Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
	Signed-off-by: John Garry <john.garry@huawei.com>
Link: https://lore.kernel.org/r/1626088340-5838-6-git-send-email-john.garry@huawei.com
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 02252b3bfe9f98770a8d902925711676ff5bd766)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/Kconfig
#	drivers/iommu/amd/iommu.c
diff --cc drivers/iommu/Kconfig
index bead5de04ae1,c84da8205be7..000000000000
--- a/drivers/iommu/Kconfig
+++ b/drivers/iommu/Kconfig
@@@ -89,6 -90,47 +89,50 @@@ config IOMMU_DEFAULT_PASSTHROUG
  
  	  If unsure, say N here.
  
++<<<<<<< HEAD
++=======
+ choice
+ 	prompt "IOMMU default DMA IOTLB invalidation mode"
+ 	depends on IOMMU_DMA
+ 
+ 	default IOMMU_DEFAULT_LAZY if (AMD_IOMMU || INTEL_IOMMU)
+ 	default IOMMU_DEFAULT_STRICT
+ 	help
+ 	  This option allows an IOMMU DMA IOTLB invalidation mode to be
+ 	  chosen at build time, to override the default mode of each ARCH,
+ 	  removing the need to pass in kernel parameters through command line.
+ 	  It is still possible to provide common boot params to override this
+ 	  config.
+ 
+ 	  If unsure, keep the default.
+ 
+ config IOMMU_DEFAULT_STRICT
+ 	bool "strict"
+ 	help
+ 	  For every IOMMU DMA unmap operation, the flush operation of IOTLB and
+ 	  the free operation of IOVA are guaranteed to be done in the unmap
+ 	  function.
+ 
+ config IOMMU_DEFAULT_LAZY
+ 	bool "lazy"
+ 	help
+ 	  Support lazy mode, where for every IOMMU DMA unmap operation, the
+ 	  flush operation of IOTLB and the free operation of IOVA are deferred.
+ 	  They are only guaranteed to be done before the related IOVA will be
+ 	  reused.
+ 
+ 	  The isolation provided in this mode is not as secure as STRICT mode,
+ 	  such that a vulnerable time window may be created between the DMA
+ 	  unmap and the mappings cached in the IOMMU IOTLB or device TLB
+ 	  finally being invalidated, where the device could still access the
+ 	  memory which has already been unmapped by the device driver.
+ 	  However this mode may provide better performance in high throughput
+ 	  scenarios, and is still considerably more secure than passthrough
+ 	  mode or no IOMMU.
+ 
+ endchoice
+ 
++>>>>>>> 02252b3bfe9f (iommu/amd: Add support for IOMMU default DMA mode build options)
  config OF_IOMMU
  	def_bool y
  	depends on OF && IOMMU_API
diff --cc drivers/iommu/amd/iommu.c
index 61346e15af3a,52fe2326042a..000000000000
--- a/drivers/iommu/amd/iommu.c
+++ b/drivers/iommu/amd/iommu.c
@@@ -1836,11 -1774,7 +1836,15 @@@ void amd_iommu_domain_update(struct pro
  
  static void __init amd_iommu_init_dma_ops(void)
  {
++<<<<<<< HEAD
 +	if (amd_iommu_unmap_flush)
 +		pr_info("IO/TLB flush on unmap enabled\n");
 +	else
 +		pr_info("Lazy IO/TLB flushing enabled\n");
 +	iommu_set_dma_strict(amd_iommu_unmap_flush);
++=======
+ 	swiotlb = (iommu_default_passthrough() || sme_me_mask) ? 1 : 0;
++>>>>>>> 02252b3bfe9f (iommu/amd: Add support for IOMMU default DMA mode build options)
  }
  
  int __init amd_iommu_init_api(void)
* Unmerged path drivers/iommu/Kconfig
diff --git a/drivers/iommu/amd/amd_iommu_types.h b/drivers/iommu/amd/amd_iommu_types.h
index 44b2cc4c714c..2f93841dfe83 100644
--- a/drivers/iommu/amd/amd_iommu_types.h
+++ b/drivers/iommu/amd/amd_iommu_types.h
@@ -792,12 +792,6 @@ extern u16 amd_iommu_last_bdf;
 /* allocation bitmap for domain ids */
 extern unsigned long *amd_iommu_pd_alloc_bitmap;
 
-/*
- * If true, the addresses will be flushed on unmap time, not when
- * they are reused
- */
-extern bool amd_iommu_unmap_flush;
-
 /* Smallest max PASID supported by any IOMMU in the system */
 extern u32 amd_iommu_max_pasid;
 
diff --git a/drivers/iommu/amd/init.c b/drivers/iommu/amd/init.c
index 44780e91ab3c..4ea1da752bbd 100644
--- a/drivers/iommu/amd/init.c
+++ b/drivers/iommu/amd/init.c
@@ -173,7 +173,6 @@ u16 amd_iommu_last_bdf;			/* largest PCI device id we have
 					   to handle */
 LIST_HEAD(amd_iommu_unity_map);		/* a list of required unity mappings
 					   we find in ACPI */
-bool amd_iommu_unmap_flush;		/* if true, flush on every unmap */
 
 LIST_HEAD(amd_iommu_list);		/* list of all AMD IOMMUs in the
 					   system */
@@ -3145,7 +3144,7 @@ static int __init parse_amd_iommu_options(char *str)
 	for (; *str; ++str) {
 		if (strncmp(str, "fullflush", 9) == 0) {
 			pr_warn("amd_iommu=fullflush deprecated; use iommu.strict=1 instead\n");
-			amd_iommu_unmap_flush = true;
+			iommu_set_dma_strict(true);
 		}
 		if (strncmp(str, "force_enable", 12) == 0)
 			amd_iommu_force_enable = true;
* Unmerged path drivers/iommu/amd/iommu.c
