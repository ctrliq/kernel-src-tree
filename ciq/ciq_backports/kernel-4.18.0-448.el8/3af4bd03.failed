asm-generic/tlb: rename HAVE_MMU_GATHER_PAGE_SIZE

jira LE-1907
cve CVE-2022-39188
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit 3af4bd033759c4dab4f0ff594f0aa1e8d182b9d7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/3af4bd03.failed

Towards a more consistent naming scheme.

Link: http://lkml.kernel.org/r/20200116064531.483522-8-aneesh.kumar@linux.ibm.com
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 3af4bd033759c4dab4f0ff594f0aa1e8d182b9d7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/Kconfig
#	include/asm-generic/tlb.h
diff --cc arch/powerpc/Kconfig
index 068c558b1ac4,bf2b538aba12..000000000000
--- a/arch/powerpc/Kconfig
+++ b/arch/powerpc/Kconfig
@@@ -216,8 -222,8 +216,13 @@@ config PP
  	select HAVE_HARDLOCKUP_DETECTOR_PERF	if PERF_EVENTS && HAVE_PERF_EVENTS_NMI && !HAVE_HARDLOCKUP_DETECTOR_ARCH
  	select HAVE_PERF_REGS
  	select HAVE_PERF_USER_STACK_DUMP
++<<<<<<< HEAD
 +	select HAVE_RCU_TABLE_FREE
 +	select HAVE_MMU_GATHER_PAGE_SIZE
++=======
+ 	select MMU_GATHER_RCU_TABLE_FREE
+ 	select MMU_GATHER_PAGE_SIZE
++>>>>>>> 3af4bd033759 (asm-generic/tlb: rename HAVE_MMU_GATHER_PAGE_SIZE)
  	select HAVE_REGS_AND_STACK_ACCESS_API
  	select HAVE_RELIABLE_STACKTRACE		if PPC_BOOK3S_64 && CPU_LITTLE_ENDIAN
  	select HAVE_SYSCALL_TRACEPOINTS
diff --cc include/asm-generic/tlb.h
index 27ac8002fb01,53befa5acb27..000000000000
--- a/include/asm-generic/tlb.h
+++ b/include/asm-generic/tlb.h
@@@ -130,7 -126,10 +130,14 @@@
   *  This ensures we call tlb_flush() every time tlb_change_page_size() actually
   *  changes the size and provides mmu_gather::page_size to tlb_flush().
   *
++<<<<<<< HEAD
 + *  HAVE_RCU_TABLE_FREE
++=======
+  *  This might be useful if your architecture has size specific TLB
+  *  invalidation instructions.
+  *
+  *  MMU_GATHER_RCU_TABLE_FREE
++>>>>>>> 3af4bd033759 (asm-generic/tlb: rename HAVE_MMU_GATHER_PAGE_SIZE)
   *
   *  This provides tlb_remove_table(), to be used instead of tlb_remove_page()
   *  for page directores (__p*_free_tlb()). This provides separate freeing of
diff --git a/arch/Kconfig b/arch/Kconfig
index 1e486125c2eb..2f4adcad3abd 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -376,7 +376,7 @@ config HAVE_ARCH_JUMP_LABEL_RELATIVE
 config HAVE_RCU_TABLE_FREE
 	bool
 
-config HAVE_MMU_GATHER_PAGE_SIZE
+config MMU_GATHER_PAGE_SIZE
 	bool
 
 config MMU_GATHER_NO_RANGE
* Unmerged path arch/powerpc/Kconfig
* Unmerged path include/asm-generic/tlb.h
diff --git a/mm/mmu_gather.c b/mm/mmu_gather.c
index b84402038601..36ff5f9576e6 100644
--- a/mm/mmu_gather.c
+++ b/mm/mmu_gather.c
@@ -69,7 +69,7 @@ bool __tlb_remove_page_size(struct mmu_gather *tlb, struct page *page, int page_
 
 	VM_BUG_ON(!tlb->end);
 
-#ifdef CONFIG_HAVE_MMU_GATHER_PAGE_SIZE
+#ifdef CONFIG_MMU_GATHER_PAGE_SIZE
 	VM_WARN_ON(tlb->page_size != page_size);
 #endif
 
@@ -223,7 +223,7 @@ void tlb_gather_mmu(struct mmu_gather *tlb, struct mm_struct *mm,
 #ifdef CONFIG_HAVE_RCU_TABLE_FREE
 	tlb->batch = NULL;
 #endif
-#ifdef CONFIG_HAVE_MMU_GATHER_PAGE_SIZE
+#ifdef CONFIG_MMU_GATHER_PAGE_SIZE
 	tlb->page_size = 0;
 #endif
 
