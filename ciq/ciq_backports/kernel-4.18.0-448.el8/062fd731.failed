RDMA/mlx5: Remove size from struct mlx5_core_mkey

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Aharon Landau <aharonl@nvidia.com>
commit 062fd731e51ee29ba745b2fd1c7ac87dd460d4ca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/062fd731.failed

mkey->size is already stored in ibmr->length, no need to store it here.

	Signed-off-by: Aharon Landau <aharonl@nvidia.com>
	Reviewed-by: Shay Drory <shayd@nvidia.com>
	Acked-by: Michael S. Tsirkin <mst@redhat.com>
	Signed-off-by: Leon Romanovsky <leonro@nvidia.com>
(cherry picked from commit 062fd731e51ee29ba745b2fd1c7ac87dd460d4ca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/devx.c
#	drivers/infiniband/hw/mlx5/mr.c
#	drivers/net/ethernet/mellanox/mlx5/core/mr.c
#	drivers/vdpa/mlx5/core/resources.c
#	include/linux/mlx5/driver.h
diff --cc drivers/infiniband/hw/mlx5/devx.c
index abfde896b9aa,8f6e1350cd37..000000000000
--- a/drivers/infiniband/hw/mlx5/devx.c
+++ b/drivers/infiniband/hw/mlx5/devx.c
@@@ -1303,8 -1303,6 +1303,11 @@@ static int devx_handle_mkey_indirect(st
  	mkey->key = mlx5_idx_to_mkey(
  			MLX5_GET(create_mkey_out, out, mkey_index)) | key;
  	mkey->type = MLX5_MKEY_INDIRECT_DEVX;
++<<<<<<< HEAD
 +	mkey->iova = MLX5_GET64(mkc, mkc, start_addr);
 +	mkey->size = MLX5_GET64(mkc, mkc, len);
++=======
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	mkey->pd = MLX5_GET(mkc, mkc, pd);
  	devx_mr->ndescs = MLX5_GET(mkc, mkc, translations_octword_size);
  	init_waitqueue_head(&mkey->wait);
diff --cc drivers/infiniband/hw/mlx5/mr.c
index 4263bf96852f,1b1367c87a6b..000000000000
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@@ -971,10 -975,9 +971,13 @@@ static struct mlx5_ib_mr *alloc_mr_from
  
  	mr->ibmr.pd = pd;
  	mr->umem = umem;
++<<<<<<< HEAD
 +	mr->mmkey.iova = iova;
 +	mr->mmkey.size = umem->length;
++=======
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	mr->mmkey.pd = to_mpd(pd)->pdn;
  	mr->page_shift = order_base_2(page_size);
 -	set_mr_fields(dev, mr, umem->length, access_flags, iova);
  
  	return mr;
  }
@@@ -1083,8 -1086,8 +1086,13 @@@ static void *mlx5_ib_create_xlt_wr(stru
  	wr->wr.opcode = MLX5_IB_WR_UMR;
  	wr->pd = mr->ibmr.pd;
  	wr->mkey = mr->mmkey.key;
++<<<<<<< HEAD
 +	wr->length = mr->mmkey.size;
 +	wr->virt_addr = mr->mmkey.iova;
++=======
+ 	wr->length = mr->ibmr.length;
+ 	wr->virt_addr = mr->ibmr.iova;
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	wr->access_flags = mr->access_flags;
  	wr->page_shift = mr->page_shift;
  	wr->xlt_size = sg->length;
@@@ -1588,27 -1670,116 +1596,103 @@@ static int revoke_mr(struct mlx5_ib_mr 
  	return mlx5_ib_post_send_wait(mr_to_mdev(mr), &umrwr);
  }
  
 -/*
 - * True if the change in access flags can be done via UMR, only some access
 - * flags can be updated.
 - */
 -static bool can_use_umr_rereg_access(struct mlx5_ib_dev *dev,
 -				     unsigned int current_access_flags,
 -				     unsigned int target_access_flags)
 +static int rereg_umr(struct ib_pd *pd, struct mlx5_ib_mr *mr,
 +		     int access_flags, int flags)
  {
 -	unsigned int diffs = current_access_flags ^ target_access_flags;
 +	struct mlx5_ib_dev *dev = to_mdev(pd->device);
 +	struct mlx5_umr_wr umrwr = {};
 +	int err;
  
 -	if (diffs & ~(IB_ACCESS_LOCAL_WRITE | IB_ACCESS_REMOTE_WRITE |
 -		      IB_ACCESS_REMOTE_READ | IB_ACCESS_RELAXED_ORDERING))
 -		return false;
 -	return mlx5_ib_can_reconfig_with_umr(dev, current_access_flags,
 -					     target_access_flags);
 -}
 +	umrwr.wr.send_flags = MLX5_IB_SEND_UMR_FAIL_IF_FREE;
  
 -static int umr_rereg_pd_access(struct mlx5_ib_mr *mr, struct ib_pd *pd,
 -			       int access_flags)
 -{
 -	struct mlx5_ib_dev *dev = to_mdev(mr->ibmr.device);
 -	struct mlx5_umr_wr umrwr = {
 -		.wr = {
 -			.send_flags = MLX5_IB_SEND_UMR_FAIL_IF_FREE |
 -				      MLX5_IB_SEND_UMR_UPDATE_PD_ACCESS,
 -			.opcode = MLX5_IB_WR_UMR,
 -		},
 -		.mkey = mr->mmkey.key,
 -		.pd = pd,
 -		.access_flags = access_flags,
 -	};
 -	int err;
 +	umrwr.wr.opcode = MLX5_IB_WR_UMR;
 +	umrwr.mkey = mr->mmkey.key;
 +
 +	if (flags & IB_MR_REREG_PD || flags & IB_MR_REREG_ACCESS) {
 +		umrwr.pd = pd;
 +		umrwr.access_flags = access_flags;
 +		umrwr.wr.send_flags |= MLX5_IB_SEND_UMR_UPDATE_PD_ACCESS;
 +	}
  
  	err = mlx5_ib_post_send_wait(dev, &umrwr);
 -	if (err)
 -		return err;
  
++<<<<<<< HEAD
 +	return err;
++=======
+ 	mr->access_flags = access_flags;
+ 	mr->mmkey.pd = to_mpd(pd)->pdn;
+ 	return 0;
+ }
+ 
+ static bool can_use_umr_rereg_pas(struct mlx5_ib_mr *mr,
+ 				  struct ib_umem *new_umem,
+ 				  int new_access_flags, u64 iova,
+ 				  unsigned long *page_size)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(mr->ibmr.device);
+ 
+ 	/* We only track the allocated sizes of MRs from the cache */
+ 	if (!mr->cache_ent)
+ 		return false;
+ 	if (!mlx5_ib_can_load_pas_with_umr(dev, new_umem->length))
+ 		return false;
+ 
+ 	*page_size =
+ 		mlx5_umem_find_best_pgsz(new_umem, mkc, log_page_size, 0, iova);
+ 	if (WARN_ON(!*page_size))
+ 		return false;
+ 	return (1ULL << mr->cache_ent->order) >=
+ 	       ib_umem_num_dma_blocks(new_umem, *page_size);
+ }
+ 
+ static int umr_rereg_pas(struct mlx5_ib_mr *mr, struct ib_pd *pd,
+ 			 int access_flags, int flags, struct ib_umem *new_umem,
+ 			 u64 iova, unsigned long page_size)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(mr->ibmr.device);
+ 	int upd_flags = MLX5_IB_UPD_XLT_ADDR | MLX5_IB_UPD_XLT_ENABLE;
+ 	struct ib_umem *old_umem = mr->umem;
+ 	int err;
+ 
+ 	/*
+ 	 * To keep everything simple the MR is revoked before we start to mess
+ 	 * with it. This ensure the change is atomic relative to any use of the
+ 	 * MR.
+ 	 */
+ 	err = revoke_mr(mr);
+ 	if (err)
+ 		return err;
+ 
+ 	if (flags & IB_MR_REREG_PD) {
+ 		mr->ibmr.pd = pd;
+ 		mr->mmkey.pd = to_mpd(pd)->pdn;
+ 		upd_flags |= MLX5_IB_UPD_XLT_PD;
+ 	}
+ 	if (flags & IB_MR_REREG_ACCESS) {
+ 		mr->access_flags = access_flags;
+ 		upd_flags |= MLX5_IB_UPD_XLT_ACCESS;
+ 	}
+ 
+ 	mr->ibmr.length = new_umem->length;
+ 	mr->ibmr.iova = iova;
+ 	mr->ibmr.length = new_umem->length;
+ 	mr->page_shift = order_base_2(page_size);
+ 	mr->umem = new_umem;
+ 	err = mlx5_ib_update_mr_pas(mr, upd_flags);
+ 	if (err) {
+ 		/*
+ 		 * The MR is revoked at this point so there is no issue to free
+ 		 * new_umem.
+ 		 */
+ 		mr->umem = old_umem;
+ 		return err;
+ 	}
+ 
+ 	atomic_sub(ib_umem_num_pages(old_umem), &dev->mdev->priv.reg_pages);
+ 	ib_umem_release(old_umem);
+ 	atomic_add(ib_umem_num_pages(new_umem), &dev->mdev->priv.reg_pages);
+ 	return 0;
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  }
  
  struct ib_mr *mlx5_ib_rereg_user_mr(struct ib_mr *ib_mr, int flags, u64 start,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/mr.c
index 174f71ed5280,b5dd44944265..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/mr.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mr.c
@@@ -52,8 -52,6 +52,11 @@@ int mlx5_core_create_mkey(struct mlx5_c
  
  	mkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
  	mkey_index = MLX5_GET(create_mkey_out, lout, mkey_index);
++<<<<<<< HEAD
 +	mkey->iova = MLX5_GET64(mkc, mkc, start_addr);
 +	mkey->size = MLX5_GET64(mkc, mkc, len);
++=======
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	mkey->key = (u32)mlx5_mkey_variant(mkey->key) | mlx5_idx_to_mkey(mkey_index);
  	mkey->pd = MLX5_GET(mkc, mkc, pd);
  	init_waitqueue_head(&mkey->wait);
diff --cc drivers/vdpa/mlx5/core/resources.c
index 15e266d0e27a,d3d8b8b4e377..000000000000
--- a/drivers/vdpa/mlx5/core/resources.c
+++ b/drivers/vdpa/mlx5/core/resources.c
@@@ -215,8 -215,6 +215,11 @@@ int mlx5_vdpa_create_mkey(struct mlx5_v
  
  	mkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
  	mkey_index = MLX5_GET(create_mkey_out, lout, mkey_index);
++<<<<<<< HEAD
 +	mkey->iova = MLX5_GET64(mkc, mkc, start_addr);
 +	mkey->size = MLX5_GET64(mkc, mkc, len);
++=======
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	mkey->key |= mlx5_idx_to_mkey(mkey_index);
  	mkey->pd = MLX5_GET(mkc, mkc, pd);
  	return 0;
diff --cc include/linux/mlx5/driver.h
index 010ada427bed,ff1e991314e2..000000000000
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@@ -363,8 -364,6 +363,11 @@@ enum 
  };
  
  struct mlx5_core_mkey {
++<<<<<<< HEAD
 +	u64			iova;
 +	u64			size;
++=======
++>>>>>>> 062fd731e51e (RDMA/mlx5: Remove size from struct mlx5_core_mkey)
  	u32			key;
  	u32			pd;
  	u32			type;
* Unmerged path drivers/infiniband/hw/mlx5/devx.c
* Unmerged path drivers/infiniband/hw/mlx5/mr.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/mr.c
* Unmerged path drivers/vdpa/mlx5/core/resources.c
* Unmerged path include/linux/mlx5/driver.h
