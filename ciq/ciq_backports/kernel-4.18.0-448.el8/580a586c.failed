asm-generic/tlb: rename HAVE_MMU_GATHER_NO_GATHER

jira LE-1907
cve CVE-2022-39188
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit 580a586c409ab3040b7284a19cd9e281692c40c7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/580a586c.failed

Towards a more consistent naming scheme.

Link: http://lkml.kernel.org/r/20200116064531.483522-9-aneesh.kumar@linux.ibm.com
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 580a586c409ab3040b7284a19cd9e281692c40c7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/mmu_gather.c
diff --cc mm/mmu_gather.c
index b84402038601,a28c74328085..000000000000
--- a/mm/mmu_gather.c
+++ b/mm/mmu_gather.c
@@@ -89,9 -89,9 +89,9 @@@ bool __tlb_remove_page_size(struct mmu_
  	return false;
  }
  
- #endif /* HAVE_MMU_GATHER_NO_GATHER */
+ #endif /* MMU_GATHER_NO_GATHER */
  
 -#ifdef CONFIG_MMU_GATHER_RCU_TABLE_FREE
 +#ifdef CONFIG_HAVE_RCU_TABLE_FREE
  
  /*
   * See the comment near struct mmu_table_batch.
@@@ -177,10 -177,10 +177,10 @@@ void tlb_remove_table(struct mmu_gathe
  
  static void tlb_flush_mmu_free(struct mmu_gather *tlb)
  {
 -#ifdef CONFIG_MMU_GATHER_RCU_TABLE_FREE
 +#ifdef CONFIG_HAVE_RCU_TABLE_FREE
  	tlb_table_flush(tlb);
  #endif
- #ifndef CONFIG_HAVE_MMU_GATHER_NO_GATHER
+ #ifndef CONFIG_MMU_GATHER_NO_GATHER
  	tlb_batch_pages_flush(tlb);
  #endif
  }
@@@ -271,9 -271,7 +271,13 @@@ void tlb_finish_mmu(struct mmu_gather *
  
  	tlb_flush_mmu(tlb);
  
++<<<<<<< HEAD
 +	/* keep the page table cache within bounds */
 +	check_pgt_cache();
 +#ifndef CONFIG_HAVE_MMU_GATHER_NO_GATHER
++=======
+ #ifndef CONFIG_MMU_GATHER_NO_GATHER
++>>>>>>> 580a586c409a (asm-generic/tlb: rename HAVE_MMU_GATHER_NO_GATHER)
  	tlb_batch_list_free(tlb);
  #endif
  	dec_tlb_flush_pending(tlb->mm);
diff --git a/arch/Kconfig b/arch/Kconfig
index 1e486125c2eb..f328c01d43b5 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -382,7 +382,7 @@ config HAVE_MMU_GATHER_PAGE_SIZE
 config MMU_GATHER_NO_RANGE
 	bool
 
-config HAVE_MMU_GATHER_NO_GATHER
+config MMU_GATHER_NO_GATHER
 	bool
 
 config ARCH_WANT_IRQS_OFF_ACTIVATE_MM
diff --git a/arch/s390/Kconfig b/arch/s390/Kconfig
index 53b3712d90ef..939f2f2ff865 100644
--- a/arch/s390/Kconfig
+++ b/arch/s390/Kconfig
@@ -159,7 +159,7 @@ config S390
 	select HAVE_PERF_REGS
 	select HAVE_PERF_USER_STACK_DUMP
 	select HAVE_MEMBLOCK_PHYS_MAP
-	select HAVE_MMU_GATHER_NO_GATHER
+	select MMU_GATHER_NO_GATHER
 	select HAVE_MOD_ARCH_SPECIFIC
 	select HAVE_OPROFILE
 	select HAVE_PERF_EVENTS
diff --git a/include/asm-generic/tlb.h b/include/asm-generic/tlb.h
index 27ac8002fb01..c3854e759553 100644
--- a/include/asm-generic/tlb.h
+++ b/include/asm-generic/tlb.h
@@ -150,6 +150,16 @@
  *  MMU_GATHER_NO_RANGE
  *
  *  Use this if your architecture lacks an efficient flush_tlb_range().
+ *
+ *  MMU_GATHER_NO_GATHER
+ *
+ *  If the option is set the mmu_gather will not track individual pages for
+ *  delayed page free anymore. A platform that enables the option needs to
+ *  provide its own implementation of the __tlb_remove_page_size() function to
+ *  free pages.
+ *
+ *  This is useful if your architecture already flushes TLB entries in the
+ *  various ptep_get_and_clear() functions.
  */
 
 #ifdef CONFIG_HAVE_RCU_TABLE_FREE
@@ -209,7 +219,7 @@ extern void tlb_remove_table(struct mmu_gather *tlb, void *table);
 #endif /* CONFIG_HAVE_RCU_TABLE_FREE */
 
 
-#ifndef CONFIG_HAVE_MMU_GATHER_NO_GATHER
+#ifndef CONFIG_MMU_GATHER_NO_GATHER
 /*
  * If we can't allocate a page to make a big batch of page pointers
  * to work on, then just handle a few from the on-stack structure.
@@ -284,7 +294,7 @@ struct mmu_gather {
 
 	unsigned int		batch_count;
 
-#ifndef CONFIG_HAVE_MMU_GATHER_NO_GATHER
+#ifndef CONFIG_MMU_GATHER_NO_GATHER
 	struct mmu_gather_batch *active;
 	struct mmu_gather_batch	local;
 	struct page		*__pages[MMU_GATHER_BUNDLE];
* Unmerged path mm/mmu_gather.c
