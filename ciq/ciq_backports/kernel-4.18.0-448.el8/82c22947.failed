blk-mq: avoid double ->queue_rq() because of early timeout

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author David Jeffery <djeffery@redhat.com>
commit 82c229476b8f6afd7e09bc4dc77d89dc19ff7688
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/82c22947.failed

David Jeffery found one double ->queue_rq() issue, so far it can
be triggered in VM use case because of long vmexit latency or preempt
latency of vCPU pthread or long page fault in vCPU pthread, then block
IO req could be timed out before queuing the request to hardware but after
calling blk_mq_start_request() during ->queue_rq(), then timeout handler
may handle it by requeue, then double ->queue_rq() is caused, and kernel
panic.

So far, it is driver's responsibility to cover the race between timeout
and completion, so it seems supposed to be solved in driver in theory,
given driver has enough knowledge.

But it is really one common problem, lots of driver could have similar
issue, and could be hard to fix all affected drivers, even it isn't easy
for driver to handle the race. So David suggests this patch by draining
in-progress ->queue_rq() for solving this issue.

	Cc: Stefan Hajnoczi <stefanha@redhat.com>
	Cc: Keith Busch <kbusch@kernel.org>
	Cc: virtualization@lists.linux-foundation.org
	Cc: Bart Van Assche <bvanassche@acm.org>
	Signed-off-by: David Jeffery <djeffery@redhat.com>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Bart Van Assche <bvanassche@acm.org>
Link: https://lore.kernel.org/r/20221026051957.358818-1-ming.lei@redhat.com
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 82c229476b8f6afd7e09bc4dc77d89dc19ff7688)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 920f9792a321,060c8cca4b24..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -955,46 -1551,38 +961,62 @@@ static bool blk_mq_req_expired(struct r
  
  void blk_mq_put_rq_ref(struct request *rq)
  {
 -	if (is_flush_rq(rq)) {
 -		if (rq->end_io(rq, 0) == RQ_END_IO_FREE)
 -			blk_mq_free_request(rq);
 -	} else if (req_ref_put_and_test(rq)) {
 +	if (is_flush_rq(rq))
 +		rq->end_io(rq, 0);
 +	else if (refcount_dec_and_test(&rq->ref))
  		__blk_mq_free_request(rq);
 -	}
  }
  
 -static bool blk_mq_check_expired(struct request *rq, void *priv)
 +static bool blk_mq_check_expired(struct blk_mq_hw_ctx *hctx,
 +		struct request *rq, void *priv, bool reserved)
  {
- 	unsigned long *next = priv;
+ 	struct blk_expired_data *expired = priv;
  
  	/*
 -	 * blk_mq_queue_tag_busy_iter() has locked the request, so it cannot
 -	 * be reallocated underneath the timeout handler's processing, then
 -	 * the expire check is reliable. If the request is not expired, then
 -	 * it was completed and reallocated as a new request after returning
 -	 * from blk_mq_check_expired().
 +	 * Just do a quick check if it is expired before locking the request in
 +	 * so we're not unnecessarilly synchronizing across CPUs.
 +	 */
 +	if (!blk_mq_req_expired(rq, next))
 +		return true;
 +
 +	/*
 +	 * We have reason to believe the request may be expired. Take a
 +	 * reference on the request to lock this request lifetime into its
 +	 * currently allocated context to prevent it from being reallocated in
 +	 * the event the completion by-passes this timeout handler.
 +	 *
 +	 * If the reference was already released, then the driver beat the
 +	 * timeout handler to posting a natural completion.
 +	 */
 +	if (!refcount_inc_not_zero(&rq->ref))
 +		return true;
 +
 +	/*
 +	 * The request is now locked and cannot be reallocated underneath the
 +	 * timeout handler's processing. Re-verify this exact request is truly
 +	 * expired; if it is not expired, then the request was completed and
 +	 * reallocated as a new request.
  	 */
++<<<<<<< HEAD
 +	if (blk_mq_req_expired(rq, next))
 +		blk_mq_rq_timed_out(rq, reserved);
 +
 +	blk_mq_put_rq_ref(rq);
++=======
+ 	if (blk_mq_req_expired(rq, expired)) {
+ 		expired->has_timedout_rq = true;
+ 		return false;
+ 	}
+ 	return true;
+ }
+ 
+ static bool blk_mq_handle_expired(struct request *rq, void *priv)
+ {
+ 	struct blk_expired_data *expired = priv;
+ 
+ 	if (blk_mq_req_expired(rq, expired))
+ 		blk_mq_rq_timed_out(rq);
++>>>>>>> 82c229476b8f (blk-mq: avoid double ->queue_rq() because of early timeout)
  	return true;
  }
  
@@@ -1002,9 -1590,11 +1024,11 @@@ static void blk_mq_timeout_work(struct 
  {
  	struct request_queue *q =
  		container_of(work, struct request_queue, timeout_work);
- 	unsigned long next = 0;
+ 	struct blk_expired_data expired = {
+ 		.timeout_start = jiffies,
+ 	};
  	struct blk_mq_hw_ctx *hctx;
 -	unsigned long i;
 +	int i;
  
  	/* A deadlock might occur if a request is stuck requiring a
  	 * timeout at the same time a queue freeze is waiting
* Unmerged path block/blk-mq.c
