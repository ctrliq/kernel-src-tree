swiotlb: consolidate rounding up default_nslabs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Chao Gao <chao.gao@intel.com>
commit 44335487bab05e06902f9184179857aae764bfe6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/44335487.failed

default_nslabs are rounded up in two cases with exactly same comments.
Add a simple wrapper to reduce duplicate code/comments. It is preparatory
to adding more logics into the round-up.

No functional change intended.

	Signed-off-by: Chao Gao <chao.gao@intel.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 44335487bab05e06902f9184179857aae764bfe6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/dma/swiotlb.c
diff --cc kernel/dma/swiotlb.c
index 623d86fa3853,604f2469ac0e..000000000000
--- a/kernel/dma/swiotlb.c
+++ b/kernel/dma/swiotlb.c
@@@ -73,6 -70,50 +73,53 @@@ struct io_tlb_mem io_tlb_default_mem
  phys_addr_t swiotlb_unencrypted_base;
  
  static unsigned long default_nslabs = IO_TLB_DEFAULT_SIZE >> IO_TLB_SHIFT;
++<<<<<<< HEAD
++=======
+ static unsigned long default_nareas;
+ 
+ /**
+  * struct io_tlb_area - IO TLB memory area descriptor
+  *
+  * This is a single area with a single lock.
+  *
+  * @used:	The number of used IO TLB block.
+  * @index:	The slot index to start searching in this area for next round.
+  * @lock:	The lock to protect the above data structures in the map and
+  *		unmap calls.
+  */
+ struct io_tlb_area {
+ 	unsigned long used;
+ 	unsigned int index;
+ 	spinlock_t lock;
+ };
+ 
+ /*
+  * Round up number of slabs to the next power of 2. The last area is going
+  * be smaller than the rest if default_nslabs is not power of two.
+  *
+  * Return true if default_nslabs is rounded up.
+  */
+ static bool round_up_default_nslabs(void)
+ {
+ 	if (!default_nareas || is_power_of_2(default_nslabs))
+ 		return false;
+ 	default_nslabs = roundup_pow_of_two(default_nslabs);
+ 	return true;
+ }
+ 
+ static void swiotlb_adjust_nareas(unsigned int nareas)
+ {
+ 	if (!is_power_of_2(nareas))
+ 		nareas = roundup_pow_of_two(nareas);
+ 
+ 	default_nareas = nareas;
+ 
+ 	pr_info("area num %d.\n", nareas);
+ 	if (round_up_default_nslabs())
+ 		pr_info("SWIOTLB bounce buffer size roundup to %luMB",
+ 			(default_nslabs << IO_TLB_SHIFT) >> 20);
+ }
++>>>>>>> 44335487bab0 (swiotlb: consolidate rounding up default_nslabs)
  
  static int __init
  setup_io_tlb_npages(char *str)
@@@ -115,8 -160,11 +162,16 @@@ void __init swiotlb_adjust_size(unsigne
  	 */
  	if (default_nslabs != IO_TLB_DEFAULT_SIZE >> IO_TLB_SHIFT)
  		return;
++<<<<<<< HEAD
++	size = ALIGN(size, IO_TLB_SIZE);
++	default_nslabs = ALIGN(size >> IO_TLB_SHIFT, IO_TLB_SEGSIZE);
++=======
+ 
  	size = ALIGN(size, IO_TLB_SIZE);
  	default_nslabs = ALIGN(size >> IO_TLB_SHIFT, IO_TLB_SEGSIZE);
+ 	if (round_up_default_nslabs())
+ 		size = default_nslabs << IO_TLB_SHIFT;
++>>>>>>> 44335487bab0 (swiotlb: consolidate rounding up default_nslabs)
  	pr_info("SWIOTLB bounce buffer size adjusted to %luMB", size >> 20);
  }
  
* Unmerged path kernel/dma/swiotlb.c
