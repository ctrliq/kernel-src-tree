ice: remove VLAN representor specific ops

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Michal Swiatkowski <michal.swiatkowski@linux.intel.com>
commit b33de560f9e97a485ebc62dac9e0c0825cfdc731
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/b33de560.failed

In switchdev mode VF VLAN caps will not be set there is no need
to have specific VLAN ops for representor that only returns not
supported error.

As VLAN configuration commands will be blocked, the VF driver
can't disable VLAN stripping at initialization. It leads to the
situation when VLAN stripping on VF VSI is on, but in kernel it
is off. To prevent this, disable VLAN stripping in VSI
initialization. It doesn't break other usecases, because it is set
according to kernel settings.

	Signed-off-by: Michal Swiatkowski <michal.swiatkowski@linux.intel.com>
	Tested-by: Sandeep Penigalapati <sandeep.penigalapati@intel.com>
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit b33de560f9e97a485ebc62dac9e0c0825cfdc731)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_lib.c
#	drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
diff --cc drivers/net/ethernet/intel/ice/ice_lib.c
index 9a907af67521,5a1e8b9b365d..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_lib.c
@@@ -853,13 -867,30 +853,31 @@@ static void ice_set_dflt_vsi_ctx(struc
  	ctxt->info.sw_flags = ICE_AQ_VSI_SW_FLAG_SRC_PRUNE;
  	/* Traffic from VSI can be sent to LAN */
  	ctxt->info.sw_flags2 = ICE_AQ_VSI_SW_FLAG_LAN_ENA;
 -	/* allow all untagged/tagged packets by default on Tx */
 -	ctxt->info.inner_vlan_flags = ((ICE_AQ_VSI_INNER_VLAN_TX_MODE_ALL &
 -				  ICE_AQ_VSI_INNER_VLAN_TX_MODE_M) >>
 -				 ICE_AQ_VSI_INNER_VLAN_TX_MODE_S);
 -	/* SVM - by default bits 3 and 4 in inner_vlan_flags are 0's which
 -	 * results in legacy behavior (show VLAN, DEI, and UP) in descriptor.
 -	 *
 -	 * DVM - leave inner VLAN in packet by default
 +	/* By default bits 3 and 4 in vlan_flags are 0's which results in legacy
 +	 * behavior (show VLAN, DEI, and UP) in descriptor. Also, allow all
 +	 * packets untagged/tagged.
  	 */
++<<<<<<< HEAD
 +	ctxt->info.vlan_flags = ((ICE_AQ_VSI_VLAN_MODE_ALL &
 +				  ICE_AQ_VSI_VLAN_MODE_M) >>
 +				 ICE_AQ_VSI_VLAN_MODE_S);
++=======
+ 	if (ice_is_dvm_ena(hw)) {
+ 		ctxt->info.inner_vlan_flags |=
+ 			ICE_AQ_VSI_INNER_VLAN_EMODE_NOTHING;
+ 		ctxt->info.outer_vlan_flags =
+ 			(ICE_AQ_VSI_OUTER_VLAN_TX_MODE_ALL <<
+ 			 ICE_AQ_VSI_OUTER_VLAN_TX_MODE_S) &
+ 			ICE_AQ_VSI_OUTER_VLAN_TX_MODE_M;
+ 		ctxt->info.outer_vlan_flags |=
+ 			(ICE_AQ_VSI_OUTER_TAG_VLAN_8100 <<
+ 			 ICE_AQ_VSI_OUTER_TAG_TYPE_S) &
+ 			ICE_AQ_VSI_OUTER_TAG_TYPE_M;
+ 		ctxt->info.outer_vlan_flags |=
+ 			FIELD_PREP(ICE_AQ_VSI_OUTER_VLAN_EMODE_M,
+ 				   ICE_AQ_VSI_OUTER_VLAN_EMODE_NOTHING);
+ 	}
++>>>>>>> b33de560f9e9 (ice: remove VLAN representor specific ops)
  	/* Have 1:1 UP mapping for both ingress/egress tables */
  	table |= ICE_UP_TABLE_TRANSLATE(0, 0);
  	table |= ICE_UP_TABLE_TRANSLATE(1, 1);
diff --cc drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
index f47989ad400e,99cb382e71fe..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
+++ b/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
@@@ -3637,1366 -3533,74 +3637,1369 @@@ error_param
  }
  
  /**
 - * ice_vc_repr_del_mac - response with success for deleting MAC
 - * @vf: pointer to VF
 - * @msg: virtchannel message
 - *
 - * Respond with success to not break normal VF flow.
 - * For legacy VF driver try to update cached MAC address.
 + * ice_is_vf_trusted
 + * @vf: pointer to the VF info
   */
 -static int
 -ice_vc_repr_del_mac(struct ice_vf __always_unused *vf, u8 __always_unused *msg)
 +static bool ice_is_vf_trusted(struct ice_vf *vf)
  {
 -	struct virtchnl_ether_addr_list *al =
 -		(struct virtchnl_ether_addr_list *)msg;
 -
 -	ice_update_legacy_cached_mac(vf, &al->list[0]);
 -
 -	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DEL_ETH_ADDR,
 -				     VIRTCHNL_STATUS_SUCCESS, NULL, 0);
 +	return test_bit(ICE_VIRTCHNL_VF_CAP_PRIVILEGE, &vf->vf_caps);
  }
  
 -static int
 -ice_vc_repr_cfg_promiscuous_mode(struct ice_vf *vf, u8 __always_unused *msg)
 +/**
 + * ice_can_vf_change_mac
 + * @vf: pointer to the VF info
 + *
 + * Return true if the VF is allowed to change its MAC filters, false otherwise
 + */
 +static bool ice_can_vf_change_mac(struct ice_vf *vf)
  {
 -	dev_dbg(ice_pf_to_dev(vf->pf),
 -		"Can't config promiscuous mode in switchdev mode for VF %d\n",
 -		vf->vf_id);
 -	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_CONFIG_PROMISCUOUS_MODE,
 -				     VIRTCHNL_STATUS_ERR_NOT_SUPPORTED,
 -				     NULL, 0);
 +	/* If the VF MAC address has been set administratively (via the
 +	 * ndo_set_vf_mac command), then deny permission to the VF to
 +	 * add/delete unicast MAC addresses, unless the VF is trusted
 +	 */
 +	if (vf->pf_set_mac && !ice_is_vf_trusted(vf))
 +		return false;
 +
 +	return true;
  }
  
 +/**
 + * ice_vc_ether_addr_type - get type of virtchnl_ether_addr
 + * @vc_ether_addr: used to extract the type
 + */
 +static u8
 +ice_vc_ether_addr_type(struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	return (vc_ether_addr->type & VIRTCHNL_ETHER_ADDR_TYPE_MASK);
 +}
 +
 +/**
 + * ice_is_vc_addr_legacy - check if the MAC address is from an older VF
 + * @vc_ether_addr: VIRTCHNL structure that contains MAC and type
 + */
 +static bool
 +ice_is_vc_addr_legacy(struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	u8 type = ice_vc_ether_addr_type(vc_ether_addr);
 +
 +	return (type == VIRTCHNL_ETHER_ADDR_LEGACY);
 +}
 +
 +/**
 + * ice_is_vc_addr_primary - check if the MAC address is the VF's primary MAC
 + * @vc_ether_addr: VIRTCHNL structure that contains MAC and type
 + *
 + * This function should only be called when the MAC address in
 + * virtchnl_ether_addr is a valid unicast MAC
 + */
 +static bool
 +ice_is_vc_addr_primary(struct virtchnl_ether_addr __maybe_unused *vc_ether_addr)
 +{
 +	u8 type = ice_vc_ether_addr_type(vc_ether_addr);
 +
 +	return (type == VIRTCHNL_ETHER_ADDR_PRIMARY);
 +}
 +
 +/**
 + * ice_vfhw_mac_add - update the VF's cached hardware MAC if allowed
 + * @vf: VF to update
 + * @vc_ether_addr: structure from VIRTCHNL with MAC to add
 + */
 +static void
 +ice_vfhw_mac_add(struct ice_vf *vf, struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	u8 *mac_addr = vc_ether_addr->addr;
 +
 +	if (!is_valid_ether_addr(mac_addr))
 +		return;
 +
 +	/* only allow legacy VF drivers to set the device and hardware MAC if it
 +	 * is zero and allow new VF drivers to set the hardware MAC if the type
 +	 * was correctly specified over VIRTCHNL
 +	 */
 +	if ((ice_is_vc_addr_legacy(vc_ether_addr) &&
 +	     is_zero_ether_addr(vf->hw_lan_addr.addr)) ||
 +	    ice_is_vc_addr_primary(vc_ether_addr)) {
 +		ether_addr_copy(vf->dev_lan_addr.addr, mac_addr);
 +		ether_addr_copy(vf->hw_lan_addr.addr, mac_addr);
 +	}
 +
 +	/* hardware and device MACs are already set, but its possible that the
 +	 * VF driver sent the VIRTCHNL_OP_ADD_ETH_ADDR message before the
 +	 * VIRTCHNL_OP_DEL_ETH_ADDR when trying to update its MAC, so save it
 +	 * away for the legacy VF driver case as it will be updated in the
 +	 * delete flow for this case
 +	 */
 +	if (ice_is_vc_addr_legacy(vc_ether_addr)) {
 +		ether_addr_copy(vf->legacy_last_added_umac.addr,
 +				mac_addr);
 +		vf->legacy_last_added_umac.time_modified = jiffies;
 +	}
 +}
 +
 +/**
 + * ice_vc_add_mac_addr - attempt to add the MAC address passed in
 + * @vf: pointer to the VF info
 + * @vsi: pointer to the VF's VSI
 + * @vc_ether_addr: VIRTCHNL MAC address structure used to add MAC
 + */
 +static int
 +ice_vc_add_mac_addr(struct ice_vf *vf, struct ice_vsi *vsi,
 +		    struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	struct device *dev = ice_pf_to_dev(vf->pf);
 +	u8 *mac_addr = vc_ether_addr->addr;
 +	int ret;
 +
 +	/* device MAC already added */
 +	if (ether_addr_equal(mac_addr, vf->dev_lan_addr.addr))
 +		return 0;
 +
 +	if (is_unicast_ether_addr(mac_addr) && !ice_can_vf_change_mac(vf)) {
 +		dev_err(dev, "VF attempting to override administratively set MAC address, bring down and up the VF interface to resume normal operation\n");
 +		return -EPERM;
 +	}
 +
 +	ret = ice_fltr_add_mac(vsi, mac_addr, ICE_FWD_TO_VSI);
 +	if (ret == -EEXIST) {
 +		dev_dbg(dev, "MAC %pM already exists for VF %d\n", mac_addr,
 +			vf->vf_id);
 +		/* don't return since we might need to update
 +		 * the primary MAC in ice_vfhw_mac_add() below
 +		 */
 +	} else if (ret) {
 +		dev_err(dev, "Failed to add MAC %pM for VF %d\n, error %d\n",
 +			mac_addr, vf->vf_id, ret);
 +		return ret;
 +	} else {
 +		vf->num_mac++;
 +	}
 +
 +	ice_vfhw_mac_add(vf, vc_ether_addr);
 +
 +	return ret;
 +}
 +
 +/**
 + * ice_is_legacy_umac_expired - check if last added legacy unicast MAC expired
 + * @last_added_umac: structure used to check expiration
 + */
 +static bool ice_is_legacy_umac_expired(struct ice_time_mac *last_added_umac)
 +{
 +#define ICE_LEGACY_VF_MAC_CHANGE_EXPIRE_TIME	msecs_to_jiffies(3000)
 +	return time_is_before_jiffies(last_added_umac->time_modified +
 +				      ICE_LEGACY_VF_MAC_CHANGE_EXPIRE_TIME);
 +}
 +
 +/**
 + * ice_update_legacy_cached_mac - update cached hardware MAC for legacy VF
 + * @vf: VF to update
 + * @vc_ether_addr: structure from VIRTCHNL with MAC to check
 + *
 + * only update cached hardware MAC for legacy VF drivers on delete
 + * because we cannot guarantee order/type of MAC from the VF driver
 + */
 +static void
 +ice_update_legacy_cached_mac(struct ice_vf *vf,
 +			     struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	if (!ice_is_vc_addr_legacy(vc_ether_addr) ||
 +	    ice_is_legacy_umac_expired(&vf->legacy_last_added_umac))
 +		return;
 +
 +	ether_addr_copy(vf->dev_lan_addr.addr, vf->legacy_last_added_umac.addr);
 +	ether_addr_copy(vf->hw_lan_addr.addr, vf->legacy_last_added_umac.addr);
 +}
 +
 +/**
 + * ice_vfhw_mac_del - update the VF's cached hardware MAC if allowed
 + * @vf: VF to update
 + * @vc_ether_addr: structure from VIRTCHNL with MAC to delete
 + */
 +static void
 +ice_vfhw_mac_del(struct ice_vf *vf, struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	u8 *mac_addr = vc_ether_addr->addr;
 +
 +	if (!is_valid_ether_addr(mac_addr) ||
 +	    !ether_addr_equal(vf->dev_lan_addr.addr, mac_addr))
 +		return;
 +
 +	/* allow the device MAC to be repopulated in the add flow and don't
 +	 * clear the hardware MAC (i.e. hw_lan_addr.addr) here as that is meant
 +	 * to be persistent on VM reboot and across driver unload/load, which
 +	 * won't work if we clear the hardware MAC here
 +	 */
 +	eth_zero_addr(vf->dev_lan_addr.addr);
 +
 +	ice_update_legacy_cached_mac(vf, vc_ether_addr);
 +}
 +
 +/**
 + * ice_vc_del_mac_addr - attempt to delete the MAC address passed in
 + * @vf: pointer to the VF info
 + * @vsi: pointer to the VF's VSI
 + * @vc_ether_addr: VIRTCHNL MAC address structure used to delete MAC
 + */
 +static int
 +ice_vc_del_mac_addr(struct ice_vf *vf, struct ice_vsi *vsi,
 +		    struct virtchnl_ether_addr *vc_ether_addr)
 +{
 +	struct device *dev = ice_pf_to_dev(vf->pf);
 +	u8 *mac_addr = vc_ether_addr->addr;
 +	int status;
 +
 +	if (!ice_can_vf_change_mac(vf) &&
 +	    ether_addr_equal(vf->dev_lan_addr.addr, mac_addr))
 +		return 0;
 +
 +	status = ice_fltr_remove_mac(vsi, mac_addr, ICE_FWD_TO_VSI);
 +	if (status == -ENOENT) {
 +		dev_err(dev, "MAC %pM does not exist for VF %d\n", mac_addr,
 +			vf->vf_id);
 +		return -ENOENT;
 +	} else if (status) {
 +		dev_err(dev, "Failed to delete MAC %pM for VF %d, error %d\n",
 +			mac_addr, vf->vf_id, status);
 +		return -EIO;
 +	}
 +
 +	ice_vfhw_mac_del(vf, vc_ether_addr);
 +
 +	vf->num_mac--;
 +
 +	return 0;
 +}
 +
 +/**
 + * ice_vc_handle_mac_addr_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + * @set: true if MAC filters are being set, false otherwise
 + *
 + * add guest MAC address filter
 + */
 +static int
 +ice_vc_handle_mac_addr_msg(struct ice_vf *vf, u8 *msg, bool set)
 +{
 +	int (*ice_vc_cfg_mac)
 +		(struct ice_vf *vf, struct ice_vsi *vsi,
 +		 struct virtchnl_ether_addr *virtchnl_ether_addr);
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct virtchnl_ether_addr_list *al =
 +	    (struct virtchnl_ether_addr_list *)msg;
 +	struct ice_pf *pf = vf->pf;
 +	enum virtchnl_ops vc_op;
 +	struct ice_vsi *vsi;
 +	int i;
 +
 +	if (set) {
 +		vc_op = VIRTCHNL_OP_ADD_ETH_ADDR;
 +		ice_vc_cfg_mac = ice_vc_add_mac_addr;
 +	} else {
 +		vc_op = VIRTCHNL_OP_DEL_ETH_ADDR;
 +		ice_vc_cfg_mac = ice_vc_del_mac_addr;
 +	}
 +
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states) ||
 +	    !ice_vc_isvalid_vsi_id(vf, al->vsi_id)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto handle_mac_exit;
 +	}
 +
 +	/* If this VF is not privileged, then we can't add more than a
 +	 * limited number of addresses. Check to make sure that the
 +	 * additions do not push us over the limit.
 +	 */
 +	if (set && !ice_is_vf_trusted(vf) &&
 +	    (vf->num_mac + al->num_elements) > ICE_MAX_MACADDR_PER_VF) {
 +		dev_err(ice_pf_to_dev(pf), "Can't add more MAC addresses, because VF-%d is not trusted, switch the VF to trusted mode in order to add more functionalities\n",
 +			vf->vf_id);
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto handle_mac_exit;
 +	}
 +
 +	vsi = ice_get_vf_vsi(vf);
 +	if (!vsi) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto handle_mac_exit;
 +	}
 +
 +	for (i = 0; i < al->num_elements; i++) {
 +		u8 *mac_addr = al->list[i].addr;
 +		int result;
 +
 +		if (is_broadcast_ether_addr(mac_addr) ||
 +		    is_zero_ether_addr(mac_addr))
 +			continue;
 +
 +		result = ice_vc_cfg_mac(vf, vsi, &al->list[i]);
 +		if (result == -EEXIST || result == -ENOENT) {
 +			continue;
 +		} else if (result) {
 +			v_ret = VIRTCHNL_STATUS_ERR_ADMIN_QUEUE_ERROR;
 +			goto handle_mac_exit;
 +		}
 +	}
 +
 +handle_mac_exit:
 +	/* send the response to the VF */
 +	return ice_vc_send_msg_to_vf(vf, vc_op, v_ret, NULL, 0);
 +}
 +
 +/**
 + * ice_vc_add_mac_addr_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + *
 + * add guest MAC address filter
 + */
 +static int ice_vc_add_mac_addr_msg(struct ice_vf *vf, u8 *msg)
 +{
 +	return ice_vc_handle_mac_addr_msg(vf, msg, true);
 +}
 +
 +/**
 + * ice_vc_del_mac_addr_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + *
 + * remove guest MAC address filter
 + */
 +static int ice_vc_del_mac_addr_msg(struct ice_vf *vf, u8 *msg)
 +{
 +	return ice_vc_handle_mac_addr_msg(vf, msg, false);
 +}
 +
 +/**
 + * ice_vc_request_qs_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + *
 + * VFs get a default number of queues but can use this message to request a
 + * different number. If the request is successful, PF will reset the VF and
 + * return 0. If unsuccessful, PF will send message informing VF of number of
 + * available queue pairs via virtchnl message response to VF.
 + */
 +static int ice_vc_request_qs_msg(struct ice_vf *vf, u8 *msg)
 +{
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct virtchnl_vf_res_request *vfres =
 +		(struct virtchnl_vf_res_request *)msg;
 +	u16 req_queues = vfres->num_queue_pairs;
 +	struct ice_pf *pf = vf->pf;
 +	u16 max_allowed_vf_queues;
 +	u16 tx_rx_queue_left;
 +	struct device *dev;
 +	u16 cur_queues;
 +
 +	dev = ice_pf_to_dev(pf);
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	cur_queues = vf->num_vf_qs;
 +	tx_rx_queue_left = min_t(u16, ice_get_avail_txq_count(pf),
 +				 ice_get_avail_rxq_count(pf));
 +	max_allowed_vf_queues = tx_rx_queue_left + cur_queues;
 +	if (!req_queues) {
 +		dev_err(dev, "VF %d tried to request 0 queues. Ignoring.\n",
 +			vf->vf_id);
 +	} else if (req_queues > ICE_MAX_RSS_QS_PER_VF) {
 +		dev_err(dev, "VF %d tried to request more than %d queues.\n",
 +			vf->vf_id, ICE_MAX_RSS_QS_PER_VF);
 +		vfres->num_queue_pairs = ICE_MAX_RSS_QS_PER_VF;
 +	} else if (req_queues > cur_queues &&
 +		   req_queues - cur_queues > tx_rx_queue_left) {
 +		dev_warn(dev, "VF %d requested %u more queues, but only %u left.\n",
 +			 vf->vf_id, req_queues - cur_queues, tx_rx_queue_left);
 +		vfres->num_queue_pairs = min_t(u16, max_allowed_vf_queues,
 +					       ICE_MAX_RSS_QS_PER_VF);
 +	} else {
 +		/* request is successful, then reset VF */
 +		vf->num_req_qs = req_queues;
 +		ice_vc_reset_vf(vf);
 +		dev_info(dev, "VF %d granted request of %u queues.\n",
 +			 vf->vf_id, req_queues);
 +		return 0;
 +	}
 +
 +error_param:
 +	/* send the response to the VF */
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_REQUEST_QUEUES,
 +				     v_ret, (u8 *)vfres, sizeof(*vfres));
 +}
 +
 +/**
 + * ice_set_vf_port_vlan
 + * @netdev: network interface device structure
 + * @vf_id: VF identifier
 + * @vlan_id: VLAN ID being set
 + * @qos: priority setting
 + * @vlan_proto: VLAN protocol
 + *
 + * program VF Port VLAN ID and/or QoS
 + */
 +int
 +ice_set_vf_port_vlan(struct net_device *netdev, int vf_id, u16 vlan_id, u8 qos,
 +		     __be16 vlan_proto)
 +{
 +	struct ice_pf *pf = ice_netdev_to_pf(netdev);
 +	struct device *dev;
 +	struct ice_vf *vf;
 +	u16 vlanprio;
 +	int ret;
 +
 +	dev = ice_pf_to_dev(pf);
 +	if (ice_validate_vf_id(pf, vf_id))
 +		return -EINVAL;
 +
 +	if (vlan_id >= VLAN_N_VID || qos > 7) {
 +		dev_err(dev, "Invalid Port VLAN parameters for VF %d, ID %d, QoS %d\n",
 +			vf_id, vlan_id, qos);
 +		return -EINVAL;
 +	}
 +
 +	if (vlan_proto != htons(ETH_P_8021Q)) {
 +		dev_err(dev, "VF VLAN protocol is not supported\n");
 +		return -EPROTONOSUPPORT;
 +	}
 +
 +	vf = &pf->vf[vf_id];
 +	ret = ice_check_vf_ready_for_cfg(vf);
 +	if (ret)
 +		return ret;
 +
 +	vlanprio = vlan_id | (qos << VLAN_PRIO_SHIFT);
 +
 +	if (vf->port_vlan_info == vlanprio) {
 +		/* duplicate request, so just return success */
 +		dev_dbg(dev, "Duplicate pvid %d request\n", vlanprio);
 +		return 0;
 +	}
 +
 +	mutex_lock(&vf->cfg_lock);
 +
 +	vf->port_vlan_info = vlanprio;
 +
 +	if (vf->port_vlan_info)
 +		dev_info(dev, "Setting VLAN %d, QoS 0x%x on VF %d\n",
 +			 vlan_id, qos, vf_id);
 +	else
 +		dev_info(dev, "Clearing port VLAN on VF %d\n", vf_id);
 +
 +	ice_vc_reset_vf(vf);
 +	mutex_unlock(&vf->cfg_lock);
 +
 +	return 0;
 +}
 +
 +/**
 + * ice_vf_vlan_offload_ena - determine if capabilities support VLAN offloads
 + * @caps: VF driver negotiated capabilities
 + *
 + * Return true if VIRTCHNL_VF_OFFLOAD_VLAN capability is set, else return false
 + */
 +static bool ice_vf_vlan_offload_ena(u32 caps)
 +{
 +	return !!(caps & VIRTCHNL_VF_OFFLOAD_VLAN);
 +}
 +
 +/**
 + * ice_vc_process_vlan_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + * @add_v: Add VLAN if true, otherwise delete VLAN
 + *
 + * Process virtchnl op to add or remove programmed guest VLAN ID
 + */
 +static int ice_vc_process_vlan_msg(struct ice_vf *vf, u8 *msg, bool add_v)
 +{
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct virtchnl_vlan_filter_list *vfl =
 +	    (struct virtchnl_vlan_filter_list *)msg;
 +	struct ice_pf *pf = vf->pf;
 +	bool vlan_promisc = false;
 +	struct ice_vsi *vsi;
 +	struct device *dev;
 +	struct ice_hw *hw;
 +	int status = 0;
 +	u8 promisc_m;
 +	int i;
 +
 +	dev = ice_pf_to_dev(pf);
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (!ice_vf_vlan_offload_ena(vf->driver_caps)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (!ice_vc_isvalid_vsi_id(vf, vfl->vsi_id)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	for (i = 0; i < vfl->num_elements; i++) {
 +		if (vfl->vlan_id[i] >= VLAN_N_VID) {
 +			v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +			dev_err(dev, "invalid VF VLAN id %d\n",
 +				vfl->vlan_id[i]);
 +			goto error_param;
 +		}
 +	}
 +
 +	hw = &pf->hw;
 +	vsi = ice_get_vf_vsi(vf);
 +	if (!vsi) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (add_v && !ice_is_vf_trusted(vf) &&
 +	    vsi->num_vlan >= ICE_MAX_VLAN_PER_VF) {
 +		dev_info(dev, "VF-%d is not trusted, switch the VF to trusted mode, in order to add more VLAN addresses\n",
 +			 vf->vf_id);
 +		/* There is no need to let VF know about being not trusted,
 +		 * so we can just return success message here
 +		 */
 +		goto error_param;
 +	}
 +
 +	if (vsi->info.pvid) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if ((test_bit(ICE_VF_STATE_UC_PROMISC, vf->vf_states) ||
 +	     test_bit(ICE_VF_STATE_MC_PROMISC, vf->vf_states)) &&
 +	    test_bit(ICE_FLAG_VF_TRUE_PROMISC_ENA, pf->flags))
 +		vlan_promisc = true;
 +
 +	if (add_v) {
 +		for (i = 0; i < vfl->num_elements; i++) {
 +			u16 vid = vfl->vlan_id[i];
 +
 +			if (!ice_is_vf_trusted(vf) &&
 +			    vsi->num_vlan >= ICE_MAX_VLAN_PER_VF) {
 +				dev_info(dev, "VF-%d is not trusted, switch the VF to trusted mode, in order to add more VLAN addresses\n",
 +					 vf->vf_id);
 +				/* There is no need to let VF know about being
 +				 * not trusted, so we can just return success
 +				 * message here as well.
 +				 */
 +				goto error_param;
 +			}
 +
 +			/* we add VLAN 0 by default for each VF so we can enable
 +			 * Tx VLAN anti-spoof without triggering MDD events so
 +			 * we don't need to add it again here
 +			 */
 +			if (!vid)
 +				continue;
 +
 +			status = ice_vsi_add_vlan(vsi, vid, ICE_FWD_TO_VSI);
 +			if (status) {
 +				v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +				goto error_param;
 +			}
 +
 +			/* Enable VLAN pruning when non-zero VLAN is added */
 +			if (!vlan_promisc && vid &&
 +			    !ice_vsi_is_vlan_pruning_ena(vsi)) {
 +				status = ice_cfg_vlan_pruning(vsi, true);
 +				if (status) {
 +					v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +					dev_err(dev, "Enable VLAN pruning on VLAN ID: %d failed error-%d\n",
 +						vid, status);
 +					goto error_param;
 +				}
 +			} else if (vlan_promisc) {
 +				/* Enable Ucast/Mcast VLAN promiscuous mode */
 +				promisc_m = ICE_PROMISC_VLAN_TX |
 +					    ICE_PROMISC_VLAN_RX;
 +
 +				status = ice_set_vsi_promisc(hw, vsi->idx,
 +							     promisc_m, vid);
 +				if (status) {
 +					v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +					dev_err(dev, "Enable Unicast/multicast promiscuous mode on VLAN ID:%d failed error-%d\n",
 +						vid, status);
 +				}
 +			}
 +		}
 +	} else {
 +		/* In case of non_trusted VF, number of VLAN elements passed
 +		 * to PF for removal might be greater than number of VLANs
 +		 * filter programmed for that VF - So, use actual number of
 +		 * VLANS added earlier with add VLAN opcode. In order to avoid
 +		 * removing VLAN that doesn't exist, which result to sending
 +		 * erroneous failed message back to the VF
 +		 */
 +		int num_vf_vlan;
 +
 +		num_vf_vlan = vsi->num_vlan;
 +		for (i = 0; i < vfl->num_elements && i < num_vf_vlan; i++) {
 +			u16 vid = vfl->vlan_id[i];
 +
 +			/* we add VLAN 0 by default for each VF so we can enable
 +			 * Tx VLAN anti-spoof without triggering MDD events so
 +			 * we don't want a VIRTCHNL request to remove it
 +			 */
 +			if (!vid)
 +				continue;
 +
 +			/* Make sure ice_vsi_kill_vlan is successful before
 +			 * updating VLAN information
 +			 */
 +			status = ice_vsi_kill_vlan(vsi, vid);
 +			if (status) {
 +				v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +				goto error_param;
 +			}
 +
 +			/* Disable VLAN pruning when only VLAN 0 is left */
 +			if (vsi->num_vlan == 1 &&
 +			    ice_vsi_is_vlan_pruning_ena(vsi))
 +				ice_cfg_vlan_pruning(vsi, false);
 +
 +			/* Disable Unicast/Multicast VLAN promiscuous mode */
 +			if (vlan_promisc) {
 +				promisc_m = ICE_PROMISC_VLAN_TX |
 +					    ICE_PROMISC_VLAN_RX;
 +
 +				ice_clear_vsi_promisc(hw, vsi->idx,
 +						      promisc_m, vid);
 +			}
 +		}
 +	}
 +
 +error_param:
 +	/* send the response to the VF */
 +	if (add_v)
 +		return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ADD_VLAN, v_ret,
 +					     NULL, 0);
 +	else
 +		return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DEL_VLAN, v_ret,
 +					     NULL, 0);
 +}
 +
 +/**
 + * ice_vc_add_vlan_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + *
 + * Add and program guest VLAN ID
 + */
 +static int ice_vc_add_vlan_msg(struct ice_vf *vf, u8 *msg)
 +{
 +	return ice_vc_process_vlan_msg(vf, msg, true);
 +}
 +
 +/**
 + * ice_vc_remove_vlan_msg
 + * @vf: pointer to the VF info
 + * @msg: pointer to the msg buffer
 + *
 + * remove programmed guest VLAN ID
 + */
 +static int ice_vc_remove_vlan_msg(struct ice_vf *vf, u8 *msg)
 +{
 +	return ice_vc_process_vlan_msg(vf, msg, false);
 +}
 +
 +/**
 + * ice_vc_ena_vlan_stripping
 + * @vf: pointer to the VF info
 + *
 + * Enable VLAN header stripping for a given VF
 + */
 +static int ice_vc_ena_vlan_stripping(struct ice_vf *vf)
 +{
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct ice_vsi *vsi;
 +
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (!ice_vf_vlan_offload_ena(vf->driver_caps)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	vsi = ice_get_vf_vsi(vf);
 +	if (ice_vsi_manage_vlan_stripping(vsi, true))
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +
 +error_param:
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ENABLE_VLAN_STRIPPING,
 +				     v_ret, NULL, 0);
 +}
 +
 +/**
 + * ice_vc_dis_vlan_stripping
 + * @vf: pointer to the VF info
 + *
 + * Disable VLAN header stripping for a given VF
 + */
 +static int ice_vc_dis_vlan_stripping(struct ice_vf *vf)
 +{
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct ice_vsi *vsi;
 +
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (!ice_vf_vlan_offload_ena(vf->driver_caps)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	vsi = ice_get_vf_vsi(vf);
 +	if (!vsi) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto error_param;
 +	}
 +
 +	if (ice_vsi_manage_vlan_stripping(vsi, false))
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +
 +error_param:
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DISABLE_VLAN_STRIPPING,
 +				     v_ret, NULL, 0);
 +}
 +
 +/**
 + * ice_vf_init_vlan_stripping - enable/disable VLAN stripping on initialization
 + * @vf: VF to enable/disable VLAN stripping for on initialization
 + *
 + * If the VIRTCHNL_VF_OFFLOAD_VLAN flag is set enable VLAN stripping, else if
 + * the flag is cleared then we want to disable stripping. For example, the flag
 + * will be cleared when port VLANs are configured by the administrator before
 + * passing the VF to the guest or if the AVF driver doesn't support VLAN
 + * offloads.
 + */
 +static int ice_vf_init_vlan_stripping(struct ice_vf *vf)
 +{
 +	struct ice_vsi *vsi = ice_get_vf_vsi(vf);
 +
 +	if (!vsi)
 +		return -EINVAL;
 +
 +	/* don't modify stripping if port VLAN is configured */
 +	if (vsi->info.pvid)
 +		return 0;
 +
 +	if (ice_vf_vlan_offload_ena(vf->driver_caps))
 +		return ice_vsi_manage_vlan_stripping(vsi, true);
 +	else
 +		return ice_vsi_manage_vlan_stripping(vsi, false);
 +}
 +
 +static struct ice_vc_vf_ops ice_vc_vf_dflt_ops = {
 +	.get_ver_msg = ice_vc_get_ver_msg,
 +	.get_vf_res_msg = ice_vc_get_vf_res_msg,
 +	.reset_vf = ice_vc_reset_vf_msg,
 +	.add_mac_addr_msg = ice_vc_add_mac_addr_msg,
 +	.del_mac_addr_msg = ice_vc_del_mac_addr_msg,
 +	.cfg_qs_msg = ice_vc_cfg_qs_msg,
 +	.ena_qs_msg = ice_vc_ena_qs_msg,
 +	.dis_qs_msg = ice_vc_dis_qs_msg,
 +	.request_qs_msg = ice_vc_request_qs_msg,
 +	.cfg_irq_map_msg = ice_vc_cfg_irq_map_msg,
 +	.config_rss_key = ice_vc_config_rss_key,
 +	.config_rss_lut = ice_vc_config_rss_lut,
 +	.get_stats_msg = ice_vc_get_stats_msg,
 +	.cfg_promiscuous_mode_msg = ice_vc_cfg_promiscuous_mode_msg,
 +	.add_vlan_msg = ice_vc_add_vlan_msg,
 +	.remove_vlan_msg = ice_vc_remove_vlan_msg,
 +	.ena_vlan_stripping = ice_vc_ena_vlan_stripping,
 +	.dis_vlan_stripping = ice_vc_dis_vlan_stripping,
 +	.handle_rss_cfg_msg = ice_vc_handle_rss_cfg,
 +	.add_fdir_fltr_msg = ice_vc_add_fdir_fltr,
 +	.del_fdir_fltr_msg = ice_vc_del_fdir_fltr,
 +};
 +
 +void ice_vc_set_dflt_vf_ops(struct ice_vc_vf_ops *ops)
 +{
 +	*ops = ice_vc_vf_dflt_ops;
 +}
 +
 +/**
 + * ice_vc_repr_add_mac
 + * @vf: pointer to VF
 + * @msg: virtchannel message
 + *
 + * When port representors are created, we do not add MAC rule
 + * to firmware, we store it so that PF could report same
 + * MAC as VF.
 + */
 +static int ice_vc_repr_add_mac(struct ice_vf *vf, u8 *msg)
 +{
 +	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 +	struct virtchnl_ether_addr_list *al =
 +	    (struct virtchnl_ether_addr_list *)msg;
 +	struct ice_vsi *vsi;
 +	struct ice_pf *pf;
 +	int i;
 +
 +	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states) ||
 +	    !ice_vc_isvalid_vsi_id(vf, al->vsi_id)) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto handle_mac_exit;
 +	}
 +
 +	pf = vf->pf;
 +
 +	vsi = ice_get_vf_vsi(vf);
 +	if (!vsi) {
 +		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 +		goto handle_mac_exit;
 +	}
 +
 +	for (i = 0; i < al->num_elements; i++) {
 +		u8 *mac_addr = al->list[i].addr;
 +		int result;
 +
 +		if (!is_unicast_ether_addr(mac_addr) ||
 +		    ether_addr_equal(mac_addr, vf->hw_lan_addr.addr))
 +			continue;
 +
 +		if (vf->pf_set_mac) {
 +			dev_err(ice_pf_to_dev(pf), "VF attempting to override administratively set MAC address\n");
 +			v_ret = VIRTCHNL_STATUS_ERR_NOT_SUPPORTED;
 +			goto handle_mac_exit;
 +		}
 +
 +		result = ice_eswitch_add_vf_mac_rule(pf, vf, mac_addr);
 +		if (result) {
 +			dev_err(ice_pf_to_dev(pf), "Failed to add MAC %pM for VF %d\n, error %d\n",
 +				mac_addr, vf->vf_id, result);
 +			goto handle_mac_exit;
 +		}
 +
 +		ice_vfhw_mac_add(vf, &al->list[i]);
 +		vf->num_mac++;
 +		break;
 +	}
 +
 +handle_mac_exit:
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ADD_ETH_ADDR,
 +				     v_ret, NULL, 0);
 +}
 +
 +/**
 + * ice_vc_repr_del_mac - response with success for deleting MAC
 + * @vf: pointer to VF
 + * @msg: virtchannel message
 + *
 + * Respond with success to not break normal VF flow.
 + * For legacy VF driver try to update cached MAC address.
 + */
 +static int
 +ice_vc_repr_del_mac(struct ice_vf __always_unused *vf, u8 __always_unused *msg)
 +{
 +	struct virtchnl_ether_addr_list *al =
 +		(struct virtchnl_ether_addr_list *)msg;
 +
 +	ice_update_legacy_cached_mac(vf, &al->list[0]);
 +
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DEL_ETH_ADDR,
 +				     VIRTCHNL_STATUS_SUCCESS, NULL, 0);
 +}
 +
- static int ice_vc_repr_add_vlan(struct ice_vf *vf, u8 __always_unused *msg)
- {
- 	dev_dbg(ice_pf_to_dev(vf->pf),
- 		"Can't add VLAN in switchdev mode for VF %d\n", vf->vf_id);
- 	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ADD_VLAN,
- 				     VIRTCHNL_STATUS_SUCCESS, NULL, 0);
- }
- 
- static int ice_vc_repr_del_vlan(struct ice_vf *vf, u8 __always_unused *msg)
- {
- 	dev_dbg(ice_pf_to_dev(vf->pf),
- 		"Can't delete VLAN in switchdev mode for VF %d\n", vf->vf_id);
- 	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DEL_VLAN,
- 				     VIRTCHNL_STATUS_SUCCESS, NULL, 0);
- }
- 
- static int ice_vc_repr_ena_vlan_stripping(struct ice_vf *vf)
- {
- 	dev_dbg(ice_pf_to_dev(vf->pf),
- 		"Can't enable VLAN stripping in switchdev mode for VF %d\n",
- 		vf->vf_id);
- 	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ENABLE_VLAN_STRIPPING,
- 				     VIRTCHNL_STATUS_ERR_NOT_SUPPORTED,
- 				     NULL, 0);
- }
- 
- static int ice_vc_repr_dis_vlan_stripping(struct ice_vf *vf)
- {
- 	dev_dbg(ice_pf_to_dev(vf->pf),
- 		"Can't disable VLAN stripping in switchdev mode for VF %d\n",
- 		vf->vf_id);
- 	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DISABLE_VLAN_STRIPPING,
- 				     VIRTCHNL_STATUS_ERR_NOT_SUPPORTED,
- 				     NULL, 0);
- }
- 
 +static int
 +ice_vc_repr_cfg_promiscuous_mode(struct ice_vf *vf, u8 __always_unused *msg)
 +{
 +	dev_dbg(ice_pf_to_dev(vf->pf),
 +		"Can't config promiscuous mode in switchdev mode for VF %d\n",
 +		vf->vf_id);
 +	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_CONFIG_PROMISCUOUS_MODE,
 +				     VIRTCHNL_STATUS_ERR_NOT_SUPPORTED,
 +				     NULL, 0);
 +}
 +
++<<<<<<< HEAD:drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
 +void ice_vc_change_ops_to_repr(struct ice_vc_vf_ops *ops)
++=======
+ static const struct ice_virtchnl_ops ice_virtchnl_repr_ops = {
+ 	.get_ver_msg = ice_vc_get_ver_msg,
+ 	.get_vf_res_msg = ice_vc_get_vf_res_msg,
+ 	.reset_vf = ice_vc_reset_vf_msg,
+ 	.add_mac_addr_msg = ice_vc_repr_add_mac,
+ 	.del_mac_addr_msg = ice_vc_repr_del_mac,
+ 	.cfg_qs_msg = ice_vc_cfg_qs_msg,
+ 	.ena_qs_msg = ice_vc_ena_qs_msg,
+ 	.dis_qs_msg = ice_vc_dis_qs_msg,
+ 	.request_qs_msg = ice_vc_request_qs_msg,
+ 	.cfg_irq_map_msg = ice_vc_cfg_irq_map_msg,
+ 	.config_rss_key = ice_vc_config_rss_key,
+ 	.config_rss_lut = ice_vc_config_rss_lut,
+ 	.get_stats_msg = ice_vc_get_stats_msg,
+ 	.cfg_promiscuous_mode_msg = ice_vc_repr_cfg_promiscuous_mode,
+ 	.add_vlan_msg = ice_vc_add_vlan_msg,
+ 	.remove_vlan_msg = ice_vc_remove_vlan_msg,
+ 	.ena_vlan_stripping = ice_vc_ena_vlan_stripping,
+ 	.dis_vlan_stripping = ice_vc_dis_vlan_stripping,
+ 	.handle_rss_cfg_msg = ice_vc_handle_rss_cfg,
+ 	.add_fdir_fltr_msg = ice_vc_add_fdir_fltr,
+ 	.del_fdir_fltr_msg = ice_vc_del_fdir_fltr,
+ 	.get_offload_vlan_v2_caps = ice_vc_get_offload_vlan_v2_caps,
+ 	.add_vlan_v2_msg = ice_vc_add_vlan_v2_msg,
+ 	.remove_vlan_v2_msg = ice_vc_remove_vlan_v2_msg,
+ 	.ena_vlan_stripping_v2_msg = ice_vc_ena_vlan_stripping_v2_msg,
+ 	.dis_vlan_stripping_v2_msg = ice_vc_dis_vlan_stripping_v2_msg,
+ 	.ena_vlan_insertion_v2_msg = ice_vc_ena_vlan_insertion_v2_msg,
+ 	.dis_vlan_insertion_v2_msg = ice_vc_dis_vlan_insertion_v2_msg,
+ };
+ 
+ /**
 - * ice_virtchnl_set_repr_ops - Switch to representor virtchnl ops
 - * @vf: the VF to switch ops
++ * ice_virtchnl_set_repr_ops - Switch to representor virtchnl ops
++ * @vf: the VF to switch ops
++ */
++void ice_virtchnl_set_repr_ops(struct ice_vf *vf)
++>>>>>>> b33de560f9e9 (ice: remove VLAN representor specific ops):drivers/net/ethernet/intel/ice/ice_virtchnl.c
 +{
 +	ops->add_mac_addr_msg = ice_vc_repr_add_mac;
 +	ops->del_mac_addr_msg = ice_vc_repr_del_mac;
 +	ops->add_vlan_msg = ice_vc_repr_add_vlan;
 +	ops->remove_vlan_msg = ice_vc_repr_del_vlan;
 +	ops->ena_vlan_stripping = ice_vc_repr_ena_vlan_stripping;
 +	ops->dis_vlan_stripping = ice_vc_repr_dis_vlan_stripping;
 +	ops->cfg_promiscuous_mode_msg = ice_vc_repr_cfg_promiscuous_mode;
 +}
 +
 +/**
 + * ice_vc_process_vf_msg - Process request from VF
 + * @pf: pointer to the PF structure
 + * @event: pointer to the AQ event
 + *
 + * called from the common asq/arq handler to
 + * process request from VF
 + */
 +void ice_vc_process_vf_msg(struct ice_pf *pf, struct ice_rq_event_info *event)
 +{
 +	u32 v_opcode = le32_to_cpu(event->desc.cookie_high);
 +	s16 vf_id = le16_to_cpu(event->desc.retval);
 +	u16 msglen = event->msg_len;
 +	struct ice_vc_vf_ops *ops;
 +	u8 *msg = event->msg_buf;
 +	struct ice_vf *vf = NULL;
 +	struct device *dev;
 +	int err = 0;
 +
 +	dev = ice_pf_to_dev(pf);
 +	if (ice_validate_vf_id(pf, vf_id)) {
 +		dev_err(dev, "Unable to locate VF for message from VF ID %d, opcode %d, len %d\n",
 +			vf_id, v_opcode, msglen);
 +		return;
 +	}
 +
 +	vf = &pf->vf[vf_id];
 +
 +	mutex_lock(&vf->cfg_lock);
 +
 +	/* Check if VF is disabled. */
 +	if (test_bit(ICE_VF_STATE_DIS, vf->vf_states)) {
 +		err = -EPERM;
 +		goto error_handler;
 +	}
 +
 +	ops = &vf->vc_ops;
 +
 +	/* Perform basic checks on the msg */
 +	err = virtchnl_vc_validate_vf_msg(&vf->vf_ver, v_opcode, msg, msglen);
 +	if (err) {
 +		if (err == VIRTCHNL_STATUS_ERR_PARAM)
 +			err = -EPERM;
 +		else
 +			err = -EINVAL;
 +	}
 +
 +error_handler:
 +	if (err) {
 +		ice_vc_send_msg_to_vf(vf, v_opcode, VIRTCHNL_STATUS_ERR_PARAM,
 +				      NULL, 0);
 +		dev_err(dev, "Invalid message from VF %d, opcode %d, len %d, error %d\n",
 +			vf_id, v_opcode, msglen, err);
 +		goto finish;
 +	}
 +
 +	if (!ice_vc_is_opcode_allowed(vf, v_opcode)) {
 +		ice_vc_send_msg_to_vf(vf, v_opcode,
 +				      VIRTCHNL_STATUS_ERR_NOT_SUPPORTED, NULL,
 +				      0);
 +		goto finish;
 +	}
 +
 +	switch (v_opcode) {
 +	case VIRTCHNL_OP_VERSION:
 +		err = ops->get_ver_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_GET_VF_RESOURCES:
 +		err = ops->get_vf_res_msg(vf, msg);
 +		if (ice_vf_init_vlan_stripping(vf))
 +			dev_err(dev, "Failed to initialize VLAN stripping for VF %d\n",
 +				vf->vf_id);
 +		ice_vc_notify_vf_link_state(vf);
 +		break;
 +	case VIRTCHNL_OP_RESET_VF:
 +		ops->reset_vf(vf);
 +		break;
 +	case VIRTCHNL_OP_ADD_ETH_ADDR:
 +		err = ops->add_mac_addr_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_DEL_ETH_ADDR:
 +		err = ops->del_mac_addr_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_CONFIG_VSI_QUEUES:
 +		err = ops->cfg_qs_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_ENABLE_QUEUES:
 +		err = ops->ena_qs_msg(vf, msg);
 +		ice_vc_notify_vf_link_state(vf);
 +		break;
 +	case VIRTCHNL_OP_DISABLE_QUEUES:
 +		err = ops->dis_qs_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_REQUEST_QUEUES:
 +		err = ops->request_qs_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_CONFIG_IRQ_MAP:
 +		err = ops->cfg_irq_map_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_CONFIG_RSS_KEY:
 +		err = ops->config_rss_key(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_CONFIG_RSS_LUT:
 +		err = ops->config_rss_lut(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_GET_STATS:
 +		err = ops->get_stats_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_CONFIG_PROMISCUOUS_MODE:
 +		err = ops->cfg_promiscuous_mode_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_ADD_VLAN:
 +		err = ops->add_vlan_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_DEL_VLAN:
 +		err = ops->remove_vlan_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_ENABLE_VLAN_STRIPPING:
 +		err = ops->ena_vlan_stripping(vf);
 +		break;
 +	case VIRTCHNL_OP_DISABLE_VLAN_STRIPPING:
 +		err = ops->dis_vlan_stripping(vf);
 +		break;
 +	case VIRTCHNL_OP_ADD_FDIR_FILTER:
 +		err = ops->add_fdir_fltr_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_DEL_FDIR_FILTER:
 +		err = ops->del_fdir_fltr_msg(vf, msg);
 +		break;
 +	case VIRTCHNL_OP_ADD_RSS_CFG:
 +		err = ops->handle_rss_cfg_msg(vf, msg, true);
 +		break;
 +	case VIRTCHNL_OP_DEL_RSS_CFG:
 +		err = ops->handle_rss_cfg_msg(vf, msg, false);
 +		break;
 +	case VIRTCHNL_OP_UNKNOWN:
 +	default:
 +		dev_err(dev, "Unsupported opcode %d from VF %d\n", v_opcode,
 +			vf_id);
 +		err = ice_vc_send_msg_to_vf(vf, v_opcode,
 +					    VIRTCHNL_STATUS_ERR_NOT_SUPPORTED,
 +					    NULL, 0);
 +		break;
 +	}
 +	if (err) {
 +		/* Helper function cares less about error return values here
 +		 * as it is busy with pending work.
 +		 */
 +		dev_info(dev, "PF failed to honor VF %d, opcode %d, error %d\n",
 +			 vf_id, v_opcode, err);
 +	}
 +
 +finish:
 +	mutex_unlock(&vf->cfg_lock);
 +}
 +
 +/**
 + * ice_get_vf_cfg
 + * @netdev: network interface device structure
 + * @vf_id: VF identifier
 + * @ivi: VF configuration structure
 + *
 + * return VF configuration
 + */
 +int
 +ice_get_vf_cfg(struct net_device *netdev, int vf_id, struct ifla_vf_info *ivi)
 +{
 +	struct ice_pf *pf = ice_netdev_to_pf(netdev);
 +	struct ice_vf *vf;
 +
 +	if (ice_validate_vf_id(pf, vf_id))
 +		return -EINVAL;
 +
 +	vf = &pf->vf[vf_id];
 +
 +	if (ice_check_vf_init(pf, vf))
 +		return -EBUSY;
 +
 +	ivi->vf = vf_id;
 +	ether_addr_copy(ivi->mac, vf->hw_lan_addr.addr);
 +
 +	/* VF configuration for VLAN and applicable QoS */
 +	ivi->vlan = vf->port_vlan_info & VLAN_VID_MASK;
 +	ivi->qos = (vf->port_vlan_info & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
 +
 +	ivi->trusted = vf->trusted;
 +	ivi->spoofchk = vf->spoofchk;
 +	if (!vf->link_forced)
 +		ivi->linkstate = IFLA_VF_LINK_STATE_AUTO;
 +	else if (vf->link_up)
 +		ivi->linkstate = IFLA_VF_LINK_STATE_ENABLE;
 +	else
 +		ivi->linkstate = IFLA_VF_LINK_STATE_DISABLE;
 +	ivi->max_tx_rate = vf->max_tx_rate;
 +	ivi->min_tx_rate = vf->min_tx_rate;
 +	return 0;
 +}
 +
 +/**
 + * ice_unicast_mac_exists - check if the unicast MAC exists on the PF's switch
 + * @pf: PF used to reference the switch's rules
 + * @umac: unicast MAC to compare against existing switch rules
 + *
 + * Return true on the first/any match, else return false
 + */
 +static bool ice_unicast_mac_exists(struct ice_pf *pf, u8 *umac)
 +{
 +	struct ice_sw_recipe *mac_recipe_list =
 +		&pf->hw.switch_info->recp_list[ICE_SW_LKUP_MAC];
 +	struct ice_fltr_mgmt_list_entry *list_itr;
 +	struct list_head *rule_head;
 +	struct mutex *rule_lock; /* protect MAC filter list access */
 +
 +	rule_head = &mac_recipe_list->filt_rules;
 +	rule_lock = &mac_recipe_list->filt_rule_lock;
 +
 +	mutex_lock(rule_lock);
 +	list_for_each_entry(list_itr, rule_head, list_entry) {
 +		u8 *existing_mac = &list_itr->fltr_info.l_data.mac.mac_addr[0];
 +
 +		if (ether_addr_equal(existing_mac, umac)) {
 +			mutex_unlock(rule_lock);
 +			return true;
 +		}
 +	}
 +
 +	mutex_unlock(rule_lock);
 +
 +	return false;
 +}
 +
 +/**
 + * ice_set_vf_mac
 + * @netdev: network interface device structure
 + * @vf_id: VF identifier
 + * @mac: MAC address
 + *
 + * program VF MAC address
 + */
 +int ice_set_vf_mac(struct net_device *netdev, int vf_id, u8 *mac)
 +{
 +	struct ice_pf *pf = ice_netdev_to_pf(netdev);
 +	struct ice_vf *vf;
 +	int ret;
 +
 +	if (ice_validate_vf_id(pf, vf_id))
 +		return -EINVAL;
 +
 +	if (is_multicast_ether_addr(mac)) {
 +		netdev_err(netdev, "%pM not a valid unicast address\n", mac);
 +		return -EINVAL;
 +	}
 +
 +	vf = &pf->vf[vf_id];
 +	/* nothing left to do, unicast MAC already set */
 +	if (ether_addr_equal(vf->dev_lan_addr.addr, mac) &&
 +	    ether_addr_equal(vf->hw_lan_addr.addr, mac))
 +		return 0;
 +
 +	ret = ice_check_vf_ready_for_cfg(vf);
 +	if (ret)
 +		return ret;
 +
 +	if (ice_unicast_mac_exists(pf, mac)) {
 +		netdev_err(netdev, "Unicast MAC %pM already exists on this PF. Preventing setting VF %u unicast MAC address to %pM\n",
 +			   mac, vf_id, mac);
 +		return -EINVAL;
 +	}
 +
 +	mutex_lock(&vf->cfg_lock);
 +
 +	/* VF is notified of its new MAC via the PF's response to the
 +	 * VIRTCHNL_OP_GET_VF_RESOURCES message after the VF has been reset
 +	 */
 +	ether_addr_copy(vf->dev_lan_addr.addr, mac);
 +	ether_addr_copy(vf->hw_lan_addr.addr, mac);
 +	if (is_zero_ether_addr(mac)) {
 +		/* VF will send VIRTCHNL_OP_ADD_ETH_ADDR message with its MAC */
 +		vf->pf_set_mac = false;
 +		netdev_info(netdev, "Removing MAC on VF %d. VF driver will be reinitialized\n",
 +			    vf->vf_id);
 +	} else {
 +		/* PF will add MAC rule for the VF */
 +		vf->pf_set_mac = true;
 +		netdev_info(netdev, "Setting MAC %pM on VF %d. VF driver will be reinitialized\n",
 +			    mac, vf_id);
 +	}
 +
 +	ice_vc_reset_vf(vf);
 +	mutex_unlock(&vf->cfg_lock);
 +	return 0;
 +}
 +
 +/**
 + * ice_set_vf_trust
 + * @netdev: network interface device structure
 + * @vf_id: VF identifier
 + * @trusted: Boolean value to enable/disable trusted VF
 + *
 + * Enable or disable a given VF as trusted
 + */
 +int ice_set_vf_trust(struct net_device *netdev, int vf_id, bool trusted)
 +{
 +	struct ice_pf *pf = ice_netdev_to_pf(netdev);
 +	struct ice_vf *vf;
 +	int ret;
 +
 +	if (ice_is_eswitch_mode_switchdev(pf)) {
 +		dev_info(ice_pf_to_dev(pf), "Trusted VF is forbidden in switchdev mode\n");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	if (ice_validate_vf_id(pf, vf_id))
 +		return -EINVAL;
 +
 +	vf = &pf->vf[vf_id];
 +	ret = ice_check_vf_ready_for_cfg(vf);
 +	if (ret)
 +		return ret;
 +
 +	/* Check if already trusted */
 +	if (trusted == vf->trusted)
 +		return 0;
 +
 +	mutex_lock(&vf->cfg_lock);
 +
 +	vf->trusted = trusted;
 +	ice_vc_reset_vf(vf);
 +	dev_info(ice_pf_to_dev(pf), "VF %u is now %strusted\n",
 +		 vf_id, trusted ? "" : "un");
 +
 +	mutex_unlock(&vf->cfg_lock);
 +
 +	return 0;
 +}
 +
 +/**
 + * ice_set_vf_link_state
 + * @netdev: network interface device structure
 + * @vf_id: VF identifier
 + * @link_state: required link state
 + *
 + * Set VF's link state, irrespective of physical link state status
 + */
 +int ice_set_vf_link_state(struct net_device *netdev, int vf_id, int link_state)
 +{
 +	struct ice_pf *pf = ice_netdev_to_pf(netdev);
 +	struct ice_vf *vf;
 +	int ret;
 +
 +	if (ice_validate_vf_id(pf, vf_id))
 +		return -EINVAL;
 +
 +	vf = &pf->vf[vf_id];
 +	ret = ice_check_vf_ready_for_cfg(vf);
 +	if (ret)
 +		return ret;
 +
 +	switch (link_state) {
 +	case IFLA_VF_LINK_STATE_AUTO:
 +		vf->link_forced = false;
 +		break;
 +	case IFLA_VF_LINK_STATE_ENABLE:
 +		vf->link_forced = true;
 +		vf->link_up = true;
 +		break;
 +	case IFLA_VF_LINK_STATE_DISABLE:
 +		vf->link_forced = true;
 +		vf->link_up = false;
 +		break;
 +	default:
 +		return -EINVAL;
 +	}
 +
 +	ice_vc_notify_vf_link_state(vf);
 +
 +	return 0;
 +}
 +
 +/**
 + * ice_calc_all_vfs_min_tx_rate - calculate cumulative min Tx rate on all VFs
 + * @pf: PF associated with VFs
 + */
 +static int ice_calc_all_vfs_min_tx_rate(struct ice_pf *pf)
 +{
 +	int rate = 0, i;
 +
 +	ice_for_each_vf(pf, i)
 +		rate += pf->vf[i].min_tx_rate;
 +
 +	return rate;
 +}
 +
 +/**
 + * ice_min_tx_rate_oversubscribed - check if min Tx rate causes oversubscription
 + * @vf: VF trying to configure min_tx_rate
 + * @min_tx_rate: min Tx rate in Mbps
 + *
 + * Check if the min_tx_rate being passed in will cause oversubscription of total
 + * min_tx_rate based on the current link speed and all other VFs configured
 + * min_tx_rate
 + *
 + * Return true if the passed min_tx_rate would cause oversubscription, else
 + * return false
   */
 -void ice_virtchnl_set_repr_ops(struct ice_vf *vf)
 +static bool
 +ice_min_tx_rate_oversubscribed(struct ice_vf *vf, int min_tx_rate)
  {
 -	vf->virtchnl_ops = &ice_virtchnl_repr_ops;
 +	int link_speed_mbps = ice_get_link_speed_mbps(ice_get_vf_vsi(vf));
 +	int all_vfs_min_tx_rate = ice_calc_all_vfs_min_tx_rate(vf->pf);
 +
 +	/* this VF's previous rate is being overwritten */
 +	all_vfs_min_tx_rate -= vf->min_tx_rate;
 +
 +	if (all_vfs_min_tx_rate + min_tx_rate > link_speed_mbps) {
 +		dev_err(ice_pf_to_dev(vf->pf), "min_tx_rate of %d Mbps on VF %u would cause oversubscription of %d Mbps based on the current link speed %d Mbps\n",
 +			min_tx_rate, vf->vf_id,
 +			all_vfs_min_tx_rate + min_tx_rate - link_speed_mbps,
 +			link_speed_mbps);
 +		return true;
 +	}
 +
 +	return false;
  }
  
  /**
* Unmerged path drivers/net/ethernet/intel/ice/ice_lib.c
* Unmerged path drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
