iommu/iova: Move fast alloc size roundup into alloc_iova_fast()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author John Garry via iommu <iommu@lists.linux-foundation.org>
commit 972bf252f86062e50f9c9ea81f84f5df0e9f1302
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/972bf252.failed

It really is a property of the IOVA rcache code that we need to alloc a
power-of-2 size, so relocate the functionality to resize into
alloc_iova_fast(), rather than the callsites.

	Signed-off-by: John Garry <john.garry@huawei.com>
	Acked-by: Will Deacon <will@kernel.org>
	Reviewed-by: Xie Yongji <xieyongji@bytedance.com>
	Acked-by: Jason Wang <jasowang@redhat.com>
	Acked-by: Michael S. Tsirkin <mst@redhat.com>
	Acked-by: Robin Murphy <robin.murphy@arm.com>
Link: https://lore.kernel.org/r/1638875846-23993-1-git-send-email-john.garry@huawei.com
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 972bf252f86062e50f9c9ea81f84f5df0e9f1302)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/vdpa/vdpa_user/iova_domain.c
* Unmerged path drivers/vdpa/vdpa_user/iova_domain.c
diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.c
index 223a46c79116..9bd346fea6ec 100644
--- a/drivers/iommu/dma-iommu.c
+++ b/drivers/iommu/dma-iommu.c
@@ -435,14 +435,6 @@ static dma_addr_t iommu_dma_alloc_iova(struct iommu_domain *domain,
 
 	shift = iova_shift(iovad);
 	iova_len = size >> shift;
-	/*
-	 * Freeing non-power-of-two-sized allocations back into the IOVA caches
-	 * will come back to bite us badly, so we have to waste a bit of space
-	 * rounding up anything cacheable to make sure that can't happen. The
-	 * order of the unadjusted size will still match upon freeing.
-	 */
-	if (iova_len < (1 << (IOVA_RANGE_CACHE_MAX_SIZE - 1)))
-		iova_len = roundup_pow_of_two(iova_len);
 
 	dma_limit = min_not_zero(dma_limit, dev->bus_dma_limit);
 
diff --git a/drivers/iommu/iova.c b/drivers/iommu/iova.c
index 1c18cdc4d102..9a3de435624e 100644
--- a/drivers/iommu/iova.c
+++ b/drivers/iommu/iova.c
@@ -510,6 +510,15 @@ alloc_iova_fast(struct iova_domain *iovad, unsigned long size,
 	unsigned long iova_pfn;
 	struct iova *new_iova;
 
+	/*
+	 * Freeing non-power-of-two-sized allocations back into the IOVA caches
+	 * will come back to bite us badly, so we have to waste a bit of space
+	 * rounding up anything cacheable to make sure that can't happen. The
+	 * order of the unadjusted size will still match upon freeing.
+	 */
+	if (size < (1 << (IOVA_RANGE_CACHE_MAX_SIZE - 1)))
+		size = roundup_pow_of_two(size);
+
 	iova_pfn = iova_rcache_get(iovad, size, limit_pfn + 1);
 	if (iova_pfn)
 		return iova_pfn;
* Unmerged path drivers/vdpa/vdpa_user/iova_domain.c
