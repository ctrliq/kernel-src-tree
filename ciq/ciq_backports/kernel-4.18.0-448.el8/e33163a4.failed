ice: switch: convert packet template match code to rodata

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Alexander Lobakin <alexandr.lobakin@intel.com>
commit e33163a40d1a1f7fead2ce26f9b75da6b581a49e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/e33163a4.failed

Trade text size for rodata size and replace tons of nested if-elses
to the const mask match based structs. The almost entire
ice_find_dummy_packet() now becomes just one plain while-increment
loop. The order in ice_dummy_pkt_profiles[] should be same with the
if-elses order previously, as masks become less and less strict
through the array to follow the original code flow.
Apart from removing 80 locs of 4-level if-elses, it brings a solid
text size optimization:

add/remove: 0/1 grow/shrink: 1/1 up/down: 2/-1058 (-1056)
Function                                     old     new   delta
ice_fill_adv_dummy_packet                    289     291      +2
ice_adv_add_update_vsi_list                  201       -    -201
ice_add_adv_rule                            2950    2093    -857
Total: Before=414512, After=413456, chg -0.25%
add/remove: 53/52 grow/shrink: 0/0 up/down: 4660/-3988 (672)
RO Data                                      old     new   delta
ice_dummy_pkt_profiles                         -     672    +672
Total: Before=37895, After=38567, chg +1.77%

	Signed-off-by: Alexander Lobakin <alexandr.lobakin@intel.com>
	Reviewed-by: Michal Swiatkowski <michal.swiatkowski@linux.intel.com>
	Tested-by: Marcin Szycik <marcin.szycik@linux.intel.com>
	Tested-by: Sandeep Penigalapati <sandeep.penigalapati@intel.com>
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit e33163a40d1a1f7fead2ce26f9b75da6b581a49e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_switch.c
diff --cc drivers/net/ethernet/intel/ice/ice_switch.c
index 7b15835f7479,496250f9f8fc..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_switch.c
+++ b/drivers/net/ethernet/intel/ice/ice_switch.c
@@@ -35,7 -48,28 +48,32 @@@ struct ice_dummy_pkt_offsets 
  	u16 offset; /* ICE_PROTOCOL_LAST indicates end of list */
  };
  
++<<<<<<< HEAD
 +static const struct ice_dummy_pkt_offsets dummy_gre_tcp_packet_offsets[] = {
++=======
+ struct ice_dummy_pkt_profile {
+ 	const struct ice_dummy_pkt_offsets *offsets;
+ 	const u8 *pkt;
+ 	u32 match;
+ 	u16 pkt_len;
+ };
+ 
+ #define ICE_DECLARE_PKT_OFFSETS(type)				\
+ 	static const struct ice_dummy_pkt_offsets		\
+ 	ice_dummy_##type##_packet_offsets[]
+ 
+ #define ICE_DECLARE_PKT_TEMPLATE(type)				\
+ 	static const u8 ice_dummy_##type##_packet[]
+ 
+ #define ICE_PKT_PROFILE(type, m) {				\
+ 	.match		= (m),					\
+ 	.pkt		= ice_dummy_##type##_packet,		\
+ 	.pkt_len	= sizeof(ice_dummy_##type##_packet),	\
+ 	.offsets	= ice_dummy_##type##_packet_offsets,	\
+ }
+ 
+ ICE_DECLARE_PKT_OFFSETS(gre_tcp) = {
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  	{ ICE_MAC_OFOS,		0 },
  	{ ICE_ETYPE_OL,		12 },
  	{ ICE_IPV4_OFOS,	14 },
@@@ -5428,29 -5568,44 +5515,51 @@@ err_free_lkup_exts
   *	   structure per protocol header
   * @lkups_cnt: number of protocols
   * @tun_type: tunnel type
 - *
 - * Returns the &ice_dummy_pkt_profile corresponding to these lookup params.
 + * @pkt: dummy packet to fill according to filter match criteria
 + * @pkt_len: packet length of dummy packet
 + * @offsets: pointer to receive the pointer to the offsets for the packet
   */
++<<<<<<< HEAD
 +static void
++=======
+ static const struct ice_dummy_pkt_profile *
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  ice_find_dummy_packet(struct ice_adv_lkup_elem *lkups, u16 lkups_cnt,
 -		      enum ice_sw_tunnel_type tun_type)
 +		      enum ice_sw_tunnel_type tun_type,
 +		      const u8 **pkt, u16 *pkt_len,
 +		      const struct ice_dummy_pkt_offsets **offsets)
  {
- 	bool inner_tcp = false, inner_udp = false, outer_ipv6 = false;
- 	bool vlan = false, inner_ipv6 = false, gtp_no_pay = false;
+ 	const struct ice_dummy_pkt_profile *ret = ice_dummy_pkt_profiles;
+ 	u32 match = 0;
  	u16 i;
  
+ 	switch (tun_type) {
+ 	case ICE_SW_TUN_GTPC:
+ 		match |= ICE_PKT_TUN_GTPC;
+ 		break;
+ 	case ICE_SW_TUN_GTPU:
+ 		match |= ICE_PKT_TUN_GTPU;
+ 		break;
+ 	case ICE_SW_TUN_NVGRE:
+ 		match |= ICE_PKT_TUN_NVGRE;
+ 		break;
+ 	case ICE_SW_TUN_GENEVE:
+ 	case ICE_SW_TUN_VXLAN:
+ 		match |= ICE_PKT_TUN_UDP;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
  	for (i = 0; i < lkups_cnt; i++) {
  		if (lkups[i].type == ICE_UDP_ILOS)
- 			inner_udp = true;
+ 			match |= ICE_PKT_INNER_UDP;
  		else if (lkups[i].type == ICE_TCP_IL)
- 			inner_tcp = true;
+ 			match |= ICE_PKT_INNER_TCP;
  		else if (lkups[i].type == ICE_IPV6_OFOS)
- 			outer_ipv6 = true;
+ 			match |= ICE_PKT_OUTER_IPV6;
  		else if (lkups[i].type == ICE_VLAN_OFOS)
- 			vlan = true;
+ 			match |= ICE_PKT_VLAN;
  		else if (lkups[i].type == ICE_ETYPE_OL &&
  			 lkups[i].h_u.ethertype.ethtype_id ==
  				cpu_to_be16(ICE_IPV6_ETHER_ID) &&
@@@ -5462,178 -5617,17 +5571,185 @@@
  				cpu_to_be16(ICE_IPV6_ETHER_ID) &&
  			 lkups[i].m_u.ethertype.ethtype_id ==
  				cpu_to_be16(0xFFFF))
- 			inner_ipv6 = true;
+ 			match |= ICE_PKT_INNER_IPV6;
  		else if (lkups[i].type == ICE_IPV6_IL)
- 			inner_ipv6 = true;
+ 			match |= ICE_PKT_INNER_IPV6;
  		else if (lkups[i].type == ICE_GTP_NO_PAY)
- 			gtp_no_pay = true;
+ 			match |= ICE_PKT_GTP_NOPAY;
  	}
  
++<<<<<<< HEAD
 +	if (tun_type == ICE_SW_TUN_GTPU) {
 +		if (outer_ipv6) {
 +			if (gtp_no_pay) {
 +				*pkt = dummy_ipv6_gtp_packet;
 +				*pkt_len = sizeof(dummy_ipv6_gtp_packet);
 +				*offsets = dummy_ipv6_gtp_no_pay_packet_offsets;
 +			} else if (inner_ipv6) {
 +				if (inner_udp) {
 +					*pkt = dummy_ipv6_gtpu_ipv6_udp_packet;
 +					*pkt_len = sizeof(dummy_ipv6_gtpu_ipv6_udp_packet);
 +					*offsets = dummy_ipv6_gtpu_ipv6_udp_packet_offsets;
 +				} else {
 +					*pkt = dummy_ipv6_gtpu_ipv6_tcp_packet;
 +					*pkt_len = sizeof(dummy_ipv6_gtpu_ipv6_tcp_packet);
 +					*offsets = dummy_ipv6_gtpu_ipv6_tcp_packet_offsets;
 +				}
 +			} else {
 +				if (inner_udp) {
 +					*pkt = dummy_ipv6_gtpu_ipv4_udp_packet;
 +					*pkt_len = sizeof(dummy_ipv6_gtpu_ipv4_udp_packet);
 +					*offsets = dummy_ipv6_gtpu_ipv4_udp_packet_offsets;
 +				} else {
 +					*pkt = dummy_ipv6_gtpu_ipv4_tcp_packet;
 +				*pkt_len = sizeof(dummy_ipv6_gtpu_ipv4_tcp_packet);
 +					*offsets = dummy_ipv6_gtpu_ipv4_tcp_packet_offsets;
 +				}
 +			}
 +		} else {
 +			if (gtp_no_pay) {
 +				*pkt = dummy_ipv4_gtpu_ipv4_packet;
 +				*pkt_len = sizeof(dummy_ipv4_gtpu_ipv4_packet);
 +				*offsets = dummy_ipv4_gtp_no_pay_packet_offsets;
 +			} else if (inner_ipv6) {
 +				if (inner_udp) {
 +					*pkt = dummy_ipv4_gtpu_ipv6_udp_packet;
 +					*pkt_len = sizeof(dummy_ipv4_gtpu_ipv6_udp_packet);
 +					*offsets = dummy_ipv4_gtpu_ipv6_udp_packet_offsets;
 +				} else {
 +					*pkt = dummy_ipv4_gtpu_ipv6_tcp_packet;
 +					*pkt_len = sizeof(dummy_ipv4_gtpu_ipv6_tcp_packet);
 +					*offsets = dummy_ipv4_gtpu_ipv6_tcp_packet_offsets;
 +				}
 +			} else {
 +				if (inner_udp) {
 +					*pkt = dummy_ipv4_gtpu_ipv4_udp_packet;
 +					*pkt_len = sizeof(dummy_ipv4_gtpu_ipv4_udp_packet);
 +					*offsets = dummy_ipv4_gtpu_ipv4_udp_packet_offsets;
 +				} else {
 +					*pkt = dummy_ipv4_gtpu_ipv4_tcp_packet;
 +					*pkt_len = sizeof(dummy_ipv4_gtpu_ipv4_tcp_packet);
 +					*offsets = dummy_ipv4_gtpu_ipv4_tcp_packet_offsets;
 +				}
 +			}
 +		}
 +		return;
 +	}
 +
 +	if (tun_type == ICE_SW_TUN_GTPC) {
 +		if (outer_ipv6) {
 +			*pkt = dummy_ipv6_gtp_packet;
 +			*pkt_len = sizeof(dummy_ipv6_gtp_packet);
 +			*offsets = dummy_ipv6_gtp_no_pay_packet_offsets;
 +		} else {
 +			*pkt = dummy_ipv4_gtpu_ipv4_packet;
 +			*pkt_len = sizeof(dummy_ipv4_gtpu_ipv4_packet);
 +			*offsets = dummy_ipv4_gtp_no_pay_packet_offsets;
 +		}
 +		return;
 +	}
 +
 +	if (tun_type == ICE_SW_TUN_NVGRE) {
 +		if (inner_tcp && inner_ipv6) {
 +			*pkt = dummy_gre_ipv6_tcp_packet;
 +			*pkt_len = sizeof(dummy_gre_ipv6_tcp_packet);
 +			*offsets = dummy_gre_ipv6_tcp_packet_offsets;
 +			return;
 +		}
 +		if (inner_tcp) {
 +			*pkt = dummy_gre_tcp_packet;
 +			*pkt_len = sizeof(dummy_gre_tcp_packet);
 +			*offsets = dummy_gre_tcp_packet_offsets;
 +			return;
 +		}
 +		if (inner_ipv6) {
 +			*pkt = dummy_gre_ipv6_udp_packet;
 +			*pkt_len = sizeof(dummy_gre_ipv6_udp_packet);
 +			*offsets = dummy_gre_ipv6_udp_packet_offsets;
 +			return;
 +		}
 +		*pkt = dummy_gre_udp_packet;
 +		*pkt_len = sizeof(dummy_gre_udp_packet);
 +		*offsets = dummy_gre_udp_packet_offsets;
 +		return;
 +	}
 +
 +	if (tun_type == ICE_SW_TUN_VXLAN ||
 +	    tun_type == ICE_SW_TUN_GENEVE) {
 +		if (inner_tcp && inner_ipv6) {
 +			*pkt = dummy_udp_tun_ipv6_tcp_packet;
 +			*pkt_len = sizeof(dummy_udp_tun_ipv6_tcp_packet);
 +			*offsets = dummy_udp_tun_ipv6_tcp_packet_offsets;
 +			return;
 +		}
 +		if (inner_tcp) {
 +			*pkt = dummy_udp_tun_tcp_packet;
 +			*pkt_len = sizeof(dummy_udp_tun_tcp_packet);
 +			*offsets = dummy_udp_tun_tcp_packet_offsets;
 +			return;
 +		}
 +		if (inner_ipv6) {
 +			*pkt = dummy_udp_tun_ipv6_udp_packet;
 +			*pkt_len = sizeof(dummy_udp_tun_ipv6_udp_packet);
 +			*offsets = dummy_udp_tun_ipv6_udp_packet_offsets;
 +			return;
 +		}
 +		*pkt = dummy_udp_tun_udp_packet;
 +		*pkt_len = sizeof(dummy_udp_tun_udp_packet);
 +		*offsets = dummy_udp_tun_udp_packet_offsets;
 +		return;
 +	}
 +
 +	if (inner_udp && !outer_ipv6) {
 +		if (vlan) {
 +			*pkt = dummy_vlan_udp_packet;
 +			*pkt_len = sizeof(dummy_vlan_udp_packet);
 +			*offsets = dummy_vlan_udp_packet_offsets;
 +			return;
 +		}
 +		*pkt = dummy_udp_packet;
 +		*pkt_len = sizeof(dummy_udp_packet);
 +		*offsets = dummy_udp_packet_offsets;
 +		return;
 +	} else if (inner_udp && outer_ipv6) {
 +		if (vlan) {
 +			*pkt = dummy_vlan_udp_ipv6_packet;
 +			*pkt_len = sizeof(dummy_vlan_udp_ipv6_packet);
 +			*offsets = dummy_vlan_udp_ipv6_packet_offsets;
 +			return;
 +		}
 +		*pkt = dummy_udp_ipv6_packet;
 +		*pkt_len = sizeof(dummy_udp_ipv6_packet);
 +		*offsets = dummy_udp_ipv6_packet_offsets;
 +		return;
 +	} else if ((inner_tcp && outer_ipv6) || outer_ipv6) {
 +		if (vlan) {
 +			*pkt = dummy_vlan_tcp_ipv6_packet;
 +			*pkt_len = sizeof(dummy_vlan_tcp_ipv6_packet);
 +			*offsets = dummy_vlan_tcp_ipv6_packet_offsets;
 +			return;
 +		}
 +		*pkt = dummy_tcp_ipv6_packet;
 +		*pkt_len = sizeof(dummy_tcp_ipv6_packet);
 +		*offsets = dummy_tcp_ipv6_packet_offsets;
 +		return;
 +	}
 +
 +	if (vlan) {
 +		*pkt = dummy_vlan_tcp_packet;
 +		*pkt_len = sizeof(dummy_vlan_tcp_packet);
 +		*offsets = dummy_vlan_tcp_packet_offsets;
 +	} else {
 +		*pkt = dummy_tcp_packet;
 +		*pkt_len = sizeof(dummy_tcp_packet);
 +		*offsets = dummy_tcp_packet_offsets;
 +	}
++=======
+ 	while (ret->match && (match & ret->match) != ret->match)
+ 		ret++;
+ 
+ 	return ret;
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  }
  
  /**
@@@ -5971,12 -5963,11 +6087,17 @@@ ice_add_adv_rule(struct ice_hw *hw, str
  		 struct ice_rule_query_data *added_entry)
  {
  	struct ice_adv_fltr_mgmt_list_entry *m_entry, *adv_fltr = NULL;
 +	u16 rid = 0, i, pkt_len, rule_buf_sz, vsi_handle;
 +	const struct ice_dummy_pkt_offsets *pkt_offsets;
  	struct ice_aqc_sw_rules_elem *s_rule = NULL;
++<<<<<<< HEAD
++=======
+ 	const struct ice_dummy_pkt_profile *profile;
+ 	u16 rid = 0, i, rule_buf_sz, vsi_handle;
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  	struct list_head *rule_head;
  	struct ice_switch_info *sw;
 +	const u8 *pkt = NULL;
  	u16 word_cnt;
  	u32 act = 0;
  	int status;
@@@ -6051,7 -6037,7 +6172,11 @@@
  		}
  		return status;
  	}
++<<<<<<< HEAD
 +	rule_buf_sz = ICE_SW_RULE_RX_TX_NO_HDR_SIZE + pkt_len;
++=======
+ 	rule_buf_sz = ICE_SW_RULE_RX_TX_NO_HDR_SIZE + profile->pkt_len;
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  	s_rule = kzalloc(rule_buf_sz, GFP_KERNEL);
  	if (!s_rule)
  		return -ENOMEM;
@@@ -6111,8 -6097,7 +6236,12 @@@
  	s_rule->pdata.lkup_tx_rx.recipe_id = cpu_to_le16(rid);
  	s_rule->pdata.lkup_tx_rx.act = cpu_to_le32(act);
  
++<<<<<<< HEAD
 +	status = ice_fill_adv_dummy_packet(lkups, lkups_cnt, s_rule, pkt,
 +					   pkt_len, pkt_offsets);
++=======
+ 	status = ice_fill_adv_dummy_packet(lkups, lkups_cnt, s_rule, profile);
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  	if (status)
  		goto err_ice_add_adv_rule;
  
@@@ -6120,7 -6105,7 +6249,11 @@@
  	    rinfo->tun_type != ICE_SW_TUN_AND_NON_TUN) {
  		status = ice_fill_adv_packet_tun(hw, rinfo->tun_type,
  						 s_rule->pdata.lkup_tx_rx.hdr,
++<<<<<<< HEAD
 +						 pkt_offsets);
++=======
+ 						 profile->offsets);
++>>>>>>> e33163a40d1a (ice: switch: convert packet template match code to rodata)
  		if (status)
  			goto err_ice_add_adv_rule;
  	}
* Unmerged path drivers/net/ethernet/intel/ice/ice_switch.c
