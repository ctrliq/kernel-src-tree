ice: remove PF pointer from ice_check_vf_init

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Jacob Keller <jacob.e.keller@intel.com>
commit 5a57ee83d9612342552f63b7a7f4f4bd2e885832
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/5a57ee83.failed

The ice_check_vf_init function takes both a PF and a VF pointer. Every
caller looks up the PF pointer from the VF structure. Some callers only
use of the PF pointer is call this function. Move the lookup inside
ice_check_vf_init and drop the unnecessary argument.

Cleanup the callers to drop the now unnecessary local variables. In
particular, replace the local PF pointer with a HW structure pointer in
ice_vc_get_vf_res_msg which simplifies a few accesses to the HW
structure in that function.

	Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
	Tested-by: Konrad Jankowski <konrad0.jankowski@intel.com>
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit 5a57ee83d9612342552f63b7a7f4f4bd2e885832)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_vf_lib.c
#	drivers/net/ethernet/intel/ice/ice_vf_lib_private.h
#	drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
diff --cc drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
index e45882c22848,3f1a63815bac..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
+++ b/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
@@@ -2186,119 -1897,163 +2186,153 @@@ static u16 ice_vc_get_max_frame_size(st
  }
  
  /**
 - * ice_vc_handle_mac_addr_msg
 + * ice_vc_get_vf_res_msg
   * @vf: pointer to the VF info
   * @msg: pointer to the msg buffer
 - * @set: true if MAC filters are being set, false otherwise
   *
 - * add guest MAC address filter
 + * called from the VF to request its resources
   */
 -static int
 -ice_vc_handle_mac_addr_msg(struct ice_vf *vf, u8 *msg, bool set)
 +static int ice_vc_get_vf_res_msg(struct ice_vf *vf, u8 *msg)
  {
 -	int (*ice_vc_cfg_mac)
 -		(struct ice_vf *vf, struct ice_vsi *vsi,
 -		 struct virtchnl_ether_addr *virtchnl_ether_addr);
  	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 -	struct virtchnl_ether_addr_list *al =
 -	    (struct virtchnl_ether_addr_list *)msg;
 -	struct ice_pf *pf = vf->pf;
 -	enum virtchnl_ops vc_op;
 +	struct virtchnl_vf_resource *vfres = NULL;
- 	struct ice_pf *pf = vf->pf;
++	struct ice_hw *hw = &vf->pf->hw;
  	struct ice_vsi *vsi;
 -	int i;
 -
 -	if (set) {
 -		vc_op = VIRTCHNL_OP_ADD_ETH_ADDR;
 -		ice_vc_cfg_mac = ice_vc_add_mac_addr;
 -	} else {
 -		vc_op = VIRTCHNL_OP_DEL_ETH_ADDR;
 -		ice_vc_cfg_mac = ice_vc_del_mac_addr;
 -	}
 +	int len = 0;
 +	int ret;
  
- 	if (ice_check_vf_init(pf, vf)) {
 -	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states) ||
 -	    !ice_vc_isvalid_vsi_id(vf, al->vsi_id)) {
++	if (ice_check_vf_init(vf)) {
  		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 -		goto handle_mac_exit;
 +		goto err;
  	}
  
 -	/* If this VF is not privileged, then we can't add more than a
 -	 * limited number of addresses. Check to make sure that the
 -	 * additions do not push us over the limit.
 -	 */
 -	if (set && !ice_is_vf_trusted(vf) &&
 -	    (vf->num_mac + al->num_elements) > ICE_MAX_MACADDR_PER_VF) {
 -		dev_err(ice_pf_to_dev(pf), "Can't add more MAC addresses, because VF-%d is not trusted, switch the VF to trusted mode in order to add more functionalities\n",
 -			vf->vf_id);
 -		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 -		goto handle_mac_exit;
 +	len = sizeof(struct virtchnl_vf_resource);
 +
 +	vfres = kzalloc(len, GFP_KERNEL);
 +	if (!vfres) {
 +		v_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;
 +		len = 0;
 +		goto err;
  	}
 +	if (VF_IS_V11(&vf->vf_ver))
 +		vf->driver_caps = *(u32 *)msg;
 +	else
 +		vf->driver_caps = VIRTCHNL_VF_OFFLOAD_L2 |
 +				  VIRTCHNL_VF_OFFLOAD_RSS_REG |
 +				  VIRTCHNL_VF_OFFLOAD_VLAN;
  
 +	vfres->vf_cap_flags = VIRTCHNL_VF_OFFLOAD_L2;
  	vsi = ice_get_vf_vsi(vf);
  	if (!vsi) {
  		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 -		goto handle_mac_exit;
 +		goto err;
  	}
  
 -	for (i = 0; i < al->num_elements; i++) {
 -		u8 *mac_addr = al->list[i].addr;
 -		int result;
 -
 -		if (is_broadcast_ether_addr(mac_addr) ||
 -		    is_zero_ether_addr(mac_addr))
 -			continue;
 -
 -		result = ice_vc_cfg_mac(vf, vsi, &al->list[i]);
 -		if (result == -EEXIST || result == -ENOENT) {
 -			continue;
 -		} else if (result) {
 -			v_ret = VIRTCHNL_STATUS_ERR_ADMIN_QUEUE_ERROR;
 -			goto handle_mac_exit;
++<<<<<<< HEAD:drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
 +	if (!vsi->info.pvid)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_VLAN;
++=======
++	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_VLAN_V2) {
++		/* VLAN offloads based on current device configuration */
++		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_VLAN_V2;
++	} else if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_VLAN) {
++		/* allow VF to negotiate VIRTCHNL_VF_OFFLOAD explicitly for
++		 * these two conditions, which amounts to guest VLAN filtering
++		 * and offloads being based on the inner VLAN or the
++		 * inner/single VLAN respectively and don't allow VF to
++		 * negotiate VIRTCHNL_VF_OFFLOAD in any other cases
++		 */
++		if (ice_is_dvm_ena(hw) && ice_vf_is_port_vlan_ena(vf)) {
++			vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_VLAN;
++		} else if (!ice_is_dvm_ena(hw) &&
++			   !ice_vf_is_port_vlan_ena(vf)) {
++			vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_VLAN;
++			/* configure backward compatible support for VFs that
++			 * only support VIRTCHNL_VF_OFFLOAD_VLAN, the PF is
++			 * configured in SVM, and no port VLAN is configured
++			 */
++			ice_vf_vsi_cfg_svm_legacy_vlan_mode(vsi);
++		} else if (ice_is_dvm_ena(hw)) {
++			/* configure software offloaded VLAN support when DVM
++			 * is enabled, but no port VLAN is enabled
++			 */
++			ice_vf_vsi_cfg_dvm_legacy_vlan_mode(vsi);
+ 		}
+ 	}
++>>>>>>> 5a57ee83d961 (ice: remove PF pointer from ice_check_vf_init):drivers/net/ethernet/intel/ice/ice_virtchnl.c
  
 -handle_mac_exit:
 -	/* send the response to the VF */
 -	return ice_vc_send_msg_to_vf(vf, vc_op, v_ret, NULL, 0);
 -}
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_RSS_PF) {
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_RSS_PF;
 +	} else {
 +		if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_RSS_AQ)
 +			vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_RSS_AQ;
 +		else
 +			vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_RSS_REG;
 +	}
  
 -/**
 - * ice_vc_add_mac_addr_msg
 - * @vf: pointer to the VF info
 - * @msg: pointer to the msg buffer
 - *
 - * add guest MAC address filter
 - */
 -static int ice_vc_add_mac_addr_msg(struct ice_vf *vf, u8 *msg)
 -{
 -	return ice_vc_handle_mac_addr_msg(vf, msg, true);
 -}
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_FDIR_PF)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_FDIR_PF;
  
 -/**
 - * ice_vc_del_mac_addr_msg
 - * @vf: pointer to the VF info
 - * @msg: pointer to the msg buffer
 - *
 - * remove guest MAC address filter
 - */
 -static int ice_vc_del_mac_addr_msg(struct ice_vf *vf, u8 *msg)
 -{
 -	return ice_vc_handle_mac_addr_msg(vf, msg, false);
 -}
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_RSS_PCTYPE_V2)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_RSS_PCTYPE_V2;
  
 -/**
 - * ice_vc_request_qs_msg
 - * @vf: pointer to the VF info
 - * @msg: pointer to the msg buffer
 - *
 - * VFs get a default number of queues but can use this message to request a
 - * different number. If the request is successful, PF will reset the VF and
 - * return 0. If unsuccessful, PF will send message informing VF of number of
 - * available queue pairs via virtchnl message response to VF.
 - */
 -static int ice_vc_request_qs_msg(struct ice_vf *vf, u8 *msg)
 -{
 -	enum virtchnl_status_code v_ret = VIRTCHNL_STATUS_SUCCESS;
 -	struct virtchnl_vf_res_request *vfres =
 -		(struct virtchnl_vf_res_request *)msg;
 -	u16 req_queues = vfres->num_queue_pairs;
 -	struct ice_pf *pf = vf->pf;
 -	u16 max_allowed_vf_queues;
 -	u16 tx_rx_queue_left;
 -	struct device *dev;
 -	u16 cur_queues;
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_ENCAP)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_ENCAP;
  
 -	dev = ice_pf_to_dev(pf);
 -	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states)) {
 -		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
 -		goto error_param;
 -	}
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_ENCAP_CSUM)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_ENCAP_CSUM;
  
 -	cur_queues = vf->num_vf_qs;
 -	tx_rx_queue_left = min_t(u16, ice_get_avail_txq_count(pf),
 -				 ice_get_avail_rxq_count(pf));
 -	max_allowed_vf_queues = tx_rx_queue_left + cur_queues;
 -	if (!req_queues) {
 -		dev_err(dev, "VF %d tried to request 0 queues. Ignoring.\n",
 -			vf->vf_id);
 -	} else if (req_queues > ICE_MAX_RSS_QS_PER_VF) {
 -		dev_err(dev, "VF %d tried to request more than %d queues.\n",
 -			vf->vf_id, ICE_MAX_RSS_QS_PER_VF);
 -		vfres->num_queue_pairs = ICE_MAX_RSS_QS_PER_VF;
 -	} else if (req_queues > cur_queues &&
 -		   req_queues - cur_queues > tx_rx_queue_left) {
 -		dev_warn(dev, "VF %d requested %u more queues, but only %u left.\n",
 -			 vf->vf_id, req_queues - cur_queues, tx_rx_queue_left);
 -		vfres->num_queue_pairs = min_t(u16, max_allowed_vf_queues,
 -					       ICE_MAX_RSS_QS_PER_VF);
 -	} else {
 -		/* request is successful, then reset VF */
 -		vf->num_req_qs = req_queues;
 -		ice_reset_vf(vf, ICE_VF_RESET_NOTIFY);
 -		dev_info(dev, "VF %d granted request of %u queues.\n",
 -			 vf->vf_id, req_queues);
 -		return 0;
 -	}
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_RX_POLLING)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_RX_POLLING;
  
 -error_param:
 -	/* send the response to the VF */
 -	return ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_REQUEST_QUEUES,
 -				     v_ret, (u8 *)vfres, sizeof(*vfres));
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_WB_ON_ITR)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_WB_ON_ITR;
 +
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_REQ_QUEUES)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_REQ_QUEUES;
 +
 +	if (vf->driver_caps & VIRTCHNL_VF_CAP_ADV_LINK_SPEED)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_CAP_ADV_LINK_SPEED;
 +
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_ADV_RSS_PF)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_ADV_RSS_PF;
 +
 +	if (vf->driver_caps & VIRTCHNL_VF_OFFLOAD_USO)
 +		vfres->vf_cap_flags |= VIRTCHNL_VF_OFFLOAD_USO;
 +
 +	vfres->num_vsis = 1;
 +	/* Tx and Rx queue are equal for VF */
 +	vfres->num_queue_pairs = vsi->num_txq;
++<<<<<<< HEAD:drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
 +	vfres->max_vectors = pf->num_msix_per_vf;
++=======
++	vfres->max_vectors = vf->pf->vfs.num_msix_per;
++>>>>>>> 5a57ee83d961 (ice: remove PF pointer from ice_check_vf_init):drivers/net/ethernet/intel/ice/ice_virtchnl.c
 +	vfres->rss_key_size = ICE_VSIQF_HKEY_ARRAY_SIZE;
 +	vfres->rss_lut_size = ICE_VSIQF_HLUT_ARRAY_SIZE;
 +	vfres->max_mtu = ice_vc_get_max_frame_size(vf);
 +
 +	vfres->vsi_res[0].vsi_id = vf->lan_vsi_num;
 +	vfres->vsi_res[0].vsi_type = VIRTCHNL_VSI_SRIOV;
 +	vfres->vsi_res[0].num_queue_pairs = vsi->num_txq;
 +	ether_addr_copy(vfres->vsi_res[0].default_mac_addr,
 +			vf->hw_lan_addr.addr);
 +
 +	/* match guest capabilities */
 +	vf->driver_caps = vfres->vf_cap_flags;
 +
 +	ice_vc_set_caps_allowlist(vf);
 +	ice_vc_set_working_allowlist(vf);
 +
 +	set_bit(ICE_VF_STATE_ACTIVE, vf->vf_states);
 +
 +err:
 +	/* send the response back to the VF */
 +	ret = ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_GET_VF_RESOURCES, v_ret,
 +				    (u8 *)vfres, len);
 +
 +	kfree(vfres);
 +	return ret;
  }
  
  /**
* Unmerged path drivers/net/ethernet/intel/ice/ice_vf_lib.c
* Unmerged path drivers/net/ethernet/intel/ice/ice_vf_lib_private.h
* Unmerged path drivers/net/ethernet/intel/ice/ice_vf_lib.c
* Unmerged path drivers/net/ethernet/intel/ice/ice_vf_lib_private.h
* Unmerged path drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
