drm/i915: add i915_gem_object_create_region_at()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Matthew Auld <matthew.auld@intel.com>
commit 9b78b5dade2d26e2b77f1ac27044946e4e8e7247
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/9b78b5da.failed

Add a generic interface for allocating an object at some specific
offset, and convert stolen over. Later we will want to hook this up to
different backends.

	Signed-off-by: Matthew Auld <matthew.auld@intel.com>
	Cc: Thomas Hellstr√∂m <thomas.hellstrom@linux.intel.com>
	Reviewed-by: Nirmoy Das <nirmoy.das@linux.intel.com>
Link: https://patchwork.freedesktop.org/patch/msgid/20220315181425.576828-4-matthew.auld@intel.com
(cherry picked from commit 9b78b5dade2d26e2b77f1ac27044946e4e8e7247)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/display/intel_plane_initial.c
#	drivers/gpu/drm/i915/gem/i915_gem_create.c
#	drivers/gpu/drm/i915/gem/i915_gem_region.c
#	drivers/gpu/drm/i915/gem/i915_gem_region.h
#	drivers/gpu/drm/i915/gem/i915_gem_ttm.c
#	drivers/gpu/drm/i915/gem/i915_gem_ttm.h
diff --cc drivers/gpu/drm/i915/gem/i915_gem_create.c
index 548ddf39d853,5802692ea604..000000000000
--- a/drivers/gpu/drm/i915/gem/i915_gem_create.c
+++ b/drivers/gpu/drm/i915/gem/i915_gem_create.c
@@@ -82,20 -107,25 +82,24 @@@ i915_gem_setup(struct drm_i915_gem_obje
  	GEM_BUG_ON(!IS_ALIGNED(size, PAGE_SIZE));
  
  	if (i915_gem_object_size_2big(size))
 -		return ERR_PTR(-E2BIG);
 -
 -	obj = i915_gem_object_alloc();
 -	if (!obj)
 -		return ERR_PTR(-ENOMEM);
 -
 -	ret = object_set_placements(obj, placements, n_placements);
 -	if (ret)
 -		goto object_free;
 +		return -E2BIG;
  
  	/*
 -	 * I915_BO_ALLOC_USER will make sure the object is cleared before
 -	 * any user access.
 +	 * For now resort to CPU based clearing for device local-memory, in the
 +	 * near future this will use the blitter engine for accelerated, GPU
 +	 * based clearing.
  	 */
 -	flags = I915_BO_ALLOC_USER;
 +	flags = 0;
 +	if (mr->type == INTEL_MEMORY_LOCAL)
 +		flags = I915_BO_ALLOC_CPU_CLEAR;
  
++<<<<<<< HEAD
 +	ret = mr->ops->init_object(mr, obj, size, flags);
++=======
+ 	ret = mr->ops->init_object(mr, obj, I915_BO_INVALID_OFFSET, size, 0, flags);
++>>>>>>> 9b78b5dade2d (drm/i915: add i915_gem_object_create_region_at())
  	if (ret)
 -		goto object_free;
 +		return ret;
  
  	GEM_BUG_ON(size != obj->base.size);
  
diff --cc drivers/gpu/drm/i915/gem/i915_gem_region.c
index f25e6646c5b7,3428ddfb2fdb..000000000000
--- a/drivers/gpu/drm/i915/gem/i915_gem_region.c
+++ b/drivers/gpu/drm/i915/gem/i915_gem_region.c
@@@ -33,16 -25,17 +33,25 @@@ void i915_gem_object_release_memory_reg
  	mutex_lock(&mem->objects.lock);
  	list_del(&obj->mm.region_link);
  	mutex_unlock(&mem->objects.lock);
 +
 +	intel_memory_region_put(mem);
  }
  
++<<<<<<< HEAD
 +struct drm_i915_gem_object *
 +i915_gem_object_create_region(struct intel_memory_region *mem,
 +			      resource_size_t size,
 +			      unsigned int flags)
++=======
+ static struct drm_i915_gem_object *
+ __i915_gem_object_create_region(struct intel_memory_region *mem,
+ 				resource_size_t offset,
+ 				resource_size_t size,
+ 				resource_size_t page_size,
+ 				unsigned int flags)
++>>>>>>> 9b78b5dade2d (drm/i915: add i915_gem_object_create_region_at())
  {
  	struct drm_i915_gem_object *obj;
 -	resource_size_t default_page_size;
  	int err;
  
  	/*
@@@ -68,7 -76,18 +77,22 @@@
  	if (!obj)
  		return ERR_PTR(-ENOMEM);
  
++<<<<<<< HEAD
 +	err = mem->ops->init_object(mem, obj, size, flags);
++=======
+ 	/*
+ 	 * Anything smaller than the min_page_size can't be freely inserted into
+ 	 * the GTT, due to alignemnt restrictions. For such special objects,
+ 	 * make sure we force memcpy based suspend-resume. In the future we can
+ 	 * revisit this, either by allowing special mis-aligned objects in the
+ 	 * migration path, or by mapping all of LMEM upfront using cheap 1G
+ 	 * GTT entries.
+ 	 */
+ 	if (default_page_size < mem->min_page_size)
+ 		flags |= I915_BO_ALLOC_PM_EARLY;
+ 
+ 	err = mem->ops->init_object(mem, obj, offset, size, page_size, flags);
++>>>>>>> 9b78b5dade2d (drm/i915: add i915_gem_object_create_region_at())
  	if (err)
  		goto err_object_free;
  
@@@ -79,3 -98,107 +103,110 @@@ err_object_free
  	i915_gem_object_free(obj);
  	return ERR_PTR(err);
  }
++<<<<<<< HEAD
++=======
+ 
+ struct drm_i915_gem_object *
+ i915_gem_object_create_region(struct intel_memory_region *mem,
+ 			      resource_size_t size,
+ 			      resource_size_t page_size,
+ 			      unsigned int flags)
+ {
+ 	return __i915_gem_object_create_region(mem, I915_BO_INVALID_OFFSET,
+ 					       size, page_size, flags);
+ }
+ 
+ struct drm_i915_gem_object *
+ i915_gem_object_create_region_at(struct intel_memory_region *mem,
+ 				 resource_size_t offset,
+ 				 resource_size_t size,
+ 				 unsigned int flags)
+ {
+ 	GEM_BUG_ON(offset == I915_BO_INVALID_OFFSET);
+ 
+ 	if (GEM_WARN_ON(!IS_ALIGNED(size, mem->min_page_size)) ||
+ 	    GEM_WARN_ON(!IS_ALIGNED(offset, mem->min_page_size)))
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	if (range_overflows(offset, size, resource_size(&mem->region)))
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	if (!(flags & I915_BO_ALLOC_GPU_ONLY) &&
+ 	    offset + size > mem->io_size &&
+ 	    !i915_ggtt_has_aperture(to_gt(mem->i915)->ggtt))
+ 		return ERR_PTR(-ENOSPC);
+ 
+ 	return __i915_gem_object_create_region(mem, offset, size, 0,
+ 					       flags | I915_BO_ALLOC_CONTIGUOUS);
+ }
+ 
+ /**
+  * i915_gem_process_region - Iterate over all objects of a region using ops
+  * to process and optionally skip objects
+  * @mr: The memory region
+  * @apply: ops and private data
+  *
+  * This function can be used to iterate over the regions object list,
+  * checking whether to skip objects, and, if not, lock the objects and
+  * process them using the supplied ops. Note that this function temporarily
+  * removes objects from the region list while iterating, so that if run
+  * concurrently with itself may not iterate over all objects.
+  *
+  * Return: 0 if successful, negative error code on failure.
+  */
+ int i915_gem_process_region(struct intel_memory_region *mr,
+ 			    struct i915_gem_apply_to_region *apply)
+ {
+ 	const struct i915_gem_apply_to_region_ops *ops = apply->ops;
+ 	struct drm_i915_gem_object *obj;
+ 	struct list_head still_in_list;
+ 	int ret = 0;
+ 
+ 	/*
+ 	 * In the future, a non-NULL apply->ww could mean the caller is
+ 	 * already in a locking transaction and provides its own context.
+ 	 */
+ 	GEM_WARN_ON(apply->ww);
+ 
+ 	INIT_LIST_HEAD(&still_in_list);
+ 	mutex_lock(&mr->objects.lock);
+ 	for (;;) {
+ 		struct i915_gem_ww_ctx ww;
+ 
+ 		obj = list_first_entry_or_null(&mr->objects.list, typeof(*obj),
+ 					       mm.region_link);
+ 		if (!obj)
+ 			break;
+ 
+ 		list_move_tail(&obj->mm.region_link, &still_in_list);
+ 		if (!kref_get_unless_zero(&obj->base.refcount))
+ 			continue;
+ 
+ 		/*
+ 		 * Note: Someone else might be migrating the object at this
+ 		 * point. The object's region is not stable until we lock
+ 		 * the object.
+ 		 */
+ 		mutex_unlock(&mr->objects.lock);
+ 		apply->ww = &ww;
+ 		for_i915_gem_ww(&ww, ret, apply->interruptible) {
+ 			ret = i915_gem_object_lock(obj, apply->ww);
+ 			if (ret)
+ 				continue;
+ 
+ 			if (obj->mm.region == mr)
+ 				ret = ops->process_obj(apply, obj);
+ 			/* Implicit object unlock */
+ 		}
+ 
+ 		i915_gem_object_put(obj);
+ 		mutex_lock(&mr->objects.lock);
+ 		if (ret)
+ 			break;
+ 	}
+ 	list_splice_tail(&still_in_list, &mr->objects.list);
+ 	mutex_unlock(&mr->objects.lock);
+ 
+ 	return ret;
+ }
++>>>>>>> 9b78b5dade2d (drm/i915: add i915_gem_object_create_region_at())
diff --cc drivers/gpu/drm/i915/gem/i915_gem_region.h
index 84fcb3297400,2dfcc41c0170..000000000000
--- a/drivers/gpu/drm/i915/gem/i915_gem_region.h
+++ b/drivers/gpu/drm/i915/gem/i915_gem_region.h
@@@ -12,6 -12,43 +12,46 @@@ struct intel_memory_region
  struct drm_i915_gem_object;
  struct sg_table;
  
++<<<<<<< HEAD
++=======
+ struct i915_gem_apply_to_region;
+ 
+ #define I915_BO_INVALID_OFFSET ((resource_size_t)-1)
+ 
+ /**
+  * struct i915_gem_apply_to_region_ops - ops to use when iterating over all
+  * region objects.
+  */
+ struct i915_gem_apply_to_region_ops {
+ 	/**
+ 	 * process_obj - Process the current object
+ 	 * @apply: Embed this for private data.
+ 	 * @obj: The current object.
+ 	 *
+ 	 * Note that if this function is part of a ww transaction, and
+ 	 * if returns -EDEADLK for one of the objects, it may be
+ 	 * rerun for that same object in the same pass.
+ 	 */
+ 	int (*process_obj)(struct i915_gem_apply_to_region *apply,
+ 			   struct drm_i915_gem_object *obj);
+ };
+ 
+ /**
+  * struct i915_gem_apply_to_region - Argument to the struct
+  * i915_gem_apply_to_region_ops functions.
+  * @ops: The ops for the operation.
+  * @ww: Locking context used for the transaction.
+  * @interruptible: Whether to perform object locking interruptible.
+  *
+  * This structure is intended to be embedded in a private struct if needed
+  */
+ struct i915_gem_apply_to_region {
+ 	const struct i915_gem_apply_to_region_ops *ops;
+ 	struct i915_gem_ww_ctx *ww;
+ 	u32 interruptible:1;
+ };
+ 
++>>>>>>> 9b78b5dade2d (drm/i915: add i915_gem_object_create_region_at())
  void i915_gem_object_init_memory_region(struct drm_i915_gem_object *obj,
  					struct intel_memory_region *mem);
  void i915_gem_object_release_memory_region(struct drm_i915_gem_object *obj);
@@@ -19,6 -56,14 +59,11 @@@
  struct drm_i915_gem_object *
  i915_gem_object_create_region(struct intel_memory_region *mem,
  			      resource_size_t size,
 -			      resource_size_t page_size,
  			      unsigned int flags);
+ struct drm_i915_gem_object *
+ i915_gem_object_create_region_at(struct intel_memory_region *mem,
+ 				 resource_size_t offset,
+ 				 resource_size_t size,
+ 				 unsigned int flags);
  
 -int i915_gem_process_region(struct intel_memory_region *mr,
 -			    struct i915_gem_apply_to_region *apply);
  #endif
* Unmerged path drivers/gpu/drm/i915/display/intel_plane_initial.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_ttm.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_ttm.h
* Unmerged path drivers/gpu/drm/i915/display/intel_plane_initial.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_create.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_region.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_region.h
diff --git a/drivers/gpu/drm/i915/gem/i915_gem_shmem.c b/drivers/gpu/drm/i915/gem/i915_gem_shmem.c
index 5d16c4462fda..27cbbe4dd292 100644
--- a/drivers/gpu/drm/i915/gem/i915_gem_shmem.c
+++ b/drivers/gpu/drm/i915/gem/i915_gem_shmem.c
@@ -488,6 +488,7 @@ static int __create_shmem(struct drm_i915_private *i915,
 
 static int shmem_object_init(struct intel_memory_region *mem,
 			     struct drm_i915_gem_object *obj,
+			     resource_size_t offset,
 			     resource_size_t size,
 			     unsigned int flags)
 {
diff --git a/drivers/gpu/drm/i915/gem/i915_gem_stolen.c b/drivers/gpu/drm/i915/gem/i915_gem_stolen.c
index b0c3a7dc60d1..ea04850fa0fd 100644
--- a/drivers/gpu/drm/i915/gem/i915_gem_stolen.c
+++ b/drivers/gpu/drm/i915/gem/i915_gem_stolen.c
@@ -669,6 +669,7 @@ static int __i915_gem_object_create_stolen(struct intel_memory_region *mem,
 
 static int _i915_gem_object_stolen_init(struct intel_memory_region *mem,
 					struct drm_i915_gem_object *obj,
+					resource_size_t offset,
 					resource_size_t size,
 					unsigned int flags)
 {
@@ -686,8 +687,20 @@ static int _i915_gem_object_stolen_init(struct intel_memory_region *mem,
 	if (!stolen)
 		return -ENOMEM;
 
-	ret = i915_gem_stolen_insert_node(i915, stolen, size,
-					  mem->min_page_size);
+	if (offset != I915_BO_INVALID_OFFSET) {
+		drm_dbg(&i915->drm,
+			"creating preallocated stolen object: stolen_offset=%pa, size=%pa\n",
+			&offset, &size);
+
+		stolen->start = offset;
+		stolen->size = size;
+		mutex_lock(&i915->mm.stolen_lock);
+		ret = drm_mm_reserve_node(&i915->mm.stolen, stolen);
+		mutex_unlock(&i915->mm.stolen_lock);
+	} else {
+		ret = i915_gem_stolen_insert_node(i915, stolen, size,
+						  mem->min_page_size);
+	}
 	if (ret)
 		goto err_free;
 
@@ -832,63 +845,6 @@ i915_gem_stolen_smem_setup(struct drm_i915_private *i915, u16 type,
 	return mem;
 }
 
-struct drm_i915_gem_object *
-i915_gem_object_create_stolen_for_preallocated(struct drm_i915_private *i915,
-					       resource_size_t stolen_offset,
-					       resource_size_t size)
-{
-	struct intel_memory_region *mem = i915->mm.stolen_region;
-	struct drm_i915_gem_object *obj;
-	struct drm_mm_node *stolen;
-	int ret;
-
-	if (!drm_mm_initialized(&i915->mm.stolen))
-		return ERR_PTR(-ENODEV);
-
-	drm_dbg(&i915->drm,
-		"creating preallocated stolen object: stolen_offset=%pa, size=%pa\n",
-		&stolen_offset, &size);
-
-	/* KISS and expect everything to be page-aligned */
-	if (GEM_WARN_ON(size == 0) ||
-	    GEM_WARN_ON(!IS_ALIGNED(size, mem->min_page_size)) ||
-	    GEM_WARN_ON(!IS_ALIGNED(stolen_offset, mem->min_page_size)))
-		return ERR_PTR(-EINVAL);
-
-	stolen = kzalloc(sizeof(*stolen), GFP_KERNEL);
-	if (!stolen)
-		return ERR_PTR(-ENOMEM);
-
-	stolen->start = stolen_offset;
-	stolen->size = size;
-	mutex_lock(&i915->mm.stolen_lock);
-	ret = drm_mm_reserve_node(&i915->mm.stolen, stolen);
-	mutex_unlock(&i915->mm.stolen_lock);
-	if (ret)
-		goto err_free;
-
-	obj = i915_gem_object_alloc();
-	if (!obj) {
-		ret = -ENOMEM;
-		goto err_stolen;
-	}
-
-	ret = __i915_gem_object_create_stolen(mem, obj, stolen);
-	if (ret)
-		goto err_object_free;
-
-	i915_gem_object_set_cache_coherency(obj, I915_CACHE_NONE);
-	return obj;
-
-err_object_free:
-	i915_gem_object_free(obj);
-err_stolen:
-	i915_gem_stolen_remove_node(i915, stolen);
-err_free:
-	kfree(stolen);
-	return ERR_PTR(ret);
-}
-
 bool i915_gem_object_is_stolen(const struct drm_i915_gem_object *obj)
 {
 	return obj->ops == &i915_gem_object_stolen_ops;
diff --git a/drivers/gpu/drm/i915/gem/i915_gem_stolen.h b/drivers/gpu/drm/i915/gem/i915_gem_stolen.h
index ccdf7befc571..d5005a39d130 100644
--- a/drivers/gpu/drm/i915/gem/i915_gem_stolen.h
+++ b/drivers/gpu/drm/i915/gem/i915_gem_stolen.h
@@ -31,10 +31,6 @@ i915_gem_stolen_lmem_setup(struct drm_i915_private *i915, u16 type,
 struct drm_i915_gem_object *
 i915_gem_object_create_stolen(struct drm_i915_private *dev_priv,
 			      resource_size_t size);
-struct drm_i915_gem_object *
-i915_gem_object_create_stolen_for_preallocated(struct drm_i915_private *dev_priv,
-					       resource_size_t stolen_offset,
-					       resource_size_t size);
 
 bool i915_gem_object_is_stolen(const struct drm_i915_gem_object *obj);
 
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_ttm.c
* Unmerged path drivers/gpu/drm/i915/gem/i915_gem_ttm.h
diff --git a/drivers/gpu/drm/i915/gt/intel_rc6.c b/drivers/gpu/drm/i915/gt/intel_rc6.c
index 259d7eb4e165..485671ed1d7e 100644
--- a/drivers/gpu/drm/i915/gt/intel_rc6.c
+++ b/drivers/gpu/drm/i915/gt/intel_rc6.c
@@ -5,6 +5,7 @@
 
 #include <linux/pm_runtime.h>
 
+#include "gem/i915_gem_region.h"
 #include "i915_drv.h"
 #include "i915_vgpu.h"
 #include "intel_gt.h"
@@ -302,9 +303,10 @@ static int vlv_rc6_init(struct intel_rc6 *rc6)
 		resource_size_t pcbr_offset;
 
 		pcbr_offset = (pcbr & ~4095) - i915->dsm.start;
-		pctx = i915_gem_object_create_stolen_for_preallocated(i915,
-								      pcbr_offset,
-								      pctx_size);
+		pctx = i915_gem_object_create_region_at(i915->mm.stolen_region,
+							pcbr_offset,
+							pctx_size,
+							0);
 		if (IS_ERR(pctx))
 			return PTR_ERR(pctx);
 
diff --git a/drivers/gpu/drm/i915/intel_memory_region.h b/drivers/gpu/drm/i915/intel_memory_region.h
index 1f7dac63abb7..f90650b67c35 100644
--- a/drivers/gpu/drm/i915/intel_memory_region.h
+++ b/drivers/gpu/drm/i915/intel_memory_region.h
@@ -55,6 +55,7 @@ struct intel_memory_region_ops {
 
 	int (*init_object)(struct intel_memory_region *mem,
 			   struct drm_i915_gem_object *obj,
+			   resource_size_t offset,
 			   resource_size_t size,
 			   unsigned int flags);
 };
diff --git a/drivers/gpu/drm/i915/selftests/mock_region.c b/drivers/gpu/drm/i915/selftests/mock_region.c
index eafc5a04975c..e9f420669b04 100644
--- a/drivers/gpu/drm/i915/selftests/mock_region.c
+++ b/drivers/gpu/drm/i915/selftests/mock_region.c
@@ -56,6 +56,7 @@ static const struct drm_i915_gem_object_ops mock_region_obj_ops = {
 
 static int mock_object_init(struct intel_memory_region *mem,
 			    struct drm_i915_gem_object *obj,
+			    resource_size_t offset,
 			    resource_size_t size,
 			    unsigned int flags)
 {
