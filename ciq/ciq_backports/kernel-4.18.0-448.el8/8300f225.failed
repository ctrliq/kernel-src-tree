net/mlx5e: Create new flow attr for multi table actions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Roi Dayan <roid@nvidia.com>
commit 8300f225268be9ee2c0daf5a3f23929fcdcbf213
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/8300f225.failed

Some TC actions use post actions for their implementation.
For example CT and sample actions.

Create a new flow attr after each multi table action and
create a post action rule for it.

First flow attr being offloaded normally and linked to the next
attr (post action rule) with setting an id on reg_c.
Post action rules match the id on reg_c and continue to the next one.

The flow counter is allocated on the last rule.

	Signed-off-by: Roi Dayan <roid@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 8300f225268be9ee2c0daf5a3f23929fcdcbf213)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.h
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
index b689701ac7d8,f76624699a8d..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
@@@ -103,10 -108,20 +103,11 @@@ struct mlx5e_tc_flow 
  	struct rcu_head rcu_head;
  	struct completion init_done;
  	struct completion del_hw_done;
 +	int tunnel_id; /* the mapped tunnel id of this flow */
  	struct mlx5_flow_attr *attr;
+ 	struct list_head attrs;
  };
  
 -struct mlx5_flow_handle *
 -mlx5e_tc_rule_offload(struct mlx5e_priv *priv,
 -		      struct mlx5_flow_spec *spec,
 -		      struct mlx5_flow_attr *attr);
 -
 -void
 -mlx5e_tc_rule_unoffload(struct mlx5e_priv *priv,
 -			struct mlx5_flow_handle *rule,
 -			struct mlx5_flow_attr *attr);
 -
  u8 mlx5e_tc_get_ip_version(struct mlx5_flow_spec *spec, bool outer);
  
  struct mlx5_flow_handle *
@@@ -115,7 -130,17 +116,18 @@@ mlx5e_tc_offload_fdb_rules(struct mlx5_
  			   struct mlx5_flow_spec *spec,
  			   struct mlx5_flow_attr *attr);
  
++<<<<<<< HEAD
++=======
+ struct mlx5_flow_attr *
+ mlx5e_tc_get_encap_attr(struct mlx5e_tc_flow *flow);
+ 
+ void mlx5e_tc_unoffload_flow_post_acts(struct mlx5e_tc_flow *flow);
+ int mlx5e_tc_offload_flow_post_acts(struct mlx5e_tc_flow *flow);
+ 
+ bool mlx5e_is_eswitch_flow(struct mlx5e_tc_flow *flow);
+ bool mlx5e_is_ft_flow(struct mlx5e_tc_flow *flow);
++>>>>>>> 8300f225268b (net/mlx5e: Create new flow attr for multi table actions)
  bool mlx5e_is_offloaded_flow(struct mlx5e_tc_flow *flow);
 -int mlx5e_get_flow_namespace(struct mlx5e_tc_flow *flow);
 -bool mlx5e_same_hw_devs(struct mlx5e_priv *priv, struct mlx5e_priv *peer_priv);
  
  static inline void __flow_flag_set(struct mlx5e_tc_flow *flow, unsigned long flag)
  {
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index e11d6f95f302,b9d6a2e8b240..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -278,8 -273,24 +279,25 @@@ get_sample_priv(struct mlx5e_priv *priv
  
  	return NULL;
  }
 +#endif
  
+ static struct mlx5e_post_act *
+ get_post_action(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+ 	struct mlx5_rep_uplink_priv *uplink_priv;
+ 	struct mlx5e_rep_priv *uplink_rpriv;
+ 
+ 	if (is_mdev_switchdev_mode(priv->mdev)) {
+ 		uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+ 		uplink_priv = &uplink_rpriv->uplink_priv;
+ 
+ 		return uplink_priv->post_act;
+ 	}
+ 
+ 	return priv->fs.tc.post_act;
+ }
+ 
  struct mlx5_flow_handle *
  mlx5_tc_rule_insert(struct mlx5e_priv *priv,
  		    struct mlx5_flow_spec *spec,
@@@ -1696,7 -1738,8 +1722,12 @@@ static void mlx5e_tc_del_fdb_flow(struc
  	if (flow_flag_test(flow, L3_TO_L2_DECAP))
  		mlx5e_detach_decap(priv, flow);
  
++<<<<<<< HEAD
 +	kfree(attr->sample_attr);
++=======
+ 	free_flow_post_acts(flow);
+ 
++>>>>>>> 8300f225268b (net/mlx5e: Create new flow attr for multi table actions)
  	kvfree(attr->esw_attr->rx_tun_attr);
  	kvfree(attr->parse_attr);
  	kfree(flow->attr);
@@@ -3463,131 -3347,6 +3497,134 @@@ static bool same_hw_devs(struct mlx5e_p
  	return (fsystem_guid == psystem_guid);
  }
  
++<<<<<<< HEAD
 +static bool same_vf_reps(struct mlx5e_priv *priv,
 +			 struct net_device *out_dev)
 +{
 +	return mlx5e_eswitch_vf_rep(priv->netdev) &&
 +	       priv->netdev == out_dev;
 +}
 +
 +static int add_vlan_rewrite_action(struct mlx5e_priv *priv, int namespace,
 +				   const struct flow_action_entry *act,
 +				   struct mlx5e_tc_flow_parse_attr *parse_attr,
 +				   struct pedit_headers_action *hdrs,
 +				   u32 *action, struct netlink_ext_ack *extack)
 +{
 +	u16 mask16 = VLAN_VID_MASK;
 +	u16 val16 = act->vlan.vid & VLAN_VID_MASK;
 +	const struct flow_action_entry pedit_act = {
 +		.id = FLOW_ACTION_MANGLE,
 +		.mangle.htype = FLOW_ACT_MANGLE_HDR_TYPE_ETH,
 +		.mangle.offset = offsetof(struct vlan_ethhdr, h_vlan_TCI),
 +		.mangle.mask = ~(u32)be16_to_cpu(*(__be16 *)&mask16),
 +		.mangle.val = (u32)be16_to_cpu(*(__be16 *)&val16),
 +	};
 +	u8 match_prio_mask, match_prio_val;
 +	void *headers_c, *headers_v;
 +	int err;
 +
 +	headers_c = get_match_headers_criteria(*action, &parse_attr->spec);
 +	headers_v = get_match_headers_value(*action, &parse_attr->spec);
 +
 +	if (!(MLX5_GET(fte_match_set_lyr_2_4, headers_c, cvlan_tag) &&
 +	      MLX5_GET(fte_match_set_lyr_2_4, headers_v, cvlan_tag))) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "VLAN rewrite action must have VLAN protocol match");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	match_prio_mask = MLX5_GET(fte_match_set_lyr_2_4, headers_c, first_prio);
 +	match_prio_val = MLX5_GET(fte_match_set_lyr_2_4, headers_v, first_prio);
 +	if (act->vlan.prio != (match_prio_val & match_prio_mask)) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "Changing VLAN prio is not supported");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	err = parse_tc_pedit_action(priv, &pedit_act, namespace, parse_attr, hdrs, NULL, extack);
 +	*action |= MLX5_FLOW_CONTEXT_ACTION_MOD_HDR;
 +
 +	return err;
 +}
 +
 +static int
 +add_vlan_prio_tag_rewrite_action(struct mlx5e_priv *priv,
 +				 struct mlx5e_tc_flow_parse_attr *parse_attr,
 +				 struct pedit_headers_action *hdrs,
 +				 u32 *action, struct netlink_ext_ack *extack)
 +{
 +	const struct flow_action_entry prio_tag_act = {
 +		.vlan.vid = 0,
 +		.vlan.prio =
 +			MLX5_GET(fte_match_set_lyr_2_4,
 +				 get_match_headers_value(*action,
 +							 &parse_attr->spec),
 +				 first_prio) &
 +			MLX5_GET(fte_match_set_lyr_2_4,
 +				 get_match_headers_criteria(*action,
 +							    &parse_attr->spec),
 +				 first_prio),
 +	};
 +
 +	return add_vlan_rewrite_action(priv, MLX5_FLOW_NAMESPACE_FDB,
 +				       &prio_tag_act, parse_attr, hdrs, action,
 +				       extack);
 +}
 +
 +static int validate_goto_chain(struct mlx5e_priv *priv,
 +			       struct mlx5e_tc_flow *flow,
 +			       const struct flow_action_entry *act,
 +			       u32 actions,
 +			       struct netlink_ext_ack *extack)
 +{
 +	bool is_esw = mlx5e_is_eswitch_flow(flow);
 +	struct mlx5_flow_attr *attr = flow->attr;
 +	bool ft_flow = mlx5e_is_ft_flow(flow);
 +	u32 dest_chain = act->chain_index;
 +	struct mlx5_fs_chains *chains;
 +	struct mlx5_eswitch *esw;
 +	u32 reformat_and_fwd;
 +	u32 max_chain;
 +
 +	esw = priv->mdev->priv.eswitch;
 +	chains = is_esw ? esw_chains(esw) : nic_chains(priv);
 +	max_chain = mlx5_chains_get_chain_range(chains);
 +	reformat_and_fwd = is_esw ?
 +			   MLX5_CAP_ESW_FLOWTABLE_FDB(priv->mdev, reformat_and_fwd_to_table) :
 +			   MLX5_CAP_FLOWTABLE_NIC_RX(priv->mdev, reformat_and_fwd_to_table);
 +
 +	if (ft_flow) {
 +		NL_SET_ERR_MSG_MOD(extack, "Goto action is not supported");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	if (!mlx5_chains_backwards_supported(chains) &&
 +	    dest_chain <= attr->chain) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "Goto lower numbered chain isn't supported");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	if (dest_chain > max_chain) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "Requested destination chain is out of supported range");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	if (actions & (MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT |
 +		       MLX5_FLOW_CONTEXT_ACTION_DECAP) &&
 +	    !reformat_and_fwd) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "Goto chain is not allowed if action has reformat or decap");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	return 0;
 +}
 +
++=======
++>>>>>>> 8300f225268b (net/mlx5e: Create new flow attr for multi table actions)
  static int
  actions_prepare_mod_hdr_actions(struct mlx5e_priv *priv,
  				struct mlx5e_tc_flow *flow,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index fb629ee12aff,a80b00946f1b..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@@ -82,8 -81,10 +81,13 @@@ struct mlx5_flow_attr 
  	u8 outer_match_level;
  	u8 ip_version;
  	u8 tun_ip_version;
 -	int tunnel_id; /* mapped tunnel id */
  	u32 flags;
++<<<<<<< HEAD
 +	bool ct_clear;
++=======
+ 	struct list_head list;
+ 	struct mlx5e_post_act_handle *post_act_handle;
++>>>>>>> 8300f225268b (net/mlx5e: Create new flow attr for multi table actions)
  	union {
  		struct mlx5_esw_flow_attr esw_attr[0];
  		struct mlx5_nic_flow_attr nic_attr[0];
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc/act/act.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc/post_act.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc/post_act.c
index efc81bec5b80..a31a4e330a06 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc/post_act.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc/post_act.c
@@ -139,15 +139,9 @@ mlx5e_tc_post_act_add(struct mlx5e_post_act *post_act, struct mlx5_flow_attr *at
 		goto err_xarray;
 
 	handle->attr = post_attr;
-	err = mlx5e_tc_post_act_offload(post_act, handle);
-	if (err)
-		goto err_rule;
-
 
 	return handle;
 
-err_rule:
-	xa_erase(&post_act->ids, handle->id);
 err_xarray:
 	kfree(post_attr);
 	kfree(handle);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc/sample.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc/sample.c
index ff4b4f8a5a9d..e1859de711e0 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc/sample.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc/sample.c
@@ -533,6 +533,9 @@ mlx5e_tc_sample_offload(struct mlx5e_tc_psample *tc_psample,
 			err = PTR_ERR(post_act_handle);
 			goto err_post_act;
 		}
+		err = mlx5e_tc_post_act_offload(tc_psample->post_act, post_act_handle);
+		if (err)
+			goto err_post_rule;
 		sample_flow->post_act_handle = post_act_handle;
 	} else {
 		err = add_post_rule(esw, sample_flow, spec, attr, &default_tbl_id);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
index bdde5fe4e17e..b7d873f283c9 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
@@ -1784,6 +1784,9 @@ __mlx5_tc_ct_flow_offload(struct mlx5_tc_ct_priv *ct_priv,
 		ct_dbg("Failed to allocate post action handle");
 		goto err_post_act_handle;
 	}
+	err = mlx5e_tc_post_act_offload(ct_priv->post_act, handle);
+	if (err)
+		goto err_alloc_pre;
 	ct_flow->post_act_handle = handle;
 
 	/* Base flow attributes of both rules on original rule attribute */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
index ba7b9bf6dc78..b55512f56bb4 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
@@ -174,19 +174,29 @@ void mlx5e_tc_encap_flows_add(struct mlx5e_priv *priv,
 	list_for_each_entry(flow, flow_list, tmp_list) {
 		if (!mlx5e_is_offloaded_flow(flow) || !flow_flag_test(flow, SLOW))
 			continue;
-		attr = flow->attr;
-		esw_attr = attr->esw_attr;
-		spec = &attr->parse_attr->spec;
 
+		spec = &flow->attr->parse_attr->spec;
+
+		attr = mlx5e_tc_get_encap_attr(flow);
+		esw_attr = attr->esw_attr;
 		esw_attr->dests[flow->tmp_entry_index].pkt_reformat = e->pkt_reformat;
 		esw_attr->dests[flow->tmp_entry_index].flags |= MLX5_ESW_DEST_ENCAP_VALID;
 
 		/* Do not offload flows with unresolved neighbors */
 		if (!mlx5e_tc_flow_all_encaps_valid(esw_attr))
 			continue;
+
+		err = mlx5e_tc_offload_flow_post_acts(flow);
+		if (err) {
+			mlx5_core_warn(priv->mdev, "Failed to update flow post acts, %d\n",
+				       err);
+			continue;
+		}
+
 		/* update from slow path rule to encap rule */
-		rule = mlx5e_tc_offload_fdb_rules(esw, flow, spec, attr);
+		rule = mlx5e_tc_offload_fdb_rules(esw, flow, spec, flow->attr);
 		if (IS_ERR(rule)) {
+			mlx5e_tc_unoffload_flow_post_acts(flow);
 			err = PTR_ERR(rule);
 			mlx5_core_warn(priv->mdev, "Failed to update cached encapsulation flow, %d\n",
 				       err);
@@ -215,12 +225,13 @@ void mlx5e_tc_encap_flows_del(struct mlx5e_priv *priv,
 	list_for_each_entry(flow, flow_list, tmp_list) {
 		if (!mlx5e_is_offloaded_flow(flow) || flow_flag_test(flow, SLOW))
 			continue;
-		attr = flow->attr;
-		esw_attr = attr->esw_attr;
-		spec = &attr->parse_attr->spec;
+		spec = &flow->attr->parse_attr->spec;
 
 		/* update from encap rule to slow path rule */
 		rule = mlx5e_tc_offload_to_slow_path(esw, flow, spec);
+
+		attr = mlx5e_tc_get_encap_attr(flow);
+		esw_attr = attr->esw_attr;
 		/* mark the flow's encap dest as non-valid */
 		esw_attr->dests[flow->tmp_entry_index].flags &= ~MLX5_ESW_DEST_ENCAP_VALID;
 
@@ -231,7 +242,8 @@ void mlx5e_tc_encap_flows_del(struct mlx5e_priv *priv,
 			continue;
 		}
 
-		mlx5e_tc_unoffload_fdb_rules(esw, flow, attr);
+		mlx5e_tc_unoffload_fdb_rules(esw, flow, flow->attr);
+		mlx5e_tc_unoffload_flow_post_acts(flow);
 		flow->rule[0] = rule;
 		/* was unset when fast path rule removed */
 		flow_flag_set(flow, OFFLOADED);
@@ -496,6 +508,9 @@ void mlx5e_detach_encap(struct mlx5e_priv *priv,
 	struct mlx5e_encap_entry *e = flow->encaps[out_index].e;
 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 
+	if (!mlx5e_is_eswitch_flow(flow))
+		return;
+
 	if (attr->esw_attr->dests[out_index].flags &
 	    MLX5_ESW_DEST_CHAIN_WITH_SRC_PORT_CHANGE)
 		mlx5e_detach_encap_route(priv, flow, out_index);
@@ -1361,17 +1376,19 @@ static void mlx5e_reoffload_encap(struct mlx5e_priv *priv,
 
 	list_for_each_entry(flow, encap_flows, tmp_list) {
 		struct mlx5e_tc_flow_parse_attr *parse_attr;
-		struct mlx5_flow_attr *attr = flow->attr;
 		struct mlx5_esw_flow_attr *esw_attr;
 		struct mlx5_flow_handle *rule;
+		struct mlx5_flow_attr *attr;
 		struct mlx5_flow_spec *spec;
 
 		if (flow_flag_test(flow, FAILED))
 			continue;
 
+		spec = &flow->attr->parse_attr->spec;
+
+		attr = mlx5e_tc_get_encap_attr(flow);
 		esw_attr = attr->esw_attr;
 		parse_attr = attr->parse_attr;
-		spec = &parse_attr->spec;
 
 		err = mlx5e_update_vf_tunnel(esw, esw_attr, &parse_attr->mod_hdr_acts,
 					     e->out_dev, e->route_dev_ifindex,
@@ -1393,9 +1410,18 @@ static void mlx5e_reoffload_encap(struct mlx5e_priv *priv,
 			esw_attr->dests[flow->tmp_entry_index].flags |= MLX5_ESW_DEST_ENCAP_VALID;
 			if (!mlx5e_tc_flow_all_encaps_valid(esw_attr))
 				goto offload_to_slow_path;
+
+			err = mlx5e_tc_offload_flow_post_acts(flow);
+			if (err) {
+				mlx5_core_warn(priv->mdev, "Failed to update flow post acts, %d\n",
+					       err);
+				goto offload_to_slow_path;
+			}
+
 			/* update from slow path rule to encap rule */
-			rule = mlx5e_tc_offload_fdb_rules(esw, flow, spec, attr);
+			rule = mlx5e_tc_offload_fdb_rules(esw, flow, spec, flow->attr);
 			if (IS_ERR(rule)) {
+				mlx5e_tc_unoffload_flow_post_acts(flow);
 				err = PTR_ERR(rule);
 				mlx5_core_warn(priv->mdev, "Failed to update cached encapsulation flow, %d\n",
 					       err);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
