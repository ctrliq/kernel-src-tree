sched/fair: fix case with reduced capacity CPU

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Vincent Guittot <vincent.guittot@linaro.org>
commit c82a69629c53eda5233f13fc11c3c01585ef48a2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/c82a6962.failed

The capacity of the CPU available for CFS tasks can be reduced because of
other activities running on the latter. In such case, it's worth trying to
move CFS tasks on a CPU with more available capacity.

The rework of the load balance has filtered the case when the CPU is
classified to be fully busy but its capacity is reduced.

Check if CPU's capacity is reduced while gathering load balance statistic
and classify it group_misfit_task instead of group_fully_busy so we can
try to move the load on another CPU.

	Reported-by: David Chen <david.chen@nutanix.com>
	Reported-by: Zhang Qiao <zhangqiao22@huawei.com>
	Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Tested-by: David Chen <david.chen@nutanix.com>
	Tested-by: Zhang Qiao <zhangqiao22@huawei.com>
Link: https://lkml.kernel.org/r/20220708154401.21411-1-vincent.guittot@linaro.org
(cherry picked from commit c82a69629c53eda5233f13fc11c3c01585ef48a2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
diff --cc kernel/sched/fair.c
index 672d98723c8b,914096c5b1ae..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -8571,9 -8833,10 +8584,15 @@@ static inline void update_sg_lb_stats(s
  
  	for_each_cpu_and(i, sched_group_span(group), env->cpus) {
  		struct rq *rq = cpu_rq(i);
+ 		unsigned long load = cpu_load(rq);
  
++<<<<<<< HEAD
 +		sgs->group_load += cpu_load(rq);
 +		sgs->group_util += cpu_util(i);
++=======
+ 		sgs->group_load += load;
+ 		sgs->group_util += cpu_util_cfs(i);
++>>>>>>> c82a69629c53 (sched/fair: fix case with reduced capacity CPU)
  		sgs->group_runnable += cpu_runnable(rq);
  		sgs->sum_h_nr_running += rq->cfs.h_nr_running;
  
* Unmerged path kernel/sched/fair.c
