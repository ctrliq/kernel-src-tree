swiotlb: ensure a segment doesn't cross the area boundary

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Chao Gao <chao.gao@intel.com>
commit 57e6840cf79a4af84f44af3f8cfeacd8a14a6c6f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/57e6840c.failed

Free slots tracking assumes that slots in a segment can be allocated to
fulfill a request. This implies that slots in a segment should belong to
the same area. Although the possibility of a violation is low, it is better
to explicitly enforce segments won't span multiple areas by adjusting the
number of slabs when configuring areas.

	Signed-off-by: Chao Gao <chao.gao@intel.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 57e6840cf79a4af84f44af3f8cfeacd8a14a6c6f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/dma/swiotlb.c
diff --cc kernel/dma/swiotlb.c
index 623d86fa3853,608923e8dab1..000000000000
--- a/kernel/dma/swiotlb.c
+++ b/kernel/dma/swiotlb.c
@@@ -73,6 -70,59 +73,62 @@@ struct io_tlb_mem io_tlb_default_mem
  phys_addr_t swiotlb_unencrypted_base;
  
  static unsigned long default_nslabs = IO_TLB_DEFAULT_SIZE >> IO_TLB_SHIFT;
++<<<<<<< HEAD
++=======
+ static unsigned long default_nareas;
+ 
+ /**
+  * struct io_tlb_area - IO TLB memory area descriptor
+  *
+  * This is a single area with a single lock.
+  *
+  * @used:	The number of used IO TLB block.
+  * @index:	The slot index to start searching in this area for next round.
+  * @lock:	The lock to protect the above data structures in the map and
+  *		unmap calls.
+  */
+ struct io_tlb_area {
+ 	unsigned long used;
+ 	unsigned int index;
+ 	spinlock_t lock;
+ };
+ 
+ /*
+  * Round up number of slabs to the next power of 2. The last area is going
+  * be smaller than the rest if default_nslabs is not power of two.
+  * The number of slot in an area should be a multiple of IO_TLB_SEGSIZE,
+  * otherwise a segment may span two or more areas. It conflicts with free
+  * contiguous slots tracking: free slots are treated contiguous no matter
+  * whether they cross an area boundary.
+  *
+  * Return true if default_nslabs is rounded up.
+  */
+ static bool round_up_default_nslabs(void)
+ {
+ 	if (!default_nareas)
+ 		return false;
+ 
+ 	if (default_nslabs < IO_TLB_SEGSIZE * default_nareas)
+ 		default_nslabs = IO_TLB_SEGSIZE * default_nareas;
+ 	else if (is_power_of_2(default_nslabs))
+ 		return false;
+ 	default_nslabs = roundup_pow_of_two(default_nslabs);
+ 	return true;
+ }
+ 
+ static void swiotlb_adjust_nareas(unsigned int nareas)
+ {
+ 	if (!is_power_of_2(nareas))
+ 		nareas = roundup_pow_of_two(nareas);
+ 
+ 	default_nareas = nareas;
+ 
+ 	pr_info("area num %d.\n", nareas);
+ 	if (round_up_default_nslabs())
+ 		pr_info("SWIOTLB bounce buffer size roundup to %luMB",
+ 			(default_nslabs << IO_TLB_SHIFT) >> 20);
+ }
++>>>>>>> 57e6840cf79a (swiotlb: ensure a segment doesn't cross the area boundary)
  
  static int __init
  setup_io_tlb_npages(char *str)
* Unmerged path kernel/dma/swiotlb.c
