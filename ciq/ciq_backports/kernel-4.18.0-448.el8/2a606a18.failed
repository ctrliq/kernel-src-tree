ACPI: Add perf low power callback

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Stephane Eranian <eranian@google.com>
commit 2a606a18cd672a16343d146a126721b34cc6adbd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/2a606a18.failed

Add an optional callback needed by some PMU features, e.g., AMD
BRS, to give a chance to the perf_events code to change its state before
a CPU goes to low power and after it comes back.

The callback is void when the PERF_NEEDS_LOPWR_CB flag is not set.
This flag must be set in arch specific perf_event.h header whenever needed.
When not set, there is no impact on the ACPI code.

	Signed-off-by: Stephane Eranian <eranian@google.com>
[peterz: build fix]
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lore.kernel.org/r/20220322221517.2510440-9-eranian@google.com
(cherry picked from commit 2a606a18cd672a16343d146a126721b34cc6adbd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/perf_event.h
diff --cc include/linux/perf_event.h
index efde2100d598,da759560eec5..000000000000
--- a/include/linux/perf_event.h
+++ b/include/linux/perf_event.h
@@@ -1658,4 -1650,36 +1658,39 @@@ extern void __weak arch_perf_update_use
  					     struct perf_event_mmap_page *userpg,
  					     u64 now);
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_MMU
+ extern __weak u64 arch_perf_get_page_size(struct mm_struct *mm, unsigned long addr);
+ #endif
+ 
+ /*
+  * Snapshot branch stack on software events.
+  *
+  * Branch stack can be very useful in understanding software events. For
+  * example, when a long function, e.g. sys_perf_event_open, returns an
+  * errno, it is not obvious why the function failed. Branch stack could
+  * provide very helpful information in this type of scenarios.
+  *
+  * On software event, it is necessary to stop the hardware branch recorder
+  * fast. Otherwise, the hardware register/buffer will be flushed with
+  * entries of the triggering event. Therefore, static call is used to
+  * stop the hardware recorder.
+  */
+ 
+ /*
+  * cnt is the number of entries allocated for entries.
+  * Return number of entries copied to .
+  */
+ typedef int (perf_snapshot_branch_stack_t)(struct perf_branch_entry *entries,
+ 					   unsigned int cnt);
+ DECLARE_STATIC_CALL(perf_snapshot_branch_stack, perf_snapshot_branch_stack_t);
+ 
+ #ifndef PERF_NEEDS_LOPWR_CB
+ static inline void perf_lopwr_cb(bool mode)
+ {
+ }
+ #endif
+ 
++>>>>>>> 2a606a18cd67 (ACPI: Add perf low power callback)
  #endif /* _LINUX_PERF_EVENT_H */
diff --git a/drivers/acpi/acpi_pad.c b/drivers/acpi/acpi_pad.c
index 97c8f576cc02..34a5e08d644c 100644
--- a/drivers/acpi/acpi_pad.c
+++ b/drivers/acpi/acpi_pad.c
@@ -27,6 +27,7 @@
 #include <linux/slab.h>
 #include <linux/smp.h>
 #include <linux/acpi.h>
+#include <linux/perf_event.h>
 #include <asm/mwait.h>
 #include <xen/xen.h>
 
@@ -172,6 +173,9 @@ static int power_saving_thread(void *data)
 				tsc_marked_unstable = 1;
 			}
 			local_irq_disable();
+
+			perf_lopwr_cb(true);
+
 			tick_broadcast_enable();
 			tick_broadcast_enter();
 			stop_critical_timings();
@@ -180,6 +184,9 @@ static int power_saving_thread(void *data)
 
 			start_critical_timings();
 			tick_broadcast_exit();
+
+			perf_lopwr_cb(false);
+
 			local_irq_enable();
 
 			if (time_before(expire_time, jiffies)) {
diff --git a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
index 0d96f7ca8858..c55e11f3847d 100644
--- a/drivers/acpi/processor_idle.c
+++ b/drivers/acpi/processor_idle.c
@@ -34,6 +34,7 @@
 #include <linux/cpuidle.h>
 #include <linux/cpu.h>
 #include <linux/minmax.h>
+#include <linux/perf_event.h>
 #include <acpi/processor.h>
 
 /*
@@ -560,6 +561,8 @@ static void wait_for_freeze(void)
  */
 static void __cpuidle acpi_idle_do_entry(struct acpi_processor_cx *cx)
 {
+	perf_lopwr_cb(true);
+
 	if (cx->entry_method == ACPI_CSTATE_FFH) {
 		/* Call into architectural FFH based C-state */
 		acpi_processor_ffh_cstate_enter(cx);
@@ -570,6 +573,8 @@ static void __cpuidle acpi_idle_do_entry(struct acpi_processor_cx *cx)
 		inb(cx->address);
 		wait_for_freeze();
 	}
+
+	perf_lopwr_cb(false);
 }
 
 /**
* Unmerged path include/linux/perf_event.h
