flow_offload: allow user to offload tc action to net device

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Baowen Zheng <baowen.zheng@corigine.com>
commit 8cbfe939abe905280279e84a297b1cb34e0d0ec9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/8cbfe939.failed

Use flow_indr_dev_register/flow_indr_dev_setup_offload to
offload tc action.

We need to call tc_cleanup_flow_action to clean up tc action entry since
in tc_setup_action, some actions may hold dev refcnt, especially the mirror
action.

	Signed-off-by: Baowen Zheng <baowen.zheng@corigine.com>
	Signed-off-by: Louis Peens <louis.peens@corigine.com>
	Signed-off-by: Simon Horman <simon.horman@corigine.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8cbfe939abe905280279e84a297b1cb34e0d0ec9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/act_csum.c
#	net/sched/act_ct.c
#	net/sched/act_gact.c
#	net/sched/act_gate.c
#	net/sched/act_mirred.c
#	net/sched/act_mpls.c
#	net/sched/act_police.c
#	net/sched/act_sample.c
#	net/sched/act_skbedit.c
#	net/sched/act_tunnel_key.c
#	net/sched/act_vlan.c
#	net/sched/cls_api.c
diff --cc net/sched/act_csum.c
index 7e4c90a0a58f,e0f515b774ca..000000000000
--- a/net/sched/act_csum.c
+++ b/net/sched/act_csum.c
@@@ -700,6 -695,24 +700,27 @@@ static size_t tcf_csum_get_fill_size(co
  	return nla_total_size(sizeof(struct tc_csum));
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_csum_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				      u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		entry->id = FLOW_ACTION_CSUM;
+ 		entry->csum_flags = tcf_csum_update_flags(act);
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		fl_action->id = FLOW_ACTION_CSUM;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_csum_ops = {
  	.kind		= "csum",
  	.id		= TCA_ID_CSUM,
diff --cc net/sched/act_ct.c
index 2346a574da20,1c537913a189..000000000000
--- a/net/sched/act_ct.c
+++ b/net/sched/act_ct.c
@@@ -1499,6 -1493,26 +1499,29 @@@ static void tcf_stats_update(struct tc_
  	c->tcf_tm.lastuse = max_t(u64, c->tcf_tm.lastuse, lastuse);
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_ct_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				    u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		entry->id = FLOW_ACTION_CT;
+ 		entry->ct.action = tcf_ct_action(act);
+ 		entry->ct.zone = tcf_ct_zone(act);
+ 		entry->ct.flow_table = tcf_ct_ft(act);
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		fl_action->id = FLOW_ACTION_CT;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_ct_ops = {
  	.kind		=	"ct",
  	.id		=	TCA_ID_CT,
diff --cc net/sched/act_gact.c
index 540cebb57be7,bde6a6c01e64..000000000000
--- a/net/sched/act_gact.c
+++ b/net/sched/act_gact.c
@@@ -257,6 -252,43 +257,46 @@@ static size_t tcf_gact_get_fill_size(co
  	return sz;
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_gact_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				      u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		if (is_tcf_gact_ok(act)) {
+ 			entry->id = FLOW_ACTION_ACCEPT;
+ 		} else if (is_tcf_gact_shot(act)) {
+ 			entry->id = FLOW_ACTION_DROP;
+ 		} else if (is_tcf_gact_trap(act)) {
+ 			entry->id = FLOW_ACTION_TRAP;
+ 		} else if (is_tcf_gact_goto_chain(act)) {
+ 			entry->id = FLOW_ACTION_GOTO;
+ 			entry->chain_index = tcf_gact_goto_chain_index(act);
+ 		} else {
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		if (is_tcf_gact_ok(act))
+ 			fl_action->id = FLOW_ACTION_ACCEPT;
+ 		else if (is_tcf_gact_shot(act))
+ 			fl_action->id = FLOW_ACTION_DROP;
+ 		else if (is_tcf_gact_trap(act))
+ 			fl_action->id = FLOW_ACTION_TRAP;
+ 		else if (is_tcf_gact_goto_chain(act))
+ 			fl_action->id = FLOW_ACTION_GOTO;
+ 		else
+ 			return -EOPNOTSUPP;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_gact_ops = {
  	.kind		=	"gact",
  	.id		=	TCA_ID_GACT,
diff --cc net/sched/act_gate.c
index ac985c53ebaf,d56e73843a4b..000000000000
--- a/net/sched/act_gate.c
+++ b/net/sched/act_gate.c
@@@ -597,6 -597,54 +597,57 @@@ static size_t tcf_gate_get_fill_size(co
  	return nla_total_size(sizeof(struct tc_gate));
  }
  
++<<<<<<< HEAD
++=======
+ static void tcf_gate_entry_destructor(void *priv)
+ {
+ 	struct action_gate_entry *oe = priv;
+ 
+ 	kfree(oe);
+ }
+ 
+ static int tcf_gate_get_entries(struct flow_action_entry *entry,
+ 				const struct tc_action *act)
+ {
+ 	entry->gate.entries = tcf_gate_get_list(act);
+ 
+ 	if (!entry->gate.entries)
+ 		return -EINVAL;
+ 
+ 	entry->destructor = tcf_gate_entry_destructor;
+ 	entry->destructor_priv = entry->gate.entries;
+ 
+ 	return 0;
+ }
+ 
+ static int tcf_gate_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				      u32 *index_inc, bool bind)
+ {
+ 	int err;
+ 
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		entry->id = FLOW_ACTION_GATE;
+ 		entry->gate.prio = tcf_gate_prio(act);
+ 		entry->gate.basetime = tcf_gate_basetime(act);
+ 		entry->gate.cycletime = tcf_gate_cycletime(act);
+ 		entry->gate.cycletimeext = tcf_gate_cycletimeext(act);
+ 		entry->gate.num_entries = tcf_gate_num_entries(act);
+ 		err = tcf_gate_get_entries(entry, act);
+ 		if (err)
+ 			return err;
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		fl_action->id = FLOW_ACTION_GATE;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_gate_ops = {
  	.kind		=	"gate",
  	.id		=	TCA_ID_GATE,
diff --cc net/sched/act_mirred.c
index de09f8f40c4c,39acd1d18609..000000000000
--- a/net/sched/act_mirred.c
+++ b/net/sched/act_mirred.c
@@@ -453,6 -450,55 +453,58 @@@ static size_t tcf_mirred_get_fill_size(
  	return nla_total_size(sizeof(struct tc_mirred));
  }
  
++<<<<<<< HEAD
++=======
+ static void tcf_offload_mirred_get_dev(struct flow_action_entry *entry,
+ 				       const struct tc_action *act)
+ {
+ 	entry->dev = act->ops->get_dev(act, &entry->destructor);
+ 	if (!entry->dev)
+ 		return;
+ 	entry->destructor_priv = entry->dev;
+ }
+ 
+ static int tcf_mirred_offload_act_setup(struct tc_action *act, void *entry_data,
+ 					u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		if (is_tcf_mirred_egress_redirect(act)) {
+ 			entry->id = FLOW_ACTION_REDIRECT;
+ 			tcf_offload_mirred_get_dev(entry, act);
+ 		} else if (is_tcf_mirred_egress_mirror(act)) {
+ 			entry->id = FLOW_ACTION_MIRRED;
+ 			tcf_offload_mirred_get_dev(entry, act);
+ 		} else if (is_tcf_mirred_ingress_redirect(act)) {
+ 			entry->id = FLOW_ACTION_REDIRECT_INGRESS;
+ 			tcf_offload_mirred_get_dev(entry, act);
+ 		} else if (is_tcf_mirred_ingress_mirror(act)) {
+ 			entry->id = FLOW_ACTION_MIRRED_INGRESS;
+ 			tcf_offload_mirred_get_dev(entry, act);
+ 		} else {
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		if (is_tcf_mirred_egress_redirect(act))
+ 			fl_action->id = FLOW_ACTION_REDIRECT;
+ 		else if (is_tcf_mirred_egress_mirror(act))
+ 			fl_action->id = FLOW_ACTION_MIRRED;
+ 		else if (is_tcf_mirred_ingress_redirect(act))
+ 			fl_action->id = FLOW_ACTION_REDIRECT_INGRESS;
+ 		else if (is_tcf_mirred_ingress_mirror(act))
+ 			fl_action->id = FLOW_ACTION_MIRRED_INGRESS;
+ 		else
+ 			return -EOPNOTSUPP;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_mirred_ops = {
  	.kind		=	"mirred",
  	.id		=	TCA_ID_MIRRED,
diff --cc net/sched/act_mpls.c
index 9789d894911b,b9ff3459fdab..000000000000
--- a/net/sched/act_mpls.c
+++ b/net/sched/act_mpls.c
@@@ -385,6 -384,57 +385,60 @@@ static int tcf_mpls_search(struct net *
  	return tcf_idr_search(tn, a, index);
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_mpls_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				      u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		switch (tcf_mpls_action(act)) {
+ 		case TCA_MPLS_ACT_PUSH:
+ 			entry->id = FLOW_ACTION_MPLS_PUSH;
+ 			entry->mpls_push.proto = tcf_mpls_proto(act);
+ 			entry->mpls_push.label = tcf_mpls_label(act);
+ 			entry->mpls_push.tc = tcf_mpls_tc(act);
+ 			entry->mpls_push.bos = tcf_mpls_bos(act);
+ 			entry->mpls_push.ttl = tcf_mpls_ttl(act);
+ 			break;
+ 		case TCA_MPLS_ACT_POP:
+ 			entry->id = FLOW_ACTION_MPLS_POP;
+ 			entry->mpls_pop.proto = tcf_mpls_proto(act);
+ 			break;
+ 		case TCA_MPLS_ACT_MODIFY:
+ 			entry->id = FLOW_ACTION_MPLS_MANGLE;
+ 			entry->mpls_mangle.label = tcf_mpls_label(act);
+ 			entry->mpls_mangle.tc = tcf_mpls_tc(act);
+ 			entry->mpls_mangle.bos = tcf_mpls_bos(act);
+ 			entry->mpls_mangle.ttl = tcf_mpls_ttl(act);
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		switch (tcf_mpls_action(act)) {
+ 		case TCA_MPLS_ACT_PUSH:
+ 			fl_action->id = FLOW_ACTION_MPLS_PUSH;
+ 			break;
+ 		case TCA_MPLS_ACT_POP:
+ 			fl_action->id = FLOW_ACTION_MPLS_POP;
+ 			break;
+ 		case TCA_MPLS_ACT_MODIFY:
+ 			fl_action->id = FLOW_ACTION_MPLS_MANGLE;
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_mpls_ops = {
  	.kind		=	"mpls",
  	.id		=	TCA_ID_MPLS,
diff --cc net/sched/act_police.c
index bee29ddd53eb,0923aa2b8f8a..000000000000
--- a/net/sched/act_police.c
+++ b/net/sched/act_police.c
@@@ -409,6 -405,30 +409,33 @@@ static int tcf_police_search(struct ne
  	return tcf_idr_search(tn, a, index);
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_police_offload_act_setup(struct tc_action *act, void *entry_data,
+ 					u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		entry->id = FLOW_ACTION_POLICE;
+ 		entry->police.burst = tcf_police_burst(act);
+ 		entry->police.rate_bytes_ps =
+ 			tcf_police_rate_bytes_ps(act);
+ 		entry->police.burst_pkt = tcf_police_burst_pkt(act);
+ 		entry->police.rate_pkt_ps =
+ 			tcf_police_rate_pkt_ps(act);
+ 		entry->police.mtu = tcf_police_tcfp_mtu(act);
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		fl_action->id = FLOW_ACTION_POLICE;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  MODULE_AUTHOR("Alexey Kuznetsov");
  MODULE_DESCRIPTION("Policing actions");
  MODULE_LICENSE("GPL");
diff --cc net/sched/act_sample.c
index ad03dbf8c57f,9a22cdda6bbd..000000000000
--- a/net/sched/act_sample.c
+++ b/net/sched/act_sample.c
@@@ -285,6 -282,35 +285,38 @@@ tcf_sample_get_group(const struct tc_ac
  	return group;
  }
  
++<<<<<<< HEAD
++=======
+ static void tcf_offload_sample_get_group(struct flow_action_entry *entry,
+ 					 const struct tc_action *act)
+ {
+ 	entry->sample.psample_group =
+ 		act->ops->get_psample_group(act, &entry->destructor);
+ 	entry->destructor_priv = entry->sample.psample_group;
+ }
+ 
+ static int tcf_sample_offload_act_setup(struct tc_action *act, void *entry_data,
+ 					u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		entry->id = FLOW_ACTION_SAMPLE;
+ 		entry->sample.trunc_size = tcf_sample_trunc_size(act);
+ 		entry->sample.truncate = tcf_sample_truncate(act);
+ 		entry->sample.rate = tcf_sample_rate(act);
+ 		tcf_offload_sample_get_group(entry, act);
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		fl_action->id = FLOW_ACTION_SAMPLE;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_sample_ops = {
  	.kind	  = "sample",
  	.id	  = TCA_ID_SAMPLE,
diff --cc net/sched/act_skbedit.c
index 15e1b9646bf0,ceba11b198bb..000000000000
--- a/net/sched/act_skbedit.c
+++ b/net/sched/act_skbedit.c
@@@ -338,6 -327,41 +338,44 @@@ static size_t tcf_skbedit_get_fill_size
  		+ nla_total_size_64bit(sizeof(u64)); /* TCA_SKBEDIT_FLAGS */
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_skbedit_offload_act_setup(struct tc_action *act, void *entry_data,
+ 					 u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		if (is_tcf_skbedit_mark(act)) {
+ 			entry->id = FLOW_ACTION_MARK;
+ 			entry->mark = tcf_skbedit_mark(act);
+ 		} else if (is_tcf_skbedit_ptype(act)) {
+ 			entry->id = FLOW_ACTION_PTYPE;
+ 			entry->ptype = tcf_skbedit_ptype(act);
+ 		} else if (is_tcf_skbedit_priority(act)) {
+ 			entry->id = FLOW_ACTION_PRIORITY;
+ 			entry->priority = tcf_skbedit_priority(act);
+ 		} else {
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		if (is_tcf_skbedit_mark(act))
+ 			fl_action->id = FLOW_ACTION_MARK;
+ 		else if (is_tcf_skbedit_ptype(act))
+ 			fl_action->id = FLOW_ACTION_PTYPE;
+ 		else if (is_tcf_skbedit_priority(act))
+ 			fl_action->id = FLOW_ACTION_PRIORITY;
+ 		else
+ 			return -EOPNOTSUPP;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_skbedit_ops = {
  	.kind		=	"skbedit",
  	.id		=	TCA_ID_SKBEDIT,
diff --cc net/sched/act_tunnel_key.c
index 49718e0c173b,23aba03d26a8..000000000000
--- a/net/sched/act_tunnel_key.c
+++ b/net/sched/act_tunnel_key.c
@@@ -791,6 -787,59 +791,62 @@@ static int tunnel_key_search(struct ne
  	return tcf_idr_search(tn, a, index);
  }
  
++<<<<<<< HEAD
++=======
+ static void tcf_tunnel_encap_put_tunnel(void *priv)
+ {
+ 	struct ip_tunnel_info *tunnel = priv;
+ 
+ 	kfree(tunnel);
+ }
+ 
+ static int tcf_tunnel_encap_get_tunnel(struct flow_action_entry *entry,
+ 				       const struct tc_action *act)
+ {
+ 	entry->tunnel = tcf_tunnel_info_copy(act);
+ 	if (!entry->tunnel)
+ 		return -ENOMEM;
+ 	entry->destructor = tcf_tunnel_encap_put_tunnel;
+ 	entry->destructor_priv = entry->tunnel;
+ 	return 0;
+ }
+ 
+ static int tcf_tunnel_key_offload_act_setup(struct tc_action *act,
+ 					    void *entry_data,
+ 					    u32 *index_inc,
+ 					    bool bind)
+ {
+ 	int err;
+ 
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		if (is_tcf_tunnel_set(act)) {
+ 			entry->id = FLOW_ACTION_TUNNEL_ENCAP;
+ 			err = tcf_tunnel_encap_get_tunnel(entry, act);
+ 			if (err)
+ 				return err;
+ 		} else if (is_tcf_tunnel_release(act)) {
+ 			entry->id = FLOW_ACTION_TUNNEL_DECAP;
+ 		} else {
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		if (is_tcf_tunnel_set(act))
+ 			fl_action->id = FLOW_ACTION_TUNNEL_ENCAP;
+ 		else if (is_tcf_tunnel_release(act))
+ 			fl_action->id = FLOW_ACTION_TUNNEL_DECAP;
+ 		else
+ 			return -EOPNOTSUPP;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_tunnel_key_ops = {
  	.kind		=	"tunnel_key",
  	.id		=	TCA_ID_TUNNEL_KEY,
diff --cc net/sched/act_vlan.c
index b9dcb2d5e0cb,756e2dcde1cd..000000000000
--- a/net/sched/act_vlan.c
+++ b/net/sched/act_vlan.c
@@@ -375,6 -368,53 +375,56 @@@ static size_t tcf_vlan_get_fill_size(co
  		+ nla_total_size(sizeof(u8)); /* TCA_VLAN_PUSH_VLAN_PRIORITY */
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_vlan_offload_act_setup(struct tc_action *act, void *entry_data,
+ 				      u32 *index_inc, bool bind)
+ {
+ 	if (bind) {
+ 		struct flow_action_entry *entry = entry_data;
+ 
+ 		switch (tcf_vlan_action(act)) {
+ 		case TCA_VLAN_ACT_PUSH:
+ 			entry->id = FLOW_ACTION_VLAN_PUSH;
+ 			entry->vlan.vid = tcf_vlan_push_vid(act);
+ 			entry->vlan.proto = tcf_vlan_push_proto(act);
+ 			entry->vlan.prio = tcf_vlan_push_prio(act);
+ 			break;
+ 		case TCA_VLAN_ACT_POP:
+ 			entry->id = FLOW_ACTION_VLAN_POP;
+ 			break;
+ 		case TCA_VLAN_ACT_MODIFY:
+ 			entry->id = FLOW_ACTION_VLAN_MANGLE;
+ 			entry->vlan.vid = tcf_vlan_push_vid(act);
+ 			entry->vlan.proto = tcf_vlan_push_proto(act);
+ 			entry->vlan.prio = tcf_vlan_push_prio(act);
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 		*index_inc = 1;
+ 	} else {
+ 		struct flow_offload_action *fl_action = entry_data;
+ 
+ 		switch (tcf_vlan_action(act)) {
+ 		case TCA_VLAN_ACT_PUSH:
+ 			fl_action->id = FLOW_ACTION_VLAN_PUSH;
+ 			break;
+ 		case TCA_VLAN_ACT_POP:
+ 			fl_action->id = FLOW_ACTION_VLAN_POP;
+ 			break;
+ 		case TCA_VLAN_ACT_MODIFY:
+ 			fl_action->id = FLOW_ACTION_VLAN_MANGLE;
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  static struct tc_action_ops act_vlan_ops = {
  	.kind		=	"vlan",
  	.id		=	TCA_ID_VLAN,
diff --cc net/sched/cls_api.c
index 4fa16f5b3d55,353e1eed48be..000000000000
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@@ -3487,81 -3474,25 +3487,86 @@@ void tc_cleanup_offload_action(struct f
  }
  EXPORT_SYMBOL(tc_cleanup_offload_action);
  
 -static int tc_setup_offload_act(struct tc_action *act,
 -				struct flow_action_entry *entry,
 -				u32 *index_inc)
 +static void tcf_mirred_get_dev(struct flow_action_entry *entry,
 +			       const struct tc_action *act)
  {
  #ifdef CONFIG_NET_CLS_ACT
 -	if (act->ops->offload_act_setup)
 -		return act->ops->offload_act_setup(act, entry, index_inc, true);
 -	else
 -		return -EOPNOTSUPP;
 -#else
 +	entry->dev = act->ops->get_dev(act, &entry->destructor);
 +	if (!entry->dev)
 +		return;
 +	entry->destructor_priv = entry->dev;
 +#endif
 +}
 +
++<<<<<<< HEAD
 +static void tcf_tunnel_encap_put_tunnel(void *priv)
 +{
 +	struct ip_tunnel_info *tunnel = priv;
 +
 +	kfree(tunnel);
 +}
 +
 +static int tcf_tunnel_encap_get_tunnel(struct flow_action_entry *entry,
 +				       const struct tc_action *act)
 +{
 +	entry->tunnel = tcf_tunnel_info_copy(act);
 +	if (!entry->tunnel)
 +		return -ENOMEM;
 +	entry->destructor = tcf_tunnel_encap_put_tunnel;
 +	entry->destructor_priv = entry->tunnel;
  	return 0;
 +}
 +
 +static void tcf_sample_get_group(struct flow_action_entry *entry,
 +				 const struct tc_action *act)
 +{
 +#ifdef CONFIG_NET_CLS_ACT
 +	entry->sample.psample_group =
 +		act->ops->get_psample_group(act, &entry->destructor);
 +	entry->destructor_priv = entry->sample.psample_group;
  #endif
  }
  
 +static void tcf_gate_entry_destructor(void *priv)
 +{
 +	struct action_gate_entry *oe = priv;
 +
 +	kfree(oe);
 +}
 +
 +static int tcf_gate_get_entries(struct flow_action_entry *entry,
 +				const struct tc_action *act)
 +{
 +	entry->gate.entries = tcf_gate_get_list(act);
 +
 +	if (!entry->gate.entries)
 +		return -EINVAL;
 +
 +	entry->destructor = tcf_gate_entry_destructor;
 +	entry->destructor_priv = entry->gate.entries;
 +
 +	return 0;
 +}
 +
 +static enum flow_action_hw_stats tc_act_hw_stats(u8 hw_stats)
 +{
 +	if (WARN_ON_ONCE(hw_stats > TCA_ACT_HW_STATS_ANY))
 +		return FLOW_ACTION_HW_STATS_DONT_CARE;
 +	else if (!hw_stats)
 +		return FLOW_ACTION_HW_STATS_DISABLED;
 +
 +	return hw_stats;
 +}
 +
 +int tc_setup_offload_action(struct flow_action *flow_action,
 +			    const struct tcf_exts *exts)
++=======
+ int tc_setup_action(struct flow_action *flow_action,
+ 		    struct tc_action *actions[])
++>>>>>>> 8cbfe939abe9 (flow_offload: allow user to offload tc action to net device)
  {
 -	int i, j, index, err = 0;
  	struct tc_action *act;
 +	int i, j, k, err = 0;
  
  	BUILD_BUG_ON(TCA_ACT_HW_STATS_ANY != FLOW_ACTION_HW_STATS_ANY);
  	BUILD_BUG_ON(TCA_ACT_HW_STATS_IMMEDIATE != FLOW_ACTION_HW_STATS_IMMEDIATE);
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 379d8bad852d..b5607936c551 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -863,6 +863,7 @@ enum tc_setup_type {
 	TC_SETUP_QDISC_TBF,
 	TC_SETUP_QDISC_FIFO,
 	TC_SETUP_QDISC_HTB,
+	TC_SETUP_ACT,
 };
 
 /* These structures hold the attributes of bpf state that are being passed
diff --git a/include/net/flow_offload.h b/include/net/flow_offload.h
index d20115a94aee..304eaa98b32e 100644
--- a/include/net/flow_offload.h
+++ b/include/net/flow_offload.h
@@ -557,6 +557,23 @@ struct flow_cls_offload {
 	u32 classid;
 };
 
+enum offload_act_command  {
+	FLOW_ACT_REPLACE,
+	FLOW_ACT_DESTROY,
+	FLOW_ACT_STATS,
+};
+
+struct flow_offload_action {
+	struct netlink_ext_ack *extack; /* NULL in FLOW_ACT_STATS process*/
+	enum offload_act_command  command;
+	enum flow_action_id id;
+	u32 index;
+	struct flow_stats stats;
+	struct flow_action action;
+};
+
+struct flow_offload_action *offload_action_alloc(unsigned int num_actions);
+
 static inline struct flow_rule *
 flow_cls_offload_flow_rule(struct flow_cls_offload *flow_cmd)
 {
diff --git a/include/net/pkt_cls.h b/include/net/pkt_cls.h
index 60821220f1c0..ea9a3cb8c5ae 100644
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@ -258,6 +258,9 @@ static inline void tcf_exts_put_net(struct tcf_exts *exts)
 	for (; 0; (void)(i), (void)(a), (void)(exts))
 #endif
 
+#define tcf_act_for_each_action(i, a, actions) \
+	for (i = 0; i < TCA_ACT_MAX_PRIO && ((a) = actions[i]); i++)
+
 static inline void
 tcf_exts_stats_update(const struct tcf_exts *exts,
 		      u64 bytes, u64 packets, u64 drops, u64 lastuse,
@@ -535,6 +538,8 @@ tcf_match_indev(struct sk_buff *skb, int ifindex)
 int tc_setup_offload_action(struct flow_action *flow_action,
 			    const struct tcf_exts *exts);
 void tc_cleanup_offload_action(struct flow_action *flow_action);
+int tc_setup_action(struct flow_action *flow_action,
+		    struct tc_action *actions[]);
 
 int tc_setup_cb_call(struct tcf_block *block, enum tc_setup_type type,
 		     void *type_data, bool err_stop, bool rtnl_held);
diff --git a/net/core/flow_offload.c b/net/core/flow_offload.c
index 6beaea13564a..022c945817fa 100644
--- a/net/core/flow_offload.c
+++ b/net/core/flow_offload.c
@@ -27,6 +27,26 @@ struct flow_rule *flow_rule_alloc(unsigned int num_actions)
 }
 EXPORT_SYMBOL(flow_rule_alloc);
 
+struct flow_offload_action *offload_action_alloc(unsigned int num_actions)
+{
+	struct flow_offload_action *fl_action;
+	int i;
+
+	fl_action = kzalloc(struct_size(fl_action, action.entries, num_actions),
+			    GFP_KERNEL);
+	if (!fl_action)
+		return NULL;
+
+	fl_action->action.num_entries = num_actions;
+	/* Pre-fill each action hw_stats with DONT_CARE.
+	 * Caller can override this if it wants stats for a given action.
+	 */
+	for (i = 0; i < num_actions; i++)
+		fl_action->action.entries[i].hw_stats = FLOW_ACTION_HW_STATS_DONT_CARE;
+
+	return fl_action;
+}
+
 #define FLOW_DISSECTOR_MATCH(__rule, __type, __out)				\
 	const struct flow_match *__m = &(__rule)->match;			\
 	struct flow_dissector *__d = (__m)->dissector;				\
@@ -549,19 +569,25 @@ int flow_indr_dev_setup_offload(struct net_device *dev,	struct Qdisc *sch,
 				void (*cleanup)(struct flow_block_cb *block_cb))
 {
 	struct flow_indr_dev *this;
+	u32 count = 0;
+	int err;
 
 	mutex_lock(&flow_indr_block_lock);
+	if (bo) {
+		if (bo->command == FLOW_BLOCK_BIND)
+			indir_dev_add(data, dev, sch, type, cleanup, bo);
+		else if (bo->command == FLOW_BLOCK_UNBIND)
+			indir_dev_remove(data);
+	}
 
-	if (bo->command == FLOW_BLOCK_BIND)
-		indir_dev_add(data, dev, sch, type, cleanup, bo);
-	else if (bo->command == FLOW_BLOCK_UNBIND)
-		indir_dev_remove(data);
-
-	list_for_each_entry(this, &flow_block_indr_dev_list, list)
-		this->cb(dev, sch, this->cb_priv, type, bo, data, cleanup);
+	list_for_each_entry(this, &flow_block_indr_dev_list, list) {
+		err = this->cb(dev, sch, this->cb_priv, type, bo, data, cleanup);
+		if (!err)
+			count++;
+	}
 
 	mutex_unlock(&flow_indr_block_lock);
 
-	return list_empty(&bo->cb_list) ? -EOPNOTSUPP : 0;
+	return (bo && list_empty(&bo->cb_list)) ? -EOPNOTSUPP : count;
 }
 EXPORT_SYMBOL(flow_indr_dev_setup_offload);
diff --git a/net/sched/act_api.c b/net/sched/act_api.c
index c4b1bd9de693..529a92eda7da 100644
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@ -25,8 +25,10 @@
 #include <net/sock.h>
 #include <net/sch_generic.h>
 #include <net/pkt_cls.h>
+#include <net/tc_act/tc_pedit.h>
 #include <net/act_api.h>
 #include <net/netlink.h>
+#include <net/flow_offload.h>
 
 #ifdef CONFIG_INET
 DEFINE_STATIC_KEY_FALSE(tcf_frag_xmit_count);
@@ -135,8 +137,92 @@ static void free_tcf(struct tc_action *p)
 	kfree(p);
 }
 
+static unsigned int tcf_offload_act_num_actions_single(struct tc_action *act)
+{
+	if (is_tcf_pedit(act))
+		return tcf_pedit_nkeys(act);
+	else
+		return 1;
+}
+
+static int offload_action_init(struct flow_offload_action *fl_action,
+			       struct tc_action *act,
+			       enum offload_act_command  cmd,
+			       struct netlink_ext_ack *extack)
+{
+	fl_action->extack = extack;
+	fl_action->command = cmd;
+	fl_action->index = act->tcfa_index;
+
+	if (act->ops->offload_act_setup)
+		return act->ops->offload_act_setup(act, fl_action, NULL, false);
+
+	return -EOPNOTSUPP;
+}
+
+static int tcf_action_offload_cmd(struct flow_offload_action *fl_act,
+				  struct netlink_ext_ack *extack)
+{
+	int err;
+
+	err = flow_indr_dev_setup_offload(NULL, NULL, TC_SETUP_ACT,
+					  fl_act, NULL, NULL);
+	if (err < 0)
+		return err;
+
+	return 0;
+}
+
+/* offload the tc action after it is inserted */
+static int tcf_action_offload_add(struct tc_action *action,
+				  struct netlink_ext_ack *extack)
+{
+	struct tc_action *actions[TCA_ACT_MAX_PRIO] = {
+		[0] = action,
+	};
+	struct flow_offload_action *fl_action;
+	int num, err = 0;
+
+	num = tcf_offload_act_num_actions_single(action);
+	fl_action = offload_action_alloc(num);
+	if (!fl_action)
+		return -ENOMEM;
+
+	err = offload_action_init(fl_action, action, FLOW_ACT_REPLACE, extack);
+	if (err)
+		goto fl_err;
+
+	err = tc_setup_action(&fl_action->action, actions);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Failed to setup tc actions for offload\n");
+		goto fl_err;
+	}
+
+	err = tcf_action_offload_cmd(fl_action, extack);
+	tc_cleanup_offload_action(&fl_action->action);
+
+fl_err:
+	kfree(fl_action);
+
+	return err;
+}
+
+static int tcf_action_offload_del(struct tc_action *action)
+{
+	struct flow_offload_action fl_act = {};
+	int err = 0;
+
+	err = offload_action_init(&fl_act, action, FLOW_ACT_DESTROY, NULL);
+	if (err)
+		return err;
+
+	return tcf_action_offload_cmd(&fl_act, NULL);
+}
+
 static void tcf_action_cleanup(struct tc_action *p)
 {
+	tcf_action_offload_del(p);
 	if (p->ops->cleanup)
 		p->ops->cleanup(p);
 
@@ -1070,6 +1156,11 @@ struct tc_action *tcf_action_init_1(struct net *net, struct tcf_proto *tp,
 	return ERR_PTR(err);
 }
 
+static bool tc_act_bind(u32 flags)
+{
+	return !!(flags & TCA_ACT_FLAGS_BIND);
+}
+
 /* Returns numbers of initialized actions or negative error. */
 
 int tcf_action_init(struct net *net, struct tcf_proto *tp, struct nlattr *nla,
@@ -1112,6 +1203,8 @@ int tcf_action_init(struct net *net, struct tcf_proto *tp, struct nlattr *nla,
 		sz += tcf_action_fill_size(act);
 		/* Start from index 0 */
 		actions[i - 1] = act;
+		if (!tc_act_bind(flags))
+			tcf_action_offload_add(act, extack);
 	}
 
 	/* We have to commit them all together, because if any error happened in
* Unmerged path net/sched/act_csum.c
* Unmerged path net/sched/act_ct.c
* Unmerged path net/sched/act_gact.c
* Unmerged path net/sched/act_gate.c
* Unmerged path net/sched/act_mirred.c
* Unmerged path net/sched/act_mpls.c
* Unmerged path net/sched/act_police.c
* Unmerged path net/sched/act_sample.c
* Unmerged path net/sched/act_skbedit.c
* Unmerged path net/sched/act_tunnel_key.c
* Unmerged path net/sched/act_vlan.c
* Unmerged path net/sched/cls_api.c
