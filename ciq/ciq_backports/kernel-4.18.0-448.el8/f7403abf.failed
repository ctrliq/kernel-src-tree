iommu/io-pgtable: Abstract iommu_iotlb_gather access

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Robin Murphy <robin.murphy@arm.com>
commit f7403abf5f06f407c50252e003f5fb332325147b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/f7403abf.failed

Previously io-pgtable merely passed the iommu_iotlb_gather pointer
through to helpers, but now it has grown its own direct dereference.
This turns out to break the build for !IOMMU_API configs where the
structure only has a dummy definition. It will probably also crash
drivers who don't use the gather mechanism and simply pass in NULL.

Wrap this dereference in a suitable helper which can both be stubbed
out for !IOMMU_API and encapsulate a NULL check otherwise.

Fixes: 7a7c5badf858 ("iommu: Indicate queued flushes via gather data")
	Reported-by: kernel test robot <lkp@intel.com>
	Signed-off-by: Robin Murphy <robin.murphy@arm.com>
Link: https://lore.kernel.org/r/83672ee76f6405c82845a55c148fa836f56fbbc1.1629465282.git.robin.murphy@arm.com
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit f7403abf5f06f407c50252e003f5fb332325147b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/io-pgtable-arm-v7s.c
#	drivers/iommu/io-pgtable-arm.c
diff --cc drivers/iommu/io-pgtable-arm-v7s.c
index 25a1e318422a,bfb6acb651e5..000000000000
--- a/drivers/iommu/io-pgtable-arm-v7s.c
+++ b/drivers/iommu/io-pgtable-arm-v7s.c
@@@ -665,14 -700,7 +665,18 @@@ static size_t __arm_v7s_unmap(struct ar
  						ARM_V7S_BLOCK_SIZE(lvl + 1));
  				ptep = iopte_deref(pte[i], lvl, data);
  				__arm_v7s_free_table(ptep, lvl + 1, data);
++<<<<<<< HEAD
 +			} else if (iop->cfg.quirks & IO_PGTABLE_QUIRK_NON_STRICT) {
 +				/*
 +				 * Order the PTE update against queueing the IOVA, to
 +				 * guarantee that a flush callback from a different CPU
 +				 * has observed it before the TLBIALL can be issued.
 +				 */
 +				smp_wmb();
 +			} else {
++=======
+ 			} else if (!iommu_iotlb_gather_queued(gather)) {
++>>>>>>> f7403abf5f06 (iommu/io-pgtable: Abstract iommu_iotlb_gather access)
  				io_pgtable_tlb_add_page(iop, gather, iova, blk_size);
  			}
  			iova += blk_size;
diff --cc drivers/iommu/io-pgtable-arm.c
index bf3c86225fc1,9697721f7e3a..000000000000
--- a/drivers/iommu/io-pgtable-arm.c
+++ b/drivers/iommu/io-pgtable-arm.c
@@@ -650,14 -638,7 +650,18 @@@ static size_t __arm_lpae_unmap(struct a
  				io_pgtable_tlb_flush_walk(iop, iova + i * size, size,
  							  ARM_LPAE_GRANULE(data));
  				__arm_lpae_free_pgtable(data, lvl + 1, iopte_deref(pte, data));
++<<<<<<< HEAD
 +			} else if (iop->cfg.quirks & IO_PGTABLE_QUIRK_NON_STRICT) {
 +				/*
 +				 * Order the PTE update against queueing the IOVA, to
 +				 * guarantee that a flush callback from a different CPU
 +				 * has observed it before the TLBIALL can be issued.
 +				 */
 +				smp_wmb();
 +			} else {
++=======
+ 			} else if (!iommu_iotlb_gather_queued(gather)) {
++>>>>>>> f7403abf5f06 (iommu/io-pgtable: Abstract iommu_iotlb_gather access)
  				io_pgtable_tlb_add_page(iop, gather, iova + i * size, size);
  			}
  
* Unmerged path drivers/iommu/io-pgtable-arm-v7s.c
* Unmerged path drivers/iommu/io-pgtable-arm.c
diff --git a/include/linux/iommu.h b/include/linux/iommu.h
index b00fb18b7995..cf14feb6ba3a 100644
--- a/include/linux/iommu.h
+++ b/include/linux/iommu.h
@@ -646,6 +646,11 @@ static inline void iommu_iotlb_gather_add_page(struct iommu_domain *domain,
 	iommu_iotlb_gather_add_range(gather, iova, size);
 }
 
+static inline bool iommu_iotlb_gather_queued(struct iommu_iotlb_gather *gather)
+{
+	return gather && gather->queued;
+}
+
 /* PCI device grouping function */
 extern struct iommu_group *pci_device_group(struct device *dev);
 /* Generic device grouping function */
@@ -993,6 +998,11 @@ static inline void iommu_iotlb_gather_add_page(struct iommu_domain *domain,
 {
 }
 
+static inline bool iommu_iotlb_gather_queued(struct iommu_iotlb_gather *gather)
+{
+	return false;
+}
+
 static inline void iommu_device_unregister(struct iommu_device *iommu)
 {
 }
