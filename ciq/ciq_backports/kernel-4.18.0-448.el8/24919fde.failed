perf/x86/intel: Fix unchecked MSR access error for Alder Lake N

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Kan Liang <kan.liang@linux.intel.com>
commit 24919fdea6f8b31d7cdf32ac291bc5dd0b023878
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/24919fde.failed

For some Alder Lake N machine, the below unchecked MSR access error may be
triggered.

[ 0.088017] rcu: Hierarchical SRCU implementation.
[ 0.088017] unchecked MSR access error: WRMSR to 0x38f (tried to write
0x0001000f0000003f) at rIP: 0xffffffffb5684de8 (native_write_msr+0x8/0x30)
[ 0.088017] Call Trace:
[ 0.088017] <TASK>
[ 0.088017] __intel_pmu_enable_all.constprop.46+0x4a/0xa0

The Alder Lake N only has e-cores. The X86_FEATURE_HYBRID_CPU flag is
not set. The perf cannot retrieve the correct CPU type via
get_this_hybrid_cpu_type(). The model specific get_hybrid_cpu_type() is
hardcode to p-core. The wrong CPU type is given to the PMU of the
Alder Lake N.

Since Alder Lake N isn't in fact a hybrid CPU, remove ALDERLAKE_N from
the rest of {ALDER,RAPTOP}LAKE and create a non-hybrid PMU setup.

The differences between Gracemont and the previous Tremont are,
- Number of GP counters
- Load and store latency Events
- PEBS event_constraints
- Instruction Latency support
- Data source encoding
- Memory access latency encoding

Fixes: c2a960f7c574 ("perf/x86: Add new Alder Lake and Raptor Lake support")
	Reported-by: Jianfeng Gao <jianfeng.gao@intel.com>
	Suggested-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20220831142702.153110-1-kan.liang@linux.intel.com
(cherry picked from commit 24919fdea6f8b31d7cdf32ac291bc5dd0b023878)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/events/intel/ds.c
#	arch/x86/events/perf_event.h
diff --cc arch/x86/events/intel/ds.c
index 381e759e2a07,ac973c6f82ad..000000000000
--- a/arch/x86/events/intel/ds.c
+++ b/arch/x86/events/intel/ds.c
@@@ -98,11 -98,41 +98,49 @@@ void __init intel_pmu_pebs_data_source_
  {
  	u64 pmem_or_l4 = pmem ? LEVEL(PMEM) : LEVEL(L4);
  
++<<<<<<< HEAD
 +	pebs_data_source[0x08] = OP_LH | pmem_or_l4 | P(SNOOP, HIT);
 +	pebs_data_source[0x09] = OP_LH | pmem_or_l4 | REM | P(SNOOP, HIT);
 +	pebs_data_source[0x0b] = OP_LH | LEVEL(RAM) | REM | P(SNOOP, NONE);
 +	pebs_data_source[0x0c] = OP_LH | LEVEL(ANY_CACHE) | REM | P(SNOOPX, FWD);
 +	pebs_data_source[0x0d] = OP_LH | LEVEL(ANY_CACHE) | REM | P(SNOOP, HITM);
++=======
+ 	data_source[0x08] = OP_LH | pmem_or_l4 | P(SNOOP, HIT);
+ 	data_source[0x09] = OP_LH | pmem_or_l4 | REM | P(SNOOP, HIT);
+ 	data_source[0x0b] = OP_LH | LEVEL(RAM) | REM | P(SNOOP, NONE);
+ 	data_source[0x0c] = OP_LH | LEVEL(ANY_CACHE) | REM | P(SNOOPX, FWD);
+ 	data_source[0x0d] = OP_LH | LEVEL(ANY_CACHE) | REM | P(SNOOP, HITM);
+ }
+ 
+ void __init intel_pmu_pebs_data_source_skl(bool pmem)
+ {
+ 	__intel_pmu_pebs_data_source_skl(pmem, pebs_data_source);
+ }
+ 
+ static void __init __intel_pmu_pebs_data_source_grt(u64 *data_source)
+ {
+ 	data_source[0x05] = OP_LH | P(LVL, L3) | LEVEL(L3) | P(SNOOP, HIT);
+ 	data_source[0x06] = OP_LH | P(LVL, L3) | LEVEL(L3) | P(SNOOP, HITM);
+ 	data_source[0x08] = OP_LH | P(LVL, L3) | LEVEL(L3) | P(SNOOPX, FWD);
+ }
+ 
+ void __init intel_pmu_pebs_data_source_grt(void)
+ {
+ 	__intel_pmu_pebs_data_source_grt(pebs_data_source);
+ }
+ 
+ void __init intel_pmu_pebs_data_source_adl(void)
+ {
+ 	u64 *data_source;
+ 
+ 	data_source = x86_pmu.hybrid_pmu[X86_HYBRID_PMU_CORE_IDX].pebs_data_source;
+ 	memcpy(data_source, pebs_data_source, sizeof(pebs_data_source));
+ 	__intel_pmu_pebs_data_source_skl(false, data_source);
+ 
+ 	data_source = x86_pmu.hybrid_pmu[X86_HYBRID_PMU_ATOM_IDX].pebs_data_source;
+ 	memcpy(data_source, pebs_data_source, sizeof(pebs_data_source));
+ 	__intel_pmu_pebs_data_source_grt(data_source);
++>>>>>>> 24919fdea6f8 (perf/x86/intel: Fix unchecked MSR access error for Alder Lake N)
  }
  
  static u64 precise_store_data(u64 status)
diff --cc arch/x86/events/perf_event.h
index ec6b1d551e32,266143abcbd8..000000000000
--- a/arch/x86/events/perf_event.h
+++ b/arch/x86/events/perf_event.h
@@@ -1389,6 -1514,10 +1389,13 @@@ void intel_pmu_pebs_data_source_nhm(voi
  
  void intel_pmu_pebs_data_source_skl(bool pmem);
  
++<<<<<<< HEAD
++=======
+ void intel_pmu_pebs_data_source_adl(void);
+ 
+ void intel_pmu_pebs_data_source_grt(void);
+ 
++>>>>>>> 24919fdea6f8 (perf/x86/intel: Fix unchecked MSR access error for Alder Lake N)
  int intel_pmu_setup_lbr_filter(struct perf_event *event);
  
  void intel_pt_interrupt(void);
diff --git a/arch/x86/events/intel/core.c b/arch/x86/events/intel/core.c
index 0b9951a3cc49..ca54cb7b0d06 100644
--- a/arch/x86/events/intel/core.c
+++ b/arch/x86/events/intel/core.c
@@ -2077,6 +2077,15 @@ static struct extra_reg intel_tnt_extra_regs[] __read_mostly = {
 	EVENT_EXTRA_END
 };
 
+EVENT_ATTR_STR(mem-loads,	mem_ld_grt,	"event=0xd0,umask=0x5,ldlat=3");
+EVENT_ATTR_STR(mem-stores,	mem_st_grt,	"event=0xd0,umask=0x6");
+
+static struct attribute *grt_mem_attrs[] = {
+	EVENT_PTR(mem_ld_grt),
+	EVENT_PTR(mem_st_grt),
+	NULL
+};
+
 static struct extra_reg intel_grt_extra_regs[] __read_mostly = {
 	/* must define OFFCORE_RSP_X first, see intel_fixup_er() */
 	INTEL_UEVENT_EXTRA_REG(0x01b7, MSR_OFFCORE_RSP_0, 0x3fffffffffull, RSP_0),
@@ -5788,6 +5797,36 @@ __init int intel_pmu_init(void)
 		name = "Tremont";
 		break;
 
+	case INTEL_FAM6_ALDERLAKE_N:
+		x86_pmu.mid_ack = true;
+		memcpy(hw_cache_event_ids, glp_hw_cache_event_ids,
+		       sizeof(hw_cache_event_ids));
+		memcpy(hw_cache_extra_regs, tnt_hw_cache_extra_regs,
+		       sizeof(hw_cache_extra_regs));
+		hw_cache_event_ids[C(ITLB)][C(OP_READ)][C(RESULT_ACCESS)] = -1;
+
+		x86_pmu.event_constraints = intel_slm_event_constraints;
+		x86_pmu.pebs_constraints = intel_grt_pebs_event_constraints;
+		x86_pmu.extra_regs = intel_grt_extra_regs;
+
+		x86_pmu.pebs_aliases = NULL;
+		x86_pmu.pebs_prec_dist = true;
+		x86_pmu.pebs_block = true;
+		x86_pmu.lbr_pt_coexist = true;
+		x86_pmu.flags |= PMU_FL_HAS_RSP_1;
+		x86_pmu.flags |= PMU_FL_INSTR_LATENCY;
+
+		intel_pmu_pebs_data_source_grt();
+		x86_pmu.pebs_latency_data = adl_latency_data_small;
+		x86_pmu.get_event_constraints = tnt_get_event_constraints;
+		x86_pmu.limit_period = spr_limit_period;
+		td_attr = tnt_events_attrs;
+		mem_attr = grt_mem_attrs;
+		extra_attr = nhm_format_attr;
+		pr_cont("Gracemont events, ");
+		name = "gracemont";
+		break;
+
 	case INTEL_FAM6_WESTMERE:
 	case INTEL_FAM6_WESTMERE_EP:
 	case INTEL_FAM6_WESTMERE_EX:
@@ -6130,7 +6169,6 @@ __init int intel_pmu_init(void)
 
 	case INTEL_FAM6_ALDERLAKE:
 	case INTEL_FAM6_ALDERLAKE_L:
-	case INTEL_FAM6_ALDERLAKE_N:
 	case INTEL_FAM6_RAPTORLAKE:
 	case INTEL_FAM6_RAPTORLAKE_P:
 		/*
* Unmerged path arch/x86/events/intel/ds.c
* Unmerged path arch/x86/events/perf_event.h
