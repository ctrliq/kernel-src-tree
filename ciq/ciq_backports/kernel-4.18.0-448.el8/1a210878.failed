powerpc/8xx: Use patch_site for memory setup patching

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-448.el8
commit-author Christophe Leroy <christophe.leroy@c-s.fr>
commit 1a210878bf21de3f60646c13001d04bd4f57dfe1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-448.el8/1a210878.failed

The 8xx TLB miss routines are patched at startup at several places.

This patch uses the new patch_site functionality in order
to get a better code readability and avoid a label mess when
dumping the code with 'objdump -d'

	Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 1a210878bf21de3f60646c13001d04bd4f57dfe1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/mm/8xx_mmu.c
diff --cc arch/powerpc/mm/8xx_mmu.c
index a1756cd3f80d,ca01ece28ab3..000000000000
--- a/arch/powerpc/mm/8xx_mmu.c
+++ b/arch/powerpc/mm/8xx_mmu.c
@@@ -113,7 -103,7 +104,11 @@@ static void __init mmu_patch_cmp_limit(
  
  	instr &= 0xffff0000;
  	instr |= (unsigned long)__va(mapped) >> 16;
++<<<<<<< HEAD
 +	patch_instruction(addr, ppc_inst(instr));
++=======
+ 	patch_instruction_site(site, instr);
++>>>>>>> 1a210878bf21 (powerpc/8xx: Use patch_site for memory setup patching)
  }
  
  unsigned long __init mmu_mapin_ram(unsigned long top)
@@@ -124,10 -114,10 +119,14 @@@
  		mapped = 0;
  		mmu_mapin_immr();
  #ifndef CONFIG_PIN_TLB_IMMR
++<<<<<<< HEAD
 +		patch_instruction(&DTLBMiss_jmp, ppc_inst(PPC_INST_NOP));
++=======
+ 		patch_instruction_site(&patch__dtlbmiss_immr_jmp, PPC_INST_NOP);
++>>>>>>> 1a210878bf21 (powerpc/8xx: Use patch_site for memory setup patching)
  #endif
  #ifndef CONFIG_PIN_TLB_TEXT
- 		mmu_patch_cmp_limit(&ITLBMiss_cmp, 0);
+ 		mmu_patch_cmp_limit(&patch__itlbmiss_linmem_top, 0);
  #endif
  	} else {
  		mapped = top & ~(LARGE_PAGE_SIZE_8M - 1);
diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h
index 193f53116c7a..3a15d6647d47 100644
--- a/arch/powerpc/include/asm/mmu-8xx.h
+++ b/arch/powerpc/include/asm/mmu-8xx.h
@@ -229,6 +229,11 @@ static inline unsigned int mmu_psize_to_shift(unsigned int mmu_psize)
 	BUG();
 }
 
+/* patch sites */
+extern s32 patch__itlbmiss_linmem_top;
+extern s32 patch__dtlbmiss_linmem_top, patch__dtlbmiss_immr_jmp;
+extern s32 patch__fixupdar_linmem_top;
+
 #endif /* !__ASSEMBLY__ */
 
 #if defined(CONFIG_PPC_4K_PAGES)
diff --git a/arch/powerpc/kernel/head_8xx.S b/arch/powerpc/kernel/head_8xx.S
index 19bdc65d05b8..5b06a4fa225f 100644
--- a/arch/powerpc/kernel/head_8xx.S
+++ b/arch/powerpc/kernel/head_8xx.S
@@ -32,6 +32,7 @@
 #include <asm/ptrace.h>
 #include <asm/fixmap.h>
 #include <asm/export.h>
+#include <asm/code-patching-asm.h>
 
 #if CONFIG_TASK_SIZE <= 0x80000000 && CONFIG_PAGE_OFFSET >= 0x80000000
 /* By simply checking Address >= 0x80000000, we know if its a kernel address */
@@ -319,8 +320,8 @@ InstructionTLBMiss:
 	cmpli	cr0, r11, PAGE_OFFSET@h
 #ifndef CONFIG_PIN_TLB_TEXT
 	/* It is assumed that kernel code fits into the first 8M page */
-_ENTRY(ITLBMiss_cmp)
-	cmpli	cr7, r11, (PAGE_OFFSET + 0x0800000)@h
+0:	cmpli	cr7, r11, (PAGE_OFFSET + 0x0800000)@h
+	patch_site	0b, patch__itlbmiss_linmem_top
 #endif
 #endif
 #endif
@@ -437,11 +438,11 @@ DataStoreTLBMiss:
 #ifndef CONFIG_PIN_TLB_IMMR
 	cmpli	cr0, r11, VIRT_IMMR_BASE@h
 #endif
-_ENTRY(DTLBMiss_cmp)
-	cmpli	cr7, r11, (PAGE_OFFSET + 0x1800000)@h
+0:	cmpli	cr7, r11, (PAGE_OFFSET + 0x1800000)@h
+	patch_site	0b, patch__dtlbmiss_linmem_top
 #ifndef CONFIG_PIN_TLB_IMMR
-_ENTRY(DTLBMiss_jmp)
-	beq-	DTLBMissIMMR
+0:	beq-	DTLBMissIMMR
+	patch_site	0b, patch__dtlbmiss_immr_jmp
 #endif
 	blt	cr7, DTLBMissLinear
 	lis	r11, (swapper_pg_dir-PAGE_OFFSET)@ha
@@ -715,8 +716,10 @@ FixupDAR:/* Entry point for dcbx workaround. */
 	mfspr	r11, SPRN_M_TW	/* Get level 1 table */
 	blt+	3f
 	rlwinm	r11, r10, 16, 0xfff8
-_ENTRY(FixupDAR_cmp)
-	cmpli	cr7, r11, (PAGE_OFFSET + 0x1800000)@h
+
+0:	cmpli	cr7, r11, (PAGE_OFFSET + 0x1800000)@h
+	patch_site	0b, patch__fixupdar_linmem_top
+
 	/* create physical page address from effective address */
 	tophys(r11, r10)
 	blt-	cr7, 201f
* Unmerged path arch/powerpc/mm/8xx_mmu.c
