KVM: x86: Add SBPB support

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-521.el8
commit-author Josh Poimboeuf <jpoimboe@kernel.org>
commit e47d86083c66525b89c7fc66cdd64d5937725563
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-521.el8/e47d8608.failed

Add support for the AMD Selective Branch Predictor Barrier (SBPB) by
advertising the CPUID bit and handling PRED_CMD writes accordingly.

Note, like SRSO_NO and IBPB_BRTYPE before it, advertise support for SBPB
even if it's not enumerated by in the raw CPUID.  Some CPUs that gained
support via a uCode patch don't report SBPB via CPUID (the kernel forces
the flag).

	Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
Link: https://lore.kernel.org/r/a4ab1e7fe50096d50fde33e739ed2da40b41ea6a.1692919072.git.jpoimboe@kernel.org
Co-developed-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: Sean Christopherson <seanjc@google.com>
(cherry picked from commit e47d86083c66525b89c7fc66cdd64d5937725563)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/cpuid.c
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/cpuid.c
index eec55b2b9e94,552dc4f3899b..000000000000
--- a/arch/x86/kvm/cpuid.c
+++ b/arch/x86/kvm/cpuid.c
@@@ -687,6 -764,14 +687,17 @@@ void kvm_set_cpu_caps(void
  		F(NULL_SEL_CLR_BASE) | F(AUTOIBRS) | 0 /* PrefetchCtlMsr */
  	);
  
++<<<<<<< HEAD
++=======
+ 	kvm_cpu_cap_check_and_set(X86_FEATURE_SBPB);
+ 	kvm_cpu_cap_check_and_set(X86_FEATURE_IBPB_BRTYPE);
+ 	kvm_cpu_cap_check_and_set(X86_FEATURE_SRSO_NO);
+ 
+ 	kvm_cpu_cap_init_kvm_defined(CPUID_8000_0022_EAX,
+ 		F(PERFMON_V2)
+ 	);
+ 
++>>>>>>> e47d86083c66 (KVM: x86: Add SBPB support)
  	/*
  	 * Synthesize "LFENCE is serializing" into the AMD-defined entry in
  	 * KVM's supported CPUID if the feature is reported as supported by the
diff --cc arch/x86/kvm/x86.c
index 73c403a2bb40,2b5b325e19f2..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -3485,26 -3653,47 +3485,51 @@@ int kvm_set_msr_common(struct kvm_vcpu 
  			return 1;
  		vcpu->arch.arch_capabilities = data;
  		break;
 -	case MSR_IA32_PERF_CAPABILITIES:
 +	case MSR_IA32_PERF_CAPABILITIES: {
 +		struct kvm_msr_entry msr_ent = {.index = msr, .data = 0};
 +
  		if (!msr_info->host_initiated)
  			return 1;
 -		if (data & ~kvm_caps.supported_perf_cap)
 +		if (kvm_get_msr_feature(&msr_ent))
 +			return 1;
 +		if (data & ~msr_ent.data)
  			return 1;
 -
 -		/*
 -		 * Note, this is not just a performance optimization!  KVM
 -		 * disallows changing feature MSRs after the vCPU has run; PMU
 -		 * refresh will bug the VM if called after the vCPU has run.
 -		 */
 -		if (vcpu->arch.perf_capabilities == data)
 -			break;
  
  		vcpu->arch.perf_capabilities = data;
++<<<<<<< HEAD
 +
 +		return 0;
 +	}
 +	case MSR_IA32_PRED_CMD:
 +		if (!msr_info->host_initiated && !guest_has_pred_cmd_msr(vcpu))
- 			return 1;
++=======
+ 		kvm_pmu_refresh(vcpu);
+ 		break;
+ 	case MSR_IA32_PRED_CMD: {
+ 		u64 reserved_bits = ~(PRED_CMD_IBPB | PRED_CMD_SBPB);
+ 
+ 		if (!msr_info->host_initiated) {
+ 			if ((!guest_has_pred_cmd_msr(vcpu)))
+ 				return 1;
+ 
+ 			if (!guest_cpuid_has(vcpu, X86_FEATURE_SPEC_CTRL) &&
+ 			    !guest_cpuid_has(vcpu, X86_FEATURE_AMD_IBPB))
+ 				reserved_bits |= PRED_CMD_IBPB;
+ 
+ 			if (!guest_cpuid_has(vcpu, X86_FEATURE_SBPB))
+ 				reserved_bits |= PRED_CMD_SBPB;
+ 		}
+ 
+ 		if (!boot_cpu_has(X86_FEATURE_IBPB))
+ 			reserved_bits |= PRED_CMD_IBPB;
+ 
+ 		if (!boot_cpu_has(X86_FEATURE_SBPB))
+ 			reserved_bits |= PRED_CMD_SBPB;
  
- 		if (!boot_cpu_has(X86_FEATURE_IBPB) || (data & ~PRED_CMD_IBPB))
+ 		if (data & reserved_bits)
++>>>>>>> e47d86083c66 (KVM: x86: Add SBPB support)
  			return 1;
+ 
  		if (!data)
  			break;
  
* Unmerged path arch/x86/kvm/cpuid.c
diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 71ec62694062..e43891149471 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -165,7 +165,8 @@ static inline bool guest_has_spec_ctrl_msr(struct kvm_vcpu *vcpu)
 static inline bool guest_has_pred_cmd_msr(struct kvm_vcpu *vcpu)
 {
 	return (guest_cpuid_has(vcpu, X86_FEATURE_SPEC_CTRL) ||
-		guest_cpuid_has(vcpu, X86_FEATURE_AMD_IBPB));
+		guest_cpuid_has(vcpu, X86_FEATURE_AMD_IBPB) ||
+		guest_cpuid_has(vcpu, X86_FEATURE_SBPB));
 }
 
 static inline bool supports_cpuid_fault(struct kvm_vcpu *vcpu)
* Unmerged path arch/x86/kvm/x86.c
