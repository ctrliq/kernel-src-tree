x86/alternative: Make custom return thunk unconditional

jira LE-1907
cve CVE-2023-20569
Rebuild_History Non-Buildable kernel-4.18.0-521.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit 095b8303f3835c68ac4a8b6d754ca1c3b6230711
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-521.el8/095b8303.failed

There is infrastructure to rewrite return thunks to point to any
random thunk one desires, unwrap that from CALL_THUNKS, which up to
now was the sole user of that.

  [ bp: Make the thunks visible on 32-bit and add ifdeffery for the
    32-bit builds. ]

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
Link: https://lore.kernel.org/r/20230814121148.775293785@infradead.org
(cherry picked from commit 095b8303f3835c68ac4a8b6d754ca1c3b6230711)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/nospec-branch.h
#	arch/x86/kernel/alternative.c
diff --cc arch/x86/include/asm/nospec-branch.h
index 53e56fc9cf70,b3625cceb2f0..000000000000
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@@ -201,14 -333,70 +201,58 @@@
  #define ANNOTATE_RETPOLINE_SAFE					\
  	"999:\n\t"						\
  	".pushsection .discard.retpoline_safe\n\t"		\
 -	".long 999b - .\n\t"					\
 +	_ASM_PTR " 999b\n\t"					\
  	".popsection\n\t"
  
++<<<<<<< HEAD
++=======
+ typedef u8 retpoline_thunk_t[RETPOLINE_THUNK_SIZE];
+ extern retpoline_thunk_t __x86_indirect_thunk_array[];
+ extern retpoline_thunk_t __x86_indirect_call_thunk_array[];
+ extern retpoline_thunk_t __x86_indirect_jump_thunk_array[];
+ 
+ #ifdef CONFIG_RETHUNK
++>>>>>>> 095b8303f383 (x86/alternative: Make custom return thunk unconditional)
  extern void __x86_return_thunk(void);
+ #else
+ static inline void __x86_return_thunk(void) {}
+ #endif
+ 
  extern void zen_untrain_ret(void);
 -extern void srso_untrain_ret(void);
 -extern void srso_untrain_ret_alias(void);
  extern void entry_ibpb(void);
  
++<<<<<<< HEAD
++=======
+ extern void (*x86_return_thunk)(void);
+ 
+ #ifdef CONFIG_CALL_DEPTH_TRACKING
+ extern void __x86_return_skl(void);
+ 
+ static inline void x86_set_skl_return_thunk(void)
+ {
+ 	x86_return_thunk = &__x86_return_skl;
+ }
+ 
+ #define CALL_DEPTH_ACCOUNT					\
+ 	ALTERNATIVE("",						\
+ 		    __stringify(INCREMENT_CALL_DEPTH),		\
+ 		    X86_FEATURE_CALL_DEPTH)
+ 
+ #ifdef CONFIG_CALL_THUNKS_DEBUG
+ DECLARE_PER_CPU(u64, __x86_call_count);
+ DECLARE_PER_CPU(u64, __x86_ret_count);
+ DECLARE_PER_CPU(u64, __x86_stuffs_count);
+ DECLARE_PER_CPU(u64, __x86_ctxsw_count);
+ #endif
+ #else
+ static inline void x86_set_skl_return_thunk(void) {}
+ 
+ #define CALL_DEPTH_ACCOUNT ""
+ 
+ #endif
+ 
++>>>>>>> 095b8303f383 (x86/alternative: Make custom return thunk unconditional)
  #ifdef CONFIG_RETPOLINE
 -
 -#define GEN(reg) \
 -	extern retpoline_thunk_t __x86_indirect_thunk_ ## reg;
 -#include <asm/GEN-for-each-reg.h>
 -#undef GEN
 -
 -#define GEN(reg)						\
 -	extern retpoline_thunk_t __x86_indirect_call_thunk_ ## reg;
 -#include <asm/GEN-for-each-reg.h>
 -#undef GEN
 -
 -#define GEN(reg)						\
 -	extern retpoline_thunk_t __x86_indirect_jump_thunk_ ## reg;
 -#include <asm/GEN-for-each-reg.h>
 -#undef GEN
 -
  #ifdef CONFIG_X86_64
  
  /*
diff --cc arch/x86/kernel/alternative.c
index 76e6ae92f7f2,099d58d02a26..000000000000
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@@ -446,6 -686,7 +446,10 @@@ void __init_or_module noinline apply_al
  }
  
  #ifdef CONFIG_RETHUNK
++<<<<<<< HEAD
++=======
+ 
++>>>>>>> 095b8303f383 (x86/alternative: Make custom return thunk unconditional)
  /*
   * Rewrite the compiler generated return thunk tail-calls.
   *
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/kernel/alternative.c
diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c
index adea0002a1a8..2296a737e4ec 100644
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -60,6 +60,8 @@ EXPORT_SYMBOL_GPL(x86_spec_ctrl_current);
 
 static DEFINE_MUTEX(spec_ctrl_mutex);
 
+void (*x86_return_thunk)(void) __ro_after_init = &__x86_return_thunk;
+
 /* Update SPEC_CTRL MSR and its cached copy unconditionally */
 static void update_spec_ctrl(u64 val)
 {
