x86/CPU/AMD: Do not leak quotient data after a division by 0

jira LE-1907
cve CVE-2023-20588
Rebuild_History Non-Buildable kernel-4.18.0-521.el8
commit-author Borislav Petkov (AMD) <bp@alien8.de>
commit 77245f1c3c6495521f6a3af082696ee2f8ce3921
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-521.el8/77245f1c.failed

Under certain circumstances, an integer division by 0 which faults, can
leave stale quotient data from a previous division operation on Zen1
microarchitectures.

Do a dummy division 0/1 before returning from the #DE exception handler
in order to avoid any leaks of potentially sensitive data.

	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
	Cc: <stable@kernel.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 77245f1c3c6495521f6a3af082696ee2f8ce3921)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/cpufeatures.h
#	arch/x86/include/asm/processor.h
#	arch/x86/kernel/cpu/amd.c
#	arch/x86/kernel/traps.c
diff --cc arch/x86/include/asm/cpufeatures.h
index b52ff6ff9447,b69b0d7756aa..000000000000
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@@ -472,6 -490,10 +472,12 @@@
  #define X86_BUG_MMIO_UNKNOWN		X86_BUG(26) /* CPU is too old and its MMIO Stale Data status is unknown */
  #define X86_BUG_RETBLEED		X86_BUG(27) /* CPU is affected by RETBleed */
  #define X86_BUG_EIBRS_PBRSB		X86_BUG(28) /* EIBRS is vulnerable to Post Barrier RSB Predictions */
 -#define X86_BUG_SMT_RSB			X86_BUG(29) /* CPU is vulnerable to Cross-Thread Return Address Predictions */
  #define X86_BUG_GDS			X86_BUG(30) /* CPU is affected by Gather Data Sampling */
  
++<<<<<<< HEAD
++=======
+ /* BUG word 2 */
+ #define X86_BUG_SRSO			X86_BUG(1*32 + 0) /* AMD SRSO bug */
+ #define X86_BUG_DIV0			X86_BUG(1*32 + 1) /* AMD DIV0 speculation bug */
++>>>>>>> 77245f1c3c64 (x86/CPU/AMD: Do not leak quotient data after a division by 0)
  #endif /* _ASM_X86_CPUFEATURES_H */
diff --cc arch/x86/include/asm/processor.h
index 820104bdee1f,973db0406528..000000000000
--- a/arch/x86/include/asm/processor.h
+++ b/arch/x86/include/asm/processor.h
@@@ -883,29 -682,15 +883,39 @@@ extern u16 get_llc_id(unsigned int cpu)
  #ifdef CONFIG_CPU_SUP_AMD
  extern u32 amd_get_nodes_per_socket(void);
  extern u32 amd_get_highest_perf(void);
++<<<<<<< HEAD
 +#else
 +static inline u32 amd_get_nodes_per_socket(void)	{ return 0; }
 +static inline u32 amd_get_highest_perf(void)		{ return 0; }
++=======
+ extern bool cpu_has_ibpb_brtype_microcode(void);
+ extern void amd_clear_divider(void);
+ #else
+ static inline u32 amd_get_nodes_per_socket(void)	{ return 0; }
+ static inline u32 amd_get_highest_perf(void)		{ return 0; }
+ static inline bool cpu_has_ibpb_brtype_microcode(void)	{ return false; }
+ static inline void amd_clear_divider(void)		{ }
++>>>>>>> 77245f1c3c64 (x86/CPU/AMD: Do not leak quotient data after a division by 0)
  #endif
  
 +#define for_each_possible_hypervisor_cpuid_base(function) \
 +	for (function = 0x40000000; function < 0x40010000; function += 0x100)
 +
 +static inline uint32_t hypervisor_cpuid_base(const char *sig, uint32_t leaves)
 +{
 +	uint32_t base, eax, signature[3];
 +
 +	for_each_possible_hypervisor_cpuid_base(base) {
 +		cpuid(base, &eax, &signature[0], &signature[1], &signature[2]);
 +
 +		if (!memcmp(sig, signature, 12) &&
 +		    (leaves == 0 || ((eax - base) >= leaves)))
 +			return base;
 +	}
 +
 +	return 0;
 +}
 +
  extern unsigned long arch_align_stack(unsigned long sp);
  void free_init_pages(const char *what, unsigned long begin, unsigned long end);
  extern void free_kernel_image_pages(const char *what, void *begin, void *end);
diff --cc arch/x86/kernel/cpu/amd.c
index 92e42262f300,b55d8f82b621..000000000000
--- a/arch/x86/kernel/cpu/amd.c
+++ b/arch/x86/kernel/cpu/amd.c
@@@ -1329,3 -1299,32 +1338,35 @@@ void amd_check_microcode(void
  {
  	on_each_cpu(zenbleed_check_cpu, NULL, 1);
  }
++<<<<<<< HEAD
++=======
+ 
+ bool cpu_has_ibpb_brtype_microcode(void)
+ {
+ 	switch (boot_cpu_data.x86) {
+ 	/* Zen1/2 IBPB flushes branch type predictions too. */
+ 	case 0x17:
+ 		return boot_cpu_has(X86_FEATURE_AMD_IBPB);
+ 	case 0x19:
+ 		/* Poke the MSR bit on Zen3/4 to check its presence. */
+ 		if (!wrmsrl_safe(MSR_IA32_PRED_CMD, PRED_CMD_SBPB)) {
+ 			setup_force_cpu_cap(X86_FEATURE_SBPB);
+ 			return true;
+ 		} else {
+ 			return false;
+ 		}
+ 	default:
+ 		return false;
+ 	}
+ }
+ 
+ /*
+  * Issue a DIV 0/1 insn to clear any division data from previous DIV
+  * operations.
+  */
+ void noinstr amd_clear_divider(void)
+ {
+ 	asm volatile(ALTERNATIVE("", "div %2\n\t", X86_BUG_DIV0)
+ 		     :: "a" (0), "d" (0), "r" (1));
+ }
++>>>>>>> 77245f1c3c64 (x86/CPU/AMD: Do not leak quotient data after a division by 0)
diff --cc arch/x86/kernel/traps.c
index 68ab7cadc72c,1885326a8f65..000000000000
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@@ -217,40 -186,212 +217,50 @@@ static void do_error_trap(struct pt_reg
  	}
  }
  
 -/*
 - * Posix requires to provide the address of the faulting instruction for
 - * SIGILL (#UD) and SIGFPE (#DE) in the si_addr member of siginfo_t.
 - *
 - * This address is usually regs->ip, but when an uprobe moved the code out
 - * of line then regs->ip points to the XOL code which would confuse
 - * anything which analyzes the fault address vs. the unmodified binary. If
 - * a trap happened in XOL code then uprobe maps regs->ip back to the
 - * original instruction address.
 - */
 -static __always_inline void __user *error_get_trap_addr(struct pt_regs *regs)
 -{
 -	return (void __user *)uprobe_get_trap_addr(regs);
 +#define IP ((void __user *)uprobe_get_trap_addr(regs))
 +#define DO_ERROR(trapnr, signr, sicode, addr, str, name)		   \
 +dotraplinkage void do_##name(struct pt_regs *regs, long error_code)	   \
 +{									   \
 +	do_error_trap(regs, error_code, str, trapnr, signr, sicode, addr); \
  }
  
++<<<<<<< HEAD
 +DO_ERROR(X86_TRAP_DE,     SIGFPE,  FPE_INTDIV,   IP, "divide error",        divide_error)
 +DO_ERROR(X86_TRAP_OF,     SIGSEGV,          0, NULL, "overflow",            overflow)
 +DO_ERROR(X86_TRAP_UD,     SIGILL,  ILL_ILLOPN,   IP, "invalid opcode",      invalid_op)
 +DO_ERROR(X86_TRAP_OLD_MF, SIGFPE,           0, NULL, "coprocessor segment overrun", coprocessor_segment_overrun)
 +DO_ERROR(X86_TRAP_TS,     SIGSEGV,          0, NULL, "invalid TSS",         invalid_TSS)
 +DO_ERROR(X86_TRAP_NP,     SIGBUS,           0, NULL, "segment not present", segment_not_present)
 +DO_ERROR(X86_TRAP_SS,     SIGBUS,           0, NULL, "stack segment",       stack_segment)
 +#undef IP
++=======
+ DEFINE_IDTENTRY(exc_divide_error)
+ {
+ 	do_error_trap(regs, 0, "divide error", X86_TRAP_DE, SIGFPE,
+ 		      FPE_INTDIV, error_get_trap_addr(regs));
+ 
+ 	amd_clear_divider();
+ }
++>>>>>>> 77245f1c3c64 (x86/CPU/AMD: Do not leak quotient data after a division by 0)
  
 -DEFINE_IDTENTRY(exc_overflow)
 +dotraplinkage void do_alignment_check(struct pt_regs *regs, long error_code)
  {
 -	do_error_trap(regs, 0, "overflow", X86_TRAP_OF, SIGSEGV, 0, NULL);
 -}
 -
 -#ifdef CONFIG_X86_KERNEL_IBT
 -
 -static __ro_after_init bool ibt_fatal = true;
 -
 -extern void ibt_selftest_ip(void); /* code label defined in asm below */
 -
 -enum cp_error_code {
 -	CP_EC        = (1 << 15) - 1,
 -
 -	CP_RET       = 1,
 -	CP_IRET      = 2,
 -	CP_ENDBR     = 3,
 -	CP_RSTRORSSP = 4,
 -	CP_SETSSBSY  = 5,
 -
 -	CP_ENCL	     = 1 << 15,
 -};
 +	char *str = "alignment check";
  
 -DEFINE_IDTENTRY_ERRORCODE(exc_control_protection)
 -{
 -	if (!cpu_feature_enabled(X86_FEATURE_IBT)) {
 -		pr_err("Unexpected #CP\n");
 -		BUG();
 -	}
 +	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
  
 -	if (WARN_ON_ONCE(user_mode(regs) || (error_code & CP_EC) != CP_ENDBR))
 +	if (notify_die(DIE_TRAP, str, regs, error_code, X86_TRAP_AC, SIGBUS) == NOTIFY_STOP)
  		return;
  
 -	if (unlikely(regs->ip == (unsigned long)&ibt_selftest_ip)) {
 -		regs->ax = 0;
 -		return;
 -	}
 +	local_irq_enable();
  
 -	pr_err("Missing ENDBR: %pS\n", (void *)instruction_pointer(regs));
 -	if (!ibt_fatal) {
 -		printk(KERN_DEFAULT CUT_HERE);
 -		__warn(__FILE__, __LINE__, (void *)regs->ip, TAINT_WARN, regs, NULL);
 +	if (!user_mode(regs)) {
 +		handle_kernel_split_lock(regs, error_code);
  		return;
  	}
 -	BUG();
 -}
 -
 -/* Must be noinline to ensure uniqueness of ibt_selftest_ip. */
 -noinline bool ibt_selftest(void)
 -{
 -	unsigned long ret;
 -
 -	asm ("	lea ibt_selftest_ip(%%rip), %%rax\n\t"
 -	     ANNOTATE_RETPOLINE_SAFE
 -	     "	jmp *%%rax\n\t"
 -	     "ibt_selftest_ip:\n\t"
 -	     UNWIND_HINT_FUNC
 -	     ANNOTATE_NOENDBR
 -	     "	nop\n\t"
 -
 -	     : "=a" (ret) : : "memory");
 -
 -	return !ret;
 -}
 -
 -static int __init ibt_setup(char *str)
 -{
 -	if (!strcmp(str, "off"))
 -		setup_clear_cpu_cap(X86_FEATURE_IBT);
 -
 -	if (!strcmp(str, "warn"))
 -		ibt_fatal = false;
 -
 -	return 1;
 -}
 -
 -__setup("ibt=", ibt_setup);
 -
 -#endif /* CONFIG_X86_KERNEL_IBT */
 -
 -#ifdef CONFIG_X86_F00F_BUG
 -void handle_invalid_op(struct pt_regs *regs)
 -#else
 -static inline void handle_invalid_op(struct pt_regs *regs)
 -#endif
 -{
 -	do_error_trap(regs, 0, "invalid opcode", X86_TRAP_UD, SIGILL,
 -		      ILL_ILLOPN, error_get_trap_addr(regs));
 -}
 -
 -static noinstr bool handle_bug(struct pt_regs *regs)
 -{
 -	bool handled = false;
 -
 -	/*
 -	 * Normally @regs are unpoisoned by irqentry_enter(), but handle_bug()
 -	 * is a rare case that uses @regs without passing them to
 -	 * irqentry_enter().
 -	 */
 -	kmsan_unpoison_entry_regs(regs);
 -	if (!is_valid_bugaddr(regs->ip))
 -		return handled;
 -
 -	/*
 -	 * All lies, just get the WARN/BUG out.
 -	 */
 -	instrumentation_begin();
 -	/*
 -	 * Since we're emulating a CALL with exceptions, restore the interrupt
 -	 * state to what it was at the exception site.
 -	 */
 -	if (regs->flags & X86_EFLAGS_IF)
 -		raw_local_irq_enable();
 -	if (report_bug(regs->ip, regs) == BUG_TRAP_TYPE_WARN ||
 -	    handle_cfi_failure(regs) == BUG_TRAP_TYPE_WARN) {
 -		regs->ip += LEN_UD2;
 -		handled = true;
 -	}
 -	if (regs->flags & X86_EFLAGS_IF)
 -		raw_local_irq_disable();
 -	instrumentation_end();
 -
 -	return handled;
 -}
 -
 -DEFINE_IDTENTRY_RAW(exc_invalid_op)
 -{
 -	irqentry_state_t state;
 -
 -	/*
 -	 * We use UD2 as a short encoding for 'CALL __WARN', as such
 -	 * handle it before exception entry to avoid recursive WARN
 -	 * in case exception entry is the one triggering WARNs.
 -	 */
 -	if (!user_mode(regs) && handle_bug(regs))
 -		return;
 -
 -	state = irqentry_enter(regs);
 -	instrumentation_begin();
 -	handle_invalid_op(regs);
 -	instrumentation_end();
 -	irqentry_exit(regs, state);
 -}
 -
 -DEFINE_IDTENTRY(exc_coproc_segment_overrun)
 -{
 -	do_error_trap(regs, 0, "coprocessor segment overrun",
 -		      X86_TRAP_OLD_MF, SIGFPE, 0, NULL);
 -}
 -
 -DEFINE_IDTENTRY_ERRORCODE(exc_invalid_tss)
 -{
 -	do_error_trap(regs, error_code, "invalid TSS", X86_TRAP_TS, SIGSEGV,
 -		      0, NULL);
 -}
 -
 -DEFINE_IDTENTRY_ERRORCODE(exc_segment_not_present)
 -{
 -	do_error_trap(regs, error_code, "segment not present", X86_TRAP_NP,
 -		      SIGBUS, 0, NULL);
 -}
 -
 -DEFINE_IDTENTRY_ERRORCODE(exc_stack_segment)
 -{
 -	do_error_trap(regs, error_code, "stack segment", X86_TRAP_SS, SIGBUS,
 -		      0, NULL);
 -}
 -
 -DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)
 -{
 -	char *str = "alignment check";
 -
 -	if (notify_die(DIE_TRAP, str, regs, error_code, X86_TRAP_AC, SIGBUS) == NOTIFY_STOP)
 -		return;
 -
 -	if (!user_mode(regs))
 -		die("Split lock detected\n", regs, error_code);
 -
 -	local_irq_enable();
  
  	if (handle_user_split_lock(regs, error_code))
 -		goto out;
 +		return;
  
  	do_trap(X86_TRAP_AC, SIGBUS, "alignment check", regs,
  		error_code, BUS_ADRALN, NULL);
* Unmerged path arch/x86/include/asm/cpufeatures.h
* Unmerged path arch/x86/include/asm/processor.h
* Unmerged path arch/x86/kernel/cpu/amd.c
* Unmerged path arch/x86/kernel/traps.c
