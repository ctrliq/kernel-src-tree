x86/srso: Improve i-cache locality for alias mitigation

jira LE-1907
cve CVE-2023-20569
Rebuild_History Non-Buildable kernel-4.18.0-521.el8
commit-author Josh Poimboeuf <jpoimboe@kernel.org>
commit aa730cff0c26244e88066b5b461a9f5fbac13823
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-521.el8/aa730cff.failed

Move srso_alias_return_thunk() to the same section as
srso_alias_safe_ret() so they can share a cache line.

	Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
	Acked-by: Borislav Petkov (AMD) <bp@alien8.de>
Link: https://lore.kernel.org/r/eadaf5530b46a7ae8b936522da45ae555d2b3393.1693889988.git.jpoimboe@kernel.org
(cherry picked from commit aa730cff0c26244e88066b5b461a9f5fbac13823)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/lib/retpoline.S
diff --cc arch/x86/lib/retpoline.S
index 72a7235229fd,9ab634f0b5d2..000000000000
--- a/arch/x86/lib/retpoline.S
+++ b/arch/x86/lib/retpoline.S
@@@ -53,8 -132,59 +53,63 @@@ GENERATE_THUNK(r15
   */
  #ifdef CONFIG_RETHUNK
  
++<<<<<<< HEAD
 +	.section .text.__x86.return_thunk
++=======
+ /*
+  * srso_alias_untrain_ret() and srso_alias_safe_ret() are placed at
+  * special addresses:
+  *
+  * - srso_alias_untrain_ret() is 2M aligned
+  * - srso_alias_safe_ret() is also in the same 2M page but bits 2, 8, 14
+  * and 20 in its virtual address are set (while those bits in the
+  * srso_alias_untrain_ret() function are cleared).
+  *
+  * This guarantees that those two addresses will alias in the branch
+  * target buffer of Zen3/4 generations, leading to any potential
+  * poisoned entries at that BTB slot to get evicted.
+  *
+  * As a result, srso_alias_safe_ret() becomes a safe return.
+  */
+ #ifdef CONFIG_CPU_SRSO
+ 	.section .text..__x86.rethunk_untrain
+ 
+ SYM_START(srso_alias_untrain_ret, SYM_L_GLOBAL, SYM_A_NONE)
+ 	UNWIND_HINT_FUNC
+ 	ANNOTATE_NOENDBR
+ 	ASM_NOP2
+ 	lfence
+ 	jmp srso_alias_return_thunk
+ SYM_FUNC_END(srso_alias_untrain_ret)
+ __EXPORT_THUNK(srso_alias_untrain_ret)
+ 
+ 	.section .text..__x86.rethunk_safe
+ #else
+ /* dummy definition for alternatives */
+ SYM_START(srso_alias_untrain_ret, SYM_L_GLOBAL, SYM_A_NONE)
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_FUNC_END(srso_alias_untrain_ret)
+ #endif
+ 
+ SYM_START(srso_alias_safe_ret, SYM_L_GLOBAL, SYM_A_NONE)
+ 	lea 8(%_ASM_SP), %_ASM_SP
+ 	UNWIND_HINT_FUNC
+ 	ANNOTATE_UNRET_SAFE
+ 	ret
+ 	int3
+ SYM_FUNC_END(srso_alias_safe_ret)
+ 
+ SYM_CODE_START_NOALIGN(srso_alias_return_thunk)
+ 	UNWIND_HINT_FUNC
+ 	ANNOTATE_NOENDBR
+ 	call srso_alias_safe_ret
+ 	ud2
+ SYM_CODE_END(srso_alias_return_thunk)
++>>>>>>> aa730cff0c26 (x86/srso: Improve i-cache locality for alias mitigation)
  
+ 	.section .text..__x86.return_thunk
  /*
   * Some generic notes on the untraining sequences:
   *
* Unmerged path arch/x86/lib/retpoline.S
