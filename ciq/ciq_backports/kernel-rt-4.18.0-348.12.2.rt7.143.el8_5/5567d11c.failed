x86/mce: Send #MC singal from task work

jira NONE_AUTOMATION
Rebuild_History Non-Buildable kernel-rt-4.18.0-348.12.2.rt7.143.el8_5
commit-author Peter Zijlstra <peterz@infradead.org>
commit 5567d11c21a1d508a91a8cb64a819783a0835d9f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-348.12.2.rt7.143.el8_5/5567d11c.failed

Convert #MC over to using task_work_add(); it will run the same code
slightly later, on the return to user path of the same exception.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
	Reviewed-by: Alexandre Chartre <alexandre.chartre@oracle.com>
Link: https://lkml.kernel.org/r/20200505134100.957390899@linutronix.de


(cherry picked from commit 5567d11c21a1d508a91a8cb64a819783a0835d9f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/mce/core.c
#	include/linux/sched.h
diff --cc arch/x86/kernel/cpu/mce/core.c
index 88eb3cb77d26,2f0ef95795f3..000000000000
--- a/arch/x86/kernel/cpu/mce/core.c
+++ b/arch/x86/kernel/cpu/mce/core.c
@@@ -43,8 -42,7 +43,12 @@@
  #include <linux/export.h>
  #include <linux/jump_label.h>
  #include <linux/set_memory.h>
++<<<<<<< HEAD
 +#include <linux/sync_core.h>
 +#include <linux/hardirq.h>
++=======
+ #include <linux/task_work.h>
++>>>>>>> 5567d11c21a1 (x86/mce: Send #MC singal from task work)
  
  #include <asm/intel-family.h>
  #include <asm/processor.h>
@@@ -1090,24 -1087,6 +1094,27 @@@ static void mce_clear_state(unsigned lo
  	}
  }
  
++<<<<<<< HEAD
 +static int do_memory_failure(struct mce *m)
 +{
 +	int flags = MF_ACTION_REQUIRED;
 +	int ret;
 +
 +	pr_err("Uncorrected hardware memory error in user-access at %llx", m->addr);
 +
 +	if (!current->task_struct_rh->mce_ripv)
 +		flags |= MF_MUST_KILL;
 +	ret = memory_failure(m->addr >> PAGE_SHIFT, flags);
 +	if (ret)
 +		pr_err("Memory error not recovered");
 +	else
 +		set_mce_nospec(m->addr >> PAGE_SHIFT, current->task_struct_rh->mce_whole_page);
 +	return ret;
 +}
 +
 +
++=======
++>>>>>>> 5567d11c21a1 (x86/mce: Send #MC singal from task work)
  /*
   * Cases where we avoid rendezvous handler timeout:
   * 1) If this CPU is offline.
@@@ -1214,8 -1222,14 +1244,12 @@@ static void kill_me_maybe(struct callba
   * On Intel systems this is entered on all CPUs in parallel through
   * MCE broadcast. However some CPUs might be broken beyond repair,
   * so be always careful when synchronizing with others.
 - *
 - * Tracing and kprobes are disabled: if we interrupted a kernel context
 - * with IF=1, we need to minimize stack usage.  There are also recursion
 - * issues: if the machine check was due to a failure of the memory
 - * backing the user stack, tracing that reads the user stack will cause
 - * potentially infinite recursion.
   */
++<<<<<<< HEAD
 +void do_machine_check(struct pt_regs *regs, long error_code)
++=======
+ void noinstr do_machine_check(struct pt_regs *regs, long error_code)
++>>>>>>> 5567d11c21a1 (x86/mce: Send #MC singal from task work)
  {
  	DECLARE_BITMAP(valid_banks, MAX_NR_BANKS);
  	DECLARE_BITMAP(toclear, MAX_NR_BANKS);
@@@ -1345,19 -1361,16 +1379,26 @@@
  	if ((m.cs & 3) == 3) {
  		/* If this triggers there is no way to recover. Die hard. */
  		BUG_ON(!on_thread_stack() || !user_mode(regs));
- 		local_irq_enable();
- 		preempt_enable();
  
++<<<<<<< HEAD
 +		current->task_struct_rh->mce_ripv = !!(m.mcgstatus & MCG_STATUS_RIPV);
 +		current->task_struct_rh->mce_whole_page = whole_page(&m);
 +
 +		if (kill_it || do_memory_failure(&m))
 +			force_sig(SIGBUS, current);
 +		preempt_disable();
 +		local_irq_disable();
++=======
+ 		current->mce_addr = m.addr;
+ 		current->mce_status = m.mcgstatus;
+ 		current->mce_kill_me.func = kill_me_maybe;
+ 		if (kill_it)
+ 			current->mce_kill_me.func = kill_me_now;
+ 		task_work_add(current, &current->mce_kill_me, true);
++>>>>>>> 5567d11c21a1 (x86/mce: Send #MC singal from task work)
  	} else {
 -		if (!fixup_exception(regs, X86_TRAP_MC, error_code, 0))
 -			mce_panic("Failed kernel mode recovery", &m, msg);
 +		if (!fixup_exception(regs, X86_TRAP_MC))
 +			mce_panic("Failed kernel mode recovery", &m, NULL);
  	}
  
  out_ist:
diff --cc include/linux/sched.h
index 15101f992863,57d0ed061ae4..000000000000
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@@ -1331,6 -1292,17 +1331,20 @@@ struct task_struct 
  	void				*security;
  #endif
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_GCC_PLUGIN_STACKLEAK
+ 	unsigned long			lowest_stack;
+ 	unsigned long			prev_lowest_stack;
+ #endif
+ 
+ #ifdef CONFIG_X86_MCE
+ 	u64				mce_addr;
+ 	u64				mce_status;
+ 	struct callback_head		mce_kill_me;
+ #endif
+ 
++>>>>>>> 5567d11c21a1 (x86/mce: Send #MC singal from task work)
  	/*
  	 * New fields for task_struct should be added above here, so that
  	 * they are included in the randomized portion of task_struct.
* Unmerged path arch/x86/kernel/cpu/mce/core.c
* Unmerged path include/linux/sched.h
