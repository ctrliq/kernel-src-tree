irq_work: Also rcuwait for !IRQ_WORK_HARD_IRQ on PREEMPT_RT

jira LE-1907
Rebuild_History Non-Buildable kernel-rt-4.18.0-477.10.1.rt7.274.el8_8
commit-author Sebastian Andrzej Siewior <bigeasy@linutronix.de>
commit 09089db79859cbccccd8df95b034f36f7027efa6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-477.10.1.rt7.274.el8_8/09089db7.failed

On PREEMPT_RT most items are processed as LAZY via softirq context.
Avoid to spin-wait for them because irq_work_sync() could have higher
priority and not allow the irq-work to be completed.

Wait additionally for !IRQ_WORK_HARD_IRQ irq_work items on PREEMPT_RT.

	Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20211006111852.1514359-5-bigeasy@linutronix.de
(cherry picked from commit 09089db79859cbccccd8df95b034f36f7027efa6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/irq_work.c
diff --cc kernel/irq_work.c
index 64ae81d50b5b,f7df715ec28e..000000000000
--- a/kernel/irq_work.c
+++ b/kernel/irq_work.c
@@@ -159,6 -216,10 +159,13 @@@ void irq_work_single(void *arg
  	 * else claimed it meanwhile.
  	 */
  	(void)atomic_cmpxchg(&work->node.a_flags, flags, flags & ~IRQ_WORK_BUSY);
++<<<<<<< HEAD
++=======
+ 
+ 	if ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||
+ 	    !arch_irq_work_has_interrupt())
+ 		rcuwait_wake_up(&work->irqwait);
++>>>>>>> 09089db79859 (irq_work: Also rcuwait for !IRQ_WORK_HARD_IRQ on PREEMPT_RT)
  }
  
  static void irq_work_run_list(struct llist_head *list)
@@@ -203,6 -276,14 +210,17 @@@ void irq_work_tick(void
  void irq_work_sync(struct irq_work *work)
  {
  	lockdep_assert_irqs_enabled();
++<<<<<<< HEAD
++=======
+ 	might_sleep();
+ 
+ 	if ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||
+ 	    !arch_irq_work_has_interrupt()) {
+ 		rcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),
+ 				   TASK_UNINTERRUPTIBLE);
+ 		return;
+ 	}
++>>>>>>> 09089db79859 (irq_work: Also rcuwait for !IRQ_WORK_HARD_IRQ on PREEMPT_RT)
  
  	while (irq_work_is_busy(work))
  		cpu_relax();
diff --git a/include/linux/irq_work.h b/include/linux/irq_work.h
index 5071b82ab54a..34a2a33e4446 100644
--- a/include/linux/irq_work.h
+++ b/include/linux/irq_work.h
@@ -49,6 +49,11 @@ static inline bool irq_work_is_busy(struct irq_work *work)
 	return atomic_read(&work->node.a_flags) & IRQ_WORK_BUSY;
 }
 
+static inline bool irq_work_is_hard(struct irq_work *work)
+{
+	return atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ;
+}
+
 bool irq_work_queue(struct irq_work *work);
 bool irq_work_queue_on(struct irq_work *work, int cpu);
 
* Unmerged path kernel/irq_work.c
