mm/hugetlb: fix race condition of uffd missing/minor handling

jira LE-1907
cve CVE-2022-3522
Rebuild_History Non-Buildable kernel-rt-4.18.0-477.10.1.rt7.274.el8_8
commit-author Peter Xu <peterx@redhat.com>
commit 2ea7ff1e39cbe3753d3c649beb70f2cf861dca75
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-477.10.1.rt7.274.el8_8/2ea7ff1e.failed

Patch series "mm/hugetlb: Fix selftest failures with write check", v3.

Currently akpm mm-unstable fails with uffd hugetlb private mapping test
randomly on a write check.

The initial bisection of that points to the recent pmd unshare series, but
it turns out there's no direction relationship with the series but only
some timing change caused the race to start trigger.

The race should be fixed in patch 1.  Patch 2 is a trivial cleanup on the
similar race with hugetlb migrations, patch 3 comment on the write check
so when anyone read it again it'll be clear why it's there.


This patch (of 3):

After the recent rework patchset of hugetlb locking on pmd sharing,
kselftest for userfaultfd sometimes fails on hugetlb private tests with
unexpected write fault checks.

It turns out there's nothing wrong within the locking series regarding
this matter, but it could have changed the timing of threads so it can
trigger an old bug.

The real bug is when we call hugetlb_no_page() we're not with the pgtable
lock.  It means we're reading the pte values lockless.  It's perfectly
fine in most cases because before we do normal page allocations we'll take
the lock and check pte_same() again.  However before that, there are
actually two paths on userfaultfd missing/minor handling that may directly
move on with the fault process without checking the pte values.

It means for these two paths we may be generating an uffd message based on
an unstable pte, while an unstable pte can legally be anything as long as
the modifier holds the pgtable lock.

One example, which is also what happened in the failing kselftest and
caused the test failure, is that for private mappings wr-protection
changes can happen on one page.  While hugetlb_change_protection()
generally requires pte being cleared before being changed, then there can
be a race condition like:

        thread 1                              thread 2
        --------                              --------

      UFFDIO_WRITEPROTECT                     hugetlb_fault
        hugetlb_change_protection
          pgtable_lock()
          huge_ptep_modify_prot_start
                                              pte==NULL
                                              hugetlb_no_page
                                                generate uffd missing event
                                                even if page existed!!
          huge_ptep_modify_prot_commit
          pgtable_unlock()

Fix this by rechecking the pte after pgtable lock for both userfaultfd
missing & minor fault paths.

This bug should have been around starting from uffd hugetlb introduced, so
attaching a Fixes to the commit.  Also attach another Fixes to the minor
support commit for easier tracking.

Note that userfaultfd is actually fine with false positives (e.g.  caused
by pte changed), but not wrong logical events (e.g.  caused by reading a
pte during changing).  The latter can confuse the userspace, so the
strictness is very much preferred.  E.g., MISSING event should never
happen on the page after UFFDIO_COPY has correctly installed the page and
returned.

Link: https://lkml.kernel.org/r/20221004193400.110155-1-peterx@redhat.com
Link: https://lkml.kernel.org/r/20221004193400.110155-2-peterx@redhat.com
Fixes: 1a1aad8a9b7b ("userfaultfd: hugetlbfs: add userfaultfd hugetlb hook")
Fixes: 7677f7fd8be7 ("userfaultfd: add minor fault registration mode")
	Signed-off-by: Peter Xu <peterx@redhat.com>
Co-developed-by: Mike Kravetz <mike.kravetz@oracle.com>
	Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: Axel Rasmussen <axelrasmussen@google.com>
	Cc: Nadav Amit <nadav.amit@gmail.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
(cherry picked from commit 2ea7ff1e39cbe3753d3c649beb70f2cf861dca75)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/hugetlb.c
diff --cc mm/hugetlb.c
index f194dc2dace6,bf9d8d04bf4f..000000000000
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@@ -4408,6 -5500,58 +4408,61 @@@ int huge_add_to_page_cache(struct page 
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static inline vm_fault_t hugetlb_handle_userfault(struct vm_area_struct *vma,
+ 						  struct address_space *mapping,
+ 						  pgoff_t idx,
+ 						  unsigned int flags,
+ 						  unsigned long haddr,
+ 						  unsigned long addr,
+ 						  unsigned long reason)
+ {
+ 	u32 hash;
+ 	struct vm_fault vmf = {
+ 		.vma = vma,
+ 		.address = haddr,
+ 		.real_address = addr,
+ 		.flags = flags,
+ 
+ 		/*
+ 		 * Hard to debug if it ends up being
+ 		 * used by a callee that assumes
+ 		 * something about the other
+ 		 * uninitialized fields... same as in
+ 		 * memory.c
+ 		 */
+ 	};
+ 
+ 	/*
+ 	 * vma_lock and hugetlb_fault_mutex must be dropped before handling
+ 	 * userfault. Also mmap_lock could be dropped due to handling
+ 	 * userfault, any vma operation should be careful from here.
+ 	 */
+ 	hugetlb_vma_unlock_read(vma);
+ 	hash = hugetlb_fault_mutex_hash(mapping, idx);
+ 	mutex_unlock(&hugetlb_fault_mutex_table[hash]);
+ 	return handle_userfault(&vmf, reason);
+ }
+ 
+ /*
+  * Recheck pte with pgtable lock.  Returns true if pte didn't change, or
+  * false if pte changed or is changing.
+  */
+ static bool hugetlb_pte_stable(struct hstate *h, struct mm_struct *mm,
+ 			       pte_t *ptep, pte_t old_pte)
+ {
+ 	spinlock_t *ptl;
+ 	bool same;
+ 
+ 	ptl = huge_pte_lock(h, mm, ptep);
+ 	same = pte_same(huge_ptep_get(ptep), old_pte);
+ 	spin_unlock(ptl);
+ 
+ 	return same;
+ }
+ 
++>>>>>>> 2ea7ff1e39cb (mm/hugetlb: fix race condition of uffd missing/minor handling)
  static vm_fault_t hugetlb_no_page(struct mm_struct *mm,
  			struct vm_area_struct *vma,
  			struct address_space *mapping, pgoff_t idx,
@@@ -4435,47 -5582,42 +4490,77 @@@
  	}
  
  	/*
 -	 * Use page lock to guard against racing truncation
 -	 * before we get page_table_lock.
 +	 * We can not race with truncation due to holding i_mmap_rwsem.
 +	 * i_size is modified when holding i_mmap_rwsem, so check here
 +	 * once for faults beyond end of file.
  	 */
 -	new_page = false;
 +	size = i_size_read(mapping->host) >> huge_page_shift(h);
 +	if (idx >= size)
 +		goto out;
 +
 +retry:
  	page = find_lock_page(mapping, idx);
  	if (!page) {
 -		size = i_size_read(mapping->host) >> huge_page_shift(h);
 -		if (idx >= size)
 +		/*
 +		 * Check for page in userfault range
 +		 */
 +		if (userfaultfd_missing(vma)) {
 +			u32 hash;
 +			struct vm_fault vmf = {
 +				.vma = vma,
 +				.address = haddr,
 +				.flags = flags,
 +				/*
 +				 * Hard to debug if it ends up being
 +				 * used by a callee that assumes
 +				 * something about the other
 +				 * uninitialized fields... same as in
 +				 * memory.c
 +				 */
 +			};
 +
 +			/*
 +			 * hugetlb_fault_mutex and i_mmap_rwsem must be
 +			 * dropped before handling userfault.  Reacquire
 +			 * after handling fault to make calling code simpler.
 +			 */
 +			hash = hugetlb_fault_mutex_hash(mapping, idx);
 +			mutex_unlock(&hugetlb_fault_mutex_table[hash]);
 +			i_mmap_unlock_read(mapping);
 +			ret = handle_userfault(&vmf, VM_UFFD_MISSING);
 +			i_mmap_lock_read(mapping);
 +			mutex_lock(&hugetlb_fault_mutex_table[hash]);
  			goto out;
++<<<<<<< HEAD
++=======
+ 		/* Check for page in userfault range */
+ 		if (userfaultfd_missing(vma)) {
+ 			/*
+ 			 * Since hugetlb_no_page() was examining pte
+ 			 * without pgtable lock, we need to re-test under
+ 			 * lock because the pte may not be stable and could
+ 			 * have changed from under us.  Try to detect
+ 			 * either changed or during-changing ptes and retry
+ 			 * properly when needed.
+ 			 *
+ 			 * Note that userfaultfd is actually fine with
+ 			 * false positives (e.g. caused by pte changed),
+ 			 * but not wrong logical events (e.g. caused by
+ 			 * reading a pte during changing).  The latter can
+ 			 * confuse the userspace, so the strictness is very
+ 			 * much preferred.  E.g., MISSING event should
+ 			 * never happen on the page after UFFDIO_COPY has
+ 			 * correctly installed the page and returned.
+ 			 */
+ 			if (!hugetlb_pte_stable(h, mm, ptep, old_pte)) {
+ 				ret = 0;
+ 				goto out;
+ 			}
+ 
+ 			return hugetlb_handle_userfault(vma, mapping, idx, flags,
+ 							haddr, address,
+ 							VM_UFFD_MISSING);
++>>>>>>> 2ea7ff1e39cb (mm/hugetlb: fix race condition of uffd missing/minor handling)
  		}
  
  		page = alloc_huge_page(vma, haddr, 0);
@@@ -4530,6 -5679,20 +4615,23 @@@
  				VM_FAULT_SET_HINDEX(hstate_index(h));
  			goto backout_unlocked;
  		}
++<<<<<<< HEAD
++=======
+ 
+ 		/* Check for page in userfault range. */
+ 		if (userfaultfd_minor(vma)) {
+ 			unlock_page(page);
+ 			put_page(page);
+ 			/* See comment in userfaultfd_missing() block above */
+ 			if (!hugetlb_pte_stable(h, mm, ptep, old_pte)) {
+ 				ret = 0;
+ 				goto out;
+ 			}
+ 			return hugetlb_handle_userfault(vma, mapping, idx, flags,
+ 							haddr, address,
+ 							VM_UFFD_MINOR);
+ 		}
++>>>>>>> 2ea7ff1e39cb (mm/hugetlb: fix race condition of uffd missing/minor handling)
  	}
  
  	/*
* Unmerged path mm/hugetlb.c
