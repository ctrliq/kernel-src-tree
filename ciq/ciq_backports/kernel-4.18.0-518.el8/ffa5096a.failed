cpufreq: amd-pstate: implement Pstate EPP support for the AMD processors

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-518.el8
commit-author Perry Yuan <Perry.Yuan@amd.com>
commit ffa5096a7c338641f70fb06d4778e8cf400181a8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-518.el8/ffa5096a.failed

Add EPP driver support for AMD SoCs which support a dedicated MSR for
CPPC.  EPP is used by the DPM controller to configure the frequency that
a core operates at during short periods of activity.

The SoC EPP targets are configured on a scale from 0 to 255 where 0
represents maximum performance and 255 represents maximum efficiency.

The amd-pstate driver exports profile string names to userspace that are
tied to specific EPP values.

The balance_performance string (0x80) provides the best balance for
efficiency versus power on most systems, but users can choose other
strings to meet their needs as well.

$ cat /sys/devices/system/cpu/cpufreq/policy0/energy_performance_available_preferences
default performance balance_performance balance_power power

$ cat /sys/devices/system/cpu/cpufreq/policy0/energy_performance_preference
balance_performance

To enable the driver,it needs to add `amd_pstate=active` to kernel
command line and kernel will load the active mode epp driver

	Acked-by: Huang Rui <ray.huang@amd.com>
	Reviewed-by: Mario Limonciello <Mario.Limonciello@amd.com>
	Reviewed-by: Wyes Karny <wyes.karny@amd.com>
	Tested-by: Wyes Karny <wyes.karny@amd.com>
	Signed-off-by: Perry Yuan <Perry.Yuan@amd.com>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit ffa5096a7c338641f70fb06d4778e8cf400181a8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/amd-pstate.c
#	include/linux/amd-pstate.h
diff --cc drivers/cpufreq/amd-pstate.c
index f0b221585cc8,bca86b5b8b12..000000000000
--- a/drivers/cpufreq/amd-pstate.c
+++ b/drivers/cpufreq/amd-pstate.c
@@@ -58,68 -59,171 +58,227 @@@
   * we disable it by default to go acpi-cpufreq on these processors and add a
   * module parameter to be able to enable it manually for debugging.
   */
+ static struct cpufreq_driver *current_pstate_driver;
  static struct cpufreq_driver amd_pstate_driver;
++<<<<<<< HEAD
 +static int cppc_load __initdata;
 +
 +/**
 + * struct  amd_aperf_mperf
 + * @aperf: actual performance frequency clock count
 + * @mperf: maximum performance frequency clock count
 + * @tsc:   time stamp counter
 + */
 +struct amd_aperf_mperf {
 +	u64 aperf;
 +	u64 mperf;
 +	u64 tsc;
 +};
++=======
+ static struct cpufreq_driver amd_pstate_epp_driver;
+ static int cppc_state = AMD_PSTATE_DISABLE;
+ 
+ /*
+  * AMD Energy Preference Performance (EPP)
+  * The EPP is used in the CCLK DPM controller to drive
+  * the frequency that a core is going to operate during
+  * short periods of activity. EPP values will be utilized for
+  * different OS profiles (balanced, performance, power savings)
+  * display strings corresponding to EPP index in the
+  * energy_perf_strings[]
+  *	index		String
+  *-------------------------------------
+  *	0		default
+  *	1		performance
+  *	2		balance_performance
+  *	3		balance_power
+  *	4		power
+  */
+ enum energy_perf_value_index {
+ 	EPP_INDEX_DEFAULT = 0,
+ 	EPP_INDEX_PERFORMANCE,
+ 	EPP_INDEX_BALANCE_PERFORMANCE,
+ 	EPP_INDEX_BALANCE_POWERSAVE,
+ 	EPP_INDEX_POWERSAVE,
+ };
+ 
+ static const char * const energy_perf_strings[] = {
+ 	[EPP_INDEX_DEFAULT] = "default",
+ 	[EPP_INDEX_PERFORMANCE] = "performance",
+ 	[EPP_INDEX_BALANCE_PERFORMANCE] = "balance_performance",
+ 	[EPP_INDEX_BALANCE_POWERSAVE] = "balance_power",
+ 	[EPP_INDEX_POWERSAVE] = "power",
+ 	NULL
+ };
+ 
+ static unsigned int epp_values[] = {
+ 	[EPP_INDEX_DEFAULT] = 0,
+ 	[EPP_INDEX_PERFORMANCE] = AMD_CPPC_EPP_PERFORMANCE,
+ 	[EPP_INDEX_BALANCE_PERFORMANCE] = AMD_CPPC_EPP_BALANCE_PERFORMANCE,
+ 	[EPP_INDEX_BALANCE_POWERSAVE] = AMD_CPPC_EPP_BALANCE_POWERSAVE,
+ 	[EPP_INDEX_POWERSAVE] = AMD_CPPC_EPP_POWERSAVE,
+  };
+ 
+ static inline int get_mode_idx_from_str(const char *str, size_t size)
+ {
+ 	int i;
++>>>>>>> ffa5096a7c33 (cpufreq: amd-pstate: implement Pstate EPP support for the AMD processors)
 +
 +/**
 + * struct amd_cpudata - private CPU data for AMD P-State
 + * @cpu: CPU number
 + * @req: constraint request to apply
 + * @cppc_req_cached: cached performance request hints
 + * @highest_perf: the maximum performance an individual processor may reach,
 + *		  assuming ideal conditions
 + * @nominal_perf: the maximum sustained performance level of the processor,
 + *		  assuming ideal operating conditions
 + * @lowest_nonlinear_perf: the lowest performance level at which nonlinear power
 + *			   savings are achieved
 + * @lowest_perf: the absolute lowest performance level of the processor
 + * @max_freq: the frequency that mapped to highest_perf
 + * @min_freq: the frequency that mapped to lowest_perf
 + * @nominal_freq: the frequency that mapped to nominal_perf
 + * @lowest_nonlinear_freq: the frequency that mapped to lowest_nonlinear_perf
 + * @cur: Difference of Aperf/Mperf/tsc count between last and current sample
 + * @prev: Last Aperf/Mperf/tsc count value read from register
 + * @freq: current cpu frequency value
 + * @boost_supported: check whether the Processor or SBIOS supports boost mode
 + *
 + * The amd_cpudata is key private data for each CPU thread in AMD P-State, and
 + * represents all the attributes and goals that AMD P-State requests at runtime.
 + */
 +struct amd_cpudata {
 +	int	cpu;
  
 -	for (i=0; i < AMD_PSTATE_MAX; i++) {
 -		if (!strncmp(str, amd_pstate_mode_string[i], size))
 -			return i;
 -	}
 -	return -EINVAL;
 -}
 +	struct	freq_qos_request req[2];
 +	u64	cppc_req_cached;
 +
 +	u32	highest_perf;
 +	u32	nominal_perf;
 +	u32	lowest_nonlinear_perf;
 +	u32	lowest_perf;
 +
 +	u32	max_freq;
 +	u32	min_freq;
 +	u32	nominal_freq;
 +	u32	lowest_nonlinear_freq;
 +
 +	struct amd_aperf_mperf cur;
 +	struct amd_aperf_mperf prev;
 +
 +	u64 	freq;
 +	bool	boost_supported;
 +};
  
+ static DEFINE_MUTEX(amd_pstate_limits_lock);
+ static DEFINE_MUTEX(amd_pstate_driver_lock);
+ 
+ static s16 amd_pstate_get_epp(struct amd_cpudata *cpudata, u64 cppc_req_cached)
+ {
+ 	u64 epp;
+ 	int ret;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_CPPC)) {
+ 		if (!cppc_req_cached) {
+ 			epp = rdmsrl_on_cpu(cpudata->cpu, MSR_AMD_CPPC_REQ,
+ 					&cppc_req_cached);
+ 			if (epp)
+ 				return epp;
+ 		}
+ 		epp = (cppc_req_cached >> 24) & 0xFF;
+ 	} else {
+ 		ret = cppc_get_epp_perf(cpudata->cpu, &epp);
+ 		if (ret < 0) {
+ 			pr_debug("Could not retrieve energy perf value (%d)\n", ret);
+ 			return -EIO;
+ 		}
+ 	}
+ 
+ 	return (s16)(epp & 0xff);
+ }
+ 
+ static int amd_pstate_get_energy_pref_index(struct amd_cpudata *cpudata)
+ {
+ 	s16 epp;
+ 	int index = -EINVAL;
+ 
+ 	epp = amd_pstate_get_epp(cpudata, 0);
+ 	if (epp < 0)
+ 		return epp;
+ 
+ 	switch (epp) {
+ 	case AMD_CPPC_EPP_PERFORMANCE:
+ 		index = EPP_INDEX_PERFORMANCE;
+ 		break;
+ 	case AMD_CPPC_EPP_BALANCE_PERFORMANCE:
+ 		index = EPP_INDEX_BALANCE_PERFORMANCE;
+ 		break;
+ 	case AMD_CPPC_EPP_BALANCE_POWERSAVE:
+ 		index = EPP_INDEX_BALANCE_POWERSAVE;
+ 		break;
+ 	case AMD_CPPC_EPP_POWERSAVE:
+ 		index = EPP_INDEX_POWERSAVE;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	return index;
+ }
+ 
+ static int amd_pstate_set_epp(struct amd_cpudata *cpudata, u32 epp)
+ {
+ 	int ret;
+ 	struct cppc_perf_ctrls perf_ctrls;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_CPPC)) {
+ 		u64 value = READ_ONCE(cpudata->cppc_req_cached);
+ 
+ 		value &= ~GENMASK_ULL(31, 24);
+ 		value |= (u64)epp << 24;
+ 		WRITE_ONCE(cpudata->cppc_req_cached, value);
+ 
+ 		ret = wrmsrl_on_cpu(cpudata->cpu, MSR_AMD_CPPC_REQ, value);
+ 		if (!ret)
+ 			cpudata->epp_cached = epp;
+ 	} else {
+ 		perf_ctrls.energy_perf = epp;
+ 		ret = cppc_set_epp_perf(cpudata->cpu, &perf_ctrls, 1);
+ 		if (ret) {
+ 			pr_debug("failed to set energy perf value (%d)\n", ret);
+ 			return ret;
+ 		}
+ 		cpudata->epp_cached = epp;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static int amd_pstate_set_energy_pref_index(struct amd_cpudata *cpudata,
+ 		int pref_index)
+ {
+ 	int epp = -EINVAL;
+ 	int ret;
+ 
+ 	if (!pref_index) {
+ 		pr_debug("EPP pref_index is invalid\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (epp == -EINVAL)
+ 		epp = epp_values[pref_index];
+ 
+ 	if (epp > 0 && cpudata->policy == CPUFREQ_POLICY_PERFORMANCE) {
+ 		pr_debug("EPP cannot be set under performance policy\n");
+ 		return -EBUSY;
+ 	}
+ 
+ 	ret = amd_pstate_set_epp(cpudata, epp);
+ 
+ 	return ret;
+ }
+ 
  static inline int pstate_enable(bool enable)
  {
  	return wrmsrl_safe(MSR_AMD_CPPC_ENABLE, enable);
@@@ -647,9 -761,58 +816,58 @@@ static ssize_t show_amd_pstate_highest_
  
  	perf = READ_ONCE(cpudata->highest_perf);
  
 -	return sprintf(&buf[0], "%u\n", perf);
 +	return sysfs_emit(buf, "%u\n", perf);
  }
  
+ static ssize_t show_energy_performance_available_preferences(
+ 				struct cpufreq_policy *policy, char *buf)
+ {
+ 	int i = 0;
+ 	int offset = 0;
+ 
+ 	while (energy_perf_strings[i] != NULL)
+ 		offset += sysfs_emit_at(buf, offset, "%s ", energy_perf_strings[i++]);
+ 
+ 	sysfs_emit_at(buf, offset, "\n");
+ 
+ 	return offset;
+ }
+ 
+ static ssize_t store_energy_performance_preference(
+ 		struct cpufreq_policy *policy, const char *buf, size_t count)
+ {
+ 	struct amd_cpudata *cpudata = policy->driver_data;
+ 	char str_preference[21];
+ 	ssize_t ret;
+ 
+ 	ret = sscanf(buf, "%20s", str_preference);
+ 	if (ret != 1)
+ 		return -EINVAL;
+ 
+ 	ret = match_string(energy_perf_strings, -1, str_preference);
+ 	if (ret < 0)
+ 		return -EINVAL;
+ 
+ 	mutex_lock(&amd_pstate_limits_lock);
+ 	ret = amd_pstate_set_energy_pref_index(cpudata, ret);
+ 	mutex_unlock(&amd_pstate_limits_lock);
+ 
+ 	return ret ?: count;
+ }
+ 
+ static ssize_t show_energy_performance_preference(
+ 				struct cpufreq_policy *policy, char *buf)
+ {
+ 	struct amd_cpudata *cpudata = policy->driver_data;
+ 	int preference;
+ 
+ 	preference = amd_pstate_get_energy_pref_index(cpudata);
+ 	if (preference < 0)
+ 		return preference;
+ 
+ 	return sysfs_emit(buf, "%s\n", energy_perf_strings[preference]);
+ }
+ 
  cpufreq_freq_attr_ro(amd_pstate_max_freq);
  cpufreq_freq_attr_ro(amd_pstate_lowest_nonlinear_freq);
  
@@@ -732,13 -1087,27 +1142,31 @@@ static int __init amd_pstate_param(cha
  	if (!str)
  		return -EINVAL;
  
 -	size = strlen(str);
 -	mode_idx = get_mode_idx_from_str(str, size);
 +	if (!strcmp(str, "disable")) {
 +		cppc_load = 0;
 +		pr_info("driver is explicitly disabled\n");
 +	} else if (!strcmp(str, "passive"))
 +		cppc_load = 1;
  
++<<<<<<< HEAD
 +	return 0;
++=======
+ 	if (mode_idx >= AMD_PSTATE_DISABLE && mode_idx < AMD_PSTATE_MAX) {
+ 		cppc_state = mode_idx;
+ 		if (cppc_state == AMD_PSTATE_DISABLE)
+ 			pr_info("driver is explicitly disabled\n");
+ 
+ 		if (cppc_state == AMD_PSTATE_ACTIVE)
+ 			current_pstate_driver = &amd_pstate_epp_driver;
+ 
+ 		if (cppc_state == AMD_PSTATE_PASSIVE)
+ 			current_pstate_driver = &amd_pstate_driver;
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -EINVAL;
++>>>>>>> ffa5096a7c33 (cpufreq: amd-pstate: implement Pstate EPP support for the AMD processors)
  }
  early_param("amd_pstate", amd_pstate_param);
  
* Unmerged path include/linux/amd-pstate.h
* Unmerged path drivers/cpufreq/amd-pstate.c
* Unmerged path include/linux/amd-pstate.h
