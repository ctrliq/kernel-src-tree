cpufreq: amd-pstate: Write CPPC enable bit per-socket

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-518.el8
commit-author Wyes Karny <wyes.karny@amd.com>
commit 217e67784eab30cd0704fab4109647ea68a4d850
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-518.el8/217e6778.failed

Currently amd_pstate sets CPPC enable bit in MSR_AMD_CPPC_ENABLE only
for the CPU where the module_init happened. But MSR_AMD_CPPC_ENABLE is
per-socket. This causes CPPC enable bit to set for only one socket for
servers with more than one physical packages. To fix this write
MSR_AMD_CPPC_ENABLE per-socket.

Also, handle duplicate calls for cppc_enable, because it's called from
per-policy/per-core callbacks and can result in duplicate MSR writes.

Before the fix:
amd@amd:~$ sudo rdmsr -a 0xc00102b1 | uniq --count
	192 0
    192 1

After the fix:
amd@amd:~$ sudo rdmsr -a 0xc00102b1 | uniq --count
    384 1

	Suggested-by: Gautham R. Shenoy <gautham.shenoy@amd.com>
	Signed-off-by: Wyes Karny <wyes.karny@amd.com>
	Acked-by: Huang Rui <ray.huang@amd.com>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 217e67784eab30cd0704fab4109647ea68a4d850)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/amd-pstate.c
diff --cc drivers/cpufreq/amd-pstate.c
index 2c71ef90154d,50722bfbb34a..000000000000
--- a/drivers/cpufreq/amd-pstate.c
+++ b/drivers/cpufreq/amd-pstate.c
@@@ -58,67 -59,173 +58,73 @@@
   * we disable it by default to go acpi-cpufreq on these processors and add a
   * module parameter to be able to enable it manually for debugging.
   */
 -static struct cpufreq_driver *current_pstate_driver;
  static struct cpufreq_driver amd_pstate_driver;
++<<<<<<< HEAD
 +static int cppc_load __initdata;
++=======
+ static struct cpufreq_driver amd_pstate_epp_driver;
+ static int cppc_state = AMD_PSTATE_DISABLE;
+ static bool cppc_enabled;
++>>>>>>> 217e67784eab (cpufreq: amd-pstate: Write CPPC enable bit per-socket)
  
 -/*
 - * AMD Energy Preference Performance (EPP)
 - * The EPP is used in the CCLK DPM controller to drive
 - * the frequency that a core is going to operate during
 - * short periods of activity. EPP values will be utilized for
 - * different OS profiles (balanced, performance, power savings)
 - * display strings corresponding to EPP index in the
 - * energy_perf_strings[]
 - *	index		String
 - *-------------------------------------
 - *	0		default
 - *	1		performance
 - *	2		balance_performance
 - *	3		balance_power
 - *	4		power
 +/**
 + * struct  amd_aperf_mperf
 + * @aperf: actual performance frequency clock count
 + * @mperf: maximum performance frequency clock count
 + * @tsc:   time stamp counter
   */
 -enum energy_perf_value_index {
 -	EPP_INDEX_DEFAULT = 0,
 -	EPP_INDEX_PERFORMANCE,
 -	EPP_INDEX_BALANCE_PERFORMANCE,
 -	EPP_INDEX_BALANCE_POWERSAVE,
 -	EPP_INDEX_POWERSAVE,
 -};
 -
 -static const char * const energy_perf_strings[] = {
 -	[EPP_INDEX_DEFAULT] = "default",
 -	[EPP_INDEX_PERFORMANCE] = "performance",
 -	[EPP_INDEX_BALANCE_PERFORMANCE] = "balance_performance",
 -	[EPP_INDEX_BALANCE_POWERSAVE] = "balance_power",
 -	[EPP_INDEX_POWERSAVE] = "power",
 -	NULL
 +struct amd_aperf_mperf {
 +	u64 aperf;
 +	u64 mperf;
 +	u64 tsc;
  };
  
 -static unsigned int epp_values[] = {
 -	[EPP_INDEX_DEFAULT] = 0,
 -	[EPP_INDEX_PERFORMANCE] = AMD_CPPC_EPP_PERFORMANCE,
 -	[EPP_INDEX_BALANCE_PERFORMANCE] = AMD_CPPC_EPP_BALANCE_PERFORMANCE,
 -	[EPP_INDEX_BALANCE_POWERSAVE] = AMD_CPPC_EPP_BALANCE_POWERSAVE,
 -	[EPP_INDEX_POWERSAVE] = AMD_CPPC_EPP_POWERSAVE,
 - };
 -
 -typedef int (*cppc_mode_transition_fn)(int);
 -
 -static inline int get_mode_idx_from_str(const char *str, size_t size)
 -{
 -	int i;
 -
 -	for (i=0; i < AMD_PSTATE_MAX; i++) {
 -		if (!strncmp(str, amd_pstate_mode_string[i], size))
 -			return i;
 -	}
 -	return -EINVAL;
 -}
 -
 -static DEFINE_MUTEX(amd_pstate_limits_lock);
 -static DEFINE_MUTEX(amd_pstate_driver_lock);
 -
 -static s16 amd_pstate_get_epp(struct amd_cpudata *cpudata, u64 cppc_req_cached)
 -{
 -	u64 epp;
 -	int ret;
 -
 -	if (boot_cpu_has(X86_FEATURE_CPPC)) {
 -		if (!cppc_req_cached) {
 -			epp = rdmsrl_on_cpu(cpudata->cpu, MSR_AMD_CPPC_REQ,
 -					&cppc_req_cached);
 -			if (epp)
 -				return epp;
 -		}
 -		epp = (cppc_req_cached >> 24) & 0xFF;
 -	} else {
 -		ret = cppc_get_epp_perf(cpudata->cpu, &epp);
 -		if (ret < 0) {
 -			pr_debug("Could not retrieve energy perf value (%d)\n", ret);
 -			return -EIO;
 -		}
 -	}
 -
 -	return (s16)(epp & 0xff);
 -}
 -
 -static int amd_pstate_get_energy_pref_index(struct amd_cpudata *cpudata)
 -{
 -	s16 epp;
 -	int index = -EINVAL;
 -
 -	epp = amd_pstate_get_epp(cpudata, 0);
 -	if (epp < 0)
 -		return epp;
 -
 -	switch (epp) {
 -	case AMD_CPPC_EPP_PERFORMANCE:
 -		index = EPP_INDEX_PERFORMANCE;
 -		break;
 -	case AMD_CPPC_EPP_BALANCE_PERFORMANCE:
 -		index = EPP_INDEX_BALANCE_PERFORMANCE;
 -		break;
 -	case AMD_CPPC_EPP_BALANCE_POWERSAVE:
 -		index = EPP_INDEX_BALANCE_POWERSAVE;
 -		break;
 -	case AMD_CPPC_EPP_POWERSAVE:
 -		index = EPP_INDEX_POWERSAVE;
 -		break;
 -	default:
 -		break;
 -	}
 -
 -	return index;
 -}
 -
 -static int amd_pstate_set_epp(struct amd_cpudata *cpudata, u32 epp)
 -{
 -	int ret;
 -	struct cppc_perf_ctrls perf_ctrls;
 -
 -	if (boot_cpu_has(X86_FEATURE_CPPC)) {
 -		u64 value = READ_ONCE(cpudata->cppc_req_cached);
 -
 -		value &= ~GENMASK_ULL(31, 24);
 -		value |= (u64)epp << 24;
 -		WRITE_ONCE(cpudata->cppc_req_cached, value);
 -
 -		ret = wrmsrl_on_cpu(cpudata->cpu, MSR_AMD_CPPC_REQ, value);
 -		if (!ret)
 -			cpudata->epp_cached = epp;
 -	} else {
 -		perf_ctrls.energy_perf = epp;
 -		ret = cppc_set_epp_perf(cpudata->cpu, &perf_ctrls, 1);
 -		if (ret) {
 -			pr_debug("failed to set energy perf value (%d)\n", ret);
 -			return ret;
 -		}
 -		cpudata->epp_cached = epp;
 -	}
 -
 -	return ret;
 -}
 -
 -static int amd_pstate_set_energy_pref_index(struct amd_cpudata *cpudata,
 -		int pref_index)
 -{
 -	int epp = -EINVAL;
 -	int ret;
 +/**
 + * struct amd_cpudata - private CPU data for AMD P-State
 + * @cpu: CPU number
 + * @req: constraint request to apply
 + * @cppc_req_cached: cached performance request hints
 + * @highest_perf: the maximum performance an individual processor may reach,
 + *		  assuming ideal conditions
 + * @nominal_perf: the maximum sustained performance level of the processor,
 + *		  assuming ideal operating conditions
 + * @lowest_nonlinear_perf: the lowest performance level at which nonlinear power
 + *			   savings are achieved
 + * @lowest_perf: the absolute lowest performance level of the processor
 + * @max_freq: the frequency that mapped to highest_perf
 + * @min_freq: the frequency that mapped to lowest_perf
 + * @nominal_freq: the frequency that mapped to nominal_perf
 + * @lowest_nonlinear_freq: the frequency that mapped to lowest_nonlinear_perf
 + * @cur: Difference of Aperf/Mperf/tsc count between last and current sample
 + * @prev: Last Aperf/Mperf/tsc count value read from register
 + * @freq: current cpu frequency value
 + * @boost_supported: check whether the Processor or SBIOS supports boost mode
 + *
 + * The amd_cpudata is key private data for each CPU thread in AMD P-State, and
 + * represents all the attributes and goals that AMD P-State requests at runtime.
 + */
 +struct amd_cpudata {
 +	int	cpu;
  
 -	if (!pref_index) {
 -		pr_debug("EPP pref_index is invalid\n");
 -		return -EINVAL;
 -	}
 +	struct	freq_qos_request req[2];
 +	u64	cppc_req_cached;
  
 -	if (epp == -EINVAL)
 -		epp = epp_values[pref_index];
 +	u32	highest_perf;
 +	u32	nominal_perf;
 +	u32	lowest_nonlinear_perf;
 +	u32	lowest_perf;
  
 -	if (epp > 0 && cpudata->policy == CPUFREQ_POLICY_PERFORMANCE) {
 -		pr_debug("EPP cannot be set under performance policy\n");
 -		return -EBUSY;
 -	}
 +	u32	max_freq;
 +	u32	min_freq;
 +	u32	nominal_freq;
 +	u32	lowest_nonlinear_freq;
  
 -	ret = amd_pstate_set_epp(cpudata, epp);
 +	struct amd_aperf_mperf cur;
 +	struct amd_aperf_mperf prev;
  
 -	return ret;
 -}
 +	u64 	freq;
 +	bool	boost_supported;
 +};
  
  static inline int pstate_enable(bool enable)
  {
@@@ -128,13 -256,27 +155,17 @@@
  static int cppc_enable(bool enable)
  {
  	int cpu, ret = 0;
 -	struct cppc_perf_ctrls perf_ctrls;
  
+ 	if (enable == cppc_enabled)
+ 		return 0;
+ 
  	for_each_present_cpu(cpu) {
  		ret = cppc_set_enable(cpu, enable);
  		if (ret)
  			return ret;
 -
 -		/* Enable autonomous mode for EPP */
 -		if (cppc_state == AMD_PSTATE_ACTIVE) {
 -			/* Set desired perf as zero to allow EPP firmware control */
 -			perf_ctrls.desired_perf = 0;
 -			ret = cppc_set_perf(cpu, &perf_ctrls);
 -			if (ret)
 -				return ret;
 -		}
  	}
  
+ 	cppc_enabled = enable;
  	return ret;
  }
  
* Unmerged path drivers/cpufreq/amd-pstate.c
