rxrpc: Only set/transmit aborts in the I/O thread

jira LE-1907
Rebuild_History Non-Buildable kernel-5.14.0-284.30.1.el9_2
commit-author David Howells <dhowells@redhat.com>
commit a343b174b4bdde851033996960bca5ad1394d04b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-5.14.0-284.30.1.el9_2/a343b174.failed

Only set the abort call completion state in the I/O thread and only
transmit ABORT packets from there.  rxrpc_abort_call() can then be made to
actually send the packet.

Further, ABORT packets should only be sent if the call has been exposed to
the network (ie. at least one attempted DATA transmission has occurred for
it).

	Signed-off-by: David Howells <dhowells@redhat.com>
cc: Marc Dionne <marc.dionne@auristor.com>
cc: linux-afs@lists.infradead.org
(cherry picked from commit a343b174b4bdde851033996960bca5ad1394d04b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/trace/events/rxrpc.h
#	net/rxrpc/call_event.c
#	net/rxrpc/call_object.c
#	net/rxrpc/input.c
#	net/rxrpc/recvmsg.c
diff --cc include/trace/events/rxrpc.h
index 2a52121d73a0,c44cc01de750..000000000000
--- a/include/trace/events/rxrpc.h
+++ b/include/trace/events/rxrpc.h
@@@ -16,44 -16,122 +16,55 @@@
  /*
   * Declare tracing information enums and their string mappings for display.
   */
++<<<<<<< HEAD
++=======
+ #define rxrpc_call_poke_traces \
+ 	EM(rxrpc_call_poke_abort,		"Abort")	\
+ 	EM(rxrpc_call_poke_error,		"Error")	\
+ 	EM(rxrpc_call_poke_idle,		"Idle")		\
+ 	EM(rxrpc_call_poke_start,		"Start")	\
+ 	EM(rxrpc_call_poke_timer,		"Timer")	\
+ 	E_(rxrpc_call_poke_timer_now,		"Timer-now")
+ 
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  #define rxrpc_skb_traces \
 -	EM(rxrpc_skb_eaten_by_unshare,		"ETN unshare  ") \
 -	EM(rxrpc_skb_eaten_by_unshare_nomem,	"ETN unshar-nm") \
 -	EM(rxrpc_skb_get_conn_work,		"GET conn-work") \
 -	EM(rxrpc_skb_get_local_work,		"GET locl-work") \
 -	EM(rxrpc_skb_get_reject_work,		"GET rej-work ") \
 -	EM(rxrpc_skb_get_to_recvmsg,		"GET to-recv  ") \
 -	EM(rxrpc_skb_get_to_recvmsg_oos,	"GET to-recv-o") \
 -	EM(rxrpc_skb_new_encap_rcv,		"NEW encap-rcv") \
 -	EM(rxrpc_skb_new_error_report,		"NEW error-rpt") \
 -	EM(rxrpc_skb_new_jumbo_subpacket,	"NEW jumbo-sub") \
 -	EM(rxrpc_skb_new_unshared,		"NEW unshared ") \
 -	EM(rxrpc_skb_put_conn_work,		"PUT conn-work") \
 -	EM(rxrpc_skb_put_error_report,		"PUT error-rep") \
 -	EM(rxrpc_skb_put_input,			"PUT input    ") \
 -	EM(rxrpc_skb_put_jumbo_subpacket,	"PUT jumbo-sub") \
 -	EM(rxrpc_skb_put_purge,			"PUT purge    ") \
 -	EM(rxrpc_skb_put_rotate,		"PUT rotate   ") \
 -	EM(rxrpc_skb_put_unknown,		"PUT unknown  ") \
 -	EM(rxrpc_skb_see_conn_work,		"SEE conn-work") \
 -	EM(rxrpc_skb_see_recvmsg,		"SEE recvmsg  ") \
 -	EM(rxrpc_skb_see_reject,		"SEE reject   ") \
 -	EM(rxrpc_skb_see_rotate,		"SEE rotate   ") \
 -	E_(rxrpc_skb_see_version,		"SEE version  ")
 +	EM(rxrpc_skb_ack,			"ACK") \
 +	EM(rxrpc_skb_cleaned,			"CLN") \
 +	EM(rxrpc_skb_cloned_jumbo,		"CLJ") \
 +	EM(rxrpc_skb_freed,			"FRE") \
 +	EM(rxrpc_skb_got,			"GOT") \
 +	EM(rxrpc_skb_lost,			"*L*") \
 +	EM(rxrpc_skb_new,			"NEW") \
 +	EM(rxrpc_skb_purged,			"PUR") \
 +	EM(rxrpc_skb_received,			"RCV") \
 +	EM(rxrpc_skb_rotated,			"ROT") \
 +	EM(rxrpc_skb_seen,			"SEE") \
 +	EM(rxrpc_skb_unshared,			"UNS") \
 +	E_(rxrpc_skb_unshared_nomem,		"US0")
  
  #define rxrpc_local_traces \
 -	EM(rxrpc_local_free,			"FREE        ") \
 -	EM(rxrpc_local_get_call,		"GET call    ") \
 -	EM(rxrpc_local_get_client_conn,		"GET conn-cln") \
 -	EM(rxrpc_local_get_for_use,		"GET for-use ") \
 -	EM(rxrpc_local_get_peer,		"GET peer    ") \
 -	EM(rxrpc_local_get_prealloc_conn,	"GET conn-pre") \
 -	EM(rxrpc_local_new,			"NEW         ") \
 -	EM(rxrpc_local_put_bind,		"PUT bind    ") \
 -	EM(rxrpc_local_put_call,		"PUT call    ") \
 -	EM(rxrpc_local_put_for_use,		"PUT for-use ") \
 -	EM(rxrpc_local_put_kill_conn,		"PUT conn-kil") \
 -	EM(rxrpc_local_put_peer,		"PUT peer    ") \
 -	EM(rxrpc_local_put_prealloc_conn,	"PUT conn-pre") \
 -	EM(rxrpc_local_put_release_sock,	"PUT rel-sock") \
 -	EM(rxrpc_local_stop,			"STOP        ") \
 -	EM(rxrpc_local_stopped,			"STOPPED     ") \
 -	EM(rxrpc_local_unuse_bind,		"UNU bind    ") \
 -	EM(rxrpc_local_unuse_conn_work,		"UNU conn-wrk") \
 -	EM(rxrpc_local_unuse_peer_keepalive,	"UNU peer-kpa") \
 -	EM(rxrpc_local_unuse_release_sock,	"UNU rel-sock") \
 -	EM(rxrpc_local_use_conn_work,		"USE conn-wrk") \
 -	EM(rxrpc_local_use_lookup,		"USE lookup  ") \
 -	E_(rxrpc_local_use_peer_keepalive,	"USE peer-kpa")
 +	EM(rxrpc_local_got,			"GOT") \
 +	EM(rxrpc_local_new,			"NEW") \
 +	EM(rxrpc_local_processing,		"PRO") \
 +	EM(rxrpc_local_put,			"PUT") \
 +	EM(rxrpc_local_queued,			"QUE") \
 +	E_(rxrpc_local_tx_ack,			"TAK")
  
  #define rxrpc_peer_traces \
 -	EM(rxrpc_peer_free,			"FREE        ") \
 -	EM(rxrpc_peer_get_accept,		"GET accept  ") \
 -	EM(rxrpc_peer_get_activate_call,	"GET act-call") \
 -	EM(rxrpc_peer_get_bundle,		"GET bundle  ") \
 -	EM(rxrpc_peer_get_client_conn,		"GET cln-conn") \
 -	EM(rxrpc_peer_get_input,		"GET input   ") \
 -	EM(rxrpc_peer_get_input_error,		"GET inpt-err") \
 -	EM(rxrpc_peer_get_keepalive,		"GET keepaliv") \
 -	EM(rxrpc_peer_get_lookup_client,	"GET look-cln") \
 -	EM(rxrpc_peer_get_service_conn,		"GET srv-conn") \
 -	EM(rxrpc_peer_new_client,		"NEW client  ") \
 -	EM(rxrpc_peer_new_prealloc,		"NEW prealloc") \
 -	EM(rxrpc_peer_put_bundle,		"PUT bundle  ") \
 -	EM(rxrpc_peer_put_call,			"PUT call    ") \
 -	EM(rxrpc_peer_put_conn,			"PUT conn    ") \
 -	EM(rxrpc_peer_put_discard_tmp,		"PUT disc-tmp") \
 -	EM(rxrpc_peer_put_input,		"PUT input   ") \
 -	EM(rxrpc_peer_put_input_error,		"PUT inpt-err") \
 -	E_(rxrpc_peer_put_keepalive,		"PUT keepaliv")
 -
 -#define rxrpc_bundle_traces \
 -	EM(rxrpc_bundle_free,			"FREE        ") \
 -	EM(rxrpc_bundle_get_client_call,	"GET clt-call") \
 -	EM(rxrpc_bundle_get_client_conn,	"GET clt-conn") \
 -	EM(rxrpc_bundle_get_service_conn,	"GET svc-conn") \
 -	EM(rxrpc_bundle_put_conn,		"PUT conn    ") \
 -	EM(rxrpc_bundle_put_discard,		"PUT discard ") \
 -	E_(rxrpc_bundle_new,			"NEW         ")
 +	EM(rxrpc_peer_got,			"GOT") \
 +	EM(rxrpc_peer_new,			"NEW") \
 +	EM(rxrpc_peer_processing,		"PRO") \
 +	E_(rxrpc_peer_put,			"PUT")
  
  #define rxrpc_conn_traces \
 -	EM(rxrpc_conn_free,			"FREE        ") \
 -	EM(rxrpc_conn_get_activate_call,	"GET act-call") \
 -	EM(rxrpc_conn_get_call_input,		"GET inp-call") \
 -	EM(rxrpc_conn_get_conn_input,		"GET inp-conn") \
 -	EM(rxrpc_conn_get_idle,			"GET idle    ") \
 -	EM(rxrpc_conn_get_poke,			"GET poke    ") \
 -	EM(rxrpc_conn_get_service_conn,		"GET svc-conn") \
 -	EM(rxrpc_conn_new_client,		"NEW client  ") \
 -	EM(rxrpc_conn_new_service,		"NEW service ") \
 -	EM(rxrpc_conn_put_call,			"PUT call    ") \
 -	EM(rxrpc_conn_put_call_input,		"PUT inp-call") \
 -	EM(rxrpc_conn_put_conn_input,		"PUT inp-conn") \
 -	EM(rxrpc_conn_put_discard,		"PUT discard ") \
 -	EM(rxrpc_conn_put_discard_idle,		"PUT disc-idl") \
 -	EM(rxrpc_conn_put_local_dead,		"PUT loc-dead") \
 -	EM(rxrpc_conn_put_noreuse,		"PUT noreuse ") \
 -	EM(rxrpc_conn_put_poke,			"PUT poke    ") \
 -	EM(rxrpc_conn_put_service_reaped,	"PUT svc-reap") \
 -	EM(rxrpc_conn_put_unbundle,		"PUT unbundle") \
 -	EM(rxrpc_conn_put_unidle,		"PUT unidle  ") \
 -	EM(rxrpc_conn_queue_challenge,		"QUE chall   ") \
 -	EM(rxrpc_conn_queue_retry_work,		"QUE retry-wk") \
 -	EM(rxrpc_conn_queue_rx_work,		"QUE rx-work ") \
 -	EM(rxrpc_conn_queue_timer,		"QUE timer   ") \
 -	EM(rxrpc_conn_see_new_service_conn,	"SEE new-svc ") \
 -	EM(rxrpc_conn_see_reap_service,		"SEE reap-svc") \
 -	E_(rxrpc_conn_see_work,			"SEE work    ")
 +	EM(rxrpc_conn_got,			"GOT") \
 +	EM(rxrpc_conn_new_client,		"NWc") \
 +	EM(rxrpc_conn_new_service,		"NWs") \
 +	EM(rxrpc_conn_put_client,		"PTc") \
 +	EM(rxrpc_conn_put_service,		"PTs") \
 +	EM(rxrpc_conn_queued,			"QUE") \
 +	EM(rxrpc_conn_reap_service,		"RPs") \
 +	E_(rxrpc_conn_seen,			"SEE")
  
  #define rxrpc_client_traces \
  	EM(rxrpc_client_activate_chans,		"Activa") \
diff --cc net/rxrpc/call_event.c
index a95f4604cb29,b7efecf5ccfc..000000000000
--- a/net/rxrpc/call_event.c
+++ b/net/rxrpc/call_event.c
@@@ -291,16 -251,94 +291,103 @@@ out
  	_leave("");
  }
  
++<<<<<<< HEAD
++=======
+ static bool rxrpc_tx_window_has_space(struct rxrpc_call *call)
+ {
+ 	unsigned int winsize = min_t(unsigned int, call->tx_winsize,
+ 				     call->cong_cwnd + call->cong_extra);
+ 	rxrpc_seq_t window = call->acks_hard_ack, wtop = window + winsize;
+ 	rxrpc_seq_t tx_top = call->tx_top;
+ 	int space;
+ 
+ 	space = wtop - tx_top;
+ 	return space > 0;
+ }
+ 
+ /*
+  * Decant some if the sendmsg prepared queue into the transmission buffer.
+  */
+ static void rxrpc_decant_prepared_tx(struct rxrpc_call *call)
+ {
+ 	struct rxrpc_txbuf *txb;
+ 
+ 	if (!test_bit(RXRPC_CALL_EXPOSED, &call->flags)) {
+ 		if (list_empty(&call->tx_sendmsg))
+ 			return;
+ 		rxrpc_expose_client_call(call);
+ 	}
+ 
+ 	while ((txb = list_first_entry_or_null(&call->tx_sendmsg,
+ 					       struct rxrpc_txbuf, call_link))) {
+ 		spin_lock(&call->tx_lock);
+ 		list_del(&txb->call_link);
+ 		spin_unlock(&call->tx_lock);
+ 
+ 		call->tx_top = txb->seq;
+ 		list_add_tail(&txb->call_link, &call->tx_buffer);
+ 
+ 		rxrpc_transmit_one(call, txb);
+ 
+ 		if (!rxrpc_tx_window_has_space(call))
+ 			break;
+ 	}
+ }
+ 
+ static void rxrpc_transmit_some_data(struct rxrpc_call *call)
+ {
+ 	switch (call->state) {
+ 	case RXRPC_CALL_SERVER_ACK_REQUEST:
+ 		if (list_empty(&call->tx_sendmsg))
+ 			return;
+ 		fallthrough;
+ 
+ 	case RXRPC_CALL_SERVER_SEND_REPLY:
+ 	case RXRPC_CALL_SERVER_AWAIT_ACK:
+ 	case RXRPC_CALL_CLIENT_SEND_REQUEST:
+ 	case RXRPC_CALL_CLIENT_AWAIT_REPLY:
+ 		if (!rxrpc_tx_window_has_space(call))
+ 			return;
+ 		if (list_empty(&call->tx_sendmsg)) {
+ 			rxrpc_inc_stat(call->rxnet, stat_tx_data_underflow);
+ 			return;
+ 		}
+ 		rxrpc_decant_prepared_tx(call);
+ 		break;
+ 	default:
+ 		return;
+ 	}
+ }
+ 
+ /*
+  * Ping the other end to fill our RTT cache and to retrieve the rwind
+  * and MTU parameters.
+  */
+ static void rxrpc_send_initial_ping(struct rxrpc_call *call)
+ {
+ 	if (call->peer->rtt_count < 3 ||
+ 	    ktime_before(ktime_add_ms(call->peer->rtt_last_req, 1000),
+ 			 ktime_get_real()))
+ 		rxrpc_send_ACK(call, RXRPC_ACK_PING, 0,
+ 			       rxrpc_propose_ack_ping_for_params);
+ }
+ 
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  /*
   * Handle retransmission and deferred ACK/abort generation.
   */
 -void rxrpc_input_call_event(struct rxrpc_call *call, struct sk_buff *skb)
 +void rxrpc_process_call(struct work_struct *work)
  {
 +	struct rxrpc_call *call =
 +		container_of(work, struct rxrpc_call, processor);
  	unsigned long now, next, t;
 +	unsigned int iterations = 0;
  	rxrpc_serial_t ackr_serial;
++<<<<<<< HEAD
++=======
+ 	bool resend = false, expired = false;
+ 	s32 abort_code;
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  
  	rxrpc_see_call(call, rxrpc_call_see_input);
  
@@@ -308,26 -346,21 +395,39 @@@
  	_enter("{%d,%s,%lx}",
  	       call->debug_id, rxrpc_call_states[call->state], call->events);
  
 -	if (call->state == RXRPC_CALL_COMPLETE)
 -		goto out;
 +recheck_state:
 +	/* Limit the number of times we do this before returning to the manager */
 +	iterations++;
 +	if (iterations > 5)
 +		goto requeue;
  
++<<<<<<< HEAD
 +	if (test_and_clear_bit(RXRPC_CALL_EV_ABORT, &call->events)) {
 +		rxrpc_send_abort_packet(call);
 +		goto recheck_state;
 +	}
++=======
+ 	/* Handle abort request locklessly, vs rxrpc_propose_abort(). */
+ 	abort_code = smp_load_acquire(&call->send_abort);
+ 	if (abort_code) {
+ 		rxrpc_abort_call(call->send_abort_why, call, 0, call->send_abort,
+ 				 call->send_abort_err);
+ 		goto out;
+ 	}
+ 
+ 	if (skb && skb->mark == RXRPC_SKB_MARK_ERROR)
+ 		goto out;
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
 +
 +	if (READ_ONCE(call->acks_hard_ack) != call->tx_bottom)
 +		rxrpc_shrink_call_tx_buffer(call);
 +
 +	if (call->state == RXRPC_CALL_COMPLETE) {
 +		rxrpc_delete_call_timer(call);
 +		goto out_put;
 +	}
  
 -	/* If we see our async-event poke, check for timeout trippage. */
 +	/* Work out if any timeouts tripped */
  	now = jiffies;
  	t = READ_ONCE(call->expect_rx_by);
  	if (time_after_eq(now, t)) {
@@@ -396,24 -444,27 +496,28 @@@
  		} else {
  			rxrpc_abort_call("EXP", call, 0, RX_CALL_TIMEOUT, -ETIME);
  		}
++<<<<<<< HEAD
 +		set_bit(RXRPC_CALL_EV_ABORT, &call->events);
 +		goto recheck_state;
++=======
+ 		goto out;
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  	}
  
 -	if (test_and_clear_bit(RXRPC_CALL_EV_ACK_LOST, &call->events))
 +	if (test_and_clear_bit(RXRPC_CALL_EV_ACK_LOST, &call->events)) {
 +		call->acks_lost_top = call->tx_top;
  		rxrpc_send_ACK(call, RXRPC_ACK_PING, 0,
  			       rxrpc_propose_ack_ping_for_lost_ack);
 +	}
  
 -	if (resend && call->state != RXRPC_CALL_CLIENT_RECV_REPLY)
 -		rxrpc_resend(call, NULL);
 -
 -	if (test_and_clear_bit(RXRPC_CALL_RX_IS_IDLE, &call->flags))
 -		rxrpc_send_ACK(call, RXRPC_ACK_IDLE, 0,
 -			       rxrpc_propose_ack_rx_idle);
 -
 -	if (atomic_read(&call->ackr_nr_unacked) > 2)
 -		rxrpc_send_ACK(call, RXRPC_ACK_IDLE, 0,
 -			       rxrpc_propose_ack_input_data);
 +	if (test_and_clear_bit(RXRPC_CALL_EV_RESEND, &call->events) &&
 +	    call->state != RXRPC_CALL_CLIENT_RECV_REPLY) {
 +		rxrpc_resend(call, now);
 +		goto recheck_state;
 +	}
  
  	/* Make sure the timer is restarted */
 -	if (call->state != RXRPC_CALL_COMPLETE) {
 -		next = call->expect_rx_by;
 +	next = call->expect_rx_by;
  
  #define set(T) { t = READ_ONCE(T); if (time_before(t, next)) next = t; }
  
diff --cc net/rxrpc/call_object.c
index ad495d0d21a8,298b7c465d7e..000000000000
--- a/net/rxrpc/call_object.c
+++ b/net/rxrpc/call_object.c
@@@ -405,6 -430,33 +405,36 @@@ void rxrpc_incoming_call(struct rxrpc_s
  	call->state		= RXRPC_CALL_SERVER_SECURING;
  	call->cong_tstamp	= skb->tstamp;
  
++<<<<<<< HEAD
++=======
+ 	__set_bit(RXRPC_CALL_EXPOSED, &call->flags);
+ 
+ 	spin_lock(&conn->state_lock);
+ 
+ 	switch (conn->state) {
+ 	case RXRPC_CONN_SERVICE_UNSECURED:
+ 	case RXRPC_CONN_SERVICE_CHALLENGING:
+ 		call->state = RXRPC_CALL_SERVER_SECURING;
+ 		break;
+ 	case RXRPC_CONN_SERVICE:
+ 		call->state = RXRPC_CALL_SERVER_RECV_REQUEST;
+ 		break;
+ 
+ 	case RXRPC_CONN_REMOTELY_ABORTED:
+ 		__rxrpc_set_call_completion(call, RXRPC_CALL_REMOTELY_ABORTED,
+ 					    conn->abort_code, conn->error);
+ 		break;
+ 	case RXRPC_CONN_LOCALLY_ABORTED:
+ 		__rxrpc_abort_call("CON", call, 1,
+ 				   conn->abort_code, conn->error);
+ 		break;
+ 	default:
+ 		BUG();
+ 	}
+ 
+ 	rxrpc_get_call(call, rxrpc_call_get_io_thread);
+ 
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  	/* Set the channel for this call.  We don't get channel_lock as we're
  	 * only defending against the data_ready handler (which we're called
  	 * from) and the RESPONSE packet parser (which is only really
diff --cc net/rxrpc/input.c
index b5326e160685,1f03a286620d..000000000000
--- a/net/rxrpc/input.c
+++ b/net/rxrpc/input.c
@@@ -12,10 -12,7 +12,14 @@@
  static void rxrpc_proto_abort(const char *why,
  			      struct rxrpc_call *call, rxrpc_seq_t seq)
  {
++<<<<<<< HEAD
 +	if (rxrpc_abort_call(why, call, seq, RX_PROTOCOL_ERROR, -EBADMSG)) {
 +		set_bit(RXRPC_CALL_EV_ABORT, &call->events);
 +		rxrpc_queue_call(call, rxrpc_call_queue_abort);
 +	}
++=======
+ 	rxrpc_abort_call(why, call, seq, RX_PROTOCOL_ERROR, -EBADMSG);
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  }
  
  /*
@@@ -1098,10 -1006,7 +1102,14 @@@ static void rxrpc_input_implicit_end_ca
  	case RXRPC_CALL_COMPLETE:
  		break;
  	default:
++<<<<<<< HEAD
 +		if (rxrpc_abort_call("IMP", call, 0, RX_CALL_DEAD, -ESHUTDOWN)) {
 +			set_bit(RXRPC_CALL_EV_ABORT, &call->events);
 +			rxrpc_queue_call(call, rxrpc_call_queue_abort);
 +		}
++=======
+ 		rxrpc_abort_call("IMP", call, 0, RX_CALL_DEAD, -ESHUTDOWN);
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  		trace_rxrpc_improper_term(call);
  		break;
  	}
diff --cc net/rxrpc/recvmsg.c
index c84d2b620396,a4ccdc006d0f..000000000000
--- a/net/rxrpc/recvmsg.c
+++ b/net/rxrpc/recvmsg.c
@@@ -131,9 -131,11 +131,15 @@@ bool rxrpc_abort_call(const char *why, 
  {
  	bool ret;
  
 -	write_lock(&call->state_lock);
 +	write_lock_bh(&call->state_lock);
  	ret = __rxrpc_abort_call(why, call, seq, abort_code, error);
++<<<<<<< HEAD
 +	write_unlock_bh(&call->state_lock);
++=======
+ 	write_unlock(&call->state_lock);
+ 	if (ret && test_bit(RXRPC_CALL_EXPOSED, &call->flags))
+ 		rxrpc_send_abort_packet(call);
++>>>>>>> a343b174b4bd (rxrpc: Only set/transmit aborts in the I/O thread)
  	return ret;
  }
  
* Unmerged path include/trace/events/rxrpc.h
diff --git a/net/rxrpc/ar-internal.h b/net/rxrpc/ar-internal.h
index 46ce41afb431..a27908e4c91a 100644
--- a/net/rxrpc/ar-internal.h
+++ b/net/rxrpc/ar-internal.h
@@ -602,7 +602,10 @@ struct rxrpc_call {
 	unsigned long		events;
 	spinlock_t		notify_lock;	/* Kernel notification lock */
 	rwlock_t		state_lock;	/* lock for state transition */
-	u32			abort_code;	/* Local/remote abort code */
+	const char		*send_abort_why; /* String indicating why the abort was sent */
+	s32			send_abort;	/* Abort code to be sent */
+	short			send_abort_err;	/* Error to be associated with the abort */
+	s32			abort_code;	/* Local/remote abort code */
 	int			error;		/* Local error incurred */
 	enum rxrpc_call_state	state;		/* current state of call */
 	enum rxrpc_call_completion completion;	/* Call completion condition */
@@ -1106,6 +1109,8 @@ struct key *rxrpc_look_up_server_security(struct rxrpc_connection *,
 /*
  * sendmsg.c
  */
+bool rxrpc_propose_abort(struct rxrpc_call *call,
+			 u32 abort_code, int error, const char *why);
 int rxrpc_do_sendmsg(struct rxrpc_sock *, struct msghdr *, size_t);
 
 /*
* Unmerged path net/rxrpc/call_event.c
* Unmerged path net/rxrpc/call_object.c
* Unmerged path net/rxrpc/input.c
* Unmerged path net/rxrpc/recvmsg.c
diff --git a/net/rxrpc/sendmsg.c b/net/rxrpc/sendmsg.c
index 45c09f0de6fe..9017280b07f8 100644
--- a/net/rxrpc/sendmsg.c
+++ b/net/rxrpc/sendmsg.c
@@ -17,6 +17,26 @@
 #include <net/af_rxrpc.h>
 #include "ar-internal.h"
 
+/*
+ * Propose an abort to be made in the I/O thread.
+ */
+bool rxrpc_propose_abort(struct rxrpc_call *call,
+			 u32 abort_code, int error, const char *why)
+{
+	_enter("{%d},%d,%d,%s", call->debug_id, abort_code, error, why);
+
+	if (!call->send_abort && call->state < RXRPC_CALL_COMPLETE) {
+		call->send_abort_why = why;
+		call->send_abort_err = error;
+		/* Request abort locklessly vs rxrpc_input_call_event(). */
+		smp_store_release(&call->send_abort, abort_code);
+		rxrpc_poke_call(call, rxrpc_call_poke_abort);
+		return true;
+	}
+
+	return false;
+}
+
 /*
  * Return true if there's sufficient Tx queue space.
  */
@@ -724,9 +744,8 @@ int rxrpc_do_sendmsg(struct rxrpc_sock *rx, struct msghdr *msg, size_t len)
 		/* it's too late for this call */
 		ret = -ESHUTDOWN;
 	} else if (p.command == RXRPC_CMD_SEND_ABORT) {
+		rxrpc_propose_abort(call, p.abort_code, -ECONNABORTED, "CMD");
 		ret = 0;
-		if (rxrpc_abort_call("CMD", call, 0, p.abort_code, -ECONNABORTED))
-			ret = rxrpc_send_abort_packet(call);
 	} else if (p.command != RXRPC_CMD_SEND_DATA) {
 		ret = -EINVAL;
 	} else {
@@ -821,11 +840,7 @@ bool rxrpc_kernel_abort_call(struct socket *sock, struct rxrpc_call *call,
 	_enter("{%d},%d,%d,%s", call->debug_id, abort_code, error, why);
 
 	mutex_lock(&call->user_mutex);
-
-	aborted = rxrpc_abort_call(why, call, 0, abort_code, error);
-	if (aborted)
-		rxrpc_send_abort_packet(call);
-
+	aborted = rxrpc_propose_abort(call, abort_code, error, why);
 	mutex_unlock(&call->user_mutex);
 	return aborted;
 }
