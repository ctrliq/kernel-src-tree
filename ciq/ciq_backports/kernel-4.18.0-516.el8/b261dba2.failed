arm64: kdump: Remove custom linux,usable-memory-range handling

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-516.el8
commit-author Geert Uytterhoeven <geert+renesas@glider.be>
commit b261dba2fdb2c2656935a048cdbc6f2d24231e08
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-516.el8/b261dba2.failed

Remove the architecture-specific code for handling the
"linux,usable-memory-range" property under the "/chosen" node in DT, as
the platform-agnostic FDT core code already takes care of this.

	Signed-off-by: Geert Uytterhoeven <geert+renesas@glider.be>
	Acked-by: Catalin Marinas <catalin.marinas@arm.com>
	Signed-off-by: Rob Herring <robh@kernel.org>
Link: https://lore.kernel.org/r/7356c531c49a24b4a55577bf8e46d93f4d8ae460.1628670468.git.geert+renesas@glider.be
(cherry picked from commit b261dba2fdb2c2656935a048cdbc6f2d24231e08)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/mm/init.c
diff --cc arch/arm64/mm/init.c
index 0ecabcb09871,4e90a1d17058..000000000000
--- a/arch/arm64/mm/init.c
+++ b/arch/arm64/mm/init.c
@@@ -335,61 -197,10 +335,67 @@@ static int __init early_mem(char *p
  }
  early_param("mem", early_mem);
  
++<<<<<<< HEAD
 +static int __init early_init_dt_scan_usablemem(unsigned long node,
 +		const char *uname, int depth, void *data)
 +{
 +	struct memblock_region *usablemem = data;
 +	const __be32 *reg;
 +	int len;
 +
 +	if (depth != 1 || strcmp(uname, "chosen") != 0)
 +		return 0;
 +
 +	reg = of_get_flat_dt_prop(node, "linux,usable-memory-range", &len);
 +	if (!reg || (len < (dt_root_addr_cells + dt_root_size_cells)))
 +		return 1;
 +
 +	usablemem->base = dt_mem_next_cell(dt_root_addr_cells, &reg);
 +	usablemem->size = dt_mem_next_cell(dt_root_size_cells, &reg);
 +
 +	return 1;
 +}
 +
 +static void __init fdt_enforce_memory_region(void)
 +{
 +	struct memblock_region reg = {
 +		.size = 0,
 +	};
 +
 +	//
 +	of_scan_flat_dt(early_init_dt_scan_usablemem, &reg);
 +
 +	if (reg.size)
 +		memblock_cap_memory_range(reg.base, reg.size);
 +}
 +
++=======
++>>>>>>> b261dba2fdb2 (arm64: kdump: Remove custom linux,usable-memory-range handling)
  void __init arm64_memblock_init(void)
  {
 -	const s64 linear_region_size = PAGE_END - _PAGE_OFFSET(vabits_actual);
 +	s64 linear_region_size = PAGE_END - _PAGE_OFFSET(vabits_actual);
 +
 +	/*
 +	 * Corner case: 52-bit VA capable systems running KVM in nVHE mode may
 +	 * be limited in their ability to support a linear map that exceeds 51
 +	 * bits of VA space, depending on the placement of the ID map. Given
 +	 * that the placement of the ID map may be randomized, let's simply
 +	 * limit the kernel's linear map to 51 bits as well if we detect this
 +	 * configuration.
 +	 */
 +	if (IS_ENABLED(CONFIG_KVM) && vabits_actual == 52 &&
 +	    is_hyp_mode_available() && !is_kernel_in_hyp_mode()) {
 +		pr_info("Capping linear region to 51 bits for KVM in nVHE mode on LVA capable hardware.\n");
 +		linear_region_size = min_t(u64, linear_region_size, BIT(51));
 +	}
 +
++<<<<<<< HEAD
 +	/* Handle linux,usable-memory-range property */
 +	//
 +	fdt_enforce_memory_region();
  
++=======
++>>>>>>> b261dba2fdb2 (arm64: kdump: Remove custom linux,usable-memory-range handling)
  	/* Remove memory above our supported physical address size */
  	memblock_remove(1ULL << PHYS_MASK_SHIFT, ULLONG_MAX);
  
* Unmerged path arch/arm64/mm/init.c
