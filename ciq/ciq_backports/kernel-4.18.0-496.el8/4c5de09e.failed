net: ethernet: mtk_wed: add configure wed wo support

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-496.el8
commit-author Lorenzo Bianconi <lorenzo@kernel.org>
commit 4c5de09eb0d05fc9e73ff8f0e052622f1f3df6d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-496.el8/4c5de09e.failed

Enable RX Wireless Ethernet Dispatch available on MT7986 Soc.

	Tested-by: Daniel Golle <daniel@makrotopia.org>
Co-developed-by: Sujuan Chen <sujuan.chen@mediatek.com>
	Signed-off-by: Sujuan Chen <sujuan.chen@mediatek.com>
	Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4c5de09eb0d05fc9e73ff8f0e052622f1f3df6d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mediatek/mtk_wed.c
#	drivers/net/ethernet/mediatek/mtk_wed_mcu.c
#	drivers/net/ethernet/mediatek/mtk_wed_regs.h
#	drivers/net/ethernet/mediatek/mtk_wed_wo.h
#	include/linux/soc/mediatek/mtk_wed.h
diff --cc drivers/net/ethernet/mediatek/mtk_wed.c
index 420f6a7c88c7,7d8842378c2b..000000000000
--- a/drivers/net/ethernet/mediatek/mtk_wed.c
+++ b/drivers/net/ethernet/mediatek/mtk_wed.c
@@@ -25,6 -28,15 +27,18 @@@
  
  #define MTK_WED_TX_RING_SIZE		2048
  #define MTK_WED_WDMA_RING_SIZE		1024
++<<<<<<< HEAD
++=======
+ #define MTK_WED_MAX_GROUP_SIZE		0x100
+ #define MTK_WED_VLD_GROUP_SIZE		0x40
+ #define MTK_WED_PER_GROUP_PKT		128
+ 
+ #define MTK_WED_FBUF_SIZE		128
+ #define MTK_WED_MIOD_CNT		16
+ #define MTK_WED_FB_CMD_CNT		1024
+ #define MTK_WED_RRO_QUE_CNT		8192
+ #define MTK_WED_MIOD_ENTRY_CNT		128
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  static struct mtk_wed_hw *hw_list[2];
  static DEFINE_MUTEX(hw_lock);
@@@ -237,6 -450,52 +417,55 @@@ mtk_wed_set_ext_int(struct mtk_wed_devi
  }
  
  static void
++<<<<<<< HEAD
++=======
+ mtk_wed_set_512_support(struct mtk_wed_device *dev, bool enable)
+ {
+ 	if (enable) {
+ 		wed_w32(dev, MTK_WED_TXDP_CTRL, MTK_WED_TXDP_DW9_OVERWR);
+ 		wed_w32(dev, MTK_WED_TXP_DW1,
+ 			FIELD_PREP(MTK_WED_WPDMA_WRITE_TXP, 0x0103));
+ 	} else {
+ 		wed_w32(dev, MTK_WED_TXP_DW1,
+ 			FIELD_PREP(MTK_WED_WPDMA_WRITE_TXP, 0x0100));
+ 		wed_clr(dev, MTK_WED_TXDP_CTRL, MTK_WED_TXDP_DW9_OVERWR);
+ 	}
+ }
+ 
+ #define MTK_WFMDA_RX_DMA_EN	BIT(2)
+ static void
+ mtk_wed_check_wfdma_rx_fill(struct mtk_wed_device *dev, int idx)
+ {
+ 	u32 val;
+ 	int i;
+ 
+ 	if (!(dev->rx_ring[idx].flags & MTK_WED_RING_CONFIGURED))
+ 		return; /* queue is not configured by mt76 */
+ 
+ 	for (i = 0; i < 3; i++) {
+ 		u32 cur_idx;
+ 
+ 		cur_idx = wed_r32(dev,
+ 				  MTK_WED_WPDMA_RING_RX_DATA(idx) +
+ 				  MTK_WED_RING_OFS_CPU_IDX);
+ 		if (cur_idx == MTK_WED_RX_RING_SIZE - 1)
+ 			break;
+ 
+ 		usleep_range(100000, 200000);
+ 	}
+ 
+ 	if (i == 3) {
+ 		dev_err(dev->hw->dev, "rx dma enable failed\n");
+ 		return;
+ 	}
+ 
+ 	val = wifi_r32(dev, dev->wlan.wpdma_rx_glo - dev->wlan.phy_base) |
+ 	      MTK_WFMDA_RX_DMA_EN;
+ 	wifi_w32(dev, dev->wlan.wpdma_rx_glo - dev->wlan.phy_base, val);
+ }
+ 
+ static void
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  mtk_wed_dma_disable(struct mtk_wed_device *dev)
  {
  	wed_clr(dev, MTK_WED_WPDMA_GLO_CFG,
@@@ -249,12 -508,27 +478,36 @@@
  		MTK_WED_GLO_CFG_TX_DMA_EN |
  		MTK_WED_GLO_CFG_RX_DMA_EN);
  
++<<<<<<< HEAD
 +	regmap_write(dev->hw->mirror, dev->hw->index * 4, 0);
 +	wdma_m32(dev, MTK_WDMA_GLO_CFG,
 +		 MTK_WDMA_GLO_CFG_TX_DMA_EN |
 +		 MTK_WDMA_GLO_CFG_RX_INFO1_PRERES |
 +		 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES |
 +		 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES, 0);
++=======
+ 	wdma_clr(dev, MTK_WDMA_GLO_CFG,
+ 		 MTK_WDMA_GLO_CFG_TX_DMA_EN |
+ 		 MTK_WDMA_GLO_CFG_RX_INFO1_PRERES |
+ 		 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES);
+ 
+ 	if (dev->hw->version == 1) {
+ 		regmap_write(dev->hw->mirror, dev->hw->index * 4, 0);
+ 		wdma_clr(dev, MTK_WDMA_GLO_CFG,
+ 			 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES);
+ 	} else {
+ 		wed_clr(dev, MTK_WED_WPDMA_GLO_CFG,
+ 			MTK_WED_WPDMA_GLO_CFG_RX_DRV_R0_PKT_PROC |
+ 			MTK_WED_WPDMA_GLO_CFG_RX_DRV_R0_CRX_SYNC);
+ 
+ 		wed_clr(dev, MTK_WED_WPDMA_RX_D_GLO_CFG,
+ 			MTK_WED_WPDMA_RX_D_RX_DRV_EN);
+ 		wed_clr(dev, MTK_WED_WDMA_GLO_CFG,
+ 			MTK_WED_WDMA_GLO_CFG_TX_DDONE_CHK);
+ 
+ 		mtk_wed_set_512_support(dev, false);
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  }
  
  static void
@@@ -289,13 -569,30 +549,28 @@@ mtk_wed_detach(struct mtk_wed_device *d
  	wdma_w32(dev, MTK_WDMA_RESET_IDX, 0);
  
  	mtk_wed_reset(dev, MTK_WED_RESET_WED);
+ 	if (mtk_wed_get_rx_capa(dev)) {
+ 		wdma_clr(dev, MTK_WDMA_GLO_CFG, MTK_WDMA_GLO_CFG_TX_DMA_EN);
+ 		wdma_w32(dev, MTK_WDMA_RESET_IDX, MTK_WDMA_RESET_IDX_TX);
+ 		wdma_w32(dev, MTK_WDMA_RESET_IDX, 0);
+ 	}
  
- 	mtk_wed_free_buffer(dev);
+ 	mtk_wed_free_tx_buffer(dev);
  	mtk_wed_free_tx_rings(dev);
++<<<<<<< HEAD
++=======
+ 
+ 	if (mtk_wed_get_rx_capa(dev)) {
+ 		mtk_wed_wo_reset(dev);
+ 		mtk_wed_free_rx_rings(dev);
+ 		mtk_wed_wo_deinit(hw);
+ 		mtk_wdma_rx_reset(dev);
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
 -	if (dev->wlan.bus_type == MTK_WED_BUS_PCIE) {
 -		struct device_node *wlan_node;
 -
 -		wlan_node = dev->wlan.pci_dev->dev.of_node;
 -		if (of_dma_is_coherent(wlan_node) && hw->hifsys)
 -			regmap_update_bits(hw->hifsys, HIFSYS_DMA_AG_MAP,
 -					   BIT(hw->index), BIT(hw->index));
 -	}
 +	if (of_dma_is_coherent(wlan_node))
 +		regmap_update_bits(hw->hifsys, HIFSYS_DMA_AG_MAP,
 +				   BIT(hw->index), BIT(hw->index));
  
  	if (!hw_list[!hw->index]->wed_dev &&
  	    hw->eth->dma_dev != hw->eth->dev)
@@@ -308,6 -605,70 +583,73 @@@
  	mutex_unlock(&hw_lock);
  }
  
++<<<<<<< HEAD
++=======
+ #define PCIE_BASE_ADDR0		0x11280000
+ static void
+ mtk_wed_bus_init(struct mtk_wed_device *dev)
+ {
+ 	switch (dev->wlan.bus_type) {
+ 	case MTK_WED_BUS_PCIE: {
+ 		struct device_node *np = dev->hw->eth->dev->of_node;
+ 		struct regmap *regs;
+ 
+ 		regs = syscon_regmap_lookup_by_phandle(np,
+ 						       "mediatek,wed-pcie");
+ 		if (IS_ERR(regs))
+ 			break;
+ 
+ 		regmap_update_bits(regs, 0, BIT(0), BIT(0));
+ 
+ 		wed_w32(dev, MTK_WED_PCIE_INT_CTRL,
+ 			FIELD_PREP(MTK_WED_PCIE_INT_CTRL_POLL_EN, 2));
+ 
+ 		/* pcie interrupt control: pola/source selection */
+ 		wed_set(dev, MTK_WED_PCIE_INT_CTRL,
+ 			MTK_WED_PCIE_INT_CTRL_MSK_EN_POLA |
+ 			FIELD_PREP(MTK_WED_PCIE_INT_CTRL_SRC_SEL, 1));
+ 		wed_r32(dev, MTK_WED_PCIE_INT_CTRL);
+ 
+ 		wed_w32(dev, MTK_WED_PCIE_CFG_INTM, PCIE_BASE_ADDR0 | 0x180);
+ 		wed_w32(dev, MTK_WED_PCIE_CFG_BASE, PCIE_BASE_ADDR0 | 0x184);
+ 
+ 		/* pcie interrupt status trigger register */
+ 		wed_w32(dev, MTK_WED_PCIE_INT_TRIGGER, BIT(24));
+ 		wed_r32(dev, MTK_WED_PCIE_INT_TRIGGER);
+ 
+ 		/* pola setting */
+ 		wed_set(dev, MTK_WED_PCIE_INT_CTRL,
+ 			MTK_WED_PCIE_INT_CTRL_MSK_EN_POLA);
+ 		break;
+ 	}
+ 	case MTK_WED_BUS_AXI:
+ 		wed_set(dev, MTK_WED_WPDMA_INT_CTRL,
+ 			MTK_WED_WPDMA_INT_CTRL_SIG_SRC |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_SRC_SEL, 0));
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ }
+ 
+ static void
+ mtk_wed_set_wpdma(struct mtk_wed_device *dev)
+ {
+ 	if (dev->hw->version == 1) {
+ 		wed_w32(dev, MTK_WED_WPDMA_CFG_BASE,  dev->wlan.wpdma_phys);
+ 	} else {
+ 		mtk_wed_bus_init(dev);
+ 
+ 		wed_w32(dev, MTK_WED_WPDMA_CFG_BASE, dev->wlan.wpdma_int);
+ 		wed_w32(dev, MTK_WED_WPDMA_CFG_INT_MASK, dev->wlan.wpdma_mask);
+ 		wed_w32(dev, MTK_WED_WPDMA_CFG_TX, dev->wlan.wpdma_tx);
+ 		wed_w32(dev, MTK_WED_WPDMA_CFG_TX_FREE, dev->wlan.wpdma_txfree);
+ 		wed_w32(dev, MTK_WED_WPDMA_RX_GLO_CFG, dev->wlan.wpdma_rx_glo);
+ 		wed_w32(dev, MTK_WED_WPDMA_RX_RING, dev->wlan.wpdma_rx);
+ 	}
+ }
+ 
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  static void
  mtk_wed_hw_init_early(struct mtk_wed_device *dev)
  {
@@@ -325,19 -686,161 +667,145 @@@
  	      MTK_WED_WDMA_GLO_CFG_IDLE_DMAD_SUPPLY;
  	wed_m32(dev, MTK_WED_WDMA_GLO_CFG, mask, set);
  
 -	if (dev->hw->version == 1) {
 -		u32 offset = dev->hw->index ? 0x04000400 : 0;
 +	wdma_set(dev, MTK_WDMA_GLO_CFG,
 +		 MTK_WDMA_GLO_CFG_RX_INFO1_PRERES |
 +		 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES |
 +		 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES);
  
 -		wdma_set(dev, MTK_WDMA_GLO_CFG,
 -			 MTK_WDMA_GLO_CFG_RX_INFO1_PRERES |
 -			 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES |
 -			 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES);
 +	offset = dev->hw->index ? 0x04000400 : 0;
 +	wed_w32(dev, MTK_WED_WDMA_OFFSET0, 0x2a042a20 + offset);
 +	wed_w32(dev, MTK_WED_WDMA_OFFSET1, 0x29002800 + offset);
  
 -		wed_w32(dev, MTK_WED_WDMA_OFFSET0, 0x2a042a20 + offset);
 -		wed_w32(dev, MTK_WED_WDMA_OFFSET1, 0x29002800 + offset);
 -		wed_w32(dev, MTK_WED_PCIE_CFG_BASE,
 -			MTK_PCIE_BASE(dev->hw->index));
 -	} else {
 -		wed_w32(dev, MTK_WED_WDMA_CFG_BASE, dev->hw->wdma_phy);
 -		wed_set(dev, MTK_WED_CTRL, MTK_WED_CTRL_ETH_DMAD_FMT);
 -		wed_w32(dev, MTK_WED_WDMA_OFFSET0,
 -			FIELD_PREP(MTK_WED_WDMA_OFST0_GLO_INTS,
 -				   MTK_WDMA_INT_STATUS) |
 -			FIELD_PREP(MTK_WED_WDMA_OFST0_GLO_CFG,
 -				   MTK_WDMA_GLO_CFG));
 -
 -		wed_w32(dev, MTK_WED_WDMA_OFFSET1,
 -			FIELD_PREP(MTK_WED_WDMA_OFST1_TX_CTRL,
 -				   MTK_WDMA_RING_TX(0)) |
 -			FIELD_PREP(MTK_WED_WDMA_OFST1_RX_CTRL,
 -				   MTK_WDMA_RING_RX(0)));
 -	}
 +	wed_w32(dev, MTK_WED_PCIE_CFG_BASE, MTK_PCIE_BASE(dev->hw->index));
 +	wed_w32(dev, MTK_WED_WPDMA_CFG_BASE, dev->wlan.wpdma_phys);
  }
  
+ static int
+ mtk_wed_rro_ring_alloc(struct mtk_wed_device *dev, struct mtk_wed_ring *ring,
+ 		       int size)
+ {
+ 	ring->desc = dma_alloc_coherent(dev->hw->dev,
+ 					size * sizeof(*ring->desc),
+ 					&ring->desc_phys, GFP_KERNEL);
+ 	if (!ring->desc)
+ 		return -ENOMEM;
+ 
+ 	ring->desc_size = sizeof(*ring->desc);
+ 	ring->size = size;
+ 	memset(ring->desc, 0, size);
+ 
+ 	return 0;
+ }
+ 
+ #define MTK_WED_MIOD_COUNT	(MTK_WED_MIOD_ENTRY_CNT * MTK_WED_MIOD_CNT)
+ static int
+ mtk_wed_rro_alloc(struct mtk_wed_device *dev)
+ {
+ 	struct reserved_mem *rmem;
+ 	struct device_node *np;
+ 	int index;
+ 
+ 	index = of_property_match_string(dev->hw->node, "memory-region-names",
+ 					 "wo-dlm");
+ 	if (index < 0)
+ 		return index;
+ 
+ 	np = of_parse_phandle(dev->hw->node, "memory-region", index);
+ 	if (!np)
+ 		return -ENODEV;
+ 
+ 	rmem = of_reserved_mem_lookup(np);
+ 	of_node_put(np);
+ 
+ 	if (!rmem)
+ 		return -ENODEV;
+ 
+ 	dev->rro.miod_phys = rmem->base;
+ 	dev->rro.fdbk_phys = MTK_WED_MIOD_COUNT + dev->rro.miod_phys;
+ 
+ 	return mtk_wed_rro_ring_alloc(dev, &dev->rro.ring,
+ 				      MTK_WED_RRO_QUE_CNT);
+ }
+ 
+ static int
+ mtk_wed_rro_cfg(struct mtk_wed_device *dev)
+ {
+ 	struct mtk_wed_wo *wo = dev->hw->wed_wo;
+ 	struct {
+ 		struct {
+ 			__le32 base;
+ 			__le32 cnt;
+ 			__le32 unit;
+ 		} ring[2];
+ 		__le32 wed;
+ 		u8 version;
+ 	} req = {
+ 		.ring[0] = {
+ 			.base = cpu_to_le32(MTK_WED_WOCPU_VIEW_MIOD_BASE),
+ 			.cnt = cpu_to_le32(MTK_WED_MIOD_CNT),
+ 			.unit = cpu_to_le32(MTK_WED_MIOD_ENTRY_CNT),
+ 		},
+ 		.ring[1] = {
+ 			.base = cpu_to_le32(MTK_WED_WOCPU_VIEW_MIOD_BASE +
+ 					    MTK_WED_MIOD_COUNT),
+ 			.cnt = cpu_to_le32(MTK_WED_FB_CMD_CNT),
+ 			.unit = cpu_to_le32(4),
+ 		},
+ 	};
+ 
+ 	return mtk_wed_mcu_send_msg(wo, MTK_WED_MODULE_ID_WO,
+ 				    MTK_WED_WO_CMD_WED_CFG,
+ 				    &req, sizeof(req), true);
+ }
+ 
+ static void
+ mtk_wed_rro_hw_init(struct mtk_wed_device *dev)
+ {
+ 	wed_w32(dev, MTK_WED_RROQM_MIOD_CFG,
+ 		FIELD_PREP(MTK_WED_RROQM_MIOD_MID_DW, 0x70 >> 2) |
+ 		FIELD_PREP(MTK_WED_RROQM_MIOD_MOD_DW, 0x10 >> 2) |
+ 		FIELD_PREP(MTK_WED_RROQM_MIOD_ENTRY_DW,
+ 			   MTK_WED_MIOD_ENTRY_CNT >> 2));
+ 
+ 	wed_w32(dev, MTK_WED_RROQM_MIOD_CTRL0, dev->rro.miod_phys);
+ 	wed_w32(dev, MTK_WED_RROQM_MIOD_CTRL1,
+ 		FIELD_PREP(MTK_WED_RROQM_MIOD_CNT, MTK_WED_MIOD_CNT));
+ 	wed_w32(dev, MTK_WED_RROQM_FDBK_CTRL0, dev->rro.fdbk_phys);
+ 	wed_w32(dev, MTK_WED_RROQM_FDBK_CTRL1,
+ 		FIELD_PREP(MTK_WED_RROQM_FDBK_CNT, MTK_WED_FB_CMD_CNT));
+ 	wed_w32(dev, MTK_WED_RROQM_FDBK_CTRL2, 0);
+ 	wed_w32(dev, MTK_WED_RROQ_BASE_L, dev->rro.ring.desc_phys);
+ 
+ 	wed_set(dev, MTK_WED_RROQM_RST_IDX,
+ 		MTK_WED_RROQM_RST_IDX_MIOD |
+ 		MTK_WED_RROQM_RST_IDX_FDBK);
+ 
+ 	wed_w32(dev, MTK_WED_RROQM_RST_IDX, 0);
+ 	wed_w32(dev, MTK_WED_RROQM_MIOD_CTRL2, MTK_WED_MIOD_CNT - 1);
+ 	wed_set(dev, MTK_WED_CTRL, MTK_WED_CTRL_RX_RRO_QM_EN);
+ }
+ 
+ static void
+ mtk_wed_route_qm_hw_init(struct mtk_wed_device *dev)
+ {
+ 	wed_w32(dev, MTK_WED_RESET, MTK_WED_RESET_RX_ROUTE_QM);
+ 
+ 	for (;;) {
+ 		usleep_range(100, 200);
+ 		if (!(wed_r32(dev, MTK_WED_RESET) & MTK_WED_RESET_RX_ROUTE_QM))
+ 			break;
+ 	}
+ 
+ 	/* configure RX_ROUTE_QM */
+ 	wed_clr(dev, MTK_WED_RTQM_GLO_CFG, MTK_WED_RTQM_Q_RST);
+ 	wed_clr(dev, MTK_WED_RTQM_GLO_CFG, MTK_WED_RTQM_TXDMAD_FPORT);
+ 	wed_set(dev, MTK_WED_RTQM_GLO_CFG,
+ 		FIELD_PREP(MTK_WED_RTQM_TXDMAD_FPORT, 0x3 + dev->hw->index));
+ 	wed_clr(dev, MTK_WED_RTQM_GLO_CFG, MTK_WED_RTQM_Q_RST);
+ 	/* enable RX_ROUTE_QM */
+ 	wed_set(dev, MTK_WED_CTRL, MTK_WED_CTRL_RX_ROUTE_QM_EN);
+ }
+ 
  static void
  mtk_wed_hw_init(struct mtk_wed_device *dev)
  {
@@@ -353,39 -856,80 +821,108 @@@
  		FIELD_PREP(MTK_WED_TX_BM_CTRL_RSV_GRP_NUM,
  			   MTK_WED_TX_RING_SIZE / 256));
  
- 	wed_w32(dev, MTK_WED_TX_BM_BASE, dev->buf_ring.desc_phys);
+ 	wed_w32(dev, MTK_WED_TX_BM_BASE, dev->tx_buf_ring.desc_phys);
  
 +	wed_w32(dev, MTK_WED_TX_BM_TKID,
 +		FIELD_PREP(MTK_WED_TX_BM_TKID_START,
 +			   dev->wlan.token_start) |
 +		FIELD_PREP(MTK_WED_TX_BM_TKID_END,
 +			   dev->wlan.token_start + dev->wlan.nbuf - 1));
 +
  	wed_w32(dev, MTK_WED_TX_BM_BUF_LEN, MTK_WED_PKT_SIZE);
  
++<<<<<<< HEAD
 +	wed_w32(dev, MTK_WED_TX_BM_DYN_THR,
 +		FIELD_PREP(MTK_WED_TX_BM_DYN_THR_LO, 1) |
 +		MTK_WED_TX_BM_DYN_THR_HI);
 +
 +	mtk_wed_reset(dev, MTK_WED_RESET_TX_BM);
 +
 +	wed_set(dev, MTK_WED_CTRL,
 +		MTK_WED_CTRL_WED_TX_BM_EN |
 +		MTK_WED_CTRL_WED_TX_FREE_AGENT_EN);
++=======
+ 	if (dev->hw->version == 1) {
+ 		wed_w32(dev, MTK_WED_TX_BM_TKID,
+ 			FIELD_PREP(MTK_WED_TX_BM_TKID_START,
+ 				   dev->wlan.token_start) |
+ 			FIELD_PREP(MTK_WED_TX_BM_TKID_END,
+ 				   dev->wlan.token_start +
+ 				   dev->wlan.nbuf - 1));
+ 		wed_w32(dev, MTK_WED_TX_BM_DYN_THR,
+ 			FIELD_PREP(MTK_WED_TX_BM_DYN_THR_LO, 1) |
+ 			MTK_WED_TX_BM_DYN_THR_HI);
+ 	} else {
+ 		wed_w32(dev, MTK_WED_TX_BM_TKID_V2,
+ 			FIELD_PREP(MTK_WED_TX_BM_TKID_START,
+ 				   dev->wlan.token_start) |
+ 			FIELD_PREP(MTK_WED_TX_BM_TKID_END,
+ 				   dev->wlan.token_start +
+ 				   dev->wlan.nbuf - 1));
+ 		wed_w32(dev, MTK_WED_TX_BM_DYN_THR,
+ 			FIELD_PREP(MTK_WED_TX_BM_DYN_THR_LO_V2, 0) |
+ 			MTK_WED_TX_BM_DYN_THR_HI_V2);
+ 		wed_w32(dev, MTK_WED_TX_TKID_CTRL,
+ 			MTK_WED_TX_TKID_CTRL_PAUSE |
+ 			FIELD_PREP(MTK_WED_TX_TKID_CTRL_VLD_GRP_NUM,
+ 				   dev->tx_buf_ring.size / 128) |
+ 			FIELD_PREP(MTK_WED_TX_TKID_CTRL_RSV_GRP_NUM,
+ 				   dev->tx_buf_ring.size / 128));
+ 		wed_w32(dev, MTK_WED_TX_TKID_DYN_THR,
+ 			FIELD_PREP(MTK_WED_TX_TKID_DYN_THR_LO, 0) |
+ 			MTK_WED_TX_TKID_DYN_THR_HI);
+ 	}
+ 
+ 	mtk_wed_reset(dev, MTK_WED_RESET_TX_BM);
+ 
+ 	if (dev->hw->version == 1) {
+ 		wed_set(dev, MTK_WED_CTRL,
+ 			MTK_WED_CTRL_WED_TX_BM_EN |
+ 			MTK_WED_CTRL_WED_TX_FREE_AGENT_EN);
+ 	} else {
+ 		wed_clr(dev, MTK_WED_TX_TKID_CTRL, MTK_WED_TX_TKID_CTRL_PAUSE);
+ 		/* rx hw init */
+ 		wed_w32(dev, MTK_WED_WPDMA_RX_D_RST_IDX,
+ 			MTK_WED_WPDMA_RX_D_RST_CRX_IDX |
+ 			MTK_WED_WPDMA_RX_D_RST_DRV_IDX);
+ 		wed_w32(dev, MTK_WED_WPDMA_RX_D_RST_IDX, 0);
+ 
+ 		mtk_wed_rx_buffer_hw_init(dev);
+ 		mtk_wed_rro_hw_init(dev);
+ 		mtk_wed_route_qm_hw_init(dev);
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  	wed_clr(dev, MTK_WED_TX_BM_CTRL, MTK_WED_TX_BM_CTRL_PAUSE);
  }
  
  static void
++<<<<<<< HEAD
 +mtk_wed_ring_reset(struct mtk_wdma_desc *desc, int size)
++=======
+ mtk_wed_ring_reset(struct mtk_wed_ring *ring, int size, bool tx)
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  {
 -	void *head = (void *)ring->desc;
  	int i;
  
  	for (i = 0; i < size; i++) {
++<<<<<<< HEAD
 +		desc[i].buf0 = 0;
 +		desc[i].ctrl = cpu_to_le32(MTK_WDMA_DESC_CTRL_DMA_DONE);
 +		desc[i].buf1 = 0;
 +		desc[i].info = 0;
++=======
+ 		struct mtk_wdma_desc *desc;
+ 
+ 		desc = (struct mtk_wdma_desc *)(head + i * ring->desc_size);
+ 		desc->buf0 = 0;
+ 		if (tx)
+ 			desc->ctrl = cpu_to_le32(MTK_WDMA_DESC_CTRL_DMA_DONE);
+ 		else
+ 			desc->ctrl = cpu_to_le32(MTK_WFDMA_DESC_CTRL_TO_HOST);
+ 		desc->buf1 = 0;
+ 		desc->info = 0;
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  	}
  }
  
@@@ -436,12 -980,11 +973,17 @@@ mtk_wed_reset_dma(struct mtk_wed_devic
  	int i;
  
  	for (i = 0; i < ARRAY_SIZE(dev->tx_ring); i++) {
 -		if (!dev->tx_ring[i].desc)
 +		struct mtk_wdma_desc *desc = dev->tx_ring[i].desc;
 +
 +		if (!desc)
  			continue;
  
++<<<<<<< HEAD
 +		mtk_wed_ring_reset(desc, MTK_WED_TX_RING_SIZE);
++=======
+ 		mtk_wed_ring_reset(&dev->tx_ring[i], MTK_WED_TX_RING_SIZE,
+ 				   true);
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  	}
  
  	if (mtk_wed_poll_busy(dev))
@@@ -498,26 -1043,32 +1042,46 @@@
  
  static int
  mtk_wed_ring_alloc(struct mtk_wed_device *dev, struct mtk_wed_ring *ring,
++<<<<<<< HEAD
 +		   int size)
++=======
+ 		   int size, u32 desc_size, bool tx)
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  {
 -	ring->desc = dma_alloc_coherent(dev->hw->dev, size * desc_size,
 +	ring->desc = dma_alloc_coherent(dev->hw->dev,
 +					size * sizeof(*ring->desc),
  					&ring->desc_phys, GFP_KERNEL);
  	if (!ring->desc)
  		return -ENOMEM;
  
 -	ring->desc_size = desc_size;
  	ring->size = size;
++<<<<<<< HEAD
 +	mtk_wed_ring_reset(ring->desc, size);
++=======
+ 	mtk_wed_ring_reset(ring, size, tx);
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  	return 0;
  }
  
  static int
 -mtk_wed_wdma_rx_ring_setup(struct mtk_wed_device *dev, int idx, int size)
 +mtk_wed_wdma_ring_setup(struct mtk_wed_device *dev, int idx, int size)
  {
++<<<<<<< HEAD
 +	struct mtk_wed_ring *wdma = &dev->tx_wdma[idx];
 +
 +	if (mtk_wed_ring_alloc(dev, wdma, MTK_WED_WDMA_RING_SIZE))
++=======
+ 	u32 desc_size = sizeof(struct mtk_wdma_desc) * dev->hw->version;
+ 	struct mtk_wed_ring *wdma;
+ 
+ 	if (idx >= ARRAY_SIZE(dev->rx_wdma))
+ 		return -EINVAL;
+ 
+ 	wdma = &dev->rx_wdma[idx];
+ 	if (mtk_wed_ring_alloc(dev, wdma, MTK_WED_WDMA_RING_SIZE, desc_size,
+ 			       true))
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  		return -ENOMEM;
  
  	wdma_w32(dev, MTK_WDMA_RING_RX(idx) + MTK_WED_RING_OFS_BASE,
@@@ -546,16 -1151,53 +1164,60 @@@ mtk_wed_configure_irq(struct mtk_wed_de
  		MTK_WED_CTRL_WED_TX_BM_EN |
  		MTK_WED_CTRL_WED_TX_FREE_AGENT_EN);
  
 -	if (dev->hw->version == 1) {
 -		wed_w32(dev, MTK_WED_PCIE_INT_TRIGGER,
 -			MTK_WED_PCIE_INT_TRIGGER_STATUS);
 +	wed_w32(dev, MTK_WED_PCIE_INT_TRIGGER,
 +		MTK_WED_PCIE_INT_TRIGGER_STATUS);
  
++<<<<<<< HEAD
 +	wed_w32(dev, MTK_WED_WPDMA_INT_TRIGGER,
 +		MTK_WED_WPDMA_INT_TRIGGER_RX_DONE |
 +		MTK_WED_WPDMA_INT_TRIGGER_TX_DONE);
++=======
+ 		wed_w32(dev, MTK_WED_WPDMA_INT_TRIGGER,
+ 			MTK_WED_WPDMA_INT_TRIGGER_RX_DONE |
+ 			MTK_WED_WPDMA_INT_TRIGGER_TX_DONE);
+ 
+ 		wed_clr(dev, MTK_WED_WDMA_INT_CTRL, wdma_mask);
+ 	} else {
+ 		wdma_mask |= FIELD_PREP(MTK_WDMA_INT_MASK_TX_DONE,
+ 					GENMASK(1, 0));
+ 		/* initail tx interrupt trigger */
+ 		wed_w32(dev, MTK_WED_WPDMA_INT_CTRL_TX,
+ 			MTK_WED_WPDMA_INT_CTRL_TX0_DONE_EN |
+ 			MTK_WED_WPDMA_INT_CTRL_TX0_DONE_CLR |
+ 			MTK_WED_WPDMA_INT_CTRL_TX1_DONE_EN |
+ 			MTK_WED_WPDMA_INT_CTRL_TX1_DONE_CLR |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_TX0_DONE_TRIG,
+ 				   dev->wlan.tx_tbit[0]) |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_TX1_DONE_TRIG,
+ 				   dev->wlan.tx_tbit[1]));
+ 
+ 		/* initail txfree interrupt trigger */
+ 		wed_w32(dev, MTK_WED_WPDMA_INT_CTRL_TX_FREE,
+ 			MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_EN |
+ 			MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_CLR |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_TRIG,
+ 				   dev->wlan.txfree_tbit));
+ 
+ 		wed_w32(dev, MTK_WED_WPDMA_INT_CTRL_RX,
+ 			MTK_WED_WPDMA_INT_CTRL_RX0_EN |
+ 			MTK_WED_WPDMA_INT_CTRL_RX0_CLR |
+ 			MTK_WED_WPDMA_INT_CTRL_RX1_EN |
+ 			MTK_WED_WPDMA_INT_CTRL_RX1_CLR |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_RX0_DONE_TRIG,
+ 				   dev->wlan.rx_tbit[0]) |
+ 			FIELD_PREP(MTK_WED_WPDMA_INT_CTRL_RX1_DONE_TRIG,
+ 				   dev->wlan.rx_tbit[1]));
+ 
+ 		wed_w32(dev, MTK_WED_WDMA_INT_CLR, wdma_mask);
+ 		wed_set(dev, MTK_WED_WDMA_INT_CTRL,
+ 			FIELD_PREP(MTK_WED_WDMA_INT_CTRL_POLL_SRC_SEL,
+ 				   dev->wdma_idx));
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
 +	/* initail wdma interrupt agent */
  	wed_w32(dev, MTK_WED_WDMA_INT_TRIGGER, wdma_mask);
 +	wed_clr(dev, MTK_WED_WDMA_INT_CTRL, wdma_mask);
  
  	wdma_w32(dev, MTK_WDMA_INT_MASK, wdma_mask);
  	wdma_w32(dev, MTK_WDMA_INT_GRP2, wdma_mask);
@@@ -580,8 -1222,38 +1242,43 @@@ mtk_wed_dma_enable(struct mtk_wed_devic
  	wdma_set(dev, MTK_WDMA_GLO_CFG,
  		 MTK_WDMA_GLO_CFG_TX_DMA_EN |
  		 MTK_WDMA_GLO_CFG_RX_INFO1_PRERES |
++<<<<<<< HEAD
 +		 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES |
 +		 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES);
++=======
+ 		 MTK_WDMA_GLO_CFG_RX_INFO2_PRERES);
+ 
+ 	if (dev->hw->version == 1) {
+ 		wdma_set(dev, MTK_WDMA_GLO_CFG,
+ 			 MTK_WDMA_GLO_CFG_RX_INFO3_PRERES);
+ 	} else {
+ 		int i;
+ 
+ 		wed_set(dev, MTK_WED_WPDMA_CTRL,
+ 			MTK_WED_WPDMA_CTRL_SDL1_FIXED);
+ 
+ 		wed_set(dev, MTK_WED_WDMA_GLO_CFG,
+ 			MTK_WED_WDMA_GLO_CFG_TX_DRV_EN |
+ 			MTK_WED_WDMA_GLO_CFG_TX_DDONE_CHK);
+ 
+ 		wed_set(dev, MTK_WED_WPDMA_GLO_CFG,
+ 			MTK_WED_WPDMA_GLO_CFG_RX_DRV_R0_PKT_PROC |
+ 			MTK_WED_WPDMA_GLO_CFG_RX_DRV_R0_CRX_SYNC);
+ 
+ 		wed_clr(dev, MTK_WED_WPDMA_GLO_CFG,
+ 			MTK_WED_WPDMA_GLO_CFG_TX_TKID_KEEP |
+ 			MTK_WED_WPDMA_GLO_CFG_TX_DMAD_DW3_PREV);
+ 
+ 		wed_set(dev, MTK_WED_WPDMA_RX_D_GLO_CFG,
+ 			MTK_WED_WPDMA_RX_D_RX_DRV_EN |
+ 			FIELD_PREP(MTK_WED_WPDMA_RX_D_RXD_READ_LEN, 0x18) |
+ 			FIELD_PREP(MTK_WED_WPDMA_RX_D_INIT_PHASE_RXEN_SEL,
+ 				   0x2));
+ 
+ 		for (i = 0; i < MTK_WED_RX_QUEUES; i++)
+ 			mtk_wed_check_wfdma_rx_fill(dev, i);
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  }
  
  static void
@@@ -598,14 -1269,29 +1295,39 @@@ mtk_wed_start(struct mtk_wed_device *de
  	mtk_wed_configure_irq(dev, irq_mask);
  
  	mtk_wed_set_ext_int(dev, true);
 -
 +	val = dev->wlan.wpdma_phys |
 +	      MTK_PCIE_MIRROR_MAP_EN |
 +	      FIELD_PREP(MTK_PCIE_MIRROR_MAP_WED_ID, dev->hw->index);
 +
++<<<<<<< HEAD
 +	if (dev->hw->index)
 +		val |= BIT(1);
 +	val |= BIT(0);
 +	regmap_write(dev->hw->mirror, dev->hw->index * 4, val);
++=======
+ 	if (dev->hw->version == 1) {
+ 		u32 val = dev->wlan.wpdma_phys | MTK_PCIE_MIRROR_MAP_EN |
+ 			  FIELD_PREP(MTK_PCIE_MIRROR_MAP_WED_ID,
+ 				     dev->hw->index);
+ 
+ 		val |= BIT(0) | (BIT(1) * !!dev->hw->index);
+ 		regmap_write(dev->hw->mirror, dev->hw->index * 4, val);
+ 	} else {
+ 		/* driver set mid ready and only once */
+ 		wed_w32(dev, MTK_WED_EXT_INT_MASK1,
+ 			MTK_WED_EXT_INT_STATUS_WPDMA_MID_RDY);
+ 		wed_w32(dev, MTK_WED_EXT_INT_MASK2,
+ 			MTK_WED_EXT_INT_STATUS_WPDMA_MID_RDY);
+ 
+ 		wed_r32(dev, MTK_WED_EXT_INT_MASK1);
+ 		wed_r32(dev, MTK_WED_EXT_INT_MASK2);
+ 
+ 		if (mtk_wed_rro_cfg(dev))
+ 			return;
+ 
+ 		mtk_wed_set_512_support(dev, dev->wlan.wcid_512);
+ 	}
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  	mtk_wed_dma_enable(dev);
  	dev->running = true;
@@@ -636,10 -1324,14 +1358,10 @@@ mtk_wed_attach(struct mtk_wed_device *d
  	if (!hw) {
  		module_put(THIS_MODULE);
  		ret = -ENODEV;
- 		goto out;
+ 		goto unlock;
  	}
  
 -	device = dev->wlan.bus_type == MTK_WED_BUS_PCIE
 -		? &dev->wlan.pci_dev->dev
 -		: &dev->wlan.platform_dev->dev;
 -	dev_info(device, "attaching wed device %d version %d\n",
 -		 hw->index, hw->version);
 +	dev_info(&dev->wlan.pci_dev->dev, "attaching wed device %d\n", hw->index);
  
  	dev->hw = hw;
  	dev->dev = hw->dev;
@@@ -657,9 -1358,15 +1388,20 @@@
  	}
  
  	mtk_wed_hw_init_early(dev);
++<<<<<<< HEAD
 +	regmap_update_bits(hw->hifsys, HIFSYS_DMA_AG_MAP, BIT(hw->index), 0);
 +
++=======
+ 	if (hw->version == 1)
+ 		regmap_update_bits(hw->hifsys, HIFSYS_DMA_AG_MAP,
+ 				   BIT(hw->index), 0);
+ 	else
+ 		ret = mtk_wed_wo_init(hw);
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  out:
+ 	if (ret)
+ 		mtk_wed_detach(dev);
+ unlock:
  	mutex_unlock(&hw_lock);
  
  	return ret;
@@@ -682,12 -1389,14 +1424,18 @@@ mtk_wed_tx_ring_setup(struct mtk_wed_de
  	 * WDMA RX.
  	 */
  
- 	BUG_ON(idx >= ARRAY_SIZE(dev->tx_ring));
+ 	if (WARN_ON(idx >= ARRAY_SIZE(dev->tx_ring)))
+ 		return -EINVAL;
  
++<<<<<<< HEAD
 +	if (mtk_wed_ring_alloc(dev, ring, MTK_WED_TX_RING_SIZE))
++=======
+ 	if (mtk_wed_ring_alloc(dev, ring, MTK_WED_TX_RING_SIZE,
+ 			       sizeof(*ring->desc), true))
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  		return -ENOMEM;
  
 -	if (mtk_wed_wdma_rx_ring_setup(dev, idx, MTK_WED_WDMA_RING_SIZE))
 +	if (mtk_wed_wdma_ring_setup(dev, idx, MTK_WED_WDMA_RING_SIZE))
  		return -ENOMEM;
  
  	ring->reg_base = MTK_WED_RING_TX(idx);
diff --cc drivers/net/ethernet/mediatek/mtk_wed_regs.h
index eec22daebd30,9e39dace95eb..000000000000
--- a/drivers/net/ethernet/mediatek/mtk_wed_regs.h
+++ b/drivers/net/ethernet/mediatek/mtk_wed_regs.h
@@@ -4,7 -4,9 +4,8 @@@
  #ifndef __MTK_WED_REGS_H
  #define __MTK_WED_REGS_H
  
+ #define MTK_WFDMA_DESC_CTRL_TO_HOST		BIT(8)
  #define MTK_WDMA_DESC_CTRL_LEN1			GENMASK(14, 0)
 -#define MTK_WDMA_DESC_CTRL_LEN1_V2		GENMASK(13, 0)
  #define MTK_WDMA_DESC_CTRL_LAST_SEG1		BIT(15)
  #define MTK_WDMA_DESC_CTRL_BURST		BIT(16)
  #define MTK_WDMA_DESC_CTRL_LEN0			GENMASK(29, 16)
@@@ -38,9 -42,14 +41,13 @@@ struct mtk_wdma_desc 
  #define MTK_WED_CTRL_WED_TX_BM_BUSY			BIT(9)
  #define MTK_WED_CTRL_WED_TX_FREE_AGENT_EN		BIT(10)
  #define MTK_WED_CTRL_WED_TX_FREE_AGENT_BUSY		BIT(11)
- #define MTK_WED_CTRL_RESERVE_EN				BIT(12)
- #define MTK_WED_CTRL_RESERVE_BUSY			BIT(13)
+ #define MTK_WED_CTRL_WED_RX_BM_EN			BIT(12)
+ #define MTK_WED_CTRL_WED_RX_BM_BUSY			BIT(13)
+ #define MTK_WED_CTRL_RX_RRO_QM_EN			BIT(14)
+ #define MTK_WED_CTRL_RX_RRO_QM_BUSY			BIT(15)
+ #define MTK_WED_CTRL_RX_ROUTE_QM_EN			BIT(16)
+ #define MTK_WED_CTRL_RX_ROUTE_QM_BUSY			BIT(17)
  #define MTK_WED_CTRL_FINAL_DIDX_READ			BIT(24)
 -#define MTK_WED_CTRL_ETH_DMAD_FMT			BIT(25)
  #define MTK_WED_CTRL_MIB_READ_CLEAR			BIT(28)
  
  #define MTK_WED_EXT_INT_STATUS				0x020
@@@ -57,18 -66,23 +64,23 @@@
  #define MTK_WED_EXT_INT_STATUS_RX_DRV_INIT_WDMA_EN	BIT(19)
  #define MTK_WED_EXT_INT_STATUS_RX_DRV_BM_DMAD_COHERENT	BIT(20)
  #define MTK_WED_EXT_INT_STATUS_TX_DRV_R_RESP_ERR	BIT(21)
 -#define MTK_WED_EXT_INT_STATUS_TX_DMA_R_RESP_ERR	BIT(22)
 -#define MTK_WED_EXT_INT_STATUS_TX_DMA_W_RESP_ERR	BIT(23)
 +#define MTK_WED_EXT_INT_STATUS_TX_DRV_W_RESP_ERR	BIT(22)
  #define MTK_WED_EXT_INT_STATUS_RX_DRV_DMA_RECYCLE	BIT(24)
+ #define MTK_WED_EXT_INT_STATUS_RX_DRV_GET_BM_DMAD_SKIP	BIT(25)
+ #define MTK_WED_EXT_INT_STATUS_WPDMA_RX_D_DRV_ERR	BIT(26)
+ #define MTK_WED_EXT_INT_STATUS_WPDMA_MID_RDY		BIT(27)
  #define MTK_WED_EXT_INT_STATUS_ERROR_MASK		(MTK_WED_EXT_INT_STATUS_TF_LEN_ERR | \
  							 MTK_WED_EXT_INT_STATUS_TKID_WO_PYLD | \
  							 MTK_WED_EXT_INT_STATUS_TKID_TITO_INVALID | \
  							 MTK_WED_EXT_INT_STATUS_RX_DRV_R_RESP_ERR | \
  							 MTK_WED_EXT_INT_STATUS_RX_DRV_W_RESP_ERR | \
  							 MTK_WED_EXT_INT_STATUS_RX_DRV_INIT_WDMA_EN | \
 -							 MTK_WED_EXT_INT_STATUS_TX_DMA_R_RESP_ERR)
 +							 MTK_WED_EXT_INT_STATUS_TX_DRV_R_RESP_ERR | \
 +							 MTK_WED_EXT_INT_STATUS_TX_DRV_W_RESP_ERR)
  
  #define MTK_WED_EXT_INT_MASK				0x028
+ #define MTK_WED_EXT_INT_MASK1				0x02c
+ #define MTK_WED_EXT_INT_MASK2				0x030
  
  #define MTK_WED_STATUS					0x060
  #define MTK_WED_STATUS_TX				GENMASK(15, 8)
@@@ -129,7 -163,9 +141,8 @@@
  #define MTK_WED_RING_TX(_n)				(0x300 + (_n) * 0x10)
  
  #define MTK_WED_RING_RX(_n)				(0x400 + (_n) * 0x10)
+ #define MTK_WED_RING_RX_DATA(_n)			(0x420 + (_n) * 0x10)
  
 -#define MTK_WED_SCR0					0x3c0
  #define MTK_WED_WPDMA_INT_TRIGGER			0x504
  #define MTK_WED_WPDMA_INT_TRIGGER_RX_DONE		BIT(1)
  #define MTK_WED_WPDMA_INT_TRIGGER_TX_DONE		GENMASK(5, 4)
@@@ -164,8 -215,34 +177,32 @@@
  
  #define MTK_WED_WPDMA_INT_MASK				0x524
  
++<<<<<<< HEAD
++=======
+ #define MTK_WED_WPDMA_INT_CTRL_TX			0x530
+ #define MTK_WED_WPDMA_INT_CTRL_TX0_DONE_EN		BIT(0)
+ #define MTK_WED_WPDMA_INT_CTRL_TX0_DONE_CLR		BIT(1)
+ #define MTK_WED_WPDMA_INT_CTRL_TX0_DONE_TRIG		GENMASK(6, 2)
+ #define MTK_WED_WPDMA_INT_CTRL_TX1_DONE_EN		BIT(8)
+ #define MTK_WED_WPDMA_INT_CTRL_TX1_DONE_CLR		BIT(9)
+ #define MTK_WED_WPDMA_INT_CTRL_TX1_DONE_TRIG		GENMASK(14, 10)
+ 
+ #define MTK_WED_WPDMA_INT_CTRL_RX			0x534
+ #define MTK_WED_WPDMA_INT_CTRL_RX0_EN			BIT(0)
+ #define MTK_WED_WPDMA_INT_CTRL_RX0_CLR			BIT(1)
+ #define MTK_WED_WPDMA_INT_CTRL_RX0_DONE_TRIG		GENMASK(6, 2)
+ #define MTK_WED_WPDMA_INT_CTRL_RX1_EN			BIT(8)
+ #define MTK_WED_WPDMA_INT_CTRL_RX1_CLR			BIT(9)
+ #define MTK_WED_WPDMA_INT_CTRL_RX1_DONE_TRIG		GENMASK(14, 10)
+ 
+ #define MTK_WED_WPDMA_INT_CTRL_TX_FREE			0x538
+ #define MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_EN		BIT(0)
+ #define MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_CLR		BIT(1)
+ #define MTK_WED_WPDMA_INT_CTRL_TX_FREE_DONE_TRIG	GENMASK(6, 2)
+ 
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  #define MTK_WED_PCIE_CFG_BASE				0x560
  
 -#define MTK_WED_PCIE_CFG_BASE				0x560
 -#define MTK_WED_PCIE_CFG_INTM				0x564
 -#define MTK_WED_PCIE_CFG_MSIS				0x568
  #define MTK_WED_PCIE_INT_TRIGGER			0x570
  #define MTK_WED_PCIE_INT_TRIGGER_STATUS			BIT(16)
  
diff --cc include/linux/soc/mediatek/mtk_wed.h
index 7e00cca06709,8294978f4bca..000000000000
--- a/include/linux/soc/mediatek/mtk_wed.h
+++ b/include/linux/soc/mediatek/mtk_wed.h
@@@ -5,16 -5,62 +5,63 @@@
  #include <linux/rcupdate.h>
  #include <linux/regmap.h>
  #include <linux/pci.h>
+ #include <linux/skbuff.h>
  
  #define MTK_WED_TX_QUEUES		2
 -#define MTK_WED_RX_QUEUES		2
  
+ #define WED_WO_STA_REC			0x6
+ 
  struct mtk_wed_hw;
  struct mtk_wdma_desc;
  
++<<<<<<< HEAD
++=======
+ enum mtk_wed_wo_cmd {
+ 	MTK_WED_WO_CMD_WED_CFG,
+ 	MTK_WED_WO_CMD_WED_RX_STAT,
+ 	MTK_WED_WO_CMD_RRO_SER,
+ 	MTK_WED_WO_CMD_DBG_INFO,
+ 	MTK_WED_WO_CMD_DEV_INFO,
+ 	MTK_WED_WO_CMD_BSS_INFO,
+ 	MTK_WED_WO_CMD_STA_REC,
+ 	MTK_WED_WO_CMD_DEV_INFO_DUMP,
+ 	MTK_WED_WO_CMD_BSS_INFO_DUMP,
+ 	MTK_WED_WO_CMD_STA_REC_DUMP,
+ 	MTK_WED_WO_CMD_BA_INFO_DUMP,
+ 	MTK_WED_WO_CMD_FBCMD_Q_DUMP,
+ 	MTK_WED_WO_CMD_FW_LOG_CTRL,
+ 	MTK_WED_WO_CMD_LOG_FLUSH,
+ 	MTK_WED_WO_CMD_CHANGE_STATE,
+ 	MTK_WED_WO_CMD_CPU_STATS_ENABLE,
+ 	MTK_WED_WO_CMD_CPU_STATS_DUMP,
+ 	MTK_WED_WO_CMD_EXCEPTION_INIT,
+ 	MTK_WED_WO_CMD_PROF_CTRL,
+ 	MTK_WED_WO_CMD_STA_BA_DUMP,
+ 	MTK_WED_WO_CMD_BA_CTRL_DUMP,
+ 	MTK_WED_WO_CMD_RXCNT_CTRL,
+ 	MTK_WED_WO_CMD_RXCNT_INFO,
+ 	MTK_WED_WO_CMD_SET_CAP,
+ 	MTK_WED_WO_CMD_CCIF_RING_DUMP,
+ 	MTK_WED_WO_CMD_WED_END
+ };
+ 
+ struct mtk_rxbm_desc {
+ 	__le32 buf0;
+ 	__le32 token;
+ } __packed __aligned(4);
+ 
+ enum mtk_wed_bus_tye {
+ 	MTK_WED_BUS_PCIE,
+ 	MTK_WED_BUS_AXI,
+ };
+ 
+ #define MTK_WED_RING_CONFIGURED		BIT(0)
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  struct mtk_wed_ring {
  	struct mtk_wdma_desc *desc;
  	dma_addr_t desc_phys;
 -	u32 desc_size;
  	int size;
+ 	u32 flags;
  
  	u32 reg_base;
  	void __iomem *wpdma;
@@@ -28,10 -83,13 +84,16 @@@ struct mtk_wed_device 
  	bool init_done, running;
  	int wdma_idx;
  	int irq;
+ 	u8 version;
  
  	struct mtk_wed_ring tx_ring[MTK_WED_TX_QUEUES];
+ 	struct mtk_wed_ring rx_ring[MTK_WED_RX_QUEUES];
  	struct mtk_wed_ring txfree_ring;
  	struct mtk_wed_ring tx_wdma[MTK_WED_TX_QUEUES];
++<<<<<<< HEAD
++=======
+ 	struct mtk_wed_ring rx_wdma[MTK_WED_RX_QUEUES];
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  	struct {
  		int size;
@@@ -42,13 -113,34 +117,43 @@@
  
  	/* filled by driver: */
  	struct {
++<<<<<<< HEAD
 +		struct pci_dev *pci_dev;
 +
 +		u32 wpdma_phys;
++=======
+ 		union {
+ 			struct platform_device *platform_dev;
+ 			struct pci_dev *pci_dev;
+ 		};
+ 		enum mtk_wed_bus_tye bus_type;
+ 		void __iomem *base;
+ 		u32 phy_base;
+ 
+ 		u32 wpdma_phys;
+ 		u32 wpdma_int;
+ 		u32 wpdma_mask;
+ 		u32 wpdma_tx;
+ 		u32 wpdma_txfree;
+ 		u32 wpdma_rx_glo;
+ 		u32 wpdma_rx;
+ 
+ 		bool wcid_512;
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  
  		u16 token_start;
  		unsigned int nbuf;
+ 		unsigned int rx_nbuf;
+ 		unsigned int rx_npkt;
+ 		unsigned int rx_size;
  
++<<<<<<< HEAD
++=======
+ 		u8 tx_tbit[MTK_WED_TX_QUEUES];
+ 		u8 rx_tbit[MTK_WED_RX_QUEUES];
+ 		u8 txfree_tbit;
+ 
++>>>>>>> 4c5de09eb0d0 (net: ethernet: mtk_wed: add configure wed wo support)
  		u32 (*init_buf)(void *ptr, dma_addr_t phys, int token_id);
  		int (*offload_enable)(struct mtk_wed_device *wed);
  		void (*offload_disable)(struct mtk_wed_device *wed);
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed_mcu.c
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed_wo.h
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed.c
diff --git a/drivers/net/ethernet/mediatek/mtk_wed.h b/drivers/net/ethernet/mediatek/mtk_wed.h
index 404c9a9b130d..e322b4d854dc 100644
--- a/drivers/net/ethernet/mediatek/mtk_wed.h
+++ b/drivers/net/ethernet/mediatek/mtk_wed.h
@@ -75,6 +75,24 @@ wpdma_tx_w32(struct mtk_wed_device *dev, int ring, u32 reg, u32 val)
 	writel(val, dev->tx_ring[ring].wpdma + reg);
 }
 
+static inline u32
+wpdma_rx_r32(struct mtk_wed_device *dev, int ring, u32 reg)
+{
+	if (!dev->rx_ring[ring].wpdma)
+		return 0;
+
+	return readl(dev->rx_ring[ring].wpdma + reg);
+}
+
+static inline void
+wpdma_rx_w32(struct mtk_wed_device *dev, int ring, u32 reg, u32 val)
+{
+	if (!dev->rx_ring[ring].wpdma)
+		return;
+
+	writel(val, dev->rx_ring[ring].wpdma + reg);
+}
+
 static inline u32
 wpdma_txfree_r32(struct mtk_wed_device *dev, u32 reg)
 {
@@ -115,6 +133,7 @@ static inline int mtk_wed_flow_add(int index)
 static inline void mtk_wed_flow_remove(int index)
 {
 }
+
 #endif
 
 #ifdef CONFIG_DEBUG_FS
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed_mcu.c
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed_regs.h
* Unmerged path drivers/net/ethernet/mediatek/mtk_wed_wo.h
* Unmerged path include/linux/soc/mediatek/mtk_wed.h
