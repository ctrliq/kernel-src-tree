netfilter: flowtable: fix TCP flow teardown

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.19.1.el8_6
commit-author Pablo Neira Ayuso <pablo@netfilter.org>
commit e5eaac2beb54f0a16ff851125082d9faeb475572
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.19.1.el8_6/e5eaac2b.failed

This patch addresses three possible problems:

1. ct gc may race to undo the timeout adjustment of the packet path, leaving
   the conntrack entry in place with the internal offload timeout (one day).

2. ct gc removes the ct because the IPS_OFFLOAD_BIT is not set and the CLOSE
   timeout is reached before the flow offload del.

3. tcp ct is always set to ESTABLISHED with a very long timeout
   in flow offload teardown/delete even though the state might be already
   CLOSED. Also as a remark we cannot assume that the FIN or RST packet
   is hitting flow table teardown as the packet might get bumped to the
   slow path in nftables.

This patch resets IPS_OFFLOAD_BIT from flow_offload_teardown(), so
conntrack handles the tcp rst/fin packet which triggers the CLOSE/FIN
state transition.

Moreover, teturn the connection's ownership to conntrack upon teardown
by clearing the offload flag and fixing the established timeout value.
The flow table GC thread will asynchonrnously free the flow table and
hardware offload entries.

Before this patch, the IPS_OFFLOAD_BIT remained set for expired flows on
which is also misleading since the flow is back to classic conntrack
path.

If nf_ct_delete() removes the entry from the conntrack table, then it
calls nf_ct_put() which decrements the refcnt. This is not a problem
because the flowtable holds a reference to the conntrack object from
flow_offload_alloc() path which is released via flow_offload_free().

This patch also updates nft_flow_offload to skip packets in SYN_RECV
state. Since we might miss or bump packets to slow path, we do not know
what will happen there while we are still in SYN_RECV, this patch
postpones offload up to the next packet which also aligns to the
existing behaviour in tc-ct.

flow_offload_teardown() does not reset the existing tcp state from
flow_offload_fixup_tcp() to ESTABLISHED anymore, packets bump to slow
path might have already update the state to CLOSE/FIN.

Joint work with Oz and Sven.

Fixes: 1e5b2471bcc4 ("netfilter: nf_flow_table: teardown flow timeout race")
	Signed-off-by: Oz Shlomo <ozsh@nvidia.com>
	Signed-off-by: Sven Auhagen <sven.auhagen@voleatech.de>
	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit e5eaac2beb54f0a16ff851125082d9faeb475572)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/netfilter/nf_flow_table_core.c
diff --cc net/netfilter/nf_flow_table_core.c
index 6a514ee73a5c,ebdf5332e838..000000000000
--- a/net/netfilter/nf_flow_table_core.c
+++ b/net/netfilter/nf_flow_table_core.c
@@@ -130,9 -183,8 +129,9 @@@ static void flow_offload_fixup_tcp(stru
  	tcp->seen[1].td_maxwin = 0;
  }
  
- static void flow_offload_fixup_ct_timeout(struct nf_conn *ct)
+ static void flow_offload_fixup_ct(struct nf_conn *ct)
  {
 +	const struct nf_conntrack_l4proto *l4proto;
  	struct net *net = nf_ct_net(ct);
  	int l4num = nf_ct_protonum(ct);
  	s32 timeout;
@@@ -144,8 -192,10 +143,15 @@@
  	if (l4num == IPPROTO_TCP) {
  		struct nf_tcp_net *tn = nf_tcp_pernet(net);
  
++<<<<<<< HEAD
 +		timeout = tn->timeouts[TCP_CONNTRACK_ESTABLISHED];
 +		timeout -= net->nf_tcp_net_offload_timeout;
++=======
+ 		flow_offload_fixup_tcp(&ct->proto.tcp);
+ 
+ 		timeout = tn->timeouts[ct->proto.tcp.state];
+ 		timeout -= tn->offload_timeout;
++>>>>>>> e5eaac2beb54 (netfilter: flowtable: fix TCP flow teardown)
  	} else if (l4num == IPPROTO_UDP) {
  		struct nf_udp_net *tn = nf_udp_pernet(net);
  
@@@ -162,22 -212,10 +168,10 @@@
  		WRITE_ONCE(ct->timeout, nfct_time_stamp + timeout);
  }
  
- static void flow_offload_fixup_ct_state(struct nf_conn *ct)
- {
- 	if (nf_ct_protonum(ct) == IPPROTO_TCP)
- 		flow_offload_fixup_tcp(&ct->proto.tcp);
- }
- 
- static void flow_offload_fixup_ct(struct nf_conn *ct)
- {
- 	flow_offload_fixup_ct_state(ct);
- 	flow_offload_fixup_ct_timeout(ct);
- }
- 
  static void flow_offload_route_release(struct flow_offload *flow)
  {
 -	nft_flow_dst_release(flow, FLOW_OFFLOAD_DIR_ORIGINAL);
 -	nft_flow_dst_release(flow, FLOW_OFFLOAD_DIR_REPLY);
 +	dst_release(flow->tuplehash[FLOW_OFFLOAD_DIR_ORIGINAL].tuple.dst_cache);
 +	dst_release(flow->tuplehash[FLOW_OFFLOAD_DIR_REPLY].tuple.dst_cache);
  }
  
  void flow_offload_free(struct flow_offload *flow)
@@@ -385,12 -421,33 +371,38 @@@ nf_flow_table_iterate(struct nf_flowtab
  	return err;
  }
  
 -static bool flow_offload_stale_dst(struct flow_offload_tuple *tuple)
 +static void nf_flow_offload_gc_step(struct flow_offload *flow, void *data)
  {
 -	struct dst_entry *dst;
 +	struct nf_flowtable *flow_table = data;
  
++<<<<<<< HEAD
 +	if (nf_flow_has_expired(flow) || nf_ct_is_dying(flow->ct))
 +		set_bit(NF_FLOW_TEARDOWN, &flow->flags);
++=======
+ 	if (tuple->xmit_type == FLOW_OFFLOAD_XMIT_NEIGH ||
+ 	    tuple->xmit_type == FLOW_OFFLOAD_XMIT_XFRM) {
+ 		dst = tuple->dst_cache;
+ 		if (!dst_check(dst, tuple->dst_cookie))
+ 			return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static bool nf_flow_has_stale_dst(struct flow_offload *flow)
+ {
+ 	return flow_offload_stale_dst(&flow->tuplehash[FLOW_OFFLOAD_DIR_ORIGINAL].tuple) ||
+ 	       flow_offload_stale_dst(&flow->tuplehash[FLOW_OFFLOAD_DIR_REPLY].tuple);
+ }
+ 
+ static void nf_flow_offload_gc_step(struct nf_flowtable *flow_table,
+ 				    struct flow_offload *flow, void *data)
+ {
+ 	if (nf_flow_has_expired(flow) ||
+ 	    nf_ct_is_dying(flow->ct) ||
+ 	    nf_flow_has_stale_dst(flow))
+ 		flow_offload_teardown(flow);
++>>>>>>> e5eaac2beb54 (netfilter: flowtable: fix TCP flow teardown)
  
  	if (test_bit(NF_FLOW_TEARDOWN, &flow->flags)) {
  		if (test_bit(NF_FLOW_HW, &flow->flags)) {
* Unmerged path net/netfilter/nf_flow_table_core.c
diff --git a/net/netfilter/nft_flow_offload.c b/net/netfilter/nft_flow_offload.c
index c722f104134d..5aac5c994c8f 100644
--- a/net/netfilter/nft_flow_offload.c
+++ b/net/netfilter/nft_flow_offload.c
@@ -91,7 +91,8 @@ static void nft_flow_offload_eval(const struct nft_expr *expr,
 	case IPPROTO_TCP:
 		tcph = skb_header_pointer(pkt->skb, pkt->xt.thoff,
 					  sizeof(_tcph), &_tcph);
-		if (unlikely(!tcph || tcph->fin || tcph->rst))
+		if (unlikely(!tcph || tcph->fin || tcph->rst ||
+			     !nf_conntrack_tcp_established(ct)))
 			goto out;
 		break;
 	case IPPROTO_UDP:
