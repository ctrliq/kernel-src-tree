net/mlx5: Bridge, support pvid and untagged vlan configurations

jira LE-1907
Rebuild_History Non-Buildable kernel-rt-4.18.0-372.9.1.rt7.166.el8
commit-author Vlad Buslov <vladbu@nvidia.com>
commit 36e55079e54955a70b2c340eedd6125f794a911d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-372.9.1.rt7.166.el8/36e55079.failed

Implement support for pushing vlan header into untagged packet on ingress
of port that has pvid configured and support for popping vlan on egress of
port that has the matching vlan configured as untagged. To support such
configurations packet reformat contexts of {INSERT|REMOVE}_HEADER types are
created per such vlan and saved to struct mlx5_esw_bridge_vlan which allows
all FDB entries on particular vlan to share single packet reformat
instance. When initializing FDB entries with pvid or untagged vlan type set
its mlx5_flow_act->pkt_reformat action accordingly.

Flush all flows when removing vlan from port. This is necessary because
even though software bridge removes all FDB entries before removing their
vlan, mlx5 bridge implementation deletes their corresponding flow entries
from hardware in asynchronous workqueue task, which will cause firmware
error if vlan packet reformat context is deleted before all flows that
point to it.

	Signed-off-by: Vlad Buslov <vladbu@nvidia.com>
	Reviewed-by: Jianbo Liu <jianbol@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 36e55079e54955a70b2c340eedd6125f794a911d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
#	drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
index b503562f97d0,442a62ff7b43..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
@@@ -3,6 -3,11 +3,14 @@@
  
  #include <linux/netdevice.h>
  #include <linux/list.h>
++<<<<<<< HEAD
++=======
+ #include <linux/rhashtable.h>
+ #include <linux/xarray.h>
+ #include <linux/if_bridge.h>
+ #include <linux/if_vlan.h>
+ #include <linux/if_ether.h>
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  #include <net/switchdev.h>
  #include "bridge.h"
  #include "eswitch.h"
@@@ -21,6 -32,54 +29,57 @@@ enum 
  	MLX5_ESW_BRIDGE_LEVEL_EGRESS_TABLE,
  };
  
++<<<<<<< HEAD
++=======
+ struct mlx5_esw_bridge_fdb_key {
+ 	unsigned char addr[ETH_ALEN];
+ 	u16 vid;
+ };
+ 
+ enum {
+ 	MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER = BIT(0),
+ };
+ 
+ struct mlx5_esw_bridge_fdb_entry {
+ 	struct mlx5_esw_bridge_fdb_key key;
+ 	struct rhash_head ht_node;
+ 	struct net_device *dev;
+ 	struct list_head list;
+ 	struct list_head vlan_list;
+ 	u16 vport_num;
+ 	u16 flags;
+ 
+ 	struct mlx5_flow_handle *ingress_handle;
+ 	struct mlx5_fc *ingress_counter;
+ 	unsigned long lastuse;
+ 	struct mlx5_flow_handle *egress_handle;
+ };
+ 
+ static const struct rhashtable_params fdb_ht_params = {
+ 	.key_offset = offsetof(struct mlx5_esw_bridge_fdb_entry, key),
+ 	.key_len = sizeof(struct mlx5_esw_bridge_fdb_key),
+ 	.head_offset = offsetof(struct mlx5_esw_bridge_fdb_entry, ht_node),
+ 	.automatic_shrinking = true,
+ };
+ 
+ struct mlx5_esw_bridge_vlan {
+ 	u16 vid;
+ 	u16 flags;
+ 	struct list_head fdb_list;
+ 	struct mlx5_pkt_reformat *pkt_reformat_push;
+ 	struct mlx5_pkt_reformat *pkt_reformat_pop;
+ };
+ 
+ struct mlx5_esw_bridge_port {
+ 	u16 vport_num;
+ 	struct xarray vlans;
+ };
+ 
+ enum {
+ 	MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG = BIT(0),
+ };
+ 
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  struct mlx5_esw_bridge {
  	int ifindex;
  	int refcnt;
@@@ -194,6 -368,118 +254,120 @@@ mlx5_esw_bridge_egress_table_cleanup(st
  	mlx5_destroy_flow_table(bridge->egress_ft);
  }
  
++<<<<<<< HEAD
++=======
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_ingress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				    struct mlx5_esw_bridge_vlan *vlan, u32 counter_id,
+ 				    struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_offloads *br_offloads = bridge->br_offloads;
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST | MLX5_FLOW_CONTEXT_ACTION_COUNT,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_destination dests[2] = {};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *smac_v, *smac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS | MLX5_MATCH_MISC_PARAMETERS_2;
+ 
+ 	smac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.smac_47_16);
+ 	ether_addr_copy(smac_v, addr);
+ 	smac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.smac_47_16);
+ 	eth_broadcast_addr(smac_c);
+ 
+ 	MLX5_SET(fte_match_param, rule_spec->match_criteria,
+ 		 misc_parameters_2.metadata_reg_c_0, mlx5_eswitch_get_vport_metadata_mask());
+ 	MLX5_SET(fte_match_param, rule_spec->match_value, misc_parameters_2.metadata_reg_c_0,
+ 		 mlx5_eswitch_get_vport_metadata_for_match(br_offloads->esw, vport_num));
+ 
+ 	if (vlan && vlan->pkt_reformat_push) {
+ 		flow_act.action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT;
+ 		flow_act.pkt_reformat = vlan->pkt_reformat_push;
+ 	} else if (vlan) {
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	dests[0].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dests[0].ft = bridge->egress_ft;
+ 	dests[1].type = MLX5_FLOW_DESTINATION_TYPE_COUNTER;
+ 	dests[1].counter_id = counter_id;
+ 
+ 	handle = mlx5_add_flow_rules(br_offloads->ingress_ft, rule_spec, &flow_act, dests,
+ 				     ARRAY_SIZE(dests));
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
+ static struct mlx5_flow_handle *
+ mlx5_esw_bridge_egress_flow_create(u16 vport_num, const unsigned char *addr,
+ 				   struct mlx5_esw_bridge_vlan *vlan,
+ 				   struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_flow_destination dest = {
+ 		.type = MLX5_FLOW_DESTINATION_TYPE_VPORT,
+ 		.vport.num = vport_num,
+ 	};
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flags = FLOW_ACT_NO_APPEND,
+ 	};
+ 	struct mlx5_flow_spec *rule_spec;
+ 	struct mlx5_flow_handle *handle;
+ 	u8 *dmac_v, *dmac_c;
+ 
+ 	rule_spec = kvzalloc(sizeof(*rule_spec), GFP_KERNEL);
+ 	if (!rule_spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rule_spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 
+ 	dmac_v = MLX5_ADDR_OF(fte_match_param, rule_spec->match_value,
+ 			      outer_headers.dmac_47_16);
+ 	ether_addr_copy(dmac_v, addr);
+ 	dmac_c = MLX5_ADDR_OF(fte_match_param, rule_spec->match_criteria,
+ 			      outer_headers.dmac_47_16);
+ 	eth_broadcast_addr(dmac_c);
+ 
+ 	if (vlan) {
+ 		if (vlan->pkt_reformat_pop) {
+ 			flow_act.action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT;
+ 			flow_act.pkt_reformat = vlan->pkt_reformat_pop;
+ 		}
+ 
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_value,
+ 				 outer_headers.cvlan_tag);
+ 		MLX5_SET_TO_ONES(fte_match_param, rule_spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, rule_spec->match_value, outer_headers.first_vid,
+ 			 vlan->vid);
+ 	}
+ 
+ 	handle = mlx5_add_flow_rules(bridge->egress_ft, rule_spec, &flow_act, &dest, 1);
+ 
+ 	kvfree(rule_spec);
+ 	return handle;
+ }
+ 
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  static struct mlx5_esw_bridge *mlx5_esw_bridge_create(int ifindex,
  						      struct mlx5_esw_bridge_offloads *br_offloads)
  {
@@@ -265,17 -563,420 +439,403 @@@ mlx5_esw_bridge_lookup(int ifindex, str
  	return bridge;
  }
  
++<<<<<<< HEAD
 +static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge *bridge,
++=======
+ static int mlx5_esw_bridge_port_insert(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_insert(&bridge->vports, port->vport_num, port, GFP_KERNEL);
+ }
+ 
+ static struct mlx5_esw_bridge_port *
+ mlx5_esw_bridge_port_lookup(u16 vport_num, struct mlx5_esw_bridge *bridge)
+ {
+ 	return xa_load(&bridge->vports, vport_num);
+ }
+ 
+ static void mlx5_esw_bridge_port_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	xa_erase(&bridge->vports, port->vport_num);
+ }
+ 
+ static void
+ mlx5_esw_bridge_fdb_entry_cleanup(struct mlx5_esw_bridge_fdb_entry *entry,
+ 				  struct mlx5_esw_bridge *bridge)
+ {
+ 	rhashtable_remove_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ 	mlx5_fc_destroy(bridge->br_offloads->esw->dev, entry->ingress_counter);
+ 	list_del(&entry->list);
+ 	kvfree(entry);
+ }
+ 
+ static void mlx5_esw_bridge_fdb_flush(struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 		if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 			mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 							   entry->key.vid,
+ 							   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_lookup(u16 vid, struct mlx5_esw_bridge_port *port)
+ {
+ 	return xa_load(&port->vlans, vid);
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_push_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct {
+ 		__be16	h_vlan_proto;
+ 		__be16	h_vlan_TCI;
+ 	} vlan_hdr = { htons(ETH_P_8021Q), htons(vlan->vid) };
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_insert)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_size) < sizeof(vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_insert_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat INSERT_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_INSERT_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(vlan_hdr);
+ 	reformat_params.data = &vlan_hdr;
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat INSERT_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_push = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_push_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_push);
+ 	vlan->pkt_reformat_push = NULL;
+ }
+ 
+ static int
+ mlx5_esw_bridge_vlan_pop_create(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_pkt_reformat_params reformat_params = {};
+ 	struct mlx5_pkt_reformat *pkt_reformat;
+ 
+ 	if (!BIT(MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, reformat_remove)) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_size) < sizeof(struct vlan_hdr) ||
+ 	    MLX5_CAP_GEN_2(esw->dev, max_reformat_remove_offset) <
+ 	    offsetof(struct vlan_ethhdr, h_vlan_proto)) {
+ 		esw_warn(esw->dev, "Packet reformat REMOVE_HEADER is not supported\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	reformat_params.type = MLX5_REFORMAT_TYPE_REMOVE_HDR;
+ 	reformat_params.param_0 = MLX5_REFORMAT_CONTEXT_ANCHOR_MAC_START;
+ 	reformat_params.param_1 = offsetof(struct vlan_ethhdr, h_vlan_proto);
+ 	reformat_params.size = sizeof(struct vlan_hdr);
+ 	pkt_reformat = mlx5_packet_reformat_alloc(esw->dev,
+ 						  &reformat_params,
+ 						  MLX5_FLOW_NAMESPACE_FDB);
+ 	if (IS_ERR(pkt_reformat)) {
+ 		esw_warn(esw->dev, "Failed to alloc packet reformat REMOVE_HEADER (err=%ld)\n",
+ 			 PTR_ERR(pkt_reformat));
+ 		return PTR_ERR(pkt_reformat);
+ 	}
+ 
+ 	vlan->pkt_reformat_pop = pkt_reformat;
+ 	return 0;
+ }
+ 
+ static void
+ mlx5_esw_bridge_vlan_pop_cleanup(struct mlx5_esw_bridge_vlan *vlan, struct mlx5_eswitch *esw)
+ {
+ 	mlx5_packet_reformat_dealloc(esw->dev, vlan->pkt_reformat_pop);
+ 	vlan->pkt_reformat_pop = NULL;
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_vlan_create(u16 vid, u16 flags, struct mlx5_esw_bridge_port *port,
+ 			    struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	int err;
+ 
+ 	vlan = kvzalloc(sizeof(*vlan), GFP_KERNEL);
+ 	if (!vlan)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	vlan->vid = vid;
+ 	vlan->flags = flags;
+ 	INIT_LIST_HEAD(&vlan->fdb_list);
+ 
+ 	if (flags & BRIDGE_VLAN_INFO_PVID) {
+ 		err = mlx5_esw_bridge_vlan_push_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_push;
+ 	}
+ 	if (flags & BRIDGE_VLAN_INFO_UNTAGGED) {
+ 		err = mlx5_esw_bridge_vlan_pop_create(vlan, esw);
+ 		if (err)
+ 			goto err_vlan_pop;
+ 	}
+ 
+ 	err = xa_insert(&port->vlans, vid, vlan, GFP_KERNEL);
+ 	if (err)
+ 		goto err_xa_insert;
+ 
+ 	return vlan;
+ 
+ err_xa_insert:
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, esw);
+ err_vlan_pop:
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, esw);
+ err_vlan_push:
+ 	kvfree(vlan);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_erase(struct mlx5_esw_bridge_port *port,
+ 				       struct mlx5_esw_bridge_vlan *vlan)
+ {
+ 	xa_erase(&port->vlans, vlan->vid);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_flush(struct mlx5_esw_bridge_vlan *vlan,
+ 				       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &vlan->fdb_list, vlan_list) {
+ 		if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 			mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 							   entry->key.vid,
+ 							   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 		mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 	}
+ 
+ 	if (vlan->pkt_reformat_pop)
+ 		mlx5_esw_bridge_vlan_pop_cleanup(vlan, bridge->br_offloads->esw);
+ 	if (vlan->pkt_reformat_push)
+ 		mlx5_esw_bridge_vlan_push_cleanup(vlan, bridge->br_offloads->esw);
+ }
+ 
+ static void mlx5_esw_bridge_vlan_cleanup(struct mlx5_esw_bridge_port *port,
+ 					 struct mlx5_esw_bridge_vlan *vlan,
+ 					 struct mlx5_esw_bridge *bridge)
+ {
+ 	mlx5_esw_bridge_vlan_flush(vlan, bridge);
+ 	mlx5_esw_bridge_vlan_erase(port, vlan);
+ 	kvfree(vlan);
+ }
+ 
+ static void mlx5_esw_bridge_port_vlans_flush(struct mlx5_esw_bridge_port *port,
+ 					     struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 	unsigned long index;
+ 
+ 	xa_for_each(&port->vlans, index, vlan)
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan, bridge);
+ }
+ 
+ static struct mlx5_esw_bridge_vlan *
+ mlx5_esw_bridge_port_vlan_lookup(u16 vid, u16 vport_num, struct mlx5_esw_bridge *bridge,
+ 				 struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport_num, bridge);
+ 	if (!port) {
+ 		/* FDB is added asynchronously on wq while port might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port (vport=%u)\n", vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan) {
+ 		/* FDB is added asynchronously on wq while vlan might have been deleted
+ 		 * concurrently. Report on 'info' logging level and skip the FDB offload.
+ 		 */
+ 		esw_info(esw->dev, "Failed to lookup bridge port vlan metadata (vport=%u)\n",
+ 			 vport_num);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	return vlan;
+ }
+ 
+ static struct mlx5_esw_bridge_fdb_entry *
+ mlx5_esw_bridge_fdb_entry_init(struct net_device *dev, u16 vport_num, const unsigned char *addr,
+ 			       u16 vid, bool added_by_user, struct mlx5_eswitch *esw,
+ 			       struct mlx5_esw_bridge *bridge)
+ {
+ 	struct mlx5_esw_bridge_vlan *vlan = NULL;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_flow_handle *handle;
+ 	struct mlx5_fc *counter;
+ 	struct mlx5e_priv *priv;
+ 	int err;
+ 
+ 	if (bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG && vid) {
+ 		vlan = mlx5_esw_bridge_port_vlan_lookup(vid, vport_num, bridge, esw);
+ 		if (IS_ERR(vlan))
+ 			return ERR_CAST(vlan);
+ 	}
+ 
+ 	priv = netdev_priv(dev);
+ 	entry = kvzalloc(sizeof(*entry), GFP_KERNEL);
+ 	if (!entry)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ether_addr_copy(entry->key.addr, addr);
+ 	entry->key.vid = vid;
+ 	entry->dev = dev;
+ 	entry->vport_num = vport_num;
+ 	entry->lastuse = jiffies;
+ 	if (added_by_user)
+ 		entry->flags |= MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER;
+ 
+ 	counter = mlx5_fc_create(priv->mdev, true);
+ 	if (IS_ERR(counter)) {
+ 		err = PTR_ERR(counter);
+ 		goto err_ingress_fc_create;
+ 	}
+ 	entry->ingress_counter = counter;
+ 
+ 	handle = mlx5_esw_bridge_ingress_flow_create(vport_num, addr, vlan, mlx5_fc_id(counter),
+ 						     bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create ingress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_ingress_flow_create;
+ 	}
+ 	entry->ingress_handle = handle;
+ 
+ 	handle = mlx5_esw_bridge_egress_flow_create(vport_num, addr, vlan, bridge);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		esw_warn(esw->dev, "Failed to create egress flow(vport=%u,err=%d)\n",
+ 			 vport_num, err);
+ 		goto err_egress_flow_create;
+ 	}
+ 	entry->egress_handle = handle;
+ 
+ 	err = rhashtable_insert_fast(&bridge->fdb_ht, &entry->ht_node, fdb_ht_params);
+ 	if (err) {
+ 		esw_warn(esw->dev, "Failed to insert FDB flow(vport=%u,err=%d)\n", vport_num, err);
+ 		goto err_ht_init;
+ 	}
+ 
+ 	if (vlan)
+ 		list_add(&entry->vlan_list, &vlan->fdb_list);
+ 	else
+ 		INIT_LIST_HEAD(&entry->vlan_list);
+ 	list_add(&entry->list, &bridge->fdb_list);
+ 	return entry;
+ 
+ err_ht_init:
+ 	mlx5_del_flow_rules(entry->egress_handle);
+ err_egress_flow_create:
+ 	mlx5_del_flow_rules(entry->ingress_handle);
+ err_ingress_flow_create:
+ 	mlx5_fc_destroy(priv->mdev, entry->ingress_counter);
+ err_ingress_fc_create:
+ 	kvfree(entry);
+ 	return ERR_PTR(err);
+ }
+ 
+ int mlx5_esw_bridge_ageing_time_set(unsigned long ageing_time, struct mlx5_eswitch *esw,
+ 				    struct mlx5_vport *vport)
+ {
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	vport->bridge->ageing_time = ageing_time;
+ 	return 0;
+ }
+ 
+ int mlx5_esw_bridge_vlan_filtering_set(bool enable, struct mlx5_eswitch *esw,
+ 				       struct mlx5_vport *vport)
+ {
+ 	struct mlx5_esw_bridge *bridge;
+ 	bool filtering;
+ 
+ 	if (!vport->bridge)
+ 		return -EINVAL;
+ 
+ 	bridge = vport->bridge;
+ 	filtering = bridge->flags & MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	if (filtering == enable)
+ 		return 0;
+ 
+ 	mlx5_esw_bridge_fdb_flush(bridge);
+ 	if (enable)
+ 		bridge->flags |= MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 	else
+ 		bridge->flags &= ~MLX5_ESW_BRIDGE_VLAN_FILTERING_FLAG;
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_esw_bridge_vport_init(struct mlx5_esw_bridge_offloads *br_offloads,
+ 				      struct mlx5_esw_bridge *bridge,
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  				      struct mlx5_vport *vport)
  {
 -	struct mlx5_eswitch *esw = br_offloads->esw;
 -	struct mlx5_esw_bridge_port *port;
 -	int err;
 -
 -	port = kvzalloc(sizeof(*port), GFP_KERNEL);
 -	if (!port) {
 -		err = -ENOMEM;
 -		goto err_port_alloc;
 -	}
 -
 -	port->vport_num = vport->vport;
 -	xa_init(&port->vlans);
 -	err = mlx5_esw_bridge_port_insert(port, bridge);
 -	if (err) {
 -		esw_warn(esw->dev, "Failed to insert port metadata (vport=%u,err=%d)\n",
 -			 vport->vport, err);
 -		goto err_port_insert;
 -	}
 -
  	vport->bridge = bridge;
  	return 0;
 -
 -err_port_insert:
 -	kvfree(port);
 -err_port_alloc:
 -	mlx5_esw_bridge_put(br_offloads, bridge);
 -	return err;
  }
  
  static int mlx5_esw_bridge_vport_cleanup(struct mlx5_esw_bridge_offloads *br_offloads,
  					 struct mlx5_vport *vport)
  {
++<<<<<<< HEAD
 +	mlx5_esw_bridge_put(br_offloads, vport->bridge);
++=======
+ 	struct mlx5_esw_bridge *bridge = vport->bridge;
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 	struct mlx5_esw_bridge_port *port;
+ 
+ 	list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list)
+ 		if (entry->vport_num == vport->vport)
+ 			mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport->vport, bridge);
+ 	if (!port) {
+ 		WARN(1, "Vport %u metadata not found on bridge", vport->vport);
+ 		return -EINVAL;
+ 	}
+ 
+ 	mlx5_esw_bridge_port_vlans_flush(port, bridge);
+ 	mlx5_esw_bridge_port_erase(port, bridge);
+ 	kvfree(port);
+ 	mlx5_esw_bridge_put(br_offloads, bridge);
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  	vport->bridge = NULL;
  	return 0;
  }
@@@ -308,7 -1016,136 +868,140 @@@ int mlx5_esw_bridge_vport_unlink(int if
  		return -EINVAL;
  	}
  
++<<<<<<< HEAD
 +	return mlx5_esw_bridge_vport_cleanup(br_offloads, vport);
++=======
+ 	err = mlx5_esw_bridge_vport_cleanup(br_offloads, vport);
+ 	if (err)
+ 		NL_SET_ERR_MSG_MOD(extack, "Port cleanup failed");
+ 	return err;
+ }
+ 
+ int mlx5_esw_bridge_port_vlan_add(u16 vid, u16 flags, struct mlx5_eswitch *esw,
+ 				  struct mlx5_vport *vport, struct netlink_ext_ack *extack)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport->vport, vport->bridge);
+ 	if (!port)
+ 		return -EINVAL;
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (vlan) {
+ 		if (vlan->flags == flags)
+ 			return 0;
+ 		mlx5_esw_bridge_vlan_cleanup(port, vlan, vport->bridge);
+ 	}
+ 
+ 	vlan = mlx5_esw_bridge_vlan_create(vid, flags, port, esw);
+ 	if (IS_ERR(vlan)) {
+ 		NL_SET_ERR_MSG_MOD(extack, "Failed to create VLAN entry");
+ 		return PTR_ERR(vlan);
+ 	}
+ 	return 0;
+ }
+ 
+ void mlx5_esw_bridge_port_vlan_del(u16 vid, struct mlx5_eswitch *esw, struct mlx5_vport *vport)
+ {
+ 	struct mlx5_esw_bridge_port *port;
+ 	struct mlx5_esw_bridge_vlan *vlan;
+ 
+ 	port = mlx5_esw_bridge_port_lookup(vport->vport, vport->bridge);
+ 	if (!port)
+ 		return;
+ 
+ 	vlan = mlx5_esw_bridge_vlan_lookup(vid, port);
+ 	if (!vlan)
+ 		return;
+ 	mlx5_esw_bridge_vlan_cleanup(port, vlan, vport->bridge);
+ }
+ 
+ void mlx5_esw_bridge_fdb_create(struct net_device *dev, struct mlx5_eswitch *esw,
+ 				struct mlx5_vport *vport,
+ 				struct switchdev_notifier_fdb_info *fdb_info)
+ {
+ 	struct mlx5_esw_bridge *bridge = vport->bridge;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	u16 vport_num = vport->vport;
+ 
+ 	if (!bridge) {
+ 		esw_info(esw->dev, "Vport is not assigned to bridge (vport=%u)\n", vport_num);
+ 		return;
+ 	}
+ 
+ 	entry = mlx5_esw_bridge_fdb_entry_init(dev, vport_num, fdb_info->addr, fdb_info->vid,
+ 					       fdb_info->added_by_user, esw, bridge);
+ 	if (IS_ERR(entry))
+ 		return;
+ 
+ 	if (entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER)
+ 		mlx5_esw_bridge_fdb_offload_notify(dev, entry->key.addr, entry->key.vid,
+ 						   SWITCHDEV_FDB_OFFLOADED);
+ 	else
+ 		/* Take over dynamic entries to prevent kernel bridge from aging them out. */
+ 		mlx5_esw_bridge_fdb_offload_notify(dev, entry->key.addr, entry->key.vid,
+ 						   SWITCHDEV_FDB_ADD_TO_BRIDGE);
+ }
+ 
+ void mlx5_esw_bridge_fdb_remove(struct net_device *dev, struct mlx5_eswitch *esw,
+ 				struct mlx5_vport *vport,
+ 				struct switchdev_notifier_fdb_info *fdb_info)
+ {
+ 	struct mlx5_esw_bridge *bridge = vport->bridge;
+ 	struct mlx5_esw_bridge_fdb_entry *entry;
+ 	struct mlx5_esw_bridge_fdb_key key;
+ 	u16 vport_num = vport->vport;
+ 
+ 	if (!bridge) {
+ 		esw_warn(esw->dev, "Vport is not assigned to bridge (vport=%u)\n", vport_num);
+ 		return;
+ 	}
+ 
+ 	ether_addr_copy(key.addr, fdb_info->addr);
+ 	key.vid = fdb_info->vid;
+ 	entry = rhashtable_lookup_fast(&bridge->fdb_ht, &key, fdb_ht_params);
+ 	if (!entry) {
+ 		esw_warn(esw->dev,
+ 			 "FDB entry with specified key not found (MAC=%pM,vid=%u,vport=%u)\n",
+ 			 key.addr, key.vid, vport_num);
+ 		return;
+ 	}
+ 
+ 	if (!(entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER))
+ 		mlx5_esw_bridge_fdb_offload_notify(dev, entry->key.addr, entry->key.vid,
+ 						   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 	mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ }
+ 
+ void mlx5_esw_bridge_update(struct mlx5_esw_bridge_offloads *br_offloads)
+ {
+ 	struct mlx5_esw_bridge_fdb_entry *entry, *tmp;
+ 	struct mlx5_esw_bridge *bridge;
+ 
+ 	list_for_each_entry(bridge, &br_offloads->bridges, list) {
+ 		list_for_each_entry_safe(entry, tmp, &bridge->fdb_list, list) {
+ 			unsigned long lastuse =
+ 				(unsigned long)mlx5_fc_query_lastuse(entry->ingress_counter);
+ 
+ 			if (entry->flags & MLX5_ESW_BRIDGE_FLAG_ADDED_BY_USER)
+ 				continue;
+ 
+ 			if (time_after(lastuse, entry->lastuse)) {
+ 				entry->lastuse = lastuse;
+ 				/* refresh existing bridge entry */
+ 				mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 								   entry->key.vid,
+ 								   SWITCHDEV_FDB_ADD_TO_BRIDGE);
+ 			} else if (time_is_before_jiffies(entry->lastuse + bridge->ageing_time)) {
+ 				mlx5_esw_bridge_fdb_offload_notify(entry->dev, entry->key.addr,
+ 								   entry->key.vid,
+ 								   SWITCHDEV_FDB_DEL_TO_BRIDGE);
+ 				mlx5_esw_bridge_fdb_entry_cleanup(entry, bridge);
+ 			}
+ 		}
+ 	}
++>>>>>>> 36e55079e549 (net/mlx5: Bridge, support pvid and untagged vlan configurations)
  }
  
  static void mlx5_esw_bridge_flush(struct mlx5_esw_bridge_offloads *br_offloads)
* Unmerged path Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
* Unmerged path Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/esw/bridge.c
