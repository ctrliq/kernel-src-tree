x86/MCE/AMD, EDAC/mce_amd: Support non-uniform MCA bank type enumeration

jira LE-1907
Rebuild_History Non-Buildable kernel-rt-4.18.0-372.9.1.rt7.166.el8
commit-author Yazen Ghannam <yazen.ghannam@amd.com>
commit 91f75eb481cfaee5c4ed8fb5214bf2fbfa04bd7b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-4.18.0-372.9.1.rt7.166.el8/91f75eb4.failed

AMD systems currently lay out MCA bank types such that the type of bank
number "i" is either the same across all CPUs or is Reserved/Read-as-Zero.

For example:

  Bank # | CPUx | CPUy
    0      LS     LS
    1      RAZ    UMC
    2      CS     CS
    3      SMU    RAZ

Future AMD systems will lay out MCA bank types such that the type of
bank number "i" may be different across CPUs.

For example:

  Bank # | CPUx | CPUy
    0      LS     LS
    1      RAZ    UMC
    2      CS     NBIO
    3      SMU    RAZ

Change the structures that cache MCA bank types to be per-CPU and update
smca_get_bank_type() to handle this change.

Move some SMCA-specific structures to amd.c from mce.h, since they no
longer need to be global.

Break out the "count" for bank types from struct smca_hwid, since this
should provide a per-CPU count rather than a system-wide count.

Apply the "const" qualifier to the struct smca_hwid_mcatypes array. The
values in this array should not change at runtime.

	Signed-off-by: Yazen Ghannam <yazen.ghannam@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lore.kernel.org/r/20211216162905.4132657-3-yazen.ghannam@amd.com
(cherry picked from commit 91f75eb481cfaee5c4ed8fb5214bf2fbfa04bd7b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mce.h
#	arch/x86/kernel/cpu/mce/amd.c
#	drivers/gpu/drm/amd/amdgpu/amdgpu_ras.c
diff --cc arch/x86/include/asm/mce.h
index e0431f277493,cc73061e7255..000000000000
--- a/arch/x86/include/asm/mce.h
+++ b/arch/x86/include/asm/mce.h
@@@ -339,8 -336,7 +323,12 @@@ extern int mce_threshold_create_device(
  extern int mce_threshold_remove_device(unsigned int cpu);
  
  void mce_amd_feature_init(struct cpuinfo_x86 *c);
++<<<<<<< HEAD
 +int umc_normaddr_to_sysaddr(u64 norm_addr, u16 nid, u8 umc, u64 *sys_addr);
 +
++=======
+ enum smca_bank_types smca_get_bank_type(unsigned int cpu, unsigned int bank);
++>>>>>>> 91f75eb481cf (x86/MCE/AMD, EDAC/mce_amd: Support non-uniform MCA bank type enumeration)
  #else
  
  static inline int mce_threshold_create_device(unsigned int cpu)		{ return 0; };
diff --cc arch/x86/kernel/cpu/mce/amd.c
index 205737c4c474,a1e2f41796dc..000000000000
--- a/arch/x86/kernel/cpu/mce/amd.c
+++ b/arch/x86/kernel/cpu/mce/amd.c
@@@ -121,7 -142,7 +137,11 @@@ const char *smca_get_long_name(enum smc
  }
  EXPORT_SYMBOL_GPL(smca_get_long_name);
  
++<<<<<<< HEAD
 +static enum smca_bank_types smca_get_bank_type(unsigned int bank)
++=======
+ enum smca_bank_types smca_get_bank_type(unsigned int cpu, unsigned int bank)
++>>>>>>> 91f75eb481cf (x86/MCE/AMD, EDAC/mce_amd: Support non-uniform MCA bank type enumeration)
  {
  	struct smca_bank *b;
  
@@@ -134,8 -155,9 +154,8 @@@
  
  	return b->hwid->bank_type;
  }
 -EXPORT_SYMBOL_GPL(smca_get_bank_type);
  
- static struct smca_hwid smca_hwid_mcatypes[] = {
+ static const struct smca_hwid smca_hwid_mcatypes[] = {
  	/* { bank_type, hwid_mcatype } */
  
  	/* Reserved type */
@@@ -182,19 -207,17 +202,16 @@@
  	{ SMCA_PCIE,	 HWID_MCATYPE(0x46, 0x0)	},
  	{ SMCA_PCIE_V2,	 HWID_MCATYPE(0x46, 0x1)	},
  
 +	/* xGMI PCS MCA type */
  	{ SMCA_XGMI_PCS, HWID_MCATYPE(0x50, 0x0)	},
 -	{ SMCA_NBIF,	 HWID_MCATYPE(0x6C, 0x0)	},
 -	{ SMCA_SHUB,	 HWID_MCATYPE(0x80, 0x0)	},
 -	{ SMCA_SATA,	 HWID_MCATYPE(0xA8, 0x0)	},
 -	{ SMCA_USB,	 HWID_MCATYPE(0xAA, 0x0)	},
 -	{ SMCA_GMI_PCS,  HWID_MCATYPE(0x241, 0x0)	},
 +
 +	/* xGMI PHY MCA type */
  	{ SMCA_XGMI_PHY, HWID_MCATYPE(0x259, 0x0)	},
 +
 +	/* WAFL PHY MCA type */
  	{ SMCA_WAFL_PHY, HWID_MCATYPE(0x267, 0x0)	},
 -	{ SMCA_GMI_PHY,	 HWID_MCATYPE(0x269, 0x0)	},
  };
  
- struct smca_bank smca_banks[MAX_NR_BANKS];
- EXPORT_SYMBOL_GPL(smca_banks);
- 
  /*
   * In SMCA enabled processors, we can have multiple banks for a given IP type.
   * So to define a unique name for each bank, we use a temp c-string to append
diff --cc drivers/gpu/drm/amd/amdgpu/amdgpu_ras.c
index 95d5842385b3,75dad0214dc7..000000000000
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ras.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ras.c
@@@ -2509,3 -2606,136 +2509,139 @@@ void amdgpu_release_ras_context(struct 
  		kfree(con);
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ #ifdef CONFIG_X86_MCE_AMD
+ static struct amdgpu_device *find_adev(uint32_t node_id)
+ {
+ 	int i;
+ 	struct amdgpu_device *adev = NULL;
+ 
+ 	for (i = 0; i < mce_adev_list.num_gpu; i++) {
+ 		adev = mce_adev_list.devs[i];
+ 
+ 		if (adev && adev->gmc.xgmi.connected_to_cpu &&
+ 		    adev->gmc.xgmi.physical_node_id == node_id)
+ 			break;
+ 		adev = NULL;
+ 	}
+ 
+ 	return adev;
+ }
+ 
+ #define GET_MCA_IPID_GPUID(m)	(((m) >> 44) & 0xF)
+ #define GET_UMC_INST(m)		(((m) >> 21) & 0x7)
+ #define GET_CHAN_INDEX(m)	((((m) >> 12) & 0x3) | (((m) >> 18) & 0x4))
+ #define GPU_ID_OFFSET		8
+ 
+ static int amdgpu_bad_page_notifier(struct notifier_block *nb,
+ 				    unsigned long val, void *data)
+ {
+ 	struct mce *m = (struct mce *)data;
+ 	struct amdgpu_device *adev = NULL;
+ 	uint32_t gpu_id = 0;
+ 	uint32_t umc_inst = 0;
+ 	uint32_t ch_inst, channel_index = 0;
+ 	struct ras_err_data err_data = {0, 0, 0, NULL};
+ 	struct eeprom_table_record err_rec;
+ 	uint64_t retired_page;
+ 
+ 	/*
+ 	 * If the error was generated in UMC_V2, which belongs to GPU UMCs,
+ 	 * and error occurred in DramECC (Extended error code = 0) then only
+ 	 * process the error, else bail out.
+ 	 */
+ 	if (!m || !((smca_get_bank_type(m->extcpu, m->bank) == SMCA_UMC_V2) &&
+ 		    (XEC(m->status, 0x3f) == 0x0)))
+ 		return NOTIFY_DONE;
+ 
+ 	/*
+ 	 * If it is correctable error, return.
+ 	 */
+ 	if (mce_is_correctable(m))
+ 		return NOTIFY_OK;
+ 
+ 	/*
+ 	 * GPU Id is offset by GPU_ID_OFFSET in MCA_IPID_UMC register.
+ 	 */
+ 	gpu_id = GET_MCA_IPID_GPUID(m->ipid) - GPU_ID_OFFSET;
+ 
+ 	adev = find_adev(gpu_id);
+ 	if (!adev) {
+ 		DRM_WARN("%s: Unable to find adev for gpu_id: %d\n", __func__,
+ 								gpu_id);
+ 		return NOTIFY_DONE;
+ 	}
+ 
+ 	/*
+ 	 * If it is uncorrectable error, then find out UMC instance and
+ 	 * channel index.
+ 	 */
+ 	umc_inst = GET_UMC_INST(m->ipid);
+ 	ch_inst = GET_CHAN_INDEX(m->ipid);
+ 
+ 	dev_info(adev->dev, "Uncorrectable error detected in UMC inst: %d, chan_idx: %d",
+ 			     umc_inst, ch_inst);
+ 
+ 	memset(&err_rec, 0x0, sizeof(struct eeprom_table_record));
+ 
+ 	/*
+ 	 * Translate UMC channel address to Physical address
+ 	 */
+ 	channel_index =
+ 		adev->umc.channel_idx_tbl[umc_inst * adev->umc.channel_inst_num
+ 					  + ch_inst];
+ 
+ 	retired_page = ADDR_OF_8KB_BLOCK(m->addr) |
+ 			ADDR_OF_256B_BLOCK(channel_index) |
+ 			OFFSET_IN_256B_BLOCK(m->addr);
+ 
+ 	err_rec.address = m->addr;
+ 	err_rec.retired_page = retired_page >> AMDGPU_GPU_PAGE_SHIFT;
+ 	err_rec.ts = (uint64_t)ktime_get_real_seconds();
+ 	err_rec.err_type = AMDGPU_RAS_EEPROM_ERR_NON_RECOVERABLE;
+ 	err_rec.cu = 0;
+ 	err_rec.mem_channel = channel_index;
+ 	err_rec.mcumc_id = umc_inst;
+ 
+ 	err_data.err_addr = &err_rec;
+ 	err_data.err_addr_cnt = 1;
+ 
+ 	if (amdgpu_bad_page_threshold != 0) {
+ 		amdgpu_ras_add_bad_pages(adev, err_data.err_addr,
+ 						err_data.err_addr_cnt);
+ 		amdgpu_ras_save_bad_pages(adev);
+ 	}
+ 
+ 	return NOTIFY_OK;
+ }
+ 
+ static struct notifier_block amdgpu_bad_page_nb = {
+ 	.notifier_call  = amdgpu_bad_page_notifier,
+ 	.priority       = MCE_PRIO_UC,
+ };
+ 
+ static void amdgpu_register_bad_pages_mca_notifier(struct amdgpu_device *adev)
+ {
+ 	/*
+ 	 * Add the adev to the mce_adev_list.
+ 	 * During mode2 reset, amdgpu device is temporarily
+ 	 * removed from the mgpu_info list which can cause
+ 	 * page retirement to fail.
+ 	 * Use this list instead of mgpu_info to find the amdgpu
+ 	 * device on which the UMC error was reported.
+ 	 */
+ 	mce_adev_list.devs[mce_adev_list.num_gpu++] = adev;
+ 
+ 	/*
+ 	 * Register the x86 notifier only once
+ 	 * with MCE subsystem.
+ 	 */
+ 	if (notifier_registered == false) {
+ 		mce_register_decode_chain(&amdgpu_bad_page_nb);
+ 		notifier_registered = true;
+ 	}
+ }
+ #endif
++>>>>>>> 91f75eb481cf (x86/MCE/AMD, EDAC/mce_amd: Support non-uniform MCA bank type enumeration)
* Unmerged path arch/x86/include/asm/mce.h
* Unmerged path arch/x86/kernel/cpu/mce/amd.c
diff --git a/drivers/edac/mce_amd.c b/drivers/edac/mce_amd.c
index 7f35da415a6a..656ba08121d9 100644
--- a/drivers/edac/mce_amd.c
+++ b/drivers/edac/mce_amd.c
@@ -1044,20 +1044,13 @@ static void decode_mc6_mce(struct mce *m)
 /* Decode errors according to Scalable MCA specification */
 static void decode_smca_error(struct mce *m)
 {
-	struct smca_hwid *hwid;
-	enum smca_bank_types bank_type;
+	enum smca_bank_types bank_type = smca_get_bank_type(m->extcpu, m->bank);
 	const char *ip_name;
 	u8 xec = XEC(m->status, xec_mask);
 
-	if (m->bank >= ARRAY_SIZE(smca_banks))
+	if (bank_type >= N_SMCA_BANK_TYPES)
 		return;
 
-	hwid = smca_banks[m->bank].hwid;
-	if (!hwid)
-		return;
-
-	bank_type = hwid->bank_type;
-
 	if (bank_type == SMCA_RESERVED) {
 		pr_emerg(HW_ERR "Bank %d is reserved.\n", m->bank);
 		return;
* Unmerged path drivers/gpu/drm/amd/amdgpu/amdgpu_ras.c
