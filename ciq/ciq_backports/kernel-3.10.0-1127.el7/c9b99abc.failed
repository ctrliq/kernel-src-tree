net/mlx5: E-Switch, Split VF and special vports for offloads mode

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1127.el7
commit-author Bodong Wang <bodong@mellanox.com>
commit c9b99abcf232f69ddff158b1f313fd7d2654414b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1127.el7/c9b99abc.failed

When driver is entering offloads mode, there are two major tasks to
do: initialize flow steering and create representors. Flow steering
should make sure enough flow table/group spaces are reserved for all
reps. Representors will be created in a group, all or none.

With the introduction of ECPF, flow steering should still reserve the
same spaces. But, the representors are not always loaded/unloaded in a
single piece. Once ECPF is in offloads mode, it will get the number
of VF changing event from host PF. In such scenario, only the VF reps
should be loaded/unloaded, not the reps for special vports (such as
the uplink vport).

Thus, when entering offloads mode, driver should specify the total
number of reps, and the number of VF reps separately. When leaving
offloads mode, the cleanup should use the information self-contained
in eswitch such as number of VFs.

This patch doesn't change any functionality.

	Signed-off-by: Bodong Wang <bodong@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit c9b99abcf232f69ddff158b1f313fd7d2654414b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	include/linux/mlx5/vport.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 7a65b2da3f8b,be6c2931d2a0..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1614,9 -1639,10 +1614,14 @@@ int mlx5_eswitch_enable_sriov(struct ml
  	if (mode == SRIOV_LEGACY) {
  		err = esw_create_legacy_fdb_table(esw);
  	} else {
 -		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_ETH);
  		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_IB);
++<<<<<<< HEAD
 +
 +		err = esw_offloads_init(esw, nvfs + 1);
++=======
+ 		err = esw_offloads_init(esw, nvfs,
+ 					nvfs + MLX5_SPECIAL_VPORTS);
++>>>>>>> c9b99abcf232 (net/mlx5: E-Switch, Split VF and special vports for offloads mode)
  	}
  
  	if (err)
@@@ -1661,8 -1693,10 +1665,7 @@@ void mlx5_eswitch_disable_sriov(struct 
  		 esw->enabled_vports, esw->mode);
  
  	mc_promisc = &esw->mc_promisc;
- 	nvports = esw->enabled_vports;
  
 -	if (esw->mode == SRIOV_LEGACY)
 -		mlx5_eq_notifier_unregister(esw->dev, &esw->nb);
 -
  	for (i = 0; i < esw->total_vports; i++)
  		esw_disable_vport(esw, i);
  
diff --cc include/linux/mlx5/vport.h
index 9c694808c212,755aeea19e1c..000000000000
--- a/include/linux/mlx5/vport.h
+++ b/include/linux/mlx5/vport.h
@@@ -42,9 -51,16 +42,19 @@@ enum 
  	MLX5_CAP_INLINE_MODE_NOT_REQUIRED,
  };
  
++<<<<<<< HEAD
++=======
+ enum {
+ 	MLX5_VPORT_PF			= 0x0,
+ 	MLX5_VPORT_FIRST_VF		= 0x1,
+ 	MLX5_VPORT_ECPF			= 0xfffe,
+ 	MLX5_VPORT_UPLINK		= 0xffff
+ };
+ 
++>>>>>>> c9b99abcf232 (net/mlx5: E-Switch, Split VF and special vports for offloads mode)
  u8 mlx5_query_vport_state(struct mlx5_core_dev *mdev, u8 opmod, u16 vport);
  int mlx5_modify_vport_admin_state(struct mlx5_core_dev *mdev, u8 opmod,
 -				  u16 vport, u8 other_vport, u8 state);
 +				  u16 vport, u8 state);
  int mlx5_query_nic_vport_mac_address(struct mlx5_core_dev *mdev,
  				     u16 vport, u8 *addr);
  int mlx5_query_nic_vport_min_inline(struct mlx5_core_dev *mdev,
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 16e70a4d64b2..622233ebbb3f 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -208,8 +208,9 @@ struct mlx5_eswitch {
 	int                     nvports;
 };
 
-void esw_offloads_cleanup(struct mlx5_eswitch *esw, int nvports);
-int esw_offloads_init(struct mlx5_eswitch *esw, int nvports);
+void esw_offloads_cleanup(struct mlx5_eswitch *esw);
+int esw_offloads_init(struct mlx5_eswitch *esw, int vf_nvports,
+		      int total_nvports);
 void esw_offloads_cleanup_reps(struct mlx5_eswitch *esw);
 int esw_offloads_init_reps(struct mlx5_eswitch *esw);
 void esw_vport_cleanup_ingress_rules(struct mlx5_eswitch *esw,
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index c04fe56f0335..2e6f6f9a7481 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@ -49,6 +49,8 @@ enum {
 #define fdb_prio_table(esw, chain, prio, level) \
 	(esw)->fdb_table.offloads.fdb_prio[(chain)][(prio)][(level)]
 
+#define UPLINK_REP_INDEX 0
+
 static struct mlx5_flow_table *
 esw_get_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level);
 static void
@@ -1232,19 +1234,28 @@ int esw_offloads_init_reps(struct mlx5_eswitch *esw)
 	return 0;
 }
 
+static void __esw_offloads_unload_rep(struct mlx5_eswitch *esw,
+				      struct mlx5_eswitch_rep *rep, u8 rep_type)
+{
+	if (!rep->rep_if[rep_type].valid)
+		return;
+
+	rep->rep_if[rep_type].unload(rep);
+}
+
 static void esw_offloads_unload_reps_type(struct mlx5_eswitch *esw, int nvports,
 					  u8 rep_type)
 {
 	struct mlx5_eswitch_rep *rep;
 	int vport;
 
-	for (vport = nvports - 1; vport >= 0; vport--) {
+	for (vport = nvports; vport >= MLX5_VPORT_FIRST_VF; vport--) {
 		rep = &esw->offloads.vport_reps[vport];
-		if (!rep->rep_if[rep_type].valid)
-			continue;
-
-		rep->rep_if[rep_type].unload(rep);
+		__esw_offloads_unload_rep(esw, rep, rep_type);
 	}
+
+	rep = &esw->offloads.vport_reps[UPLINK_REP_INDEX];
+	__esw_offloads_unload_rep(esw, rep, rep_type);
 }
 
 static void esw_offloads_unload_reps(struct mlx5_eswitch *esw, int nvports)
@@ -1255,6 +1266,15 @@ static void esw_offloads_unload_reps(struct mlx5_eswitch *esw, int nvports)
 		esw_offloads_unload_reps_type(esw, nvports, rep_type);
 }
 
+static int __esw_offloads_load_rep(struct mlx5_eswitch *esw,
+				   struct mlx5_eswitch_rep *rep, u8 rep_type)
+{
+	if (!rep->rep_if[rep_type].valid)
+		return 0;
+
+	return rep->rep_if[rep_type].load(esw->dev, rep);
+}
+
 static int esw_offloads_load_reps_type(struct mlx5_eswitch *esw, int nvports,
 				       u8 rep_type)
 {
@@ -1262,12 +1282,14 @@ static int esw_offloads_load_reps_type(struct mlx5_eswitch *esw, int nvports,
 	int vport;
 	int err;
 
-	for (vport = 0; vport < nvports; vport++) {
-		rep = &esw->offloads.vport_reps[vport];
-		if (!rep->rep_if[rep_type].valid)
-			continue;
+	rep = &esw->offloads.vport_reps[UPLINK_REP_INDEX];
+	err = __esw_offloads_load_rep(esw, rep, rep_type);
+	if (err)
+		goto out;
 
-		err = rep->rep_if[rep_type].load(esw->dev, rep);
+	for (vport = MLX5_VPORT_FIRST_VF; vport <= nvports; vport++) {
+		rep = &esw->offloads.vport_reps[vport];
+		err = __esw_offloads_load_rep(esw, rep, rep_type);
 		if (err)
 			goto err_reps;
 	}
@@ -1276,6 +1298,7 @@ static int esw_offloads_load_reps_type(struct mlx5_eswitch *esw, int nvports,
 
 err_reps:
 	esw_offloads_unload_reps_type(esw, vport, rep_type);
+out:
 	return err;
 }
 
@@ -1600,17 +1623,18 @@ static void esw_offloads_steering_cleanup(struct mlx5_eswitch *esw)
 		esw_prio_tag_acls_cleanup(esw);
 }
 
-int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)
+int esw_offloads_init(struct mlx5_eswitch *esw, int vf_nvports,
+		      int total_nvports)
 {
 	int err;
 
 	mutex_init(&esw->fdb_table.offloads.fdb_prio_lock);
 
-	err = esw_offloads_steering_init(esw, nvports);
+	err = esw_offloads_steering_init(esw, total_nvports);
 	if (err)
 		return err;
 
-	err = esw_offloads_load_reps(esw, nvports);
+	err = esw_offloads_load_reps(esw, vf_nvports);
 	if (err)
 		goto err_reps;
 
@@ -1643,10 +1667,12 @@ static int esw_offloads_stop(struct mlx5_eswitch *esw)
 	return err;
 }
 
-void esw_offloads_cleanup(struct mlx5_eswitch *esw, int nvports)
+void esw_offloads_cleanup(struct mlx5_eswitch *esw)
 {
+	u16 num_vfs = esw->dev->priv.sriov.num_vfs;
+
 	esw_offloads_devcom_cleanup(esw);
-	esw_offloads_unload_reps(esw, nvports);
+	esw_offloads_unload_reps(esw, num_vfs);
 	esw_offloads_steering_cleanup(esw);
 }
 
@@ -1981,7 +2007,6 @@ EXPORT_SYMBOL(mlx5_eswitch_unregister_vport_rep);
 
 void *mlx5_eswitch_get_uplink_priv(struct mlx5_eswitch *esw, u8 rep_type)
 {
-#define UPLINK_REP_INDEX 0
 	struct mlx5_esw_offload *offloads = &esw->offloads;
 	struct mlx5_eswitch_rep *rep;
 
* Unmerged path include/linux/mlx5/vport.h
