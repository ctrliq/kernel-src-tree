bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL

jira LE-1907
cve CVE-2022-23222
cve CVE-2022-0500
Rebuild_History Non-Buildable kernel-4.18.0-532.el8
commit-author Hao Luo <haoluo@google.com>
commit c25b2ae136039ffa820c26138ed4a5e5f3ab3841
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-532.el8/c25b2ae1.failed

We have introduced a new type to make bpf_reg composable, by
allocating bits in the type to represent flags.

One of the flags is PTR_MAYBE_NULL which indicates a pointer
may be NULL. This patch switches the qualified reg_types to
use this flag. The reg_types changed in this patch include:

1. PTR_TO_MAP_VALUE_OR_NULL
2. PTR_TO_SOCKET_OR_NULL
3. PTR_TO_SOCK_COMMON_OR_NULL
4. PTR_TO_TCP_SOCK_OR_NULL
5. PTR_TO_BTF_ID_OR_NULL
6. PTR_TO_MEM_OR_NULL
7. PTR_TO_RDONLY_BUF_OR_NULL
8. PTR_TO_RDWR_BUF_OR_NULL

	Signed-off-by: Hao Luo <haoluo@google.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/r/20211217003152.48334-5-haoluo@google.com
(cherry picked from commit c25b2ae136039ffa820c26138ed4a5e5f3ab3841)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/linux/bpf_verifier.h
#	kernel/bpf/verifier.c
diff --cc include/linux/bpf.h
index 83377e4c1c34,c3de62267b84..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -431,18 -491,27 +428,29 @@@ enum bpf_reg_type 
  	 * been checked for null. Used primarily to inform the verifier
  	 * an explicit null check is required for this struct.
  	 */
- 	PTR_TO_BTF_ID_OR_NULL,
  	PTR_TO_MEM,		 /* reg points to valid memory region */
- 	PTR_TO_MEM_OR_NULL,	 /* reg points to valid memory region or NULL */
  	PTR_TO_RDONLY_BUF,	 /* reg points to a readonly buffer */
- 	PTR_TO_RDONLY_BUF_OR_NULL, /* reg points to a readonly buffer or NULL */
  	PTR_TO_RDWR_BUF,	 /* reg points to a read/write buffer */
- 	PTR_TO_RDWR_BUF_OR_NULL, /* reg points to a read/write buffer or NULL */
  	PTR_TO_PERCPU_BTF_ID,	 /* reg points to a percpu kernel variable */
  	PTR_TO_FUNC,		 /* reg points to a bpf program function */
- 	PTR_TO_MAP_KEY,		 /* reg points to a map element key */
  	__BPF_REG_TYPE_MAX,
++<<<<<<< HEAD
++=======
+ 
+ 	/* Extended reg_types. */
+ 	PTR_TO_MAP_VALUE_OR_NULL	= PTR_MAYBE_NULL | PTR_TO_MAP_VALUE,
+ 	PTR_TO_SOCKET_OR_NULL		= PTR_MAYBE_NULL | PTR_TO_SOCKET,
+ 	PTR_TO_SOCK_COMMON_OR_NULL	= PTR_MAYBE_NULL | PTR_TO_SOCK_COMMON,
+ 	PTR_TO_TCP_SOCK_OR_NULL		= PTR_MAYBE_NULL | PTR_TO_TCP_SOCK,
+ 	PTR_TO_BTF_ID_OR_NULL		= PTR_MAYBE_NULL | PTR_TO_BTF_ID,
+ 	PTR_TO_MEM_OR_NULL		= PTR_MAYBE_NULL | PTR_TO_MEM,
+ 
+ 	/* This must be the last entry. Its purpose is to ensure the enum is
+ 	 * wide enough to hold the higher bits reserved for bpf_type_flag.
+ 	 */
+ 	__BPF_REG_TYPE_LIMIT	= BPF_TYPE_LIMIT,
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  };
 -static_assert(__BPF_REG_TYPE_MAX <= BPF_BASE_TYPE_LIMIT);
  
  /* The information passed from prog-specific *_is_valid_access
   * back to the verifier.
diff --cc include/linux/bpf_verifier.h
index 828d08afeee0,143401d4c9d9..000000000000
--- a/include/linux/bpf_verifier.h
+++ b/include/linux/bpf_verifier.h
@@@ -452,6 -478,16 +454,19 @@@ struct bpf_verifier_env 
  	/* longest register parentage chain walked for liveness marking */
  	u32 longest_mark_read_walk;
  	bpfptr_t fd_array;
++<<<<<<< HEAD
++=======
+ 
+ 	/* bit mask to keep track of whether a register has been accessed
+ 	 * since the last time the function state was printed
+ 	 */
+ 	u32 scratched_regs;
+ 	/* Same as scratched_regs but for stack slots */
+ 	u64 scratched_stack_slots;
+ 	u32 prev_log_len, prev_insn_print_len;
+ 	/* buffer used in reg_type_str() to generate reg_type string */
+ 	char type_str_buf[TYPE_STR_BUF_LEN];
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  };
  
  __printf(2, 0) void bpf_verifier_vlog(struct bpf_verifier_log *log,
diff --cc kernel/bpf/verifier.c
index 627d7910d79e,97e9d3f31443..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -627,9 -669,11 +625,9 @@@ static void print_verifier_state(struc
  		t = reg->type;
  		if (t == NOT_INIT)
  			continue;
 -		if (!print_all && !reg_scratched(env, i))
 -			continue;
  		verbose(env, " R%d", i);
  		print_liveness(env, reg->live);
- 		verbose(env, "=%s", reg_type_str[t]);
+ 		verbose(env, "=%s", reg_type_str(env, t));
  		if (t == SCALAR_VALUE && reg->precise)
  			verbose(env, "P");
  		if ((t == SCALAR_VALUE || t == PTR_TO_STACK) &&
@@@ -716,12 -758,14 +712,12 @@@
  		types_buf[BPF_REG_SIZE] = 0;
  		if (!valid)
  			continue;
 -		if (!print_all && !stack_slot_scratched(env, i))
 -			continue;
  		verbose(env, " fp%d", (-i - 1) * BPF_REG_SIZE);
  		print_liveness(env, state->stack[i].spilled_ptr.live);
 -		if (is_spilled_reg(&state->stack[i])) {
 +		if (state->stack[i].slot_type[0] == STACK_SPILL) {
  			reg = &state->stack[i].spilled_ptr;
  			t = reg->type;
- 			verbose(env, "=%s", reg_type_str[t]);
+ 			verbose(env, "=%s", reg_type_str(env, t));
  			if (t == SCALAR_VALUE && reg->precise)
  				verbose(env, "P");
  			if (t == SCALAR_VALUE && tnum_is_const(reg->var_off))
@@@ -5942,6 -6437,8 +5906,11 @@@ static int check_helper_call(struct bpf
  			     int *insn_idx_p)
  {
  	const struct bpf_func_proto *fn = NULL;
++<<<<<<< HEAD
++=======
+ 	enum bpf_return_type ret_type;
+ 	enum bpf_type_flag ret_flag;
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  	struct bpf_reg_state *regs;
  	struct bpf_call_arg_meta meta;
  	int insn_idx = *insn_idx_p;
@@@ -6068,13 -6578,14 +6037,19 @@@
  	regs[BPF_REG_0].subreg_def = DEF_NOT_SUBREG;
  
  	/* update return register (already marked as written above) */
++<<<<<<< HEAD
 +	if (fn->ret_type == RET_INTEGER) {
++=======
+ 	ret_type = fn->ret_type;
+ 	ret_flag = type_flag(fn->ret_type);
+ 	if (ret_type == RET_INTEGER) {
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  		/* sets type to SCALAR_VALUE */
  		mark_reg_unknown(env, regs, BPF_REG_0);
 -	} else if (ret_type == RET_VOID) {
 +	} else if (fn->ret_type == RET_VOID) {
  		regs[BPF_REG_0].type = NOT_INIT;
 -	} else if (base_type(ret_type) == RET_PTR_TO_MAP_VALUE) {
 +	} else if (fn->ret_type == RET_PTR_TO_MAP_VALUE_OR_NULL ||
 +		   fn->ret_type == RET_PTR_TO_MAP_VALUE) {
  		/* There is no offset yet applied, variable or fixed */
  		mark_reg_known_zero(env, regs, BPF_REG_0);
  		/* remember map_ptr, so that check_map_access()
@@@ -6087,28 -6598,26 +6062,47 @@@
  			return -EINVAL;
  		}
  		regs[BPF_REG_0].map_ptr = meta.map_ptr;
++<<<<<<< HEAD
 +		if (fn->ret_type == RET_PTR_TO_MAP_VALUE) {
 +			regs[BPF_REG_0].type = PTR_TO_MAP_VALUE;
 +			if (map_value_has_spin_lock(meta.map_ptr))
 +				regs[BPF_REG_0].id = ++env->id_gen;
 +		} else {
 +			regs[BPF_REG_0].type = PTR_TO_MAP_VALUE_OR_NULL;
++=======
+ 		regs[BPF_REG_0].map_uid = meta.map_uid;
+ 		regs[BPF_REG_0].type = PTR_TO_MAP_VALUE | ret_flag;
+ 		if (!type_may_be_null(ret_type) &&
+ 		    map_value_has_spin_lock(meta.map_ptr)) {
+ 			regs[BPF_REG_0].id = ++env->id_gen;
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  		}
 -	} else if (base_type(ret_type) == RET_PTR_TO_SOCKET) {
 +	} else if (fn->ret_type == RET_PTR_TO_SOCKET_OR_NULL) {
 +		mark_reg_known_zero(env, regs, BPF_REG_0);
++<<<<<<< HEAD
 +		regs[BPF_REG_0].type = PTR_TO_SOCKET_OR_NULL;
 +	} else if (fn->ret_type == RET_PTR_TO_SOCK_COMMON_OR_NULL) {
  		mark_reg_known_zero(env, regs, BPF_REG_0);
 +		regs[BPF_REG_0].type = PTR_TO_SOCK_COMMON_OR_NULL;
 +	} else if (fn->ret_type == RET_PTR_TO_TCP_SOCK_OR_NULL) {
 +		mark_reg_known_zero(env, regs, BPF_REG_0);
 +		regs[BPF_REG_0].type = PTR_TO_TCP_SOCK_OR_NULL;
 +	} else if (fn->ret_type == RET_PTR_TO_ALLOC_MEM_OR_NULL) {
++=======
+ 		regs[BPF_REG_0].type = PTR_TO_SOCKET | ret_flag;
+ 	} else if (base_type(ret_type) == RET_PTR_TO_SOCK_COMMON) {
+ 		mark_reg_known_zero(env, regs, BPF_REG_0);
+ 		regs[BPF_REG_0].type = PTR_TO_SOCK_COMMON | ret_flag;
+ 	} else if (base_type(ret_type) == RET_PTR_TO_TCP_SOCK) {
  		mark_reg_known_zero(env, regs, BPF_REG_0);
- 		regs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;
+ 		regs[BPF_REG_0].type = PTR_TO_TCP_SOCK | ret_flag;
+ 	} else if (base_type(ret_type) == RET_PTR_TO_ALLOC_MEM) {
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
+ 		mark_reg_known_zero(env, regs, BPF_REG_0);
+ 		regs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;
  		regs[BPF_REG_0].mem_size = meta.mem_size;
 -	} else if (base_type(ret_type) == RET_PTR_TO_MEM_OR_BTF_ID) {
 +	} else if (fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID_OR_NULL ||
 +		   fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID) {
  		const struct btf_type *t;
  
  		mark_reg_known_zero(env, regs, BPF_REG_0);
@@@ -6126,14 -6635,10 +6120,21 @@@
  					tname, PTR_ERR(ret));
  				return -EINVAL;
  			}
++<<<<<<< HEAD
 +			regs[BPF_REG_0].type =
 +				fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID ?
 +				PTR_TO_MEM : PTR_TO_MEM_OR_NULL;
 +			regs[BPF_REG_0].mem_size = tsize;
 +		} else {
 +			regs[BPF_REG_0].type =
 +				fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID ?
 +				PTR_TO_BTF_ID : PTR_TO_BTF_ID_OR_NULL;
++=======
+ 			regs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;
+ 			regs[BPF_REG_0].mem_size = tsize;
+ 		} else {
+ 			regs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  			regs[BPF_REG_0].btf = meta.ret_btf;
  			regs[BPF_REG_0].btf_id = meta.ret_btf_id;
  		}
@@@ -6142,13 -6646,12 +6143,17 @@@
  		int ret_btf_id;
  
  		mark_reg_known_zero(env, regs, BPF_REG_0);
++<<<<<<< HEAD
 +		regs[BPF_REG_0].type = fn->ret_type == RET_PTR_TO_BTF_ID ?
 +						     PTR_TO_BTF_ID :
 +						     PTR_TO_BTF_ID_OR_NULL;
++=======
+ 		regs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  		ret_btf_id = *fn->ret_btf_id;
  		if (ret_btf_id == 0) {
 -			verbose(env, "invalid return type %u of func %s#%d\n",
 -				base_type(ret_type), func_id_name(func_id),
 -				func_id);
 +			verbose(env, "invalid return type %d of func %s#%d\n",
 +				fn->ret_type, func_id_name(func_id), func_id);
  			return -EINVAL;
  		}
  		/* current BPF helper definitions are only coming from
@@@ -9114,6 -9633,22 +9118,25 @@@ static int check_return_code(struct bpf
  	}
  
  	reg = cur_regs(env) + BPF_REG_0;
++<<<<<<< HEAD
++=======
+ 
+ 	if (frame->in_async_callback_fn) {
+ 		/* enforce return zero from async callbacks like timer */
+ 		if (reg->type != SCALAR_VALUE) {
+ 			verbose(env, "In async callback the register R0 is not a known value (%s)\n",
+ 				reg_type_str(env, reg->type));
+ 			return -EINVAL;
+ 		}
+ 
+ 		if (!tnum_in(tnum_const(0), reg->var_off)) {
+ 			verbose_invalid_scalar(env, reg, &range, "async callback", "R0");
+ 			return -EINVAL;
+ 		}
+ 		return 0;
+ 	}
+ 
++>>>>>>> c25b2ae13603 (bpf: Replace PTR_TO_XXX_OR_NULL with PTR_TO_XXX | PTR_MAYBE_NULL)
  	if (is_subprog) {
  		if (reg->type != SCALAR_VALUE) {
  			verbose(env, "At subprogram exit the register R0 is not a scalar value (%s)\n",
* Unmerged path include/linux/bpf.h
* Unmerged path include/linux/bpf_verifier.h
diff --git a/kernel/bpf/btf.c b/kernel/bpf/btf.c
index 89da4652c9ca..b54f1584c2b6 100644
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@ -4753,10 +4753,13 @@ bool btf_ctx_access(int off, int size, enum bpf_access_type type,
 	/* check for PTR_TO_RDONLY_BUF_OR_NULL or PTR_TO_RDWR_BUF_OR_NULL */
 	for (i = 0; i < prog->aux->ctx_arg_info_size; i++) {
 		const struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];
+		u32 type, flag;
 
+		type = base_type(ctx_arg_info->reg_type);
+		flag = type_flag(ctx_arg_info->reg_type);
 		if (ctx_arg_info->offset == off &&
-		    (ctx_arg_info->reg_type == PTR_TO_RDONLY_BUF_OR_NULL ||
-		     ctx_arg_info->reg_type == PTR_TO_RDWR_BUF_OR_NULL)) {
+		    (type == PTR_TO_RDWR_BUF || type == PTR_TO_RDONLY_BUF) &&
+		    (flag & PTR_MAYBE_NULL)) {
 			info->reg_type = ctx_arg_info->reg_type;
 			return true;
 		}
diff --git a/kernel/bpf/map_iter.c b/kernel/bpf/map_iter.c
index 6a9542af4212..631f0e44b7a9 100644
--- a/kernel/bpf/map_iter.c
+++ b/kernel/bpf/map_iter.c
@@ -174,9 +174,9 @@ static const struct bpf_iter_reg bpf_map_elem_reg_info = {
 	.ctx_arg_info_size	= 2,
 	.ctx_arg_info		= {
 		{ offsetof(struct bpf_iter__bpf_map_elem, key),
-		  PTR_TO_RDONLY_BUF_OR_NULL },
+		  PTR_TO_RDONLY_BUF | PTR_MAYBE_NULL },
 		{ offsetof(struct bpf_iter__bpf_map_elem, value),
-		  PTR_TO_RDWR_BUF_OR_NULL },
+		  PTR_TO_RDWR_BUF | PTR_MAYBE_NULL },
 	},
 };
 
* Unmerged path kernel/bpf/verifier.c
diff --git a/net/core/bpf_sk_storage.c b/net/core/bpf_sk_storage.c
index 903bd4b8d209..83842edf87e0 100644
--- a/net/core/bpf_sk_storage.c
+++ b/net/core/bpf_sk_storage.c
@@ -929,7 +929,7 @@ static struct bpf_iter_reg bpf_sk_storage_map_reg_info = {
 		{ offsetof(struct bpf_iter__bpf_sk_storage_map, sk),
 		  PTR_TO_BTF_ID_OR_NULL },
 		{ offsetof(struct bpf_iter__bpf_sk_storage_map, value),
-		  PTR_TO_RDWR_BUF_OR_NULL },
+		  PTR_TO_RDWR_BUF | PTR_MAYBE_NULL },
 	},
 	.seq_info		= &iter_seq_info,
 };
diff --git a/net/core/sock_map.c b/net/core/sock_map.c
index a12337bdfb02..92a10c8d61c9 100644
--- a/net/core/sock_map.c
+++ b/net/core/sock_map.c
@@ -1587,7 +1587,7 @@ static struct bpf_iter_reg sock_map_iter_reg = {
 	.ctx_arg_info_size	= 2,
 	.ctx_arg_info		= {
 		{ offsetof(struct bpf_iter__sockmap, key),
-		  PTR_TO_RDONLY_BUF_OR_NULL },
+		  PTR_TO_RDONLY_BUF | PTR_MAYBE_NULL },
 		{ offsetof(struct bpf_iter__sockmap, sk),
 		  PTR_TO_BTF_ID_OR_NULL },
 	},
