x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr'

jira LE-1907
cve CVE-2024-2201
Rebuild_History Non-Buildable kernel-4.18.0-553.16.1.el8_10
commit-author Ingo Molnar <mingo@kernel.org>
commit d0485730d2189ffe5d986d4e9e191f1e4d5ffd24
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.16.1.el8_10/d0485730.failed

So we are using the 'ia32_cap' value in a number of places,
which got its name from MSR_IA32_ARCH_CAPABILITIES MSR register.

But there's very little 'IA32' about it - this isn't 32-bit only
code, nor does it originate from there, it's just a historic
quirk that many Intel MSR names are prefixed with IA32_.

This is already clear from the helper method around the MSR:
x86_read_arch_cap_msr(), which doesn't have the IA32 prefix.

So rename 'ia32_cap' to 'x86_arch_cap_msr' to be consistent with
its role and with the naming of the helper function.

	Signed-off-by: Ingo Molnar <mingo@kernel.org>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Nikolay Borisov <nik.borisov@suse.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Sean Christopherson <seanjc@google.com>
Link: https://lore.kernel.org/r/9592a18a814368e75f8f4b9d74d3883aa4fd1eaf.1712813475.git.jpoimboe@kernel.org
(cherry picked from commit d0485730d2189ffe5d986d4e9e191f1e4d5ffd24)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/apic/apic.c
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
diff --cc arch/x86/kernel/apic/apic.c
index 53a9426a6551,c342c4aa9c68..000000000000
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@@ -1739,6 -1685,19 +1739,22 @@@ enum 
  };
  static int x2apic_state;
  
++<<<<<<< HEAD
++=======
+ static bool x2apic_hw_locked(void)
+ {
+ 	u64 x86_arch_cap_msr;
+ 	u64 msr;
+ 
+ 	x86_arch_cap_msr = x86_read_arch_cap_msr();
+ 	if (x86_arch_cap_msr & ARCH_CAP_XAPIC_DISABLE) {
+ 		rdmsrl(MSR_IA32_XAPIC_DISABLE_STATUS, msr);
+ 		return (msr & LEGACY_XAPIC_DISABLED);
+ 	}
+ 	return false;
+ }
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static void __x2apic_disable(void)
  {
  	u64 msr;
diff --cc arch/x86/kernel/cpu/bugs.c
index 845ec3ddb3cc,1b0cfc136432..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -63,6 -61,8 +63,11 @@@ EXPORT_SYMBOL_GPL(x86_spec_ctrl_current
  u64 x86_pred_cmd __ro_after_init = PRED_CMD_IBPB;
  EXPORT_SYMBOL_GPL(x86_pred_cmd);
  
++<<<<<<< HEAD
++=======
+ static u64 __ro_after_init x86_arch_cap_msr;
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static DEFINE_MUTEX(spec_ctrl_mutex);
  
  void (*x86_return_thunk)(void) __ro_after_init = __x86_return_thunk;
@@@ -157,6 -146,8 +162,11 @@@ void __init check_bugs(void
  		x86_spec_ctrl_base &= ~SPEC_CTRL_MITIGATIONS_MASK;
  	}
  
++<<<<<<< HEAD
++=======
+ 	x86_arch_cap_msr = x86_read_arch_cap_msr();
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  	/* Select the proper CPU mitigations before patching alternatives: */
  	spectre_v1_select_mitigation();
  	spectre_v2_select_mitigation();
@@@ -393,9 -343,8 +403,14 @@@ static void __init taa_select_mitigatio
  	 * On MDS_NO=1 CPUs if ARCH_CAP_TSX_CTRL_MSR is not set, microcode
  	 * update is required.
  	 */
++<<<<<<< HEAD
 +	ia32_cap = x86_read_arch_cap_msr();
 +	if ( (ia32_cap & ARCH_CAP_MDS_NO) &&
 +	    !(ia32_cap & ARCH_CAP_TSX_CTRL_MSR))
++=======
+ 	if ( (x86_arch_cap_msr & ARCH_CAP_MDS_NO) &&
+ 	    !(x86_arch_cap_msr & ARCH_CAP_TSX_CTRL_MSR))
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		taa_mitigation = TAA_MITIGATION_UCODE_NEEDED;
  
  	/*
@@@ -526,6 -478,57 +541,60 @@@ static int __init mmio_stale_data_parse
  early_param("mmio_stale_data", mmio_stale_data_parse_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)	"Register File Data Sampling: " fmt
+ 
+ enum rfds_mitigations {
+ 	RFDS_MITIGATION_OFF,
+ 	RFDS_MITIGATION_VERW,
+ 	RFDS_MITIGATION_UCODE_NEEDED,
+ };
+ 
+ /* Default mitigation for Register File Data Sampling */
+ static enum rfds_mitigations rfds_mitigation __ro_after_init =
+ 	IS_ENABLED(CONFIG_MITIGATION_RFDS) ? RFDS_MITIGATION_VERW : RFDS_MITIGATION_OFF;
+ 
+ static const char * const rfds_strings[] = {
+ 	[RFDS_MITIGATION_OFF]			= "Vulnerable",
+ 	[RFDS_MITIGATION_VERW]			= "Mitigation: Clear Register File",
+ 	[RFDS_MITIGATION_UCODE_NEEDED]		= "Vulnerable: No microcode",
+ };
+ 
+ static void __init rfds_select_mitigation(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_RFDS) || cpu_mitigations_off()) {
+ 		rfds_mitigation = RFDS_MITIGATION_OFF;
+ 		return;
+ 	}
+ 	if (rfds_mitigation == RFDS_MITIGATION_OFF)
+ 		return;
+ 
+ 	if (x86_arch_cap_msr & ARCH_CAP_RFDS_CLEAR)
+ 		setup_force_cpu_cap(X86_FEATURE_CLEAR_CPU_BUF);
+ 	else
+ 		rfds_mitigation = RFDS_MITIGATION_UCODE_NEEDED;
+ }
+ 
+ static __init int rfds_parse_cmdline(char *str)
+ {
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_RFDS))
+ 		return 0;
+ 
+ 	if (!strcmp(str, "off"))
+ 		rfds_mitigation = RFDS_MITIGATION_OFF;
+ 	else if (!strcmp(str, "on"))
+ 		rfds_mitigation = RFDS_MITIGATION_VERW;
+ 
+ 	return 0;
+ }
+ early_param("reg_file_data_sampling", rfds_parse_cmdline);
+ 
+ #undef pr_fmt
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  #define pr_fmt(fmt)     "" fmt
  
  static void __init md_clear_update_mitigation(void)
@@@ -652,8 -664,7 +721,12 @@@ static void __init srbds_select_mitigat
  	 * are only exposed to SRBDS when TSX is enabled or when CPU is affected
  	 * by Processor MMIO Stale Data vulnerability.
  	 */
++<<<<<<< HEAD
 +	ia32_cap = x86_read_arch_cap_msr();
 +	if ((ia32_cap & ARCH_CAP_MDS_NO) && !boot_cpu_has(X86_FEATURE_RTM) &&
++=======
+ 	if ((x86_arch_cap_msr & ARCH_CAP_MDS_NO) && !boot_cpu_has(X86_FEATURE_RTM) &&
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  	    !boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA))
  		srbds_mitigation = SRBDS_MITIGATION_TSX_OFF;
  	else if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
@@@ -768,7 -807,7 +841,11 @@@ static void __init gds_select_mitigatio
  	/* Will verify below that mitigation _can_ be disabled */
  
  	/* No microcode */
++<<<<<<< HEAD
 +	if (!(x86_read_arch_cap_msr() & ARCH_CAP_GDS_CTRL)) {
++=======
+ 	if (!(x86_arch_cap_msr & ARCH_CAP_GDS_CTRL)) {
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		if (gds_mitigation == GDS_MITIGATION_FORCE) {
  			/*
  			 * This only needs to be done on the boot CPU so do it
@@@ -2723,6 -2801,23 +2800,26 @@@ static char *pbrsb_eibrs_state(void
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static const char *spectre_bhi_state(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_BHI))
+ 		return "; BHI: Not affected";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_HW))
+ 		return "; BHI: BHI_DIS_S";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP))
+ 		return "; BHI: SW loop, KVM: SW loop";
+ 	else if (boot_cpu_has(X86_FEATURE_RETPOLINE) &&
+ 		 !(x86_arch_cap_msr & ARCH_CAP_RRSBA))
+ 		return "; BHI: Retpoline";
+ 	else if  (boot_cpu_has(X86_FEATURE_CLEAR_BHB_LOOP_ON_VMEXIT))
+ 		return "; BHI: Syscall hardening, KVM: SW loop";
+ 
+ 	return "; BHI: Vulnerable (Syscall hardening enabled)";
+ }
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static ssize_t spectre_v2_show_state(char *buf)
  {
  	if (spectre_v2_enabled == SPECTRE_V2_LFENCE)
diff --cc arch/x86/kernel/cpu/common.c
index cce3aa9507f0,605c26c009c8..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -1200,24 -1284,42 +1200,45 @@@ static bool __init cpu_matches(const st
  
  u64 x86_read_arch_cap_msr(void)
  {
- 	u64 ia32_cap = 0;
+ 	u64 x86_arch_cap_msr = 0;
  
  	if (boot_cpu_has(X86_FEATURE_ARCH_CAPABILITIES))
- 		rdmsrl(MSR_IA32_ARCH_CAPABILITIES, ia32_cap);
+ 		rdmsrl(MSR_IA32_ARCH_CAPABILITIES, x86_arch_cap_msr);
  
- 	return ia32_cap;
+ 	return x86_arch_cap_msr;
  }
  
- static bool arch_cap_mmio_immune(u64 ia32_cap)
+ static bool arch_cap_mmio_immune(u64 x86_arch_cap_msr)
  {
- 	return (ia32_cap & ARCH_CAP_FBSDP_NO &&
- 		ia32_cap & ARCH_CAP_PSDP_NO &&
- 		ia32_cap & ARCH_CAP_SBDR_SSDP_NO);
+ 	return (x86_arch_cap_msr & ARCH_CAP_FBSDP_NO &&
+ 		x86_arch_cap_msr & ARCH_CAP_PSDP_NO &&
+ 		x86_arch_cap_msr & ARCH_CAP_SBDR_SSDP_NO);
  }
  
++<<<<<<< HEAD
++=======
+ static bool __init vulnerable_to_rfds(u64 x86_arch_cap_msr)
+ {
+ 	/* The "immunity" bit trumps everything else: */
+ 	if (x86_arch_cap_msr & ARCH_CAP_RFDS_NO)
+ 		return false;
+ 
+ 	/*
+ 	 * VMMs set ARCH_CAP_RFDS_CLEAR for processors not in the blacklist to
+ 	 * indicate that mitigation is needed because guest is running on a
+ 	 * vulnerable hardware or may migrate to such hardware:
+ 	 */
+ 	if (x86_arch_cap_msr & ARCH_CAP_RFDS_CLEAR)
+ 		return true;
+ 
+ 	/* Only consult the blacklist when there is no enumeration: */
+ 	return cpu_matches(cpu_vuln_blacklist, RFDS);
+ }
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  static void __init cpu_set_bug_bits(struct cpuinfo_x86 *c)
  {
- 	u64 ia32_cap = x86_read_arch_cap_msr();
+ 	u64 x86_arch_cap_msr = x86_read_arch_cap_msr();
  
  	/* Set ITLB_MULTIHIT bug if cpu is not in the whitelist and not mitigated */
  	if (!cpu_matches(cpu_vuln_whitelist, NO_ITLB_MULTIHIT) &&
@@@ -1228,21 -1330,28 +1249,27 @@@
  		return;
  
  	setup_force_cpu_bug(X86_BUG_SPECTRE_V1);
 -
 -	if (!cpu_matches(cpu_vuln_whitelist, NO_SPECTRE_V2))
 -		setup_force_cpu_bug(X86_BUG_SPECTRE_V2);
 +	setup_force_cpu_bug(X86_BUG_SPECTRE_V2);
  
  	if (!cpu_matches(cpu_vuln_whitelist, NO_SSB) &&
- 	    !(ia32_cap & ARCH_CAP_SSB_NO) &&
+ 	    !(x86_arch_cap_msr & ARCH_CAP_SSB_NO) &&
  	   !cpu_has(c, X86_FEATURE_AMD_SSB_NO))
  		setup_force_cpu_bug(X86_BUG_SPEC_STORE_BYPASS);
  
  	/*
  	 * AMD's AutoIBRS is equivalent to Intel's eIBRS - use the Intel feature
  	 * flag and protect from vendor-specific bugs via the whitelist.
 -	 *
 -	 * Don't use AutoIBRS when SNP is enabled because it degrades host
 -	 * userspace indirect branch performance.
  	 */
++<<<<<<< HEAD
 +	if ((ia32_cap & ARCH_CAP_IBRS_ALL) || cpu_has(c, X86_FEATURE_AUTOIBRS)) {
++=======
+ 	if ((x86_arch_cap_msr & ARCH_CAP_IBRS_ALL) ||
+ 	    (cpu_has(c, X86_FEATURE_AUTOIBRS) &&
+ 	     !cpu_feature_enabled(X86_FEATURE_SEV_SNP))) {
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  		setup_force_cpu_cap(X86_FEATURE_IBRS_ENHANCED);
  		if (!cpu_matches(cpu_vuln_whitelist, NO_EIBRS_PBRSB) &&
- 		    !(ia32_cap & ARCH_CAP_PBRSB_NO))
+ 		    !(x86_arch_cap_msr & ARCH_CAP_PBRSB_NO))
  			setup_force_cpu_bug(X86_BUG_EIBRS_PBRSB);
  	}
  
@@@ -1302,8 -1411,7 +1329,12 @@@
  	}
  
  	if (!cpu_has(c, X86_FEATURE_BTC_NO)) {
++<<<<<<< HEAD
 +		if (cpu_matches(cpu_vuln_blacklist, RETBLEED) ||
 +		   ((ia32_cap & ARCH_CAP_RSBA) && !cpu_in_retbleed_whitelist(c)))
++=======
+ 		if (cpu_matches(cpu_vuln_blacklist, RETBLEED) || (x86_arch_cap_msr & ARCH_CAP_RSBA))
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  			setup_force_cpu_bug(X86_BUG_RETBLEED);
  	}
  
@@@ -1322,6 -1433,16 +1353,19 @@@
  	    boot_cpu_has(X86_FEATURE_AVX))
  		setup_force_cpu_bug(X86_BUG_GDS);
  
++<<<<<<< HEAD
++=======
+ 	if (vulnerable_to_rfds(x86_arch_cap_msr))
+ 		setup_force_cpu_bug(X86_BUG_RFDS);
+ 
+ 	/* When virtualized, eIBRS could be hidden, assume vulnerable */
+ 	if (!(x86_arch_cap_msr & ARCH_CAP_BHI_NO) &&
+ 	    !cpu_matches(cpu_vuln_whitelist, NO_BHI) &&
+ 	    (boot_cpu_has(X86_FEATURE_IBRS_ENHANCED) ||
+ 	     boot_cpu_has(X86_FEATURE_HYPERVISOR)))
+ 		setup_force_cpu_bug(X86_BUG_BHI);
+ 
++>>>>>>> d0485730d218 (x86/bugs: Rename various 'ia32_cap' variables to 'x86_arch_cap_msr')
  	if (cpu_matches(cpu_vuln_whitelist, NO_MELTDOWN))
  		return;
  
* Unmerged path arch/x86/kernel/apic/apic.c
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
