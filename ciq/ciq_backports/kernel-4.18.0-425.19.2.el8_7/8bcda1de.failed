KVM: x86: smm: use smram struct for 64 bit smram load/restore

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.19.2.el8_7
commit-author Maxim Levitsky <mlevitsk@redhat.com>
commit 8bcda1dee95ae88cade0ad671e0f4d371c005c4d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.19.2.el8_7/8bcda1de.failed

Use kvm_smram_state_64 struct to save/restore the 64 bit SMM state
(used when X86_FEATURE_LM is present in the guest CPUID,
regardless of 32-bitness of the guest).

	Signed-off-by: Maxim Levitsky <mlevitsk@redhat.com>
Message-Id: <20221025124741.228045-20-mlevitsk@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 8bcda1dee95ae88cade0ad671e0f4d371c005c4d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/smm.c
diff --cc arch/x86/kvm/smm.c
index e4ce2d06521c,e3ecb1f84168..000000000000
--- a/arch/x86/kvm/smm.c
+++ b/arch/x86/kvm/smm.c
@@@ -197,15 -276,18 +189,19 @@@ void enter_smm(struct kvm_vcpu *vcpu
  	struct kvm_segment cs, ds;
  	struct desc_ptr dt;
  	unsigned long cr0;
 -	union kvm_smram smram;
 -
 -	check_smram_offsets();
 -
 -	memset(smram.bytes, 0, sizeof(smram.bytes));
 +	char buf[512];
  
 +	memset(buf, 0, 512);
  #ifdef CONFIG_X86_64
  	if (guest_cpuid_has(vcpu, X86_FEATURE_LM))
++<<<<<<< HEAD
 +		enter_smm_save_state_64(vcpu, buf);
++=======
+ 		enter_smm_save_state_64(vcpu, &smram.smram64);
++>>>>>>> 8bcda1dee95a (KVM: x86: smm: use smram struct for 64 bit smram load/restore)
  	else
  #endif
 -		enter_smm_save_state_32(vcpu, &smram.smram32);
 +		enter_smm_save_state_32(vcpu, buf);
  
  	/*
  	 * Give enter_smm() a chance to make ISA-specific changes to the vCPU
@@@ -441,12 -500,10 +436,14 @@@ static int rsm_load_state_32(struct x86
  
  #ifdef CONFIG_X86_64
  static int rsm_load_state_64(struct x86_emulate_ctxt *ctxt,
++<<<<<<< HEAD
 +			     const char *smstate)
++=======
+ 			     const struct kvm_smram_state_64 *smstate)
++>>>>>>> 8bcda1dee95a (KVM: x86: smm: use smram struct for 64 bit smram load/restore)
  {
  	struct kvm_vcpu *vcpu = ctxt->vcpu;
- 	struct kvm_segment desc;
  	struct desc_ptr dt;
- 	u64 val, cr0, cr3, cr4;
  	int i, r;
  
  	for (i = 0; i < 16; i++)
@@@ -580,8 -621,8 +561,12 @@@ int emulator_leave_smm(struct x86_emula
  
  #ifdef CONFIG_X86_64
  	if (guest_cpuid_has(vcpu, X86_FEATURE_LM))
++<<<<<<< HEAD
 +		return rsm_load_state_64(ctxt, buf);
++=======
+ 		return rsm_load_state_64(ctxt, &smram.smram64);
++>>>>>>> 8bcda1dee95a (KVM: x86: smm: use smram struct for 64 bit smram load/restore)
  	else
  #endif
 -		return rsm_load_state_32(ctxt, &smram.smram32);
 +		return rsm_load_state_32(ctxt, buf);
  }
* Unmerged path arch/x86/kvm/smm.c
