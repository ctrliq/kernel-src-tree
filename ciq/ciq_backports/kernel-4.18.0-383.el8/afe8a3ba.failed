ice: xsk: return xsk buffers back to pool when cleaning the ring

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-383.el8
commit-author Maciej Fijalkowski <maciej.fijalkowski@intel.com>
commit afe8a3ba85ec2a6b6849367e25c06a2f8e0ddd05
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-383.el8/afe8a3ba.failed

Currently we only NULL the xdp_buff pointer in the internal SW ring but
we never give it back to the xsk buffer pool. This means that buffers
can be leaked out of the buff pool and never be used again.

Add missing xsk_buff_free() call to the routine that is supposed to
clean the entries that are left in the ring so that these buffers in the
umem can be used by other sockets.

Also, only go through the space that is actually left to be cleaned
instead of a whole ring.

Fixes: 2d4238f55697 ("ice: Add support for AF_XDP")
	Signed-off-by: Magnus Karlsson <magnus.karlsson@intel.com>
	Signed-off-by: Maciej Fijalkowski <maciej.fijalkowski@intel.com>
	Tested-by: Kiran Bhandare <kiranx.bhandare@intel.com>
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit afe8a3ba85ec2a6b6849367e25c06a2f8e0ddd05)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_xsk.c
diff --cc drivers/net/ethernet/intel/ice/ice_xsk.c
index 295bfdac4d32,8593717a755e..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_xsk.c
+++ b/drivers/net/ethernet/intel/ice/ice_xsk.c
@@@ -816,15 -811,15 +816,25 @@@ bool ice_xsk_any_rx_ring_ena(struct ice
   */
  void ice_xsk_clean_rx_ring(struct ice_rx_ring *rx_ring)
  {
- 	u16 i;
+ 	u16 count_mask = rx_ring->count - 1;
+ 	u16 ntc = rx_ring->next_to_clean;
+ 	u16 ntu = rx_ring->next_to_use;
  
++<<<<<<< HEAD
 +	for (i = 0; i < rx_ring->count; i++) {
 +		struct ice_rx_buf *rx_buf = &rx_ring->rx_buf[i];
 +
 +		if (!rx_buf->xdp)
 +			continue;
 +
 +		rx_buf->xdp = NULL;
++=======
+ 	for ( ; ntc != ntu; ntc = (ntc + 1) & count_mask) {
+ 		struct xdp_buff **xdp = &rx_ring->xdp_buf[ntc];
+ 
+ 		xsk_buff_free(*xdp);
+ 		*xdp = NULL;
++>>>>>>> afe8a3ba85ec (ice: xsk: return xsk buffers back to pool when cleaning the ring)
  	}
  }
  
* Unmerged path drivers/net/ethernet/intel/ice/ice_xsk.c
