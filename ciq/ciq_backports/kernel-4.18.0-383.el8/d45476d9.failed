x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE

jira LE-1907
cve CVE-2022-0002
cve CVE-2022-0001
Rebuild_History Non-Buildable kernel-4.18.0-383.el8
commit-author Peter Zijlstra (Intel) <peterz@infradead.org>
commit d45476d9832409371537013ebdd8dc1a7781f97a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-383.el8/d45476d9.failed

The RETPOLINE_AMD name is unfortunate since it isn't necessarily
AMD only, in fact Hygon also uses it. Furthermore it will likely be
sufficient for some Intel processors. Therefore rename the thing to
RETPOLINE_LFENCE to better describe what it is.

Add the spectre_v2=retpoline,lfence option as an alias to
spectre_v2=retpoline,amd to preserve existing setups. However, the output
of /sys/devices/system/cpu/vulnerabilities/spectre_v2 will be changed.

  [ bp: Fix typos, massage. ]

Co-developed-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
(cherry picked from commit d45476d9832409371537013ebdd8dc1a7781f97a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/nospec-branch.h
#	arch/x86/kernel/alternative.c
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/lib/retpoline.S
#	arch/x86/net/bpf_jit_comp.c
diff --cc arch/x86/include/asm/nospec-branch.h
index a154c2d99bc0,c91d97bee237..000000000000
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@@ -116,23 -82,21 +116,35 @@@
   */
  .macro JMP_NOSPEC reg:req
  #ifdef CONFIG_RETPOLINE
++<<<<<<< HEAD
 +	ANNOTATE_NOSPEC_ALTERNATIVE
 +	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; jmp *\reg),	\
 +		__stringify(RETPOLINE_JMP \reg), X86_FEATURE_RETPOLINE,	\
 +		__stringify(lfence; ANNOTATE_RETPOLINE_SAFE; jmp *\reg), X86_FEATURE_RETPOLINE_AMD
++=======
+ 	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; jmp *%\reg), \
+ 		      __stringify(jmp __x86_indirect_thunk_\reg), X86_FEATURE_RETPOLINE, \
+ 		      __stringify(lfence; ANNOTATE_RETPOLINE_SAFE; jmp *%\reg), X86_FEATURE_RETPOLINE_LFENCE
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  #else
 -	jmp	*%\reg
 +	jmp	*\reg
  #endif
  .endm
  
  .macro CALL_NOSPEC reg:req
  #ifdef CONFIG_RETPOLINE
++<<<<<<< HEAD
 +	ANNOTATE_NOSPEC_ALTERNATIVE
 +	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; call *\reg),	\
 +		__stringify(RETPOLINE_CALL \reg), X86_FEATURE_RETPOLINE,\
 +		__stringify(lfence; ANNOTATE_RETPOLINE_SAFE; call *\reg), X86_FEATURE_RETPOLINE_AMD
++=======
+ 	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; call *%\reg), \
+ 		      __stringify(call __x86_indirect_thunk_\reg), X86_FEATURE_RETPOLINE, \
+ 		      __stringify(lfence; ANNOTATE_RETPOLINE_SAFE; call *%\reg), X86_FEATURE_RETPOLINE_LFENCE
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  #else
 -	call	*%\reg
 +	call	*\reg
  #endif
  .endm
  
@@@ -181,7 -146,8 +193,12 @@@
  	"lfence;\n"						\
  	ANNOTATE_RETPOLINE_SAFE					\
  	"call *%[thunk_target]\n",				\
++<<<<<<< HEAD
 +	X86_FEATURE_RETPOLINE_AMD)
++=======
+ 	X86_FEATURE_RETPOLINE_LFENCE)
+ 
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  # define THUNK_TARGET(addr) [thunk_target] "r" (addr)
  
  #else /* CONFIG_X86_32 */
@@@ -223,12 -188,9 +240,12 @@@
  /* The Spectre V2 mitigation variants */
  enum spectre_v2_mitigation {
  	SPECTRE_V2_NONE,
- 	SPECTRE_V2_RETPOLINE_GENERIC,
- 	SPECTRE_V2_RETPOLINE_AMD,
+ 	SPECTRE_V2_RETPOLINE,
+ 	SPECTRE_V2_LFENCE,
  	SPECTRE_V2_IBRS_ENHANCED,
 +	SPECTRE_V2_IBRS,
 +	SPECTRE_V2_RETPOLINE_IBRS_USER,
 +	SPECTRE_V2_IBRS_ALWAYS,
  };
  
  /* The indirect branch speculation control variants */
diff --cc arch/x86/kernel/alternative.c
index 2ba3aea41b85,b4470eabf151..000000000000
--- a/arch/x86/kernel/alternative.c
+++ b/arch/x86/kernel/alternative.c
@@@ -419,16 -323,186 +419,184 @@@ void __init_or_module noinline apply_al
  		}
  
  		if (a->replacementlen && is_jmp(replacement[0]))
 -			recompute_jump(a, instr, replacement, insn_buff);
 -
 +			recompute_jump(a, instr, replacement, insnbuf);
 +
++<<<<<<< HEAD
 +		if (a->instrlen > a->replacementlen) {
 +			add_nops(insnbuf + a->replacementlen,
 +				 a->instrlen - a->replacementlen);
 +			insnbuf_sz += a->instrlen - a->replacementlen;
++=======
+ 		for (; insn_buff_sz < a->instrlen; insn_buff_sz++)
+ 			insn_buff[insn_buff_sz] = 0x90;
+ 
+ 		DUMP_BYTES(insn_buff, insn_buff_sz, "%px: final_insn: ", instr);
+ 
+ 		text_poke_early(instr, insn_buff, insn_buff_sz);
+ 
+ next:
+ 		optimize_nops(instr, a->instrlen);
+ 	}
+ }
+ 
+ #if defined(CONFIG_RETPOLINE) && defined(CONFIG_STACK_VALIDATION)
+ 
+ /*
+  * CALL/JMP *%\reg
+  */
+ static int emit_indirect(int op, int reg, u8 *bytes)
+ {
+ 	int i = 0;
+ 	u8 modrm;
+ 
+ 	switch (op) {
+ 	case CALL_INSN_OPCODE:
+ 		modrm = 0x10; /* Reg = 2; CALL r/m */
+ 		break;
+ 
+ 	case JMP32_INSN_OPCODE:
+ 		modrm = 0x20; /* Reg = 4; JMP r/m */
+ 		break;
+ 
+ 	default:
+ 		WARN_ON_ONCE(1);
+ 		return -1;
+ 	}
+ 
+ 	if (reg >= 8) {
+ 		bytes[i++] = 0x41; /* REX.B prefix */
+ 		reg -= 8;
+ 	}
+ 
+ 	modrm |= 0xc0; /* Mod = 3 */
+ 	modrm += reg;
+ 
+ 	bytes[i++] = 0xff; /* opcode */
+ 	bytes[i++] = modrm;
+ 
+ 	return i;
+ }
+ 
+ /*
+  * Rewrite the compiler generated retpoline thunk calls.
+  *
+  * For spectre_v2=off (!X86_FEATURE_RETPOLINE), rewrite them into immediate
+  * indirect instructions, avoiding the extra indirection.
+  *
+  * For example, convert:
+  *
+  *   CALL __x86_indirect_thunk_\reg
+  *
+  * into:
+  *
+  *   CALL *%\reg
+  *
+  * It also tries to inline spectre_v2=retpoline,lfence when size permits.
+  */
+ static int patch_retpoline(void *addr, struct insn *insn, u8 *bytes)
+ {
+ 	retpoline_thunk_t *target;
+ 	int reg, ret, i = 0;
+ 	u8 op, cc;
+ 
+ 	target = addr + insn->length + insn->immediate.value;
+ 	reg = target - __x86_indirect_thunk_array;
+ 
+ 	if (WARN_ON_ONCE(reg & ~0xf))
+ 		return -1;
+ 
+ 	/* If anyone ever does: CALL/JMP *%rsp, we're in deep trouble. */
+ 	BUG_ON(reg == 4);
+ 
+ 	if (cpu_feature_enabled(X86_FEATURE_RETPOLINE) &&
+ 	    !cpu_feature_enabled(X86_FEATURE_RETPOLINE_LFENCE))
+ 		return -1;
+ 
+ 	op = insn->opcode.bytes[0];
+ 
+ 	/*
+ 	 * Convert:
+ 	 *
+ 	 *   Jcc.d32 __x86_indirect_thunk_\reg
+ 	 *
+ 	 * into:
+ 	 *
+ 	 *   Jncc.d8 1f
+ 	 *   [ LFENCE ]
+ 	 *   JMP *%\reg
+ 	 *   [ NOP ]
+ 	 * 1:
+ 	 */
+ 	/* Jcc.d32 second opcode byte is in the range: 0x80-0x8f */
+ 	if (op == 0x0f && (insn->opcode.bytes[1] & 0xf0) == 0x80) {
+ 		cc = insn->opcode.bytes[1] & 0xf;
+ 		cc ^= 1; /* invert condition */
+ 
+ 		bytes[i++] = 0x70 + cc;        /* Jcc.d8 */
+ 		bytes[i++] = insn->length - 2; /* sizeof(Jcc.d8) == 2 */
+ 
+ 		/* Continue as if: JMP.d32 __x86_indirect_thunk_\reg */
+ 		op = JMP32_INSN_OPCODE;
+ 	}
+ 
+ 	/*
+ 	 * For RETPOLINE_LFENCE: prepend the indirect CALL/JMP with an LFENCE.
+ 	 */
+ 	if (cpu_feature_enabled(X86_FEATURE_RETPOLINE_LFENCE)) {
+ 		bytes[i++] = 0x0f;
+ 		bytes[i++] = 0xae;
+ 		bytes[i++] = 0xe8; /* LFENCE */
+ 	}
+ 
+ 	ret = emit_indirect(op, reg, bytes + i);
+ 	if (ret < 0)
+ 		return ret;
+ 	i += ret;
+ 
+ 	for (; i < insn->length;)
+ 		bytes[i++] = BYTES_NOP1;
+ 
+ 	return i;
+ }
+ 
+ /*
+  * Generated by 'objtool --retpoline'.
+  */
+ void __init_or_module noinline apply_retpolines(s32 *start, s32 *end)
+ {
+ 	s32 *s;
+ 
+ 	for (s = start; s < end; s++) {
+ 		void *addr = (void *)s + *s;
+ 		struct insn insn;
+ 		int len, ret;
+ 		u8 bytes[16];
+ 		u8 op1, op2;
+ 
+ 		ret = insn_decode_kernel(&insn, addr);
+ 		if (WARN_ON_ONCE(ret < 0))
+ 			continue;
+ 
+ 		op1 = insn.opcode.bytes[0];
+ 		op2 = insn.opcode.bytes[1];
+ 
+ 		switch (op1) {
+ 		case CALL_INSN_OPCODE:
+ 		case JMP32_INSN_OPCODE:
+ 			break;
+ 
+ 		case 0x0f: /* escape */
+ 			if (op2 >= 0x80 && op2 <= 0x8f)
+ 				break;
+ 			fallthrough;
+ 		default:
+ 			WARN_ON_ONCE(1);
+ 			continue;
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  		}
 +		DUMP_BYTES(insnbuf, insnbuf_sz, "%px: final_insn: ", instr);
  
 -		DPRINTK("retpoline at: %pS (%px) len: %d to: %pS",
 -			addr, addr, insn.length,
 -			addr + insn.length + insn.immediate.value);
 -
 -		len = patch_retpoline(addr, &insn, bytes);
 -		if (len == insn.length) {
 -			optimize_nops(bytes, len);
 -			DUMP_BYTES(((u8*)addr),  len, "%px: orig: ", addr);
 -			DUMP_BYTES(((u8*)bytes), len, "%px: repl: ", addr);
 -			text_poke_early(addr, bytes, len);
 -		}
 +		text_poke_early(instr, insnbuf, insnbuf_sz);
  	}
  }
  
diff --cc arch/x86/kernel/cpu/bugs.c
index 7357f251348a,e3bb8afc6768..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -632,10 -664,7 +632,14 @@@ enum spectre_v2_mitigation_cmd 
  	SPECTRE_V2_CMD_FORCE,
  	SPECTRE_V2_CMD_RETPOLINE,
  	SPECTRE_V2_CMD_RETPOLINE_GENERIC,
++<<<<<<< HEAD
 +	SPECTRE_V2_CMD_RETPOLINE_AMD,
 +	SPECTRE_V2_CMD_RETPOLINE_IBRS_USER,
 +	SPECTRE_V2_CMD_IBRS,
 +	SPECTRE_V2_CMD_IBRS_ALWAYS,
++=======
+ 	SPECTRE_V2_CMD_RETPOLINE_LFENCE,
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  };
  
  enum spectre_v2_user_cmd {
@@@ -795,12 -824,9 +799,12 @@@ set_mode
  
  static const char * const spectre_v2_strings[] = {
  	[SPECTRE_V2_NONE]			= "Vulnerable",
- 	[SPECTRE_V2_RETPOLINE_GENERIC]		= "Mitigation: Full generic retpoline",
- 	[SPECTRE_V2_RETPOLINE_AMD]		= "Mitigation: Full AMD retpoline",
+ 	[SPECTRE_V2_RETPOLINE]			= "Mitigation: Retpolines",
+ 	[SPECTRE_V2_LFENCE]			= "Mitigation: LFENCE",
  	[SPECTRE_V2_IBRS_ENHANCED]		= "Mitigation: Enhanced IBRS",
 +	[SPECTRE_V2_IBRS]			= "Mitigation: IBRS (kernel)",
 +	[SPECTRE_V2_RETPOLINE_IBRS_USER]	= "Mitigation: Full retpoline and IBRS (user space)",
 +	[SPECTRE_V2_IBRS_ALWAYS]		= "Mitigation: IBRS (kernel and user space)",
  };
  
  static const struct {
@@@ -811,12 -837,10 +815,13 @@@
  	{ "off",		SPECTRE_V2_CMD_NONE,		  false },
  	{ "on",			SPECTRE_V2_CMD_FORCE,		  true  },
  	{ "retpoline",		SPECTRE_V2_CMD_RETPOLINE,	  false },
- 	{ "retpoline,amd",	SPECTRE_V2_CMD_RETPOLINE_AMD,	  false },
+ 	{ "retpoline,amd",	SPECTRE_V2_CMD_RETPOLINE_LFENCE,  false },
+ 	{ "retpoline,lfence",	SPECTRE_V2_CMD_RETPOLINE_LFENCE,  false },
  	{ "retpoline,generic",	SPECTRE_V2_CMD_RETPOLINE_GENERIC, false },
  	{ "auto",		SPECTRE_V2_CMD_AUTO,		  false },
 +	{ "ibrs",		SPECTRE_V2_CMD_IBRS,		  false },
 +	{ "ibrs_always",	SPECTRE_V2_CMD_IBRS_ALWAYS,	  false },
 +	{ "retpoline,ibrs_user", SPECTRE_V2_CMD_RETPOLINE_IBRS_USER, false},
  };
  
  static void __init spec_v2_print_cond(const char *reason, bool secure)
@@@ -859,9 -883,9 +864,15 @@@ static enum spectre_v2_mitigation_cmd _
  		return SPECTRE_V2_CMD_AUTO;
  	}
  
++<<<<<<< HEAD
 +	if (cmd == SPECTRE_V2_CMD_RETPOLINE_AMD &&
 +	    boot_cpu_data.x86_vendor != X86_VENDOR_AMD) {
 +		pr_err("retpoline,amd selected but CPU is not AMD. Switching to AUTO select\n");
++=======
+ 	if ((cmd == SPECTRE_V2_CMD_RETPOLINE_LFENCE) &&
+ 	    !boot_cpu_has(X86_FEATURE_LFENCE_RDTSC)) {
+ 		pr_err("%s selected, but CPU doesn't have a serializing LFENCE. Switching to AUTO select\n", mitigation_options[i].option);
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  		return SPECTRE_V2_CMD_AUTO;
  	}
  
@@@ -946,8 -940,9 +957,14 @@@ set_ibrs_enhanced
  	return;
  
  retpoline_auto:
++<<<<<<< HEAD
 +	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
 +	retpoline_amd:
++=======
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD ||
+ 	    boot_cpu_data.x86_vendor == X86_VENDOR_HYGON) {
+ 	retpoline_lfence:
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  		if (!boot_cpu_has(X86_FEATURE_LFENCE_RDTSC)) {
  			pr_err("Spectre mitigation: LFENCE not serializing, switching to generic retpoline\n");
  			goto retpoline_generic;
diff --cc arch/x86/lib/retpoline.S
index 363ec132df7e,afbdda539b80..000000000000
--- a/arch/x86/lib/retpoline.S
+++ b/arch/x86/lib/retpoline.S
@@@ -4,18 -4,38 +4,29 @@@
  #include <linux/linkage.h>
  #include <asm/dwarf2.h>
  #include <asm/cpufeatures.h>
 -#include <asm/alternative.h>
 +#include <asm/alternative-asm.h>
  #include <asm/export.h>
  #include <asm/nospec-branch.h>
 -#include <asm/unwind_hints.h>
 -#include <asm/frame.h>
 -
 -	.section .text.__x86.indirect_thunk
 -
 -.macro RETPOLINE reg
 -	ANNOTATE_INTRA_FUNCTION_CALL
 -	call    .Ldo_rop_\@
 -.Lspec_trap_\@:
 -	UNWIND_HINT_EMPTY
 -	pause
 -	lfence
 -	jmp .Lspec_trap_\@
 -.Ldo_rop_\@:
 -	mov     %\reg, (%_ASM_SP)
 -	UNWIND_HINT_FUNC
 -	RET
 -.endm
  
  .macro THUNK reg
 +	.section .text.__x86.indirect_thunk
  
++<<<<<<< HEAD
 +SYM_FUNC_START(__x86_indirect_thunk_\reg)
 +	CFI_STARTPROC
 +	JMP_NOSPEC %\reg
 +	CFI_ENDPROC
 +SYM_FUNC_END(__x86_indirect_thunk_\reg)
++=======
+ 	.align RETPOLINE_THUNK_SIZE
+ SYM_INNER_LABEL(__x86_indirect_thunk_\reg, SYM_L_GLOBAL)
+ 	UNWIND_HINT_EMPTY
+ 
+ 	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; jmp *%\reg), \
+ 		      __stringify(RETPOLINE \reg), X86_FEATURE_RETPOLINE, \
+ 		      __stringify(lfence; ANNOTATE_RETPOLINE_SAFE; jmp *%\reg; int3), X86_FEATURE_RETPOLINE_LFENCE
+ 
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  .endm
  
  /*
diff --cc arch/x86/net/bpf_jit_comp.c
index 6a8e83bee0d7,0ecb140864b2..000000000000
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@@ -388,20 -387,23 +388,32 @@@ int bpf_arch_text_poke(void *ip, enum b
  	return __bpf_arch_text_poke(ip, t, old_addr, new_addr, true);
  }
  
 -#define EMIT_LFENCE()	EMIT3(0x0F, 0xAE, 0xE8)
 -
 -static void emit_indirect_jump(u8 **pprog, int reg, u8 *ip)
 +static int get_pop_bytes(bool *callee_regs_used)
  {
 -	u8 *prog = *pprog;
 +	int bytes = 0;
  
++<<<<<<< HEAD
 +	if (callee_regs_used[3])
 +		bytes += 2;
 +	if (callee_regs_used[2])
 +		bytes += 2;
 +	if (callee_regs_used[1])
 +		bytes += 2;
 +	if (callee_regs_used[0])
 +		bytes += 1;
++=======
+ #ifdef CONFIG_RETPOLINE
+ 	if (cpu_feature_enabled(X86_FEATURE_RETPOLINE_LFENCE)) {
+ 		EMIT_LFENCE();
+ 		EMIT2(0xFF, 0xE0 + reg);
+ 	} else if (cpu_feature_enabled(X86_FEATURE_RETPOLINE)) {
+ 		emit_jump(&prog, &__x86_indirect_thunk_array[reg], ip);
+ 	} else
+ #endif
+ 	EMIT2(0xFF, 0xE0 + reg);
++>>>>>>> d45476d98324 (x86/speculation: Rename RETPOLINE_AMD to RETPOLINE_LFENCE)
  
 -	*pprog = prog;
 +	return bytes;
  }
  
  /*
diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h
index d0f5b59135b9..01657015927a 100644
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@ -203,7 +203,7 @@
 /* FREE!                                ( 7*32+10) */
 #define X86_FEATURE_PTI			( 7*32+11) /* Kernel Page Table Isolation enabled */
 #define X86_FEATURE_RETPOLINE		( 7*32+12) /* "" Generic Retpoline mitigation for Spectre variant 2 */
-#define X86_FEATURE_RETPOLINE_AMD	( 7*32+13) /* "" AMD Retpoline mitigation for Spectre variant 2 */
+#define X86_FEATURE_RETPOLINE_LFENCE	( 7*32+13) /* "" Use LFENCE for Spectre variant 2 */
 #define X86_FEATURE_INTEL_PPIN		( 7*32+14) /* Intel Processor Inventory Number */
 #define X86_FEATURE_CDP_L2		( 7*32+15) /* Code and Data Prioritization L2 */
 #define X86_FEATURE_MSR_SPEC_CTRL	( 7*32+16) /* "" MSR SPEC_CTRL is implemented */
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/kernel/alternative.c
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/lib/retpoline.S
* Unmerged path arch/x86/net/bpf_jit_comp.c
diff --git a/tools/arch/x86/include/asm/cpufeatures.h b/tools/arch/x86/include/asm/cpufeatures.h
index daa759b017c6..0687d2fb6633 100644
--- a/tools/arch/x86/include/asm/cpufeatures.h
+++ b/tools/arch/x86/include/asm/cpufeatures.h
@@ -203,7 +203,7 @@
 #define X86_FEATURE_SME			( 7*32+10) /* AMD Secure Memory Encryption */
 #define X86_FEATURE_PTI			( 7*32+11) /* Kernel Page Table Isolation enabled */
 #define X86_FEATURE_RETPOLINE		( 7*32+12) /* "" Generic Retpoline mitigation for Spectre variant 2 */
-#define X86_FEATURE_RETPOLINE_AMD	( 7*32+13) /* "" AMD Retpoline mitigation for Spectre variant 2 */
+#define X86_FEATURE_RETPOLINE_LFENCE	( 7*32+13) /* "" Use LFENCEs for Spectre variant 2 */
 #define X86_FEATURE_INTEL_PPIN		( 7*32+14) /* Intel Processor Inventory Number */
 #define X86_FEATURE_CDP_L2		( 7*32+15) /* Code and Data Prioritization L2 */
 #define X86_FEATURE_MSR_SPEC_CTRL	( 7*32+16) /* "" MSR SPEC_CTRL is implemented */
