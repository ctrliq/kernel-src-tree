scsi: scsi_debug: Use scsi_block_requests() to block queues

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-535.el8
commit-author John Garry <john.g.garry@oracle.com>
commit a0473bf31df5bf2da7ecb50023c129659ce0a835
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-535.el8/a0473bf3.failed

The feature to block queues is quite dubious, since it races with in-flight
IO. Indeed, it seems unnecessary for block queues for any times we do so.

Anyway, to keep the same behaviour, use standard SCSI API to stop IO being
sent - scsi_{un}block_requests().

	Signed-off-by: John Garry <john.g.garry@oracle.com>
Link: https://lore.kernel.org/r/20230327074310.1862889-6-john.g.garry@oracle.com
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit a0473bf31df5bf2da7ecb50023c129659ce0a835)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/scsi_debug.c
diff --cc drivers/scsi/scsi_debug.c
index 58c45f546123,f53f3e78aaa1..000000000000
--- a/drivers/scsi/scsi_debug.c
+++ b/drivers/scsi/scsi_debug.c
@@@ -5533,11 -5493,18 +5532,23 @@@ static void sdebug_build_parts(unsigne
  
  static void block_unblock_all_queues(bool block)
  {
- 	int j;
- 	struct sdebug_queue *sqp;
+ 	struct sdebug_host_info *sdhp;
  
++<<<<<<< HEAD
 +	for (j = 0, sqp = sdebug_q_arr; j < submit_queues; ++j, ++sqp)
 +		atomic_set(&sqp->blocked, (int)block);
++=======
+ 	lockdep_assert_held(&sdebug_host_list_mutex);
+ 
+ 	list_for_each_entry(sdhp, &sdebug_host_list, host_list) {
+ 		struct Scsi_Host *shost = sdhp->shost;
+ 
+ 		if (block)
+ 			scsi_block_requests(shost);
+ 		else
+ 			scsi_unblock_requests(shost);
+ 	}
++>>>>>>> a0473bf31df5 (scsi: scsi_debug: Use scsi_block_requests() to block queues)
  }
  
  /* Adjust (by rounding down) the sdebug_cmnd_count so abs(every_nth)-1
@@@ -5607,15 -5576,13 +5618,19 @@@ static int schedule_resp(struct scsi_cm
  
  	sqp = get_queue(cmnd);
  	spin_lock_irqsave(&sqp->qc_lock, iflags);
++<<<<<<< HEAD
 +	if (unlikely(atomic_read(&sqp->blocked))) {
 +		spin_unlock_irqrestore(&sqp->qc_lock, iflags);
 +		return SCSI_MLQUEUE_HOST_BUSY;
 +	}
 +	num_in_q = atomic_read(&devip->num_in_q);
 +	qdepth = cmnd->device->queue_depth;
++=======
+ 
++>>>>>>> a0473bf31df5 (scsi: scsi_debug: Use scsi_block_requests() to block queues)
  	if (unlikely(sdebug_every_nth && (SDEBUG_OPT_RARE_TSF & sdebug_opts) &&
  		     (scsi_result == 0))) {
 -		int num_in_q = scsi_device_busy(sdp);
 -		int qdepth = cmnd->device->queue_depth;
 -
 -		if ((num_in_q == qdepth) &&
 +		if ((num_in_q == (qdepth - 1)) &&
  		    (atomic_inc_return(&sdebug_a_tsf) >=
  		     abs(sdebug_every_nth))) {
  			atomic_set(&sdebug_a_tsf, 0);
* Unmerged path drivers/scsi/scsi_debug.c
