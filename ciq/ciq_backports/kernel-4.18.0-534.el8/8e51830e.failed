netfilter: nf_tables: defer gc run if previous batch is still pending

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-534.el8
commit-author Florian Westphal <fw@strlen.de>
commit 8e51830e29e12670b4c10df070a4ea4c9593e961
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-534.el8/8e51830e.failed

Don't queue more gc work, else we may queue the same elements multiple
times.

If an element is flagged as dead, this can mean that either the previous
gc request was invalidated/discarded by a transaction or that the previous
request is still pending in the system work queue.

The latter will happen if the gc interval is set to a very low value,
e.g. 1ms, and system work queue is backlogged.

The sets refcount is 1 if no previous gc requeusts are queued, so add
a helper for this and skip gc run if old requests are pending.

Add a helper for this and skip the gc run in this case.

Fixes: f6c383b8c31a ("netfilter: nf_tables: adapt set backend to use GC transaction API")
	Signed-off-by: Florian Westphal <fw@strlen.de>
	Reviewed-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit 8e51830e29e12670b4c10df070a4ea4c9593e961)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/netfilter/nft_set_hash.c
#	net/netfilter/nft_set_rbtree.c
diff --cc net/netfilter/nft_set_hash.c
index 037a2a90e4be,524763659f25..000000000000
--- a/net/netfilter/nft_set_hash.c
+++ b/net/netfilter/nft_set_hash.c
@@@ -304,6 -319,19 +304,19 @@@ static void nft_rhash_gc(struct work_st
  
  	priv = container_of(work, struct nft_rhash, gc_work.work);
  	set  = nft_set_container_of(priv);
++<<<<<<< HEAD
++=======
+ 	net  = read_pnet(&set->net);
+ 	nft_net = nft_pernet(net);
+ 	gc_seq = READ_ONCE(nft_net->gc_seq);
+ 
+ 	if (nft_set_gc_is_pending(set))
+ 		goto done;
+ 
+ 	gc = nft_trans_gc_alloc(set, gc_seq, GFP_KERNEL);
+ 	if (!gc)
+ 		goto done;
++>>>>>>> 8e51830e29e1 (netfilter: nf_tables: defer gc run if previous batch is still pending)
  
  	rhashtable_walk_enter(&priv->ht, &hti);
  	rhashtable_walk_start(&hti);
diff --cc net/netfilter/nft_set_rbtree.c
index c80ee6034fca,c6435e709231..000000000000
--- a/net/netfilter/nft_set_rbtree.c
+++ b/net/netfilter/nft_set_rbtree.c
@@@ -475,7 -608,15 +475,19 @@@ static void nft_rbtree_gc(struct work_s
  	priv = container_of(work, struct nft_rbtree, gc_work.work);
  	set  = nft_set_container_of(priv);
  	net  = read_pnet(&set->net);
++<<<<<<< HEAD
 +	genmask = nft_genmask_cur(net);
++=======
+ 	nft_net = nft_pernet(net);
+ 	gc_seq  = READ_ONCE(nft_net->gc_seq);
+ 
+ 	if (nft_set_gc_is_pending(set))
+ 		goto done;
+ 
+ 	gc = nft_trans_gc_alloc(set, gc_seq, GFP_KERNEL);
+ 	if (!gc)
+ 		goto done;
++>>>>>>> 8e51830e29e1 (netfilter: nf_tables: defer gc run if previous batch is still pending)
  
  	write_lock_bh(&priv->lock);
  	write_seqcount_begin(&priv->count);
diff --git a/include/net/netfilter/nf_tables.h b/include/net/netfilter/nf_tables.h
index 4b3a88701d07..1bb174bd8181 100644
--- a/include/net/netfilter/nf_tables.h
+++ b/include/net/netfilter/nf_tables.h
@@ -512,6 +512,11 @@ static inline void *nft_set_priv(const struct nft_set *set)
 	return (void *)set->data;
 }
 
+static inline bool nft_set_gc_is_pending(const struct nft_set *s)
+{
+	return refcount_read(&s->refs) != 1;
+}
+
 static inline struct nft_set *nft_set_container_of(const void *priv)
 {
 	return (void *)priv - offsetof(struct nft_set, data);
* Unmerged path net/netfilter/nft_set_hash.c
* Unmerged path net/netfilter/nft_set_rbtree.c
