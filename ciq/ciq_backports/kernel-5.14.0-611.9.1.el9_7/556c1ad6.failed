x86/vmscape: Enable the mitigation

jira KERNEL-216
cve CVE-2025-40300
Rebuild_History Non-Buildable kernel-5.14.0-611.9.1.el9_7
commit-author Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
commit 556c1ad666ad90c50ec8fccb930dd5046cfbecfb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-5.14.0-611.9.1.el9_7/556c1ad6.failed

Enable the previously added mitigation for VMscape. Add the cmdline
vmscape={off|ibpb|force} and sysfs reporting.

	Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
	Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
	Reviewed-by: Borislav Petkov (AMD) <bp@alien8.de>
	Reviewed-by: Dave Hansen <dave.hansen@linux.intel.com>
(cherry picked from commit 556c1ad666ad90c50ec8fccb930dd5046cfbecfb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/admin-guide/kernel-parameters.txt
#	arch/x86/kernel/cpu/bugs.c
diff --cc Documentation/admin-guide/kernel-parameters.txt
index 89bf79741acd,5a7a83c411e9..000000000000
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@@ -7152,7 -8042,17 +7153,21 @@@
  	vmpoff=		[KNL,S390] Perform z/VM CP command after power off.
  			Format: <command>
  
++<<<<<<< HEAD
 +	vsyscall=	[X86-64]
++=======
+ 	vmscape=	[X86] Controls mitigation for VMscape attacks.
+ 			VMscape attacks can leak information from a userspace
+ 			hypervisor to a guest via speculative side-channels.
+ 
+ 			off		- disable the mitigation
+ 			ibpb		- use Indirect Branch Prediction Barrier
+ 					  (IBPB) mitigation (default)
+ 			force		- force vulnerability detection even on
+ 					  unaffected processors
+ 
+ 	vsyscall=	[X86-64,EARLY]
++>>>>>>> 556c1ad666ad (x86/vmscape: Enable the mitigation)
  			Controls the behavior of vsyscalls (i.e. calls to
  			fixed addresses of 0xffffffffff600x00 from legacy
  			code).  Most statically-linked binaries and older
diff --cc arch/x86/kernel/cpu/bugs.c
index 0017b9e4db57,c81024dfc4c8..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -35,24 -34,71 +35,27 @@@
  
  #include "cpu.h"
  
 -/*
 - * Speculation Vulnerability Handling
 - *
 - * Each vulnerability is handled with the following functions:
 - *   <vuln>_select_mitigation() -- Selects a mitigation to use.  This should
 - *				   take into account all relevant command line
 - *				   options.
 - *   <vuln>_update_mitigation() -- This is called after all vulnerabilities have
 - *				   selected a mitigation, in case the selection
 - *				   may want to change based on other choices
 - *				   made.  This function is optional.
 - *   <vuln>_apply_mitigation() -- Enable the selected mitigation.
 - *
 - * The compile-time mitigation in all cases should be AUTO.  An explicit
 - * command-line option can override AUTO.  If no such option is
 - * provided, <vuln>_select_mitigation() will override AUTO to the best
 - * mitigation option.
 - */
 -
  static void __init spectre_v1_select_mitigation(void);
 -static void __init spectre_v1_apply_mitigation(void);
  static void __init spectre_v2_select_mitigation(void);
 -static void __init spectre_v2_update_mitigation(void);
 -static void __init spectre_v2_apply_mitigation(void);
  static void __init retbleed_select_mitigation(void);
 -static void __init retbleed_update_mitigation(void);
 -static void __init retbleed_apply_mitigation(void);
  static void __init spectre_v2_user_select_mitigation(void);
 -static void __init spectre_v2_user_update_mitigation(void);
 -static void __init spectre_v2_user_apply_mitigation(void);
  static void __init ssb_select_mitigation(void);
 -static void __init ssb_apply_mitigation(void);
  static void __init l1tf_select_mitigation(void);
 -static void __init l1tf_apply_mitigation(void);
  static void __init mds_select_mitigation(void);
 -static void __init mds_update_mitigation(void);
 -static void __init mds_apply_mitigation(void);
 +static void __init md_clear_update_mitigation(void);
 +static void __init md_clear_select_mitigation(void);
  static void __init taa_select_mitigation(void);
 -static void __init taa_update_mitigation(void);
 -static void __init taa_apply_mitigation(void);
  static void __init mmio_select_mitigation(void);
 -static void __init mmio_update_mitigation(void);
 -static void __init mmio_apply_mitigation(void);
 -static void __init rfds_select_mitigation(void);
 -static void __init rfds_update_mitigation(void);
 -static void __init rfds_apply_mitigation(void);
  static void __init srbds_select_mitigation(void);
 -static void __init srbds_apply_mitigation(void);
  static void __init l1d_flush_select_mitigation(void);
  static void __init srso_select_mitigation(void);
 -static void __init srso_update_mitigation(void);
 -static void __init srso_apply_mitigation(void);
  static void __init gds_select_mitigation(void);
 -static void __init gds_apply_mitigation(void);
 -static void __init bhi_select_mitigation(void);
 -static void __init bhi_update_mitigation(void);
 -static void __init bhi_apply_mitigation(void);
  static void __init its_select_mitigation(void);
 -static void __init its_update_mitigation(void);
 -static void __init its_apply_mitigation(void);
  static void __init tsa_select_mitigation(void);
  static void __init tsa_apply_mitigation(void);
+ static void __init vmscape_select_mitigation(void);
+ static void __init vmscape_update_mitigation(void);
+ static void __init vmscape_apply_mitigation(void);
  
  /* The base value of the SPEC_CTRL MSR without task-specific bits set */
  u64 x86_spec_ctrl_base;
@@@ -195,8 -271,59 +198,61 @@@ void __init cpu_select_mitigations(void
  	srso_select_mitigation();
  	gds_select_mitigation();
  	its_select_mitigation();
 -	bhi_select_mitigation();
  	tsa_select_mitigation();
++<<<<<<< HEAD
++=======
+ 	vmscape_select_mitigation();
+ 
+ 	/*
+ 	 * After mitigations are selected, some may need to update their
+ 	 * choices.
+ 	 */
+ 	spectre_v2_update_mitigation();
+ 	/*
+ 	 * retbleed_update_mitigation() relies on the state set by
+ 	 * spectre_v2_update_mitigation(); specifically it wants to know about
+ 	 * spectre_v2=ibrs.
+ 	 */
+ 	retbleed_update_mitigation();
+ 	/*
+ 	 * its_update_mitigation() depends on spectre_v2_update_mitigation()
+ 	 * and retbleed_update_mitigation().
+ 	 */
+ 	its_update_mitigation();
+ 
+ 	/*
+ 	 * spectre_v2_user_update_mitigation() depends on
+ 	 * retbleed_update_mitigation(), specifically the STIBP
+ 	 * selection is forced for UNRET or IBPB.
+ 	 */
+ 	spectre_v2_user_update_mitigation();
+ 	mds_update_mitigation();
+ 	taa_update_mitigation();
+ 	mmio_update_mitigation();
+ 	rfds_update_mitigation();
+ 	bhi_update_mitigation();
+ 	/* srso_update_mitigation() depends on retbleed_update_mitigation(). */
+ 	srso_update_mitigation();
+ 	vmscape_update_mitigation();
+ 
+ 	spectre_v1_apply_mitigation();
+ 	spectre_v2_apply_mitigation();
+ 	retbleed_apply_mitigation();
+ 	spectre_v2_user_apply_mitigation();
+ 	ssb_apply_mitigation();
+ 	l1tf_apply_mitigation();
+ 	mds_apply_mitigation();
+ 	taa_apply_mitigation();
+ 	mmio_apply_mitigation();
+ 	rfds_apply_mitigation();
+ 	srbds_apply_mitigation();
+ 	srso_apply_mitigation();
+ 	gds_apply_mitigation();
+ 	its_apply_mitigation();
+ 	bhi_apply_mitigation();
++>>>>>>> 556c1ad666ad (x86/vmscape: Enable the mitigation)
  	tsa_apply_mitigation();
+ 	vmscape_apply_mitigation();
  }
  
  /*
@@@ -3033,10 -3280,125 +3089,81 @@@ out
  	if (srso_mitigation != SRSO_MITIGATION_BP_SPEC_REDUCE)
  		setup_clear_cpu_cap(X86_FEATURE_SRSO_BP_SPEC_REDUCE);
  
 -	if (srso_mitigation == SRSO_MITIGATION_NONE) {
 -		if (boot_cpu_has(X86_FEATURE_SBPB))
 -			x86_pred_cmd = PRED_CMD_SBPB;
 -		return;
 -	}
 -
 -	switch (srso_mitigation) {
 -	case SRSO_MITIGATION_SAFE_RET:
 -	case SRSO_MITIGATION_SAFE_RET_UCODE_NEEDED:
 -		/*
 -		 * Enable the return thunk for generated code
 -		 * like ftrace, static_call, etc.
 -		 */
 -		setup_force_cpu_cap(X86_FEATURE_RETHUNK);
 -		setup_force_cpu_cap(X86_FEATURE_UNRET);
 -
 -		if (boot_cpu_data.x86 == 0x19) {
 -			setup_force_cpu_cap(X86_FEATURE_SRSO_ALIAS);
 -			set_return_thunk(srso_alias_return_thunk);
 -		} else {
 -			setup_force_cpu_cap(X86_FEATURE_SRSO);
 -			set_return_thunk(srso_return_thunk);
 -		}
 -		break;
 -	case SRSO_MITIGATION_IBPB:
 -		setup_force_cpu_cap(X86_FEATURE_ENTRY_IBPB);
 -		/*
 -		 * IBPB on entry already obviates the need for
 -		 * software-based untraining so clear those in case some
 -		 * other mitigation like Retbleed has selected them.
 -		 */
 -		setup_clear_cpu_cap(X86_FEATURE_UNRET);
 -		setup_clear_cpu_cap(X86_FEATURE_RETHUNK);
 -		fallthrough;
 -	case SRSO_MITIGATION_IBPB_ON_VMEXIT:
 -		setup_force_cpu_cap(X86_FEATURE_IBPB_ON_VMEXIT);
 -		/*
 -		 * There is no need for RSB filling: entry_ibpb() ensures
 -		 * all predictions, including the RSB, are invalidated,
 -		 * regardless of IBPB implementation.
 -		 */
 -		setup_clear_cpu_cap(X86_FEATURE_RSB_VMEXIT);
 -		break;
 -	default:
 -		break;
 -	}
 +	if (srso_mitigation != SRSO_MITIGATION_NONE)
 +		pr_info("%s\n", srso_strings[srso_mitigation]);
  }
  
+ #undef pr_fmt
+ #define pr_fmt(fmt)	"VMSCAPE: " fmt
+ 
+ enum vmscape_mitigations {
+ 	VMSCAPE_MITIGATION_NONE,
+ 	VMSCAPE_MITIGATION_AUTO,
+ 	VMSCAPE_MITIGATION_IBPB_EXIT_TO_USER,
+ 	VMSCAPE_MITIGATION_IBPB_ON_VMEXIT,
+ };
+ 
+ static const char * const vmscape_strings[] = {
+ 	[VMSCAPE_MITIGATION_NONE]		= "Vulnerable",
+ 	/* [VMSCAPE_MITIGATION_AUTO] */
+ 	[VMSCAPE_MITIGATION_IBPB_EXIT_TO_USER]	= "Mitigation: IBPB before exit to userspace",
+ 	[VMSCAPE_MITIGATION_IBPB_ON_VMEXIT]	= "Mitigation: IBPB on VMEXIT",
+ };
+ 
+ static enum vmscape_mitigations vmscape_mitigation __ro_after_init =
+ 	IS_ENABLED(CONFIG_MITIGATION_VMSCAPE) ? VMSCAPE_MITIGATION_AUTO : VMSCAPE_MITIGATION_NONE;
+ 
+ static int __init vmscape_parse_cmdline(char *str)
+ {
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	if (!strcmp(str, "off")) {
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_NONE;
+ 	} else if (!strcmp(str, "ibpb")) {
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_IBPB_EXIT_TO_USER;
+ 	} else if (!strcmp(str, "force")) {
+ 		setup_force_cpu_bug(X86_BUG_VMSCAPE);
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_AUTO;
+ 	} else {
+ 		pr_err("Ignoring unknown vmscape=%s option.\n", str);
+ 	}
+ 
+ 	return 0;
+ }
+ early_param("vmscape", vmscape_parse_cmdline);
+ 
+ static void __init vmscape_select_mitigation(void)
+ {
+ 	if (cpu_mitigations_off() ||
+ 	    !boot_cpu_has_bug(X86_BUG_VMSCAPE) ||
+ 	    !boot_cpu_has(X86_FEATURE_IBPB)) {
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_NONE;
+ 		return;
+ 	}
+ 
+ 	if (vmscape_mitigation == VMSCAPE_MITIGATION_AUTO)
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_IBPB_EXIT_TO_USER;
+ }
+ 
+ static void __init vmscape_update_mitigation(void)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_VMSCAPE))
+ 		return;
+ 
+ 	if (retbleed_mitigation == RETBLEED_MITIGATION_IBPB ||
+ 	    srso_mitigation == SRSO_MITIGATION_IBPB_ON_VMEXIT)
+ 		vmscape_mitigation = VMSCAPE_MITIGATION_IBPB_ON_VMEXIT;
+ 
+ 	pr_info("%s\n", vmscape_strings[vmscape_mitigation]);
+ }
+ 
+ static void __init vmscape_apply_mitigation(void)
+ {
+ 	if (vmscape_mitigation == VMSCAPE_MITIGATION_IBPB_EXIT_TO_USER)
+ 		setup_force_cpu_cap(X86_FEATURE_IBPB_EXIT_TO_USER);
+ }
+ 
  #undef pr_fmt
  #define pr_fmt(fmt) fmt
  
diff --git a/Documentation/ABI/testing/sysfs-devices-system-cpu b/Documentation/ABI/testing/sysfs-devices-system-cpu
index d3cc32677afe..ee3d8f694356 100644
--- a/Documentation/ABI/testing/sysfs-devices-system-cpu
+++ b/Documentation/ABI/testing/sysfs-devices-system-cpu
@@ -533,6 +533,7 @@ What:		/sys/devices/system/cpu/vulnerabilities
 		/sys/devices/system/cpu/vulnerabilities/srbds
 		/sys/devices/system/cpu/vulnerabilities/tsa
 		/sys/devices/system/cpu/vulnerabilities/tsx_async_abort
+		/sys/devices/system/cpu/vulnerabilities/vmscape
 Date:		January 2018
 Contact:	Linux kernel mailing list <linux-kernel@vger.kernel.org>
 Description:	Information about CPU vulnerabilities
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 08486d837757..b932cbae7eb0 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -2754,6 +2754,15 @@ config MITIGATION_TSA
 	  security vulnerability on AMD CPUs which can lead to forwarding of
 	  invalid info to subsequent instructions and thus can affect their
 	  timing and thereby cause a leakage.
+
+config MITIGATION_VMSCAPE
+	bool "Mitigate VMSCAPE"
+	depends on KVM
+	default y
+	help
+	  Enable mitigation for VMSCAPE attacks. VMSCAPE is a hardware security
+	  vulnerability on Intel and AMD CPUs that may allow a guest to do
+	  Spectre v2 style attacks on userspace hypervisor.
 endif
 
 config ARCH_HAS_ADD_PAGES
* Unmerged path arch/x86/kernel/cpu/bugs.c
diff --git a/drivers/base/cpu.c b/drivers/base/cpu.c
index 8328b3572281..88739ceb1780 100644
--- a/drivers/base/cpu.c
+++ b/drivers/base/cpu.c
@@ -581,6 +581,7 @@ CPU_SHOW_VULN_FALLBACK(gds);
 CPU_SHOW_VULN_FALLBACK(reg_file_data_sampling);
 CPU_SHOW_VULN_FALLBACK(indirect_target_selection);
 CPU_SHOW_VULN_FALLBACK(tsa);
+CPU_SHOW_VULN_FALLBACK(vmscape);
 
 static DEVICE_ATTR(meltdown, 0444, cpu_show_meltdown, NULL);
 static DEVICE_ATTR(spectre_v1, 0444, cpu_show_spectre_v1, NULL);
@@ -598,6 +599,7 @@ static DEVICE_ATTR(gather_data_sampling, 0444, cpu_show_gds, NULL);
 static DEVICE_ATTR(reg_file_data_sampling, 0444, cpu_show_reg_file_data_sampling, NULL);
 static DEVICE_ATTR(indirect_target_selection, 0444, cpu_show_indirect_target_selection, NULL);
 static DEVICE_ATTR(tsa, 0444, cpu_show_tsa, NULL);
+static DEVICE_ATTR(vmscape, 0444, cpu_show_vmscape, NULL);
 
 static struct attribute *cpu_root_vulnerabilities_attrs[] = {
 	&dev_attr_meltdown.attr,
@@ -616,6 +618,7 @@ static struct attribute *cpu_root_vulnerabilities_attrs[] = {
 	&dev_attr_reg_file_data_sampling.attr,
 	&dev_attr_indirect_target_selection.attr,
 	&dev_attr_tsa.attr,
+	&dev_attr_vmscape.attr,
 	NULL
 };
 
diff --git a/include/linux/cpu.h b/include/linux/cpu.h
index e73eb3a55ab2..19adf72edcda 100644
--- a/include/linux/cpu.h
+++ b/include/linux/cpu.h
@@ -80,6 +80,7 @@ extern ssize_t cpu_show_reg_file_data_sampling(struct device *dev,
 extern ssize_t cpu_show_indirect_target_selection(struct device *dev,
 						  struct device_attribute *attr, char *buf);
 extern ssize_t cpu_show_tsa(struct device *dev, struct device_attribute *attr, char *buf);
+extern ssize_t cpu_show_vmscape(struct device *dev, struct device_attribute *attr, char *buf);
 
 extern __printf(4, 5)
 struct device *cpu_device_create(struct device *parent, void *drvdata,
