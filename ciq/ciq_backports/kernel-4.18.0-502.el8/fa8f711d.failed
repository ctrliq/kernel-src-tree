x86/resctrl: Pass configuration type to resctrl_arch_get_config()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author James Morse <james.morse@arm.com>
commit fa8f711d2f14381d1a47420b6da94b62e6484c56
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/fa8f711d.failed

The ctrl_val[] array for a struct rdt_hw_resource only holds
configurations of one type. The type is implicit.

Once the CDP resources are merged, the ctrl_val[] array will hold all
the configurations for the hardware resource. When a particular type of
configuration is needed, it must be specified explicitly.

Pass the expected type from the schema into resctrl_arch_get_config().
Nothing uses this yet, but once a single ctrl_val[] array is used for
the three struct rdt_hw_resources that share hardware, the type will be
used to return the correct configuration value from the shared array.

	Signed-off-by: James Morse <james.morse@arm.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Jamie Iles <jamie@nuviainc.com>
	Reviewed-by: Reinette Chatre <reinette.chatre@intel.com>
	Tested-by: Babu Moger <babu.moger@amd.com>
Link: https://lkml.kernel.org/r/20210728170637.25610-18-james.morse@arm.com
(cherry picked from commit fa8f711d2f14381d1a47420b6da94b62e6484c56)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/resctrl/ctrlmondata.c
#	arch/x86/kernel/cpu/resctrl/monitor.c
#	arch/x86/kernel/cpu/resctrl/rdtgroup.c
#	include/linux/resctrl.h
diff --cc arch/x86/kernel/cpu/resctrl/ctrlmondata.c
index 9a768d89de37,9ead0c0bf6ee..000000000000
--- a/arch/x86/kernel/cpu/resctrl/ctrlmondata.c
+++ b/arch/x86/kernel/cpu/resctrl/ctrlmondata.c
@@@ -379,8 -401,20 +379,13 @@@ out
  	return ret ?: nbytes;
  }
  
++<<<<<<< HEAD
 +static void show_doms(struct seq_file *s, struct rdt_resource *r, int closid)
++=======
+ void resctrl_arch_get_config(struct rdt_resource *r, struct rdt_domain *d,
+ 			     u32 closid, enum resctrl_conf_type type, u32 *value)
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  {
 -	struct rdt_hw_domain *hw_dom = resctrl_to_arch_dom(d);
 -
 -	if (!is_mba_sc(r))
 -		*value = hw_dom->ctrl_val[closid];
 -	else
 -		*value = hw_dom->mbps_val[closid];
 -}
 -
 -static void show_doms(struct seq_file *s, struct resctrl_schema *schema, int closid)
 -{
 -	struct rdt_resource *r = schema->res;
  	struct rdt_domain *dom;
  	bool sep = false;
  	u32 ctrl_val;
@@@ -390,8 -424,8 +395,13 @@@
  		if (sep)
  			seq_puts(s, ";");
  
++<<<<<<< HEAD
 +		ctrl_val = (!is_mba_sc(r) ? dom->ctrl_val[closid] :
 +			    dom->mbps_val[closid]);
++=======
+ 		resctrl_arch_get_config(r, dom, closid, schema->conf_type,
+ 					&ctrl_val);
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  		seq_printf(s, r->format_str, dom->id, max_data_width,
  			   ctrl_val);
  		sep = true;
diff --cc arch/x86/kernel/cpu/resctrl/monitor.c
index 4454d0aaf4f2,eb227298487f..000000000000
--- a/arch/x86/kernel/cpu/resctrl/monitor.c
+++ b/arch/x86/kernel/cpu/resctrl/monitor.c
@@@ -449,11 -439,16 +449,15 @@@ static void update_mba_bw(struct rdtgro
  		pr_warn_once("Failure to get domain for MBA update\n");
  		return;
  	}
 -	hw_dom_mba = resctrl_to_arch_dom(dom_mba);
  
  	cur_bw = pmbm_data->prev_bw;
++<<<<<<< HEAD
 +	user_bw = dom_mba->mbps_val[closid];
++=======
+ 	resctrl_arch_get_config(r_mba, dom_mba, closid, CDP_NONE, &user_bw);
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  	delta_bw = pmbm_data->delta_bw;
 -	/*
 -	 * resctrl_arch_get_config() chooses the mbps/ctrl value to return
 -	 * based on is_mba_sc(). For now, reach into the hw_dom.
 -	 */
 -	cur_msr_val = hw_dom_mba->ctrl_val[closid];
 +	cur_msr_val = dom_mba->ctrl_val[closid];
  
  	/*
  	 * For Ctrl groups read data from child monitor groups.
diff --cc arch/x86/kernel/cpu/resctrl/rdtgroup.c
index a8731279ffbf,61037b239327..000000000000
--- a/arch/x86/kernel/cpu/resctrl/rdtgroup.c
+++ b/arch/x86/kernel/cpu/resctrl/rdtgroup.c
@@@ -941,9 -920,11 +941,14 @@@ static int rdt_bit_usage_show(struct ke
  		sw_shareable = 0;
  		exclusive = 0;
  		seq_printf(seq, "%d=", dom->id);
 -		for (i = 0; i < closids_supported(); i++) {
 +		for (i = 0; i < closids_supported(); i++, ctrl++) {
  			if (!closid_allocated(i))
  				continue;
++<<<<<<< HEAD
++=======
+ 			resctrl_arch_get_config(r, dom, i, s->conf_type,
+ 						&ctrl_val);
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  			mode = rdtgroup_mode_by_closid(i);
  			switch (mode) {
  			case RDT_MODE_SHAREABLE:
@@@ -1138,16 -1127,20 +1145,33 @@@ static int rdt_cdp_peer_get(struct rdt_
  
  	switch (r->rid) {
  	case RDT_RESOURCE_L3DATA:
++<<<<<<< HEAD
 +		_r_cdp = &rdt_resources_all[RDT_RESOURCE_L3CODE];
 +		break;
 +	case RDT_RESOURCE_L3CODE:
 +		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L3DATA];
 +		break;
 +	case RDT_RESOURCE_L2DATA:
 +		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L2CODE];
 +		break;
 +	case RDT_RESOURCE_L2CODE:
 +		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L2DATA];
++=======
+ 		_r_cdp = &rdt_resources_all[RDT_RESOURCE_L3CODE].r_resctrl;
+ 		*peer_type = CDP_CODE;
+ 		break;
+ 	case RDT_RESOURCE_L3CODE:
+ 		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L3DATA].r_resctrl;
+ 		*peer_type = CDP_DATA;
+ 		break;
+ 	case RDT_RESOURCE_L2DATA:
+ 		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L2CODE].r_resctrl;
+ 		*peer_type = CDP_CODE;
+ 		break;
+ 	case RDT_RESOURCE_L2CODE:
+ 		_r_cdp =  &rdt_resources_all[RDT_RESOURCE_L2DATA].r_resctrl;
+ 		*peer_type = CDP_DATA;
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  		break;
  	default:
  		ret = -ENOENT;
@@@ -1213,9 -1206,8 +1238,14 @@@ static bool __rdtgroup_cbm_overlaps(str
  	}
  
  	/* Check for overlap with other resource groups */
++<<<<<<< HEAD
 +	ctrl = d->ctrl_val;
 +	for (i = 0; i < closids_supported(); i++, ctrl++) {
 +		ctrl_b = *ctrl;
++=======
+ 	for (i = 0; i < closids_supported(); i++) {
+ 		resctrl_arch_get_config(r, d, i, type, (u32 *)&ctrl_b);
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  		mode = rdtgroup_mode_by_closid(i);
  		if (closid_allocated(i) && i != closid &&
  		    mode != RDT_MODE_PSEUDO_LOCKSETUP) {
@@@ -1253,9 -1245,11 +1283,14 @@@
   *
   * Return: true if CBM overlap detected, false if there is no overlap
   */
 -bool rdtgroup_cbm_overlaps(struct resctrl_schema *s, struct rdt_domain *d,
 +bool rdtgroup_cbm_overlaps(struct rdt_resource *r, struct rdt_domain *d,
  			   unsigned long cbm, int closid, bool exclusive)
  {
++<<<<<<< HEAD
++=======
+ 	enum resctrl_conf_type peer_type;
+ 	struct rdt_resource *r = s->res;
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  	struct rdt_resource *r_cdp;
  	struct rdt_domain *d_cdp;
  
@@@ -1292,8 -1290,8 +1328,13 @@@ static bool rdtgroup_mode_test_exclusiv
  			continue;
  		has_cache = true;
  		list_for_each_entry(d, &r->domains, list) {
++<<<<<<< HEAD
 +			if (rdtgroup_cbm_overlaps(r, d, d->ctrl_val[closid],
 +						  rdtgrp->closid, false)) {
++=======
+ 			resctrl_arch_get_config(r, d, closid, s->conf_type, &ctrl);
+ 			if (rdtgroup_cbm_overlaps(s, d, ctrl, closid, false)) {
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  				rdt_last_cmd_puts("Schemata overlaps\n");
  				return false;
  			}
@@@ -1463,9 -1463,8 +1504,14 @@@ static int rdtgroup_size_show(struct ke
  			if (rdtgrp->mode == RDT_MODE_PSEUDO_LOCKSETUP) {
  				size = 0;
  			} else {
++<<<<<<< HEAD
 +				ctrl = (!is_mba_sc(r) ?
 +						d->ctrl_val[rdtgrp->closid] :
 +						d->mbps_val[rdtgrp->closid]);
++=======
+ 				resctrl_arch_get_config(r, d, rdtgrp->closid,
+ 							schema->conf_type, &ctrl);
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  				if (r->rid == RDT_RESOURCE_MBA)
  					size = ctrl;
  				else
@@@ -2669,23 -2751,27 +2715,35 @@@ static u32 cbm_ensure_valid(u32 _val, s
   * Set the RDT domain up to start off with all usable allocations. That is,
   * all shareable and unused bits. All-zero CBM is invalid.
   */
 -static int __init_one_rdt_domain(struct rdt_domain *d, struct resctrl_schema *s,
 +static int __init_one_rdt_domain(struct rdt_domain *d, struct rdt_resource *r,
  				 u32 closid)
  {
 -	enum resctrl_conf_type t = s->conf_type;
  	struct rdt_resource *r_cdp = NULL;
++<<<<<<< HEAD
++=======
+ 	struct resctrl_staged_config *cfg;
+ 	enum resctrl_conf_type peer_type;
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  	struct rdt_domain *d_cdp = NULL;
 -	struct rdt_resource *r = s->res;
  	u32 used_b = 0, unused_b = 0;
  	unsigned long tmp_cbm;
  	enum rdtgrp_mode mode;
 -	u32 peer_ctl, ctrl_val;
 +	u32 peer_ctl, *ctrl;
  	int i;
  
++<<<<<<< HEAD
 +	rdt_cdp_peer_get(r, d, &r_cdp, &d_cdp);
 +	d->have_new_ctrl = false;
 +	d->new_ctrl = r->cache.shareable_bits;
++=======
+ 	rdt_cdp_peer_get(r, d, &r_cdp, &d_cdp, &peer_type);
+ 	cfg = &d->staged_config[t];
+ 	cfg->have_new_ctrl = false;
+ 	cfg->new_ctrl = r->cache.shareable_bits;
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  	used_b = r->cache.shareable_bits;
 -	for (i = 0; i < closids_supported(); i++) {
 +	ctrl = d->ctrl_val;
 +	for (i = 0; i < closids_supported(); i++, ctrl++) {
  		if (closid_allocated(i) && i != closid) {
  			mode = rdtgroup_mode_by_closid(i);
  			if (mode == RDT_MODE_PSEUDO_LOCKSETUP)
@@@ -2701,12 -2787,13 +2759,20 @@@
  			 * with an exclusive group.
  			 */
  			if (d_cdp)
++<<<<<<< HEAD
 +				peer_ctl = d_cdp->ctrl_val[i];
 +			else
 +				peer_ctl = 0;
 +			used_b |= *ctrl | peer_ctl;
++=======
+ 				resctrl_arch_get_config(r_cdp, d_cdp, i, peer_type, &peer_ctl);
+ 			else
+ 				peer_ctl = 0;
+ 			resctrl_arch_get_config(r, d, i, s->conf_type, &ctrl_val);
+ 			used_b |= ctrl_val | peer_ctl;
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  			if (mode == RDT_MODE_SHAREABLE)
 -				cfg->new_ctrl |= ctrl_val | peer_ctl;
 +				d->new_ctrl |= *ctrl | peer_ctl;
  		}
  	}
  	if (d->plr && d->plr->cbm > 0)
diff --cc include/linux/resctrl.h
index 9b05af9b3e28,69d7387b7f22..000000000000
--- a/include/linux/resctrl.h
+++ b/include/linux/resctrl.h
@@@ -13,4 -15,193 +13,196 @@@ int proc_resctrl_show(struct seq_file *
  
  #endif
  
++<<<<<<< HEAD
++=======
+ /**
+  * enum resctrl_conf_type - The type of configuration.
+  * @CDP_NONE:	No prioritisation, both code and data are controlled or monitored.
+  * @CDP_CODE:	Configuration applies to instruction fetches.
+  * @CDP_DATA:	Configuration applies to reads and writes.
+  */
+ enum resctrl_conf_type {
+ 	CDP_NONE,
+ 	CDP_CODE,
+ 	CDP_DATA,
+ };
+ 
+ #define CDP_NUM_TYPES	(CDP_DATA + 1)
+ 
+ /**
+  * struct resctrl_staged_config - parsed configuration to be applied
+  * @new_ctrl:		new ctrl value to be loaded
+  * @have_new_ctrl:	whether the user provided new_ctrl is valid
+  */
+ struct resctrl_staged_config {
+ 	u32			new_ctrl;
+ 	bool			have_new_ctrl;
+ };
+ 
+ /**
+  * struct rdt_domain - group of CPUs sharing a resctrl resource
+  * @list:		all instances of this resource
+  * @id:			unique id for this instance
+  * @cpu_mask:		which CPUs share this resource
+  * @rmid_busy_llc:	bitmap of which limbo RMIDs are above threshold
+  * @mbm_total:		saved state for MBM total bandwidth
+  * @mbm_local:		saved state for MBM local bandwidth
+  * @mbm_over:		worker to periodically read MBM h/w counters
+  * @cqm_limbo:		worker to periodically read CQM h/w counters
+  * @mbm_work_cpu:	worker CPU for MBM h/w counters
+  * @cqm_work_cpu:	worker CPU for CQM h/w counters
+  * @plr:		pseudo-locked region (if any) associated with domain
+  * @staged_config:	parsed configuration to be applied
+  */
+ struct rdt_domain {
+ 	struct list_head		list;
+ 	int				id;
+ 	struct cpumask			cpu_mask;
+ 	unsigned long			*rmid_busy_llc;
+ 	struct mbm_state		*mbm_total;
+ 	struct mbm_state		*mbm_local;
+ 	struct delayed_work		mbm_over;
+ 	struct delayed_work		cqm_limbo;
+ 	int				mbm_work_cpu;
+ 	int				cqm_work_cpu;
+ 	struct pseudo_lock_region	*plr;
+ 	struct resctrl_staged_config	staged_config[CDP_NUM_TYPES];
+ };
+ 
+ /**
+  * struct resctrl_cache - Cache allocation related data
+  * @cbm_len:		Length of the cache bit mask
+  * @min_cbm_bits:	Minimum number of consecutive bits to be set
+  * @cbm_idx_mult:	Multiplier of CBM index
+  * @cbm_idx_offset:	Offset of CBM index. CBM index is computed by:
+  *			closid * cbm_idx_multi + cbm_idx_offset
+  *			in a cache bit mask
+  * @shareable_bits:	Bitmask of shareable resource with other
+  *			executing entities
+  * @arch_has_sparse_bitmaps:	True if a bitmap like f00f is valid.
+  * @arch_has_empty_bitmaps:	True if the '0' bitmap is valid.
+  * @arch_has_per_cpu_cfg:	True if QOS_CFG register for this cache
+  *				level has CPU scope.
+  */
+ struct resctrl_cache {
+ 	unsigned int	cbm_len;
+ 	unsigned int	min_cbm_bits;
+ 	unsigned int	cbm_idx_mult;	// TODO remove this
+ 	unsigned int	cbm_idx_offset; // TODO remove this
+ 	unsigned int	shareable_bits;
+ 	bool		arch_has_sparse_bitmaps;
+ 	bool		arch_has_empty_bitmaps;
+ 	bool		arch_has_per_cpu_cfg;
+ };
+ 
+ /**
+  * enum membw_throttle_mode - System's memory bandwidth throttling mode
+  * @THREAD_THROTTLE_UNDEFINED:	Not relevant to the system
+  * @THREAD_THROTTLE_MAX:	Memory bandwidth is throttled at the core
+  *				always using smallest bandwidth percentage
+  *				assigned to threads, aka "max throttling"
+  * @THREAD_THROTTLE_PER_THREAD:	Memory bandwidth is throttled at the thread
+  */
+ enum membw_throttle_mode {
+ 	THREAD_THROTTLE_UNDEFINED = 0,
+ 	THREAD_THROTTLE_MAX,
+ 	THREAD_THROTTLE_PER_THREAD,
+ };
+ 
+ /**
+  * struct resctrl_membw - Memory bandwidth allocation related data
+  * @min_bw:		Minimum memory bandwidth percentage user can request
+  * @bw_gran:		Granularity at which the memory bandwidth is allocated
+  * @delay_linear:	True if memory B/W delay is in linear scale
+  * @arch_needs_linear:	True if we can't configure non-linear resources
+  * @throttle_mode:	Bandwidth throttling mode when threads request
+  *			different memory bandwidths
+  * @mba_sc:		True if MBA software controller(mba_sc) is enabled
+  * @mb_map:		Mapping of memory B/W percentage to memory B/W delay
+  */
+ struct resctrl_membw {
+ 	u32				min_bw;
+ 	u32				bw_gran;
+ 	u32				delay_linear;
+ 	bool				arch_needs_linear;
+ 	enum membw_throttle_mode	throttle_mode;
+ 	bool				mba_sc;
+ 	u32				*mb_map;
+ };
+ 
+ struct rdt_parse_data;
+ struct resctrl_schema;
+ 
+ /**
+  * struct rdt_resource - attributes of a resctrl resource
+  * @rid:		The index of the resource
+  * @alloc_enabled:	Is allocation enabled on this machine
+  * @mon_enabled:	Is monitoring enabled for this feature
+  * @alloc_capable:	Is allocation available on this machine
+  * @mon_capable:	Is monitor feature available on this machine
+  * @num_rmid:		Number of RMIDs available
+  * @cache_level:	Which cache level defines scope of this resource
+  * @cache:		Cache allocation related data
+  * @membw:		If the component has bandwidth controls, their properties.
+  * @domains:		All domains for this resource
+  * @name:		Name to use in "schemata" file.
+  * @data_width:		Character width of data when displaying
+  * @default_ctrl:	Specifies default cache cbm or memory B/W percent.
+  * @format_str:		Per resource format string to show domain value
+  * @parse_ctrlval:	Per resource function pointer to parse control values
+  * @evt_list:		List of monitoring events
+  * @fflags:		flags to choose base and info files
+  * @cdp_capable:	Is the CDP feature available on this resource
+  */
+ struct rdt_resource {
+ 	int			rid;
+ 	bool			alloc_enabled;
+ 	bool			mon_enabled;
+ 	bool			alloc_capable;
+ 	bool			mon_capable;
+ 	int			num_rmid;
+ 	int			cache_level;
+ 	struct resctrl_cache	cache;
+ 	struct resctrl_membw	membw;
+ 	struct list_head	domains;
+ 	char			*name;
+ 	int			data_width;
+ 	u32			default_ctrl;
+ 	const char		*format_str;
+ 	int			(*parse_ctrlval)(struct rdt_parse_data *data,
+ 						 struct resctrl_schema *s,
+ 						 struct rdt_domain *d);
+ 	struct list_head	evt_list;
+ 	unsigned long		fflags;
+ 	bool			cdp_capable;
+ };
+ 
+ /**
+  * struct resctrl_schema - configuration abilities of a resource presented to
+  *			   user-space
+  * @list:	Member of resctrl_schema_all.
+  * @name:	The name to use in the "schemata" file.
+  * @conf_type:	Whether this schema is specific to code/data.
+  * @res:	The resource structure exported by the architecture to describe
+  *		the hardware that is configured by this schema.
+  * @num_closid:	The number of closid that can be used with this schema. When
+  *		features like CDP are enabled, this will be lower than the
+  *		hardware supports for the resource.
+  */
+ struct resctrl_schema {
+ 	struct list_head		list;
+ 	char				name[8];
+ 	enum resctrl_conf_type		conf_type;
+ 	struct rdt_resource		*res;
+ 	u32				num_closid;
+ };
+ 
+ /* The number of closid supported by this resource regardless of CDP */
+ u32 resctrl_arch_get_num_closid(struct rdt_resource *r);
+ int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid);
+ void resctrl_arch_get_config(struct rdt_resource *r, struct rdt_domain *d,
+ 			     u32 closid, enum resctrl_conf_type type,
+ 			     u32 *value);
+ 
++>>>>>>> fa8f711d2f14 (x86/resctrl: Pass configuration type to resctrl_arch_get_config())
  #endif /* _RESCTRL_H */
* Unmerged path arch/x86/kernel/cpu/resctrl/ctrlmondata.c
* Unmerged path arch/x86/kernel/cpu/resctrl/monitor.c
* Unmerged path arch/x86/kernel/cpu/resctrl/rdtgroup.c
* Unmerged path include/linux/resctrl.h
