x86/resctrl: Rename and change the units of resctrl_cqm_threshold

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author James Morse <james.morse@arm.com>
commit ae2328b52962531c2d7c6b531022a3eb2d680f17
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/ae2328b5.failed

resctrl_cqm_threshold is stored in a hardware specific chunk size,
but exposed to user-space as bytes.

This means the filesystem parts of resctrl need to know how the hardware
counts, to convert the user provided byte value to chunks. The interface
between the architecture's resctrl code and the filesystem ought to
treat everything as bytes.

Change the unit of resctrl_cqm_threshold to bytes. resctrl_arch_rmid_read()
still returns its value in chunks, so this needs converting to bytes.
As all the users have been touched, rename the variable to
resctrl_rmid_realloc_threshold, which describes what the value is for.

Neither r->num_rmid nor hw_res->mon_scale are guaranteed to be a power
of 2, so the existing code introduces a rounding error from resctrl's
theoretical fraction of the cache usage. This behaviour is kept as it
ensures the user visible value matches the value read from hardware
when the rmid will be reallocated.

	Signed-off-by: James Morse <james.morse@arm.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Jamie Iles <quic_jiles@quicinc.com>
	Reviewed-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Reviewed-by: Reinette Chatre <reinette.chatre@intel.com>
	Tested-by: Xin Hao <xhao@linux.alibaba.com>
	Tested-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Tested-by: Cristian Marussi <cristian.marussi@arm.com>
Link: https://lore.kernel.org/r/20220902154829.30399-20-james.morse@arm.com
(cherry picked from commit ae2328b52962531c2d7c6b531022a3eb2d680f17)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/resctrl/monitor.c
#	arch/x86/kernel/cpu/resctrl/rdtgroup.c
#	include/linux/resctrl.h
diff --cc arch/x86/kernel/cpu/resctrl/monitor.c
index 810114991b5b,e91afe99b763..000000000000
--- a/arch/x86/kernel/cpu/resctrl/monitor.c
+++ b/arch/x86/kernel/cpu/resctrl/monitor.c
@@@ -178,12 -226,13 +181,16 @@@ static bool rmid_dirty(struct rmid_entr
   */
  void __check_limbo(struct rdt_domain *d, bool force_free)
  {
+ 	struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl;
+ 	struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r);
  	struct rmid_entry *entry;
- 	struct rdt_resource *r;
  	u32 crmid = 1, nrmid;
 -	bool rmid_dirty;
 -	u64 val = 0;
  
++<<<<<<< HEAD
 +	r = &rdt_resources_all[RDT_RESOURCE_L3];
 +
++=======
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  	/*
  	 * Skip RMID 0 and start from RMID 1 and check all the RMIDs that
  	 * are marked as busy for occupancy < threshold. If the occupancy
@@@ -196,7 -245,16 +203,20 @@@
  			break;
  
  		entry = __rmid_entry(nrmid);
++<<<<<<< HEAD
 +		if (force_free || !rmid_dirty(entry)) {
++=======
+ 
+ 		if (resctrl_arch_rmid_read(r, d, entry->rmid,
+ 					   QOS_L3_OCCUP_EVENT_ID, &val)) {
+ 			rmid_dirty = true;
+ 		} else {
+ 			val *= hw_res->mon_scale;
+ 			rmid_dirty = (val >= resctrl_rmid_realloc_threshold);
+ 		}
+ 
+ 		if (force_free || !rmid_dirty) {
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  			clear_bit(entry->rmid, d->rmid_busy_llc);
  			if (!--entry->busy) {
  				rmid_limbo_count--;
@@@ -235,19 -293,21 +255,31 @@@ int alloc_rmid(void
  
  static void add_rmid_to_limbo(struct rmid_entry *entry)
  {
- 	struct rdt_resource *r;
+ 	struct rdt_resource *r = &rdt_resources_all[RDT_RESOURCE_L3].r_resctrl;
+ 	struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r);
  	struct rdt_domain *d;
 -	int cpu, err;
 -	u64 val = 0;
 +	int cpu;
 +	u64 val;
  
++<<<<<<< HEAD
 +	r = &rdt_resources_all[RDT_RESOURCE_L3];
 +
++=======
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  	entry->busy = 0;
  	cpu = get_cpu();
  	list_for_each_entry(d, &r->domains, list) {
  		if (cpumask_test_cpu(cpu, &d->cpu_mask)) {
++<<<<<<< HEAD
 +			val = __rmid_read(entry->rmid, QOS_L3_OCCUP_EVENT_ID);
 +			if (val <= resctrl_cqm_threshold)
++=======
+ 			err = resctrl_arch_rmid_read(r, d, entry->rmid,
+ 						     QOS_L3_OCCUP_EVENT_ID,
+ 						     &val);
+ 			val *= hw_res->mon_scale;
+ 			if (err || val <= resctrl_rmid_realloc_threshold)
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  				continue;
  		}
  
@@@ -685,17 -745,18 +717,18 @@@ static void l3_mon_evt_init(struct rdt_
  
  int rdt_get_mon_l3_config(struct rdt_resource *r)
  {
 -	unsigned int mbm_offset = boot_cpu_data.x86_cache_mbm_width_offset;
 -	struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r);
 +	unsigned int mbm_offset
 +		= boot_cpu_data._rh.x86_cache_mbm_width_offset;
  	unsigned int cl_size = boot_cpu_data.x86_cache_size;
+ 	unsigned int threshold;
  	int ret;
  
 -	hw_res->mon_scale = boot_cpu_data.x86_cache_occ_scale;
 +	r->mon_scale = boot_cpu_data.x86_cache_occ_scale;
  	r->num_rmid = boot_cpu_data.x86_cache_max_rmid + 1;
 -	hw_res->mbm_width = MBM_CNTR_WIDTH_BASE;
 +	r->mbm_width = MBM_CNTR_WIDTH_BASE;
  
  	if (mbm_offset > 0 && mbm_offset <= MBM_CNTR_WIDTH_OFFSET_MAX)
 -		hw_res->mbm_width += mbm_offset;
 +		r->mbm_width += mbm_offset;
  	else if (mbm_offset > MBM_CNTR_WIDTH_OFFSET_MAX)
  		pr_warn("Ignoring impossible MBM counter offset\n");
  
@@@ -706,10 -767,14 +739,19 @@@
  	 *
  	 * For a 35MB LLC and 56 RMIDs, this is ~1.8% of the LLC.
  	 */
- 	resctrl_cqm_threshold = cl_size * 1024 / r->num_rmid;
+ 	threshold = cl_size * 1024 / r->num_rmid;
  
++<<<<<<< HEAD
 +	/* h/w works in units of "boot_cpu_data.x86_cache_occ_scale" */
 +	resctrl_cqm_threshold /= r->mon_scale;
++=======
+ 	/*
+ 	 * Because num_rmid may not be a power of two, round the value
+ 	 * to the nearest multiple of hw_res->mon_scale so it matches a
+ 	 * value the hardware will measure. mon_scale may not be a power of 2.
+ 	 */
+ 	resctrl_rmid_realloc_threshold = resctrl_arch_round_mon_val(threshold);
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  
  	ret = dom_data_init(r);
  	if (ret)
diff --cc arch/x86/kernel/cpu/resctrl/rdtgroup.c
index e5f7b979a288,849bdec37217..000000000000
--- a/arch/x86/kernel/cpu/resctrl/rdtgroup.c
+++ b/arch/x86/kernel/cpu/resctrl/rdtgroup.c
@@@ -1046,9 -1030,7 +1046,13 @@@ static int rdt_delay_linear_show(struc
  static int max_threshold_occ_show(struct kernfs_open_file *of,
  				  struct seq_file *seq, void *v)
  {
++<<<<<<< HEAD
 +	struct rdt_resource *r = of->kn->parent->priv;
 +
 +	seq_printf(seq, "%u\n", resctrl_cqm_threshold * r->mon_scale);
++=======
+ 	seq_printf(seq, "%u\n", resctrl_rmid_realloc_threshold);
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  
  	return 0;
  }
@@@ -1069,7 -1052,6 +1073,10 @@@ static int rdt_thread_throttle_mode_sho
  static ssize_t max_threshold_occ_write(struct kernfs_open_file *of,
  				       char *buf, size_t nbytes, loff_t off)
  {
++<<<<<<< HEAD
 +	struct rdt_resource *r = of->kn->parent->priv;
++=======
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  	unsigned int bytes;
  	int ret;
  
@@@ -1080,7 -1062,7 +1087,11 @@@
  	if (bytes > (boot_cpu_data.x86_cache_size * 1024))
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	resctrl_cqm_threshold = bytes / r->mon_scale;
++=======
+ 	resctrl_rmid_realloc_threshold = resctrl_arch_round_mon_val(bytes);
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  
  	return nbytes;
  }
diff --cc include/linux/resctrl.h
index 9b05af9b3e28,9995d043650a..000000000000
--- a/include/linux/resctrl.h
+++ b/include/linux/resctrl.h
@@@ -13,4 -15,241 +13,244 @@@ int proc_resctrl_show(struct seq_file *
  
  #endif
  
++<<<<<<< HEAD
++=======
+ /* max value for struct rdt_domain's mbps_val */
+ #define MBA_MAX_MBPS   U32_MAX
+ 
+ /**
+  * enum resctrl_conf_type - The type of configuration.
+  * @CDP_NONE:	No prioritisation, both code and data are controlled or monitored.
+  * @CDP_CODE:	Configuration applies to instruction fetches.
+  * @CDP_DATA:	Configuration applies to reads and writes.
+  */
+ enum resctrl_conf_type {
+ 	CDP_NONE,
+ 	CDP_CODE,
+ 	CDP_DATA,
+ };
+ 
+ #define CDP_NUM_TYPES	(CDP_DATA + 1)
+ 
+ /*
+  * Event IDs, the values match those used to program IA32_QM_EVTSEL before
+  * reading IA32_QM_CTR on RDT systems.
+  */
+ enum resctrl_event_id {
+ 	QOS_L3_OCCUP_EVENT_ID		= 0x01,
+ 	QOS_L3_MBM_TOTAL_EVENT_ID	= 0x02,
+ 	QOS_L3_MBM_LOCAL_EVENT_ID	= 0x03,
+ };
+ 
+ /**
+  * struct resctrl_staged_config - parsed configuration to be applied
+  * @new_ctrl:		new ctrl value to be loaded
+  * @have_new_ctrl:	whether the user provided new_ctrl is valid
+  */
+ struct resctrl_staged_config {
+ 	u32			new_ctrl;
+ 	bool			have_new_ctrl;
+ };
+ 
+ /**
+  * struct rdt_domain - group of CPUs sharing a resctrl resource
+  * @list:		all instances of this resource
+  * @id:			unique id for this instance
+  * @cpu_mask:		which CPUs share this resource
+  * @rmid_busy_llc:	bitmap of which limbo RMIDs are above threshold
+  * @mbm_total:		saved state for MBM total bandwidth
+  * @mbm_local:		saved state for MBM local bandwidth
+  * @mbm_over:		worker to periodically read MBM h/w counters
+  * @cqm_limbo:		worker to periodically read CQM h/w counters
+  * @mbm_work_cpu:	worker CPU for MBM h/w counters
+  * @cqm_work_cpu:	worker CPU for CQM h/w counters
+  * @plr:		pseudo-locked region (if any) associated with domain
+  * @staged_config:	parsed configuration to be applied
+  * @mbps_val:		When mba_sc is enabled, this holds the array of user
+  *			specified control values for mba_sc in MBps, indexed
+  *			by closid
+  */
+ struct rdt_domain {
+ 	struct list_head		list;
+ 	int				id;
+ 	struct cpumask			cpu_mask;
+ 	unsigned long			*rmid_busy_llc;
+ 	struct mbm_state		*mbm_total;
+ 	struct mbm_state		*mbm_local;
+ 	struct delayed_work		mbm_over;
+ 	struct delayed_work		cqm_limbo;
+ 	int				mbm_work_cpu;
+ 	int				cqm_work_cpu;
+ 	struct pseudo_lock_region	*plr;
+ 	struct resctrl_staged_config	staged_config[CDP_NUM_TYPES];
+ 	u32				*mbps_val;
+ };
+ 
+ /**
+  * struct resctrl_cache - Cache allocation related data
+  * @cbm_len:		Length of the cache bit mask
+  * @min_cbm_bits:	Minimum number of consecutive bits to be set
+  * @shareable_bits:	Bitmask of shareable resource with other
+  *			executing entities
+  * @arch_has_sparse_bitmaps:	True if a bitmap like f00f is valid.
+  * @arch_has_empty_bitmaps:	True if the '0' bitmap is valid.
+  * @arch_has_per_cpu_cfg:	True if QOS_CFG register for this cache
+  *				level has CPU scope.
+  */
+ struct resctrl_cache {
+ 	unsigned int	cbm_len;
+ 	unsigned int	min_cbm_bits;
+ 	unsigned int	shareable_bits;
+ 	bool		arch_has_sparse_bitmaps;
+ 	bool		arch_has_empty_bitmaps;
+ 	bool		arch_has_per_cpu_cfg;
+ };
+ 
+ /**
+  * enum membw_throttle_mode - System's memory bandwidth throttling mode
+  * @THREAD_THROTTLE_UNDEFINED:	Not relevant to the system
+  * @THREAD_THROTTLE_MAX:	Memory bandwidth is throttled at the core
+  *				always using smallest bandwidth percentage
+  *				assigned to threads, aka "max throttling"
+  * @THREAD_THROTTLE_PER_THREAD:	Memory bandwidth is throttled at the thread
+  */
+ enum membw_throttle_mode {
+ 	THREAD_THROTTLE_UNDEFINED = 0,
+ 	THREAD_THROTTLE_MAX,
+ 	THREAD_THROTTLE_PER_THREAD,
+ };
+ 
+ /**
+  * struct resctrl_membw - Memory bandwidth allocation related data
+  * @min_bw:		Minimum memory bandwidth percentage user can request
+  * @bw_gran:		Granularity at which the memory bandwidth is allocated
+  * @delay_linear:	True if memory B/W delay is in linear scale
+  * @arch_needs_linear:	True if we can't configure non-linear resources
+  * @throttle_mode:	Bandwidth throttling mode when threads request
+  *			different memory bandwidths
+  * @mba_sc:		True if MBA software controller(mba_sc) is enabled
+  * @mb_map:		Mapping of memory B/W percentage to memory B/W delay
+  */
+ struct resctrl_membw {
+ 	u32				min_bw;
+ 	u32				bw_gran;
+ 	u32				delay_linear;
+ 	bool				arch_needs_linear;
+ 	enum membw_throttle_mode	throttle_mode;
+ 	bool				mba_sc;
+ 	u32				*mb_map;
+ };
+ 
+ struct rdt_parse_data;
+ struct resctrl_schema;
+ 
+ /**
+  * struct rdt_resource - attributes of a resctrl resource
+  * @rid:		The index of the resource
+  * @alloc_capable:	Is allocation available on this machine
+  * @mon_capable:	Is monitor feature available on this machine
+  * @num_rmid:		Number of RMIDs available
+  * @cache_level:	Which cache level defines scope of this resource
+  * @cache:		Cache allocation related data
+  * @membw:		If the component has bandwidth controls, their properties.
+  * @domains:		All domains for this resource
+  * @name:		Name to use in "schemata" file.
+  * @data_width:		Character width of data when displaying
+  * @default_ctrl:	Specifies default cache cbm or memory B/W percent.
+  * @format_str:		Per resource format string to show domain value
+  * @parse_ctrlval:	Per resource function pointer to parse control values
+  * @evt_list:		List of monitoring events
+  * @fflags:		flags to choose base and info files
+  * @cdp_capable:	Is the CDP feature available on this resource
+  */
+ struct rdt_resource {
+ 	int			rid;
+ 	bool			alloc_capable;
+ 	bool			mon_capable;
+ 	int			num_rmid;
+ 	int			cache_level;
+ 	struct resctrl_cache	cache;
+ 	struct resctrl_membw	membw;
+ 	struct list_head	domains;
+ 	char			*name;
+ 	int			data_width;
+ 	u32			default_ctrl;
+ 	const char		*format_str;
+ 	int			(*parse_ctrlval)(struct rdt_parse_data *data,
+ 						 struct resctrl_schema *s,
+ 						 struct rdt_domain *d);
+ 	struct list_head	evt_list;
+ 	unsigned long		fflags;
+ 	bool			cdp_capable;
+ };
+ 
+ /**
+  * struct resctrl_schema - configuration abilities of a resource presented to
+  *			   user-space
+  * @list:	Member of resctrl_schema_all.
+  * @name:	The name to use in the "schemata" file.
+  * @conf_type:	Whether this schema is specific to code/data.
+  * @res:	The resource structure exported by the architecture to describe
+  *		the hardware that is configured by this schema.
+  * @num_closid:	The number of closid that can be used with this schema. When
+  *		features like CDP are enabled, this will be lower than the
+  *		hardware supports for the resource.
+  */
+ struct resctrl_schema {
+ 	struct list_head		list;
+ 	char				name[8];
+ 	enum resctrl_conf_type		conf_type;
+ 	struct rdt_resource		*res;
+ 	u32				num_closid;
+ };
+ 
+ /* The number of closid supported by this resource regardless of CDP */
+ u32 resctrl_arch_get_num_closid(struct rdt_resource *r);
+ int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid);
+ 
+ /*
+  * Update the ctrl_val and apply this config right now.
+  * Must be called on one of the domain's CPUs.
+  */
+ int resctrl_arch_update_one(struct rdt_resource *r, struct rdt_domain *d,
+ 			    u32 closid, enum resctrl_conf_type t, u32 cfg_val);
+ 
+ u32 resctrl_arch_get_config(struct rdt_resource *r, struct rdt_domain *d,
+ 			    u32 closid, enum resctrl_conf_type type);
+ int resctrl_online_domain(struct rdt_resource *r, struct rdt_domain *d);
+ void resctrl_offline_domain(struct rdt_resource *r, struct rdt_domain *d);
+ 
+ /**
+  * resctrl_arch_rmid_read() - Read the eventid counter corresponding to rmid
+  *			      for this resource and domain.
+  * @r:			resource that the counter should be read from.
+  * @d:			domain that the counter should be read from.
+  * @rmid:		rmid of the counter to read.
+  * @eventid:		eventid to read, e.g. L3 occupancy.
+  * @val:		result of the counter read in chunks.
+  *
+  * Call from process context on a CPU that belongs to domain @d.
+  *
+  * Return:
+  * 0 on success, or -EIO, -EINVAL etc on error.
+  */
+ int resctrl_arch_rmid_read(struct rdt_resource *r, struct rdt_domain *d,
+ 			   u32 rmid, enum resctrl_event_id eventid, u64 *val);
+ 
+ /**
+  * resctrl_arch_reset_rmid() - Reset any private state associated with rmid
+  *			       and eventid.
+  * @r:		The domain's resource.
+  * @d:		The rmid's domain.
+  * @rmid:	The rmid whose counter values should be reset.
+  * @eventid:	The eventid whose counter values should be reset.
+  *
+  * This can be called from any CPU.
+  */
+ void resctrl_arch_reset_rmid(struct rdt_resource *r, struct rdt_domain *d,
+ 			     u32 rmid, enum resctrl_event_id eventid);
+ 
+ extern unsigned int resctrl_rmid_realloc_threshold;
+ 
++>>>>>>> ae2328b52962 (x86/resctrl: Rename and change the units of resctrl_cqm_threshold)
  #endif /* _RESCTRL_H */
diff --git a/arch/x86/include/asm/resctrl.h b/arch/x86/include/asm/resctrl.h
index 07603064df8f..b712106e8f81 100644
--- a/arch/x86/include/asm/resctrl.h
+++ b/arch/x86/include/asm/resctrl.h
@@ -78,6 +78,15 @@ static void __resctrl_sched_in(void)
 	}
 }
 
+static inline unsigned int resctrl_arch_round_mon_val(unsigned int val)
+{
+	unsigned int scale = boot_cpu_data.x86_cache_occ_scale;
+
+	/* h/w works in units of "boot_cpu_data.x86_cache_occ_scale" */
+	val /= scale;
+	return val * scale;
+}
+
 static inline void resctrl_sched_in(void)
 {
 	if (static_branch_likely(&rdt_enable_key))
diff --git a/arch/x86/kernel/cpu/resctrl/internal.h b/arch/x86/kernel/cpu/resctrl/internal.h
index 9780c2d2c637..55fc70e0b91e 100644
--- a/arch/x86/kernel/cpu/resctrl/internal.h
+++ b/arch/x86/kernel/cpu/resctrl/internal.h
@@ -105,7 +105,6 @@ struct rmid_read {
 	u64			val;
 };
 
-extern unsigned int resctrl_cqm_threshold;
 extern bool rdt_alloc_capable;
 extern bool rdt_mon_capable;
 extern unsigned int rdt_mon_features;
* Unmerged path arch/x86/kernel/cpu/resctrl/monitor.c
* Unmerged path arch/x86/kernel/cpu/resctrl/rdtgroup.c
* Unmerged path include/linux/resctrl.h
