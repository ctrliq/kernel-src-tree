x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author Babu Moger <babu.moger@amd.com>
commit 5b6fac3fa44bafee12e0c3d1c5cbae6d058e9c98
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/5b6fac3f.failed

The QoS slow memory configuration details are available via
CPUID_Fn80000020_EDX_x02. Detect the available details and
initialize the rest to defaults.

	Signed-off-by: Babu Moger <babu.moger@amd.com>
	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
	Reviewed-by: Reinette Chatre <reinette.chatre@intel.com>
Link: https://lore.kernel.org/r/20230113152039.770054-7-babu.moger@amd.com
(cherry picked from commit 5b6fac3fa44bafee12e0c3d1c5cbae6d058e9c98)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/resctrl/core.c
#	arch/x86/kernel/cpu/resctrl/rdtgroup.c
diff --cc arch/x86/kernel/cpu/resctrl/core.c
index ba0be149b4a2,b4fc851f6489..000000000000
--- a/arch/x86/kernel/cpu/resctrl/core.c
+++ b/arch/x86/kernel/cpu/resctrl/core.c
@@@ -245,8 -160,15 +245,15 @@@ static inline void cache_alloc_hsw_prob
  bool is_mba_sc(struct rdt_resource *r)
  {
  	if (!r)
 -		return rdt_resources_all[RDT_RESOURCE_MBA].r_resctrl.membw.mba_sc;
 +		return rdt_resources_all[RDT_RESOURCE_MBA].membw.mba_sc;
  
+ 	/*
+ 	 * The software controller support is only applicable to MBA resource.
+ 	 * Make sure to check for resource type.
+ 	 */
+ 	if (r->rid != RDT_RESOURCE_MBA)
+ 		return false;
+ 
  	return r->membw.mba_sc;
  }
  
@@@ -307,12 -229,19 +314,23 @@@ static bool __get_mem_config_intel(stru
  
  static bool __rdt_get_mem_config_amd(struct rdt_resource *r)
  {
 -	struct rdt_hw_resource *hw_res = resctrl_to_arch_res(r);
  	union cpuid_0x10_3_eax eax;
  	union cpuid_0x10_x_edx edx;
- 	u32 ebx, ecx;
+ 	u32 ebx, ecx, subleaf;
  
++<<<<<<< HEAD
 +	cpuid_count(0x80000020, 1, &eax.full, &ebx, &ecx, &edx.full);
 +	r->num_closid = edx.split.cos_max + 1;
++=======
+ 	/*
+ 	 * Query CPUID_Fn80000020_EDX_x01 for MBA and
+ 	 * CPUID_Fn80000020_EDX_x02 for SMBA
+ 	 */
+ 	subleaf = (r->rid == RDT_RESOURCE_SMBA) ? 2 :  1;
+ 
+ 	cpuid_count(0x80000020, subleaf, &eax.full, &ebx, &ecx, &edx.full);
+ 	hw_res->num_closid = edx.split.cos_max + 1;
++>>>>>>> 5b6fac3fa44b (x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation)
  	r->default_ctrl = MAX_MBA_BW_AMD;
  
  	/* AMD does not use delay */
@@@ -864,8 -763,22 +882,21 @@@ static __init bool get_mem_config(void
  	return false;
  }
  
+ static __init bool get_slow_mem_config(void)
+ {
+ 	struct rdt_hw_resource *hw_res = &rdt_resources_all[RDT_RESOURCE_SMBA];
+ 
+ 	if (!rdt_cpu_has(X86_FEATURE_SMBA))
+ 		return false;
+ 
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
+ 		return __rdt_get_mem_config_amd(&hw_res->r_resctrl);
+ 
+ 	return false;
+ }
+ 
  static __init bool get_rdt_alloc_resources(void)
  {
 -	struct rdt_resource *r;
  	bool ret = false;
  
  	if (rdt_alloc_capable)
@@@ -968,18 -887,20 +1002,26 @@@ static __init void rdt_init_res_defs_am
  	struct rdt_resource *r;
  
  	for_each_rdt_resource(r) {
 -		hw_res = resctrl_to_arch_res(r);
 -
  		if (r->rid == RDT_RESOURCE_L3 ||
 -		    r->rid == RDT_RESOURCE_L2) {
 +		    r->rid == RDT_RESOURCE_L3DATA ||
 +		    r->rid == RDT_RESOURCE_L3CODE ||
 +		    r->rid == RDT_RESOURCE_L2 ||
 +		    r->rid == RDT_RESOURCE_L2DATA ||
 +		    r->rid == RDT_RESOURCE_L2CODE) {
  			r->cache.arch_has_sparse_bitmaps = true;
 +			r->cache.arch_has_empty_bitmaps = true;
  			r->cache.arch_has_per_cpu_cfg = true;
 -			r->cache.min_cbm_bits = 0;
  		} else if (r->rid == RDT_RESOURCE_MBA) {
++<<<<<<< HEAD
 +			r->msr_base = MSR_IA32_MBA_BW_BASE;
 +			r->msr_update = mba_wrmsr_amd;
++=======
+ 			hw_res->msr_base = MSR_IA32_MBA_BW_BASE;
+ 			hw_res->msr_update = mba_wrmsr_amd;
+ 		} else if (r->rid == RDT_RESOURCE_SMBA) {
+ 			hw_res->msr_base = MSR_IA32_SMBA_BW_BASE;
+ 			hw_res->msr_update = mba_wrmsr_amd;
++>>>>>>> 5b6fac3fa44b (x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation)
  		}
  	}
  }
diff --cc arch/x86/kernel/cpu/resctrl/rdtgroup.c
index e5f7b979a288,75169680516b..000000000000
--- a/arch/x86/kernel/cpu/resctrl/rdtgroup.c
+++ b/arch/x86/kernel/cpu/resctrl/rdtgroup.c
@@@ -1286,9 -1205,12 +1286,15 @@@ static bool rdtgroup_mode_test_exclusiv
  	struct rdt_resource *r;
  	bool has_cache = false;
  	struct rdt_domain *d;
 -	u32 ctrl;
  
++<<<<<<< HEAD
 +	for_each_alloc_enabled_rdt_resource(r) {
 +		if (r->rid == RDT_RESOURCE_MBA)
++=======
+ 	list_for_each_entry(s, &resctrl_schema_all, list) {
+ 		r = s->res;
+ 		if (r->rid == RDT_RESOURCE_MBA || r->rid == RDT_RESOURCE_SMBA)
++>>>>>>> 5b6fac3fa44b (x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation)
  			continue;
  		has_cache = true;
  		list_for_each_entry(d, &r->domains, list) {
@@@ -1463,10 -1393,14 +1469,21 @@@ static int rdtgroup_size_show(struct ke
  			if (rdtgrp->mode == RDT_MODE_PSEUDO_LOCKSETUP) {
  				size = 0;
  			} else {
++<<<<<<< HEAD
 +				ctrl = (!is_mba_sc(r) ?
 +						d->ctrl_val[rdtgrp->closid] :
 +						d->mbps_val[rdtgrp->closid]);
 +				if (r->rid == RDT_RESOURCE_MBA)
++=======
+ 				if (is_mba_sc(r))
+ 					ctrl = d->mbps_val[closid];
+ 				else
+ 					ctrl = resctrl_arch_get_config(r, d,
+ 								       closid,
+ 								       type);
+ 				if (r->rid == RDT_RESOURCE_MBA ||
+ 				    r->rid == RDT_RESOURCE_SMBA)
++>>>>>>> 5b6fac3fa44b (x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation)
  					size = ctrl;
  				else
  					size = rdtgroup_cbm_to_size(r, d, ctrl);
@@@ -2783,11 -2840,16 +2800,21 @@@ static int rdtgroup_init_alloc(struct r
  	struct rdt_resource *r;
  	int ret;
  
++<<<<<<< HEAD
 +	for_each_alloc_enabled_rdt_resource(r) {
 +		if (r->rid == RDT_RESOURCE_MBA) {
 +			rdtgroup_init_mba(r);
++=======
+ 	list_for_each_entry(s, &resctrl_schema_all, list) {
+ 		r = s->res;
+ 		if (r->rid == RDT_RESOURCE_MBA ||
+ 		    r->rid == RDT_RESOURCE_SMBA) {
+ 			rdtgroup_init_mba(r, rdtgrp->closid);
+ 			if (is_mba_sc(r))
+ 				continue;
++>>>>>>> 5b6fac3fa44b (x86/resctrl: Detect and configure Slow Memory Bandwidth Allocation)
  		} else {
 -			ret = rdtgroup_init_cat(s, rdtgrp->closid);
 +			ret = rdtgroup_init_cat(r, rdtgrp->closid);
  			if (ret < 0)
  				return ret;
  		}
diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index 8e65f9c8bdf4..69bb4b2788e1 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -1030,6 +1030,7 @@
 
 /* - AMD: */
 #define MSR_IA32_MBA_BW_BASE		0xc0000200
+#define MSR_IA32_SMBA_BW_BASE		0xc0000280
 
 /* MSR_IA32_VMX_MISC bits */
 #define MSR_IA32_VMX_MISC_INTEL_PT                 (1ULL << 14)
* Unmerged path arch/x86/kernel/cpu/resctrl/core.c
diff --git a/arch/x86/kernel/cpu/resctrl/ctrlmondata.c b/arch/x86/kernel/cpu/resctrl/ctrlmondata.c
index 9a768d89de37..ab4d8985e8c7 100644
--- a/arch/x86/kernel/cpu/resctrl/ctrlmondata.c
+++ b/arch/x86/kernel/cpu/resctrl/ctrlmondata.c
@@ -202,7 +202,7 @@ static int parse_line(char *line, struct rdt_resource *r,
 	unsigned long dom_id;
 
 	if (rdtgrp->mode == RDT_MODE_PSEUDO_LOCKSETUP &&
-	    r->rid == RDT_RESOURCE_MBA) {
+	    (r->rid == RDT_RESOURCE_MBA || r->rid == RDT_RESOURCE_SMBA)) {
 		rdt_last_cmd_puts("Cannot pseudo-lock MBA resource\n");
 		return -EINVAL;
 	}
* Unmerged path arch/x86/kernel/cpu/resctrl/rdtgroup.c
