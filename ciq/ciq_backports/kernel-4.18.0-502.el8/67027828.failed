net/mlx5e: TC, Set CT miss to the specific ct action instance

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author Paul Blakey <paulb@nvidia.com>
commit 6702782845a5bf381a19b204c369e63420041665
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/67027828.failed

Currently, CT misses restore the missed chain on the tc skb extension so
tc will continue from the relevant chain. Instead, restore the CT action's
miss cookie on the extension, which will instruct tc to continue from the
this specific CT action instance on the relevant filter's action list.

Map the CT action's miss_cookie to a new miss object (ACT_MISS), and use
this miss mapping instead of the current chain miss object (CHAIN_MISS)
for CT action misses.

To restore this new miss mapping value, add a RX restore rule for each
such mapping value.

	Signed-off-by: Paul Blakey <paulb@nvidia.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Reviewed-by: Oz Sholmo <ozsh@nvidia.com>
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 6702782845a5bf381a19b204c369e63420041665)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 46bb4efa3d07,e34d9b5fb504..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -5626,24 -5637,237 +5627,231 @@@ bool mlx5e_tc_update_skb(struct mlx5_cq
  		return false;
  	}
  
++<<<<<<< HEAD
 +	if (mapped_obj.type == MLX5_MAPPED_OBJ_CHAIN) {
 +		chain = mapped_obj.chain;
++=======
+ 	if (enc_opts_id) {
+ 		err = mapping_find(uplink_priv->tunnel_enc_opts_mapping,
+ 				   enc_opts_id, &enc_opts);
+ 		if (err) {
+ 			netdev_dbg(priv->netdev,
+ 				   "Couldn't find tunnel (opts) for tun_id: %d, err: %d\n",
+ 				   enc_opts_id, err);
+ 			return false;
+ 		}
+ 	}
+ 
+ 	switch (key.enc_control.addr_type) {
+ 	case FLOW_DISSECTOR_KEY_IPV4_ADDRS:
+ 		tun_dst = __ip_tun_set_dst(key.enc_ipv4.src, key.enc_ipv4.dst,
+ 					   key.enc_ip.tos, key.enc_ip.ttl,
+ 					   key.enc_tp.dst, TUNNEL_KEY,
+ 					   key32_to_tunnel_id(key.enc_key_id.keyid),
+ 					   enc_opts.key.len);
+ 		break;
+ 	case FLOW_DISSECTOR_KEY_IPV6_ADDRS:
+ 		tun_dst = __ipv6_tun_set_dst(&key.enc_ipv6.src, &key.enc_ipv6.dst,
+ 					     key.enc_ip.tos, key.enc_ip.ttl,
+ 					     key.enc_tp.dst, 0, TUNNEL_KEY,
+ 					     key32_to_tunnel_id(key.enc_key_id.keyid),
+ 					     enc_opts.key.len);
+ 		break;
+ 	default:
+ 		netdev_dbg(priv->netdev,
+ 			   "Couldn't restore tunnel, unsupported addr_type: %d\n",
+ 			   key.enc_control.addr_type);
+ 		return false;
+ 	}
+ 
+ 	if (!tun_dst) {
+ 		netdev_dbg(priv->netdev, "Couldn't restore tunnel, no tun_dst\n");
+ 		return false;
+ 	}
+ 
+ 	tun_dst->u.tun_info.key.tp_src = key.enc_tp.src;
+ 
+ 	if (enc_opts.key.len)
+ 		ip_tunnel_info_opts_set(&tun_dst->u.tun_info,
+ 					enc_opts.key.data,
+ 					enc_opts.key.len,
+ 					enc_opts.key.dst_opt_type);
+ 
+ 	skb_dst_set(skb, (struct dst_entry *)tun_dst);
+ 	dev = dev_get_by_index(&init_net, key.filter_ifindex);
+ 	if (!dev) {
+ 		netdev_dbg(priv->netdev,
+ 			   "Couldn't find tunnel device with ifindex: %d\n",
+ 			   key.filter_ifindex);
+ 		return false;
+ 	}
+ 
+ 	/* Set fwd_dev so we do dev_put() after datapath */
+ 	tc_priv->fwd_dev = dev;
+ 
+ 	skb->dev = dev;
+ 
+ 	return true;
+ }
+ 
+ static bool mlx5e_tc_restore_skb_tc_meta(struct sk_buff *skb, struct mlx5_tc_ct_priv *ct_priv,
+ 					 struct mlx5_mapped_obj *mapped_obj, u32 zone_restore_id,
+ 					 u32 tunnel_id,  struct mlx5e_tc_update_priv *tc_priv)
+ {
+ 	struct mlx5e_priv *priv = netdev_priv(skb->dev);
+ 	struct tc_skb_ext *tc_skb_ext;
+ 	u64 act_miss_cookie;
+ 	u32 chain;
+ 
+ 	chain = mapped_obj->type == MLX5_MAPPED_OBJ_CHAIN ? mapped_obj->chain : 0;
+ 	act_miss_cookie = mapped_obj->type == MLX5_MAPPED_OBJ_ACT_MISS ?
+ 			  mapped_obj->act_miss_cookie : 0;
+ 	if (chain || act_miss_cookie) {
+ 		if (!mlx5e_tc_ct_restore_flow(ct_priv, skb, zone_restore_id))
+ 			return false;
+ 
++>>>>>>> 6702782845a5 (net/mlx5e: TC, Set CT miss to the specific ct action instance)
  		tc_skb_ext = tc_skb_ext_alloc(skb);
 -		if (!tc_skb_ext) {
 -			WARN_ON(1);
 +		if (WARN_ON(!tc_skb_ext))
  			return false;
 -		}
  
++<<<<<<< HEAD
 +		tc_skb_ext->chain = chain;
++=======
+ 		if (act_miss_cookie) {
+ 			tc_skb_ext->act_miss_cookie = act_miss_cookie;
+ 			tc_skb_ext->act_miss = 1;
+ 		} else {
+ 			tc_skb_ext->chain = chain;
+ 		}
+ 	}
++>>>>>>> 6702782845a5 (net/mlx5e: TC, Set CT miss to the specific ct action instance)
  
 -	if (tc_priv)
 -		return mlx5e_tc_restore_tunnel(priv, skb, tc_priv, tunnel_id);
 +		zone_restore_id = (reg_b >> MLX5_REG_MAPPING_MOFFSET(NIC_ZONE_RESTORE_TO_REG)) &
 +			ESW_ZONE_ID_MASK;
  
++<<<<<<< HEAD
 +		if (!mlx5e_tc_ct_restore_flow(tc->ct, skb,
 +					      zone_restore_id))
 +			return false;
 +	} else {
++=======
+ 	return true;
+ }
+ 
+ static void mlx5e_tc_restore_skb_sample(struct mlx5e_priv *priv, struct sk_buff *skb,
+ 					struct mlx5_mapped_obj *mapped_obj,
+ 					struct mlx5e_tc_update_priv *tc_priv)
+ {
+ 	if (!mlx5e_tc_restore_tunnel(priv, skb, tc_priv, mapped_obj->sample.tunnel_id)) {
+ 		netdev_dbg(priv->netdev,
+ 			   "Failed to restore tunnel info for sampled packet\n");
+ 		return;
+ 	}
+ 	mlx5e_tc_sample_skb(skb, mapped_obj);
+ }
+ 
+ static bool mlx5e_tc_restore_skb_int_port(struct mlx5e_priv *priv, struct sk_buff *skb,
+ 					  struct mlx5_mapped_obj *mapped_obj,
+ 					  struct mlx5e_tc_update_priv *tc_priv,
+ 					  u32 tunnel_id)
+ {
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+ 	struct mlx5_rep_uplink_priv *uplink_priv;
+ 	struct mlx5e_rep_priv *uplink_rpriv;
+ 	bool forward_tx = false;
+ 
+ 	/* Tunnel restore takes precedence over int port restore */
+ 	if (tunnel_id)
+ 		return mlx5e_tc_restore_tunnel(priv, skb, tc_priv, tunnel_id);
+ 
+ 	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+ 	uplink_priv = &uplink_rpriv->uplink_priv;
+ 
+ 	if (mlx5e_tc_int_port_dev_fwd(uplink_priv->int_port_priv, skb,
+ 				      mapped_obj->int_port_metadata, &forward_tx)) {
+ 		/* Set fwd_dev for future dev_put */
+ 		tc_priv->fwd_dev = skb->dev;
+ 		tc_priv->forward_tx = forward_tx;
+ 
+ 		return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ bool mlx5e_tc_update_skb(struct mlx5_cqe64 *cqe, struct sk_buff *skb,
+ 			 struct mapping_ctx *mapping_ctx, u32 mapped_obj_id,
+ 			 struct mlx5_tc_ct_priv *ct_priv,
+ 			 u32 zone_restore_id, u32 tunnel_id,
+ 			 struct mlx5e_tc_update_priv *tc_priv)
+ {
+ 	struct mlx5e_priv *priv = netdev_priv(skb->dev);
+ 	struct mlx5_mapped_obj mapped_obj;
+ 	int err;
+ 
+ 	err = mapping_find(mapping_ctx, mapped_obj_id, &mapped_obj);
+ 	if (err) {
+ 		netdev_dbg(skb->dev,
+ 			   "Couldn't find mapped object for mapped_obj_id: %d, err: %d\n",
+ 			   mapped_obj_id, err);
+ 		return false;
+ 	}
+ 
+ 	switch (mapped_obj.type) {
+ 	case MLX5_MAPPED_OBJ_CHAIN:
+ 	case MLX5_MAPPED_OBJ_ACT_MISS:
+ 		return mlx5e_tc_restore_skb_tc_meta(skb, ct_priv, &mapped_obj, zone_restore_id,
+ 						    tunnel_id, tc_priv);
+ 	case MLX5_MAPPED_OBJ_SAMPLE:
+ 		mlx5e_tc_restore_skb_sample(priv, skb, &mapped_obj, tc_priv);
+ 		tc_priv->skb_done = true;
+ 		return true;
+ 	case MLX5_MAPPED_OBJ_INT_PORT_METADATA:
+ 		return mlx5e_tc_restore_skb_int_port(priv, skb, &mapped_obj, tc_priv, tunnel_id);
+ 	default:
++>>>>>>> 6702782845a5 (net/mlx5e: TC, Set CT miss to the specific ct action instance)
  		netdev_dbg(priv->netdev, "Invalid mapped object type: %d\n", mapped_obj.type);
  		return false;
  	}
  
 -	return false;
 -}
 -
 -bool mlx5e_tc_update_skb_nic(struct mlx5_cqe64 *cqe, struct sk_buff *skb)
 -{
 -	struct mlx5e_priv *priv = netdev_priv(skb->dev);
 -	u32 mapped_obj_id, reg_b, zone_restore_id;
 -	struct mlx5_tc_ct_priv *ct_priv;
 -	struct mapping_ctx *mapping_ctx;
 -	struct mlx5e_tc_table *tc;
 -
 -	reg_b = be32_to_cpu(cqe->ft_metadata);
 -	tc = mlx5e_fs_get_tc(priv->fs);
 -	mapped_obj_id = reg_b & MLX5E_TC_TABLE_CHAIN_TAG_MASK;
 -	zone_restore_id = (reg_b >> MLX5_REG_MAPPING_MOFFSET(NIC_ZONE_RESTORE_TO_REG)) &
 -			  ESW_ZONE_ID_MASK;
 -	ct_priv = tc->ct;
 -	mapping_ctx = tc->mapping;
 -
 -	return mlx5e_tc_update_skb(cqe, skb, mapping_ctx, mapped_obj_id, ct_priv, zone_restore_id,
 -				   0, NULL);
 +	return true;
  }
+ 
+ int mlx5e_tc_action_miss_mapping_get(struct mlx5e_priv *priv, struct mlx5_flow_attr *attr,
+ 				     u64 act_miss_cookie, u32 *act_miss_mapping)
+ {
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+ 	struct mlx5_mapped_obj mapped_obj = {};
+ 	struct mapping_ctx *ctx;
+ 	int err;
+ 
+ 	ctx = esw->offloads.reg_c0_obj_pool;
+ 
+ 	mapped_obj.type = MLX5_MAPPED_OBJ_ACT_MISS;
+ 	mapped_obj.act_miss_cookie = act_miss_cookie;
+ 	err = mapping_add(ctx, &mapped_obj, act_miss_mapping);
+ 	if (err)
+ 		return err;
+ 
+ 	attr->act_id_restore_rule = esw_add_restore_rule(esw, *act_miss_mapping);
+ 	if (IS_ERR(attr->act_id_restore_rule))
+ 		goto err_rule;
+ 
+ 	return 0;
+ 
+ err_rule:
+ 	mapping_remove(ctx, *act_miss_mapping);
+ 	return err;
+ }
+ 
+ void mlx5e_tc_action_miss_mapping_put(struct mlx5e_priv *priv, struct mlx5_flow_attr *attr,
+ 				      u32 act_miss_mapping)
+ {
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+ 	struct mapping_ctx *ctx;
+ 
+ 	ctx = esw->offloads.reg_c0_obj_pool;
+ 	mlx5_del_flow_rules(attr->act_id_restore_rule);
+ 	mapping_remove(ctx, act_miss_mapping);
+ }
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
index 008717afac60..314983bc6f08 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
@@ -60,6 +60,7 @@ struct mlx5_tc_ct_debugfs {
 
 struct mlx5_tc_ct_priv {
 	struct mlx5_core_dev *dev;
+	struct mlx5e_priv *priv;
 	const struct net_device *netdev;
 	struct mod_hdr_tbl *mod_hdr_tbl;
 	struct xarray tuple_ids;
@@ -86,7 +87,6 @@ struct mlx5_ct_flow {
 	struct mlx5_flow_attr *pre_ct_attr;
 	struct mlx5_flow_handle *pre_ct_rule;
 	struct mlx5_ct_ft *ft;
-	u32 chain_mapping;
 };
 
 struct mlx5_ct_zone_rule {
@@ -1558,6 +1558,7 @@ mlx5_tc_ct_parse_action(struct mlx5_tc_ct_priv *priv,
 	attr->ct_attr.zone = act->ct.zone;
 	attr->ct_attr.ct_action = act->ct.action;
 	attr->ct_attr.nf_ft = act->ct.flow_table;
+	attr->ct_attr.act_miss_cookie = act->miss_cookie;
 
 	return 0;
 }
@@ -1895,7 +1896,7 @@ mlx5_tc_ct_del_ft_cb(struct mlx5_tc_ct_priv *ct_priv, struct mlx5_ct_ft *ft)
  *	+ ft prio (tc chain)  +
  *	+ original match      +
  *	+---------------------+
- *		 | set chain miss mapping
+ *		 | set act_miss_cookie mapping
  *		 | set fte_id
  *		 | set tunnel_id
  *		 | do decap
@@ -1940,7 +1941,7 @@ __mlx5_tc_ct_flow_offload(struct mlx5_tc_ct_priv *ct_priv,
 	struct mlx5_flow_attr *pre_ct_attr;
 	struct mlx5_modify_hdr *mod_hdr;
 	struct mlx5_ct_flow *ct_flow;
-	int chain_mapping = 0, err;
+	int act_miss_mapping = 0, err;
 	struct mlx5_ct_ft *ft;
 	u16 zone;
 
@@ -1975,22 +1976,18 @@ __mlx5_tc_ct_flow_offload(struct mlx5_tc_ct_priv *ct_priv,
 	pre_ct_attr->action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
 			       MLX5_FLOW_CONTEXT_ACTION_MOD_HDR;
 
-	/* Write chain miss tag for miss in ct table as we
-	 * don't go though all prios of this chain as normal tc rules
-	 * miss.
-	 */
-	err = mlx5_chains_get_chain_mapping(ct_priv->chains, attr->chain,
-					    &chain_mapping);
+	err = mlx5e_tc_action_miss_mapping_get(ct_priv->priv, attr, attr->ct_attr.act_miss_cookie,
+					       &act_miss_mapping);
 	if (err) {
-		ct_dbg("Failed to get chain register mapping for chain");
-		goto err_get_chain;
+		ct_dbg("Failed to get register mapping for act miss");
+		goto err_get_act_miss;
 	}
-	ct_flow->chain_mapping = chain_mapping;
+	attr->ct_attr.act_miss_mapping = act_miss_mapping;
 
 	err = mlx5e_tc_match_to_reg_set(priv->mdev, pre_mod_acts, ct_priv->ns_type,
-					MAPPED_OBJ_TO_REG, chain_mapping);
+					MAPPED_OBJ_TO_REG, act_miss_mapping);
 	if (err) {
-		ct_dbg("Failed to set chain register mapping");
+		ct_dbg("Failed to set act miss register mapping");
 		goto err_mapping;
 	}
 
@@ -2054,8 +2051,8 @@ __mlx5_tc_ct_flow_offload(struct mlx5_tc_ct_priv *ct_priv,
 	mlx5_modify_header_dealloc(priv->mdev, pre_ct_attr->modify_hdr);
 err_mapping:
 	mlx5e_mod_hdr_dealloc(pre_mod_acts);
-	mlx5_chains_put_chain_mapping(ct_priv->chains, ct_flow->chain_mapping);
-err_get_chain:
+	mlx5e_tc_action_miss_mapping_put(ct_priv->priv, attr, act_miss_mapping);
+err_get_act_miss:
 	kfree(ct_flow->pre_ct_attr);
 err_alloc_pre:
 	mlx5_tc_ct_del_ft_cb(ct_priv, ft);
@@ -2094,7 +2091,7 @@ __mlx5_tc_ct_delete_flow(struct mlx5_tc_ct_priv *ct_priv,
 	mlx5_tc_rule_delete(priv, ct_flow->pre_ct_rule, pre_ct_attr);
 	mlx5_modify_header_dealloc(priv->mdev, pre_ct_attr->modify_hdr);
 
-	mlx5_chains_put_chain_mapping(ct_priv->chains, ct_flow->chain_mapping);
+	mlx5e_tc_action_miss_mapping_put(ct_priv->priv, attr, attr->ct_attr.act_miss_mapping);
 	mlx5_tc_ct_del_ft_cb(ct_priv, ct_flow->ft);
 
 	kfree(ct_flow->pre_ct_attr);
@@ -2267,6 +2264,7 @@ mlx5_tc_ct_init(struct mlx5e_priv *priv, struct mlx5_fs_chains *chains,
 	}
 
 	spin_lock_init(&ct_priv->ht_lock);
+	ct_priv->priv = priv;
 	ct_priv->ns_type = ns_type;
 	ct_priv->chains = chains;
 	ct_priv->netdev = priv->netdev;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h
index 5bbd6b92840f..5c5ddaa83055 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h
@@ -28,6 +28,8 @@ struct mlx5_ct_attr {
 	struct mlx5_ct_flow *ct_flow;
 	struct nf_flowtable *nf_ft;
 	u32 ct_labels_id;
+	u32 act_miss_mapping;
+	u64 act_miss_cookie;
 };
 
 #define zone_to_reg_ct {\
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index d259ebd524f6..204f224b93a3 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@ -100,6 +100,7 @@ struct mlx5_flow_attr {
 	struct mlx5_flow_attr *branch_true;
 	struct mlx5_flow_attr *branch_false;
 	struct mlx5_flow_attr *jumping_attr;
+	struct mlx5_flow_handle *act_id_restore_rule;
 	/* keep this union last */
 	union {
 		DECLARE_FLEX_ARRAY(struct mlx5_esw_flow_attr, esw_attr);
@@ -398,4 +399,9 @@ mlx5e_tc_update_skb(struct mlx5_cqe64 *cqe, struct sk_buff *skb)
 { return true; }
 #endif
 
+int mlx5e_tc_action_miss_mapping_get(struct mlx5e_priv *priv, struct mlx5_flow_attr *attr,
+				     u64 act_miss_cookie, u32 *act_miss_mapping);
+void mlx5e_tc_action_miss_mapping_put(struct mlx5e_priv *priv, struct mlx5_flow_attr *attr,
+				      u32 act_miss_mapping);
+
 #endif /* __MLX5_EN_TC_H__ */
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index f3395f193151..10a32aad1b33 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -52,12 +52,14 @@ enum mlx5_mapped_obj_type {
 	MLX5_MAPPED_OBJ_CHAIN,
 	MLX5_MAPPED_OBJ_SAMPLE,
 	MLX5_MAPPED_OBJ_INT_PORT_METADATA,
+	MLX5_MAPPED_OBJ_ACT_MISS,
 };
 
 struct mlx5_mapped_obj {
 	enum mlx5_mapped_obj_type type;
 	union {
 		u32 chain;
+		u64 act_miss_cookie;
 		struct {
 			u32 group_id;
 			u32 rate;
