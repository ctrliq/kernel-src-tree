x86/resctrl: Add domain offline callback for resctrl work

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author James Morse <james.morse@arm.com>
commit 798fd4b9ac37fec571f55fb8592497b0dd5f7a73
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/798fd4b9.failed

Because domains are exposed to user-space via resctrl, the filesystem
must update its state when CPU hotplug callbacks are triggered.

Some of this work is common to any architecture that would support
resctrl, but the work is tied up with the architecture code to
free the memory.

Move the monitor subdir removal and the cancelling of the mbm/limbo
works into a new resctrl_offline_domain() call. These bits are not
specific to the architecture. Grouping them in one function allows
that code to be moved to /fs/ and re-used by another architecture.

	Signed-off-by: James Morse <james.morse@arm.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Jamie Iles <quic_jiles@quicinc.com>
	Reviewed-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Reviewed-by: Reinette Chatre <reinette.chatre@intel.com>
	Tested-by: Xin Hao <xhao@linux.alibaba.com>
	Tested-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Tested-by: Cristian Marussi <cristian.marussi@arm.com>
Link: https://lore.kernel.org/r/20220902154829.30399-6-james.morse@arm.com
(cherry picked from commit 798fd4b9ac37fec571f55fb8592497b0dd5f7a73)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/resctrl/core.c
#	arch/x86/kernel/cpu/resctrl/internal.h
#	arch/x86/kernel/cpu/resctrl/rdtgroup.c
#	include/linux/resctrl.h
diff --cc arch/x86/kernel/cpu/resctrl/core.c
index 296d8b9fc18a,f69182973175..000000000000
--- a/arch/x86/kernel/cpu/resctrl/core.c
+++ b/arch/x86/kernel/cpu/resctrl/core.c
@@@ -655,13 -532,8 +636,18 @@@ static void domain_remove_cpu(int cpu, 
  		 */
  		if (d->plr)
  			d->plr->d = NULL;
++<<<<<<< HEAD
 +
 +		kfree(d->ctrl_val);
 +		kfree(d->mbps_val);
 +		bitmap_free(d->rmid_busy_llc);
 +		kfree(d->mbm_total);
 +		kfree(d->mbm_local);
 +		kfree(d);
++=======
+ 		domain_free(hw_dom);
+ 
++>>>>>>> 798fd4b9ac37 (x86/resctrl: Add domain offline callback for resctrl work)
  		return;
  	}
  
diff --cc arch/x86/kernel/cpu/resctrl/internal.h
index 9780c2d2c637,e12b55f815bf..000000000000
--- a/arch/x86/kernel/cpu/resctrl/internal.h
+++ b/arch/x86/kernel/cpu/resctrl/internal.h
@@@ -617,10 -522,6 +617,13 @@@ void free_rmid(u32 rmid)
  int rdt_get_mon_l3_config(struct rdt_resource *r);
  void mon_event_count(void *info);
  int rdtgroup_mondata_show(struct seq_file *m, void *arg);
++<<<<<<< HEAD
 +void rmdir_mondata_subdir_allrdtgrp(struct rdt_resource *r,
 +				    unsigned int dom_id);
 +void mkdir_mondata_subdir_allrdtgrp(struct rdt_resource *r,
 +				    struct rdt_domain *d);
++=======
++>>>>>>> 798fd4b9ac37 (x86/resctrl: Add domain offline callback for resctrl work)
  void mon_event_read(struct rmid_read *rr, struct rdt_resource *r,
  		    struct rdt_domain *d, struct rdtgroup *rdtgrp,
  		    int evtid, int first);
diff --cc arch/x86/kernel/cpu/resctrl/rdtgroup.c
index a8731279ffbf,5830905a92d2..000000000000
--- a/arch/x86/kernel/cpu/resctrl/rdtgroup.c
+++ b/arch/x86/kernel/cpu/resctrl/rdtgroup.c
@@@ -2480,9 -2505,6 +2481,12 @@@ static void rmdir_mondata_subdir_allrdt
  	struct rdtgroup *prgrp, *crgrp;
  	char name[32];
  
++<<<<<<< HEAD
 +	if (!r->mon_enabled)
 +		return;
 +
++=======
++>>>>>>> 798fd4b9ac37 (x86/resctrl: Add domain offline callback for resctrl work)
  	list_for_each_entry(prgrp, &rdt_all_groups, rdtgroup_list) {
  		sprintf(name, "mon_%s_%02d", r->name, dom_id);
  		kernfs_remove_by_name(prgrp->mon.mon_data_kn, name);
@@@ -3204,6 -3231,103 +3208,106 @@@ out
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static void domain_destroy_mon_state(struct rdt_domain *d)
+ {
+ 	bitmap_free(d->rmid_busy_llc);
+ 	kfree(d->mbm_total);
+ 	kfree(d->mbm_local);
+ }
+ 
+ void resctrl_offline_domain(struct rdt_resource *r, struct rdt_domain *d)
+ {
+ 	lockdep_assert_held(&rdtgroup_mutex);
+ 
+ 	if (!r->mon_capable)
+ 		return;
+ 
+ 	/*
+ 	 * If resctrl is mounted, remove all the
+ 	 * per domain monitor data directories.
+ 	 */
+ 	if (static_branch_unlikely(&rdt_mon_enable_key))
+ 		rmdir_mondata_subdir_allrdtgrp(r, d->id);
+ 
+ 	if (is_mbm_enabled())
+ 		cancel_delayed_work(&d->mbm_over);
+ 	if (is_llc_occupancy_enabled() && has_busy_rmid(r, d)) {
+ 		/*
+ 		 * When a package is going down, forcefully
+ 		 * decrement rmid->ebusy. There is no way to know
+ 		 * that the L3 was flushed and hence may lead to
+ 		 * incorrect counts in rare scenarios, but leaving
+ 		 * the RMID as busy creates RMID leaks if the
+ 		 * package never comes back.
+ 		 */
+ 		__check_limbo(d, true);
+ 		cancel_delayed_work(&d->cqm_limbo);
+ 	}
+ 
+ 	domain_destroy_mon_state(d);
+ }
+ 
+ static int domain_setup_mon_state(struct rdt_resource *r, struct rdt_domain *d)
+ {
+ 	size_t tsize;
+ 
+ 	if (is_llc_occupancy_enabled()) {
+ 		d->rmid_busy_llc = bitmap_zalloc(r->num_rmid, GFP_KERNEL);
+ 		if (!d->rmid_busy_llc)
+ 			return -ENOMEM;
+ 	}
+ 	if (is_mbm_total_enabled()) {
+ 		tsize = sizeof(*d->mbm_total);
+ 		d->mbm_total = kcalloc(r->num_rmid, tsize, GFP_KERNEL);
+ 		if (!d->mbm_total) {
+ 			bitmap_free(d->rmid_busy_llc);
+ 			return -ENOMEM;
+ 		}
+ 	}
+ 	if (is_mbm_local_enabled()) {
+ 		tsize = sizeof(*d->mbm_local);
+ 		d->mbm_local = kcalloc(r->num_rmid, tsize, GFP_KERNEL);
+ 		if (!d->mbm_local) {
+ 			bitmap_free(d->rmid_busy_llc);
+ 			kfree(d->mbm_total);
+ 			return -ENOMEM;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ int resctrl_online_domain(struct rdt_resource *r, struct rdt_domain *d)
+ {
+ 	int err;
+ 
+ 	lockdep_assert_held(&rdtgroup_mutex);
+ 
+ 	if (!r->mon_capable)
+ 		return 0;
+ 
+ 	err = domain_setup_mon_state(r, d);
+ 	if (err)
+ 		return err;
+ 
+ 	if (is_mbm_enabled()) {
+ 		INIT_DELAYED_WORK(&d->mbm_over, mbm_handle_overflow);
+ 		mbm_setup_overflow_handler(d, MBM_OVERFLOW_INTERVAL);
+ 	}
+ 
+ 	if (is_llc_occupancy_enabled())
+ 		INIT_DELAYED_WORK(&d->cqm_limbo, cqm_handle_limbo);
+ 
+ 	/* If resctrl is mounted, add per domain monitor data directories. */
+ 	if (static_branch_unlikely(&rdt_mon_enable_key))
+ 		mkdir_mondata_subdir_allrdtgrp(r, d);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 798fd4b9ac37 (x86/resctrl: Add domain offline callback for resctrl work)
  /*
   * rdtgroup_init - rdtgroup initialization
   *
diff --cc include/linux/resctrl.h
index 9b05af9b3e28,5d283bdd6162..000000000000
--- a/include/linux/resctrl.h
+++ b/include/linux/resctrl.h
@@@ -13,4 -15,184 +13,187 @@@ int proc_resctrl_show(struct seq_file *
  
  #endif
  
++<<<<<<< HEAD
++=======
+ /**
+  * enum resctrl_conf_type - The type of configuration.
+  * @CDP_NONE:	No prioritisation, both code and data are controlled or monitored.
+  * @CDP_CODE:	Configuration applies to instruction fetches.
+  * @CDP_DATA:	Configuration applies to reads and writes.
+  */
+ enum resctrl_conf_type {
+ 	CDP_NONE,
+ 	CDP_CODE,
+ 	CDP_DATA,
+ };
+ 
+ #define CDP_NUM_TYPES	(CDP_DATA + 1)
+ 
+ /**
+  * struct resctrl_staged_config - parsed configuration to be applied
+  * @new_ctrl:		new ctrl value to be loaded
+  * @have_new_ctrl:	whether the user provided new_ctrl is valid
+  */
+ struct resctrl_staged_config {
+ 	u32			new_ctrl;
+ 	bool			have_new_ctrl;
+ };
+ 
+ /**
+  * struct rdt_domain - group of CPUs sharing a resctrl resource
+  * @list:		all instances of this resource
+  * @id:			unique id for this instance
+  * @cpu_mask:		which CPUs share this resource
+  * @rmid_busy_llc:	bitmap of which limbo RMIDs are above threshold
+  * @mbm_total:		saved state for MBM total bandwidth
+  * @mbm_local:		saved state for MBM local bandwidth
+  * @mbm_over:		worker to periodically read MBM h/w counters
+  * @cqm_limbo:		worker to periodically read CQM h/w counters
+  * @mbm_work_cpu:	worker CPU for MBM h/w counters
+  * @cqm_work_cpu:	worker CPU for CQM h/w counters
+  * @plr:		pseudo-locked region (if any) associated with domain
+  * @staged_config:	parsed configuration to be applied
+  */
+ struct rdt_domain {
+ 	struct list_head		list;
+ 	int				id;
+ 	struct cpumask			cpu_mask;
+ 	unsigned long			*rmid_busy_llc;
+ 	struct mbm_state		*mbm_total;
+ 	struct mbm_state		*mbm_local;
+ 	struct delayed_work		mbm_over;
+ 	struct delayed_work		cqm_limbo;
+ 	int				mbm_work_cpu;
+ 	int				cqm_work_cpu;
+ 	struct pseudo_lock_region	*plr;
+ 	struct resctrl_staged_config	staged_config[CDP_NUM_TYPES];
+ };
+ 
+ /**
+  * struct resctrl_cache - Cache allocation related data
+  * @cbm_len:		Length of the cache bit mask
+  * @min_cbm_bits:	Minimum number of consecutive bits to be set
+  * @shareable_bits:	Bitmask of shareable resource with other
+  *			executing entities
+  * @arch_has_sparse_bitmaps:	True if a bitmap like f00f is valid.
+  * @arch_has_empty_bitmaps:	True if the '0' bitmap is valid.
+  * @arch_has_per_cpu_cfg:	True if QOS_CFG register for this cache
+  *				level has CPU scope.
+  */
+ struct resctrl_cache {
+ 	unsigned int	cbm_len;
+ 	unsigned int	min_cbm_bits;
+ 	unsigned int	shareable_bits;
+ 	bool		arch_has_sparse_bitmaps;
+ 	bool		arch_has_empty_bitmaps;
+ 	bool		arch_has_per_cpu_cfg;
+ };
+ 
+ /**
+  * enum membw_throttle_mode - System's memory bandwidth throttling mode
+  * @THREAD_THROTTLE_UNDEFINED:	Not relevant to the system
+  * @THREAD_THROTTLE_MAX:	Memory bandwidth is throttled at the core
+  *				always using smallest bandwidth percentage
+  *				assigned to threads, aka "max throttling"
+  * @THREAD_THROTTLE_PER_THREAD:	Memory bandwidth is throttled at the thread
+  */
+ enum membw_throttle_mode {
+ 	THREAD_THROTTLE_UNDEFINED = 0,
+ 	THREAD_THROTTLE_MAX,
+ 	THREAD_THROTTLE_PER_THREAD,
+ };
+ 
+ /**
+  * struct resctrl_membw - Memory bandwidth allocation related data
+  * @min_bw:		Minimum memory bandwidth percentage user can request
+  * @bw_gran:		Granularity at which the memory bandwidth is allocated
+  * @delay_linear:	True if memory B/W delay is in linear scale
+  * @arch_needs_linear:	True if we can't configure non-linear resources
+  * @throttle_mode:	Bandwidth throttling mode when threads request
+  *			different memory bandwidths
+  * @mba_sc:		True if MBA software controller(mba_sc) is enabled
+  * @mb_map:		Mapping of memory B/W percentage to memory B/W delay
+  */
+ struct resctrl_membw {
+ 	u32				min_bw;
+ 	u32				bw_gran;
+ 	u32				delay_linear;
+ 	bool				arch_needs_linear;
+ 	enum membw_throttle_mode	throttle_mode;
+ 	bool				mba_sc;
+ 	u32				*mb_map;
+ };
+ 
+ struct rdt_parse_data;
+ struct resctrl_schema;
+ 
+ /**
+  * struct rdt_resource - attributes of a resctrl resource
+  * @rid:		The index of the resource
+  * @alloc_capable:	Is allocation available on this machine
+  * @mon_capable:	Is monitor feature available on this machine
+  * @num_rmid:		Number of RMIDs available
+  * @cache_level:	Which cache level defines scope of this resource
+  * @cache:		Cache allocation related data
+  * @membw:		If the component has bandwidth controls, their properties.
+  * @domains:		All domains for this resource
+  * @name:		Name to use in "schemata" file.
+  * @data_width:		Character width of data when displaying
+  * @default_ctrl:	Specifies default cache cbm or memory B/W percent.
+  * @format_str:		Per resource format string to show domain value
+  * @parse_ctrlval:	Per resource function pointer to parse control values
+  * @evt_list:		List of monitoring events
+  * @fflags:		flags to choose base and info files
+  * @cdp_capable:	Is the CDP feature available on this resource
+  */
+ struct rdt_resource {
+ 	int			rid;
+ 	bool			alloc_capable;
+ 	bool			mon_capable;
+ 	int			num_rmid;
+ 	int			cache_level;
+ 	struct resctrl_cache	cache;
+ 	struct resctrl_membw	membw;
+ 	struct list_head	domains;
+ 	char			*name;
+ 	int			data_width;
+ 	u32			default_ctrl;
+ 	const char		*format_str;
+ 	int			(*parse_ctrlval)(struct rdt_parse_data *data,
+ 						 struct resctrl_schema *s,
+ 						 struct rdt_domain *d);
+ 	struct list_head	evt_list;
+ 	unsigned long		fflags;
+ 	bool			cdp_capable;
+ };
+ 
+ /**
+  * struct resctrl_schema - configuration abilities of a resource presented to
+  *			   user-space
+  * @list:	Member of resctrl_schema_all.
+  * @name:	The name to use in the "schemata" file.
+  * @conf_type:	Whether this schema is specific to code/data.
+  * @res:	The resource structure exported by the architecture to describe
+  *		the hardware that is configured by this schema.
+  * @num_closid:	The number of closid that can be used with this schema. When
+  *		features like CDP are enabled, this will be lower than the
+  *		hardware supports for the resource.
+  */
+ struct resctrl_schema {
+ 	struct list_head		list;
+ 	char				name[8];
+ 	enum resctrl_conf_type		conf_type;
+ 	struct rdt_resource		*res;
+ 	u32				num_closid;
+ };
+ 
+ /* The number of closid supported by this resource regardless of CDP */
+ u32 resctrl_arch_get_num_closid(struct rdt_resource *r);
+ int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid);
+ u32 resctrl_arch_get_config(struct rdt_resource *r, struct rdt_domain *d,
+ 			    u32 closid, enum resctrl_conf_type type);
+ int resctrl_online_domain(struct rdt_resource *r, struct rdt_domain *d);
+ void resctrl_offline_domain(struct rdt_resource *r, struct rdt_domain *d);
+ 
++>>>>>>> 798fd4b9ac37 (x86/resctrl: Add domain offline callback for resctrl work)
  #endif /* _RESCTRL_H */
* Unmerged path arch/x86/kernel/cpu/resctrl/core.c
* Unmerged path arch/x86/kernel/cpu/resctrl/internal.h
* Unmerged path arch/x86/kernel/cpu/resctrl/rdtgroup.c
* Unmerged path include/linux/resctrl.h
