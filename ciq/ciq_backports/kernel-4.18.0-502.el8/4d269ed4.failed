x86/resctrl: Kill off alloc_enabled

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-502.el8
commit-author James Morse <james.morse@arm.com>
commit 4d269ed485298e8a09485a664e7b35b370ab4ada
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-502.el8/4d269ed4.failed

rdt_resources_all[] used to have extra entries for L2CODE/L2DATA.
These were hidden from resctrl by the alloc_enabled value.

Now that the L2/L2CODE/L2DATA resources have been merged together,
alloc_enabled doesn't mean anything, it always has the same value as
alloc_capable which indicates allocation is supported by this resource.

Remove alloc_enabled and its helpers.

	Signed-off-by: James Morse <james.morse@arm.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Jamie Iles <quic_jiles@quicinc.com>
	Reviewed-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Reviewed-by: Reinette Chatre <reinette.chatre@intel.com>
	Tested-by: Xin Hao <xhao@linux.alibaba.com>
	Tested-by: Shaopeng Tan <tan.shaopeng@fujitsu.com>
	Tested-by: Cristian Marussi <cristian.marussi@arm.com>
Link: https://lore.kernel.org/r/20220902154829.30399-2-james.morse@arm.com
(cherry picked from commit 4d269ed485298e8a09485a664e7b35b370ab4ada)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/resctrl/internal.h
#	arch/x86/kernel/cpu/resctrl/rdtgroup.c
#	include/linux/resctrl.h
diff --cc arch/x86/kernel/cpu/resctrl/internal.h
index 9780c2d2c637,53f3d275a98f..000000000000
--- a/arch/x86/kernel/cpu/resctrl/internal.h
+++ b/arch/x86/kernel/cpu/resctrl/internal.h
@@@ -539,18 -456,11 +539,21 @@@ enum 
  		if (r->alloc_capable)
  
  #define for_each_mon_capable_rdt_resource(r)				      \
 -	for_each_rdt_resource(r)					      \
 +	for (r = rdt_resources_all; r < rdt_resources_all + RDT_NUM_RESOURCES;\
 +	     r++)							      \
  		if (r->mon_capable)
  
++<<<<<<< HEAD
 +#define for_each_alloc_enabled_rdt_resource(r)				      \
 +	for (r = rdt_resources_all; r < rdt_resources_all + RDT_NUM_RESOURCES;\
 +	     r++)							      \
 +		if (r->alloc_enabled)
 +
++=======
++>>>>>>> 4d269ed48529 (x86/resctrl: Kill off alloc_enabled)
  #define for_each_mon_enabled_rdt_resource(r)				      \
 -	for_each_rdt_resource(r)					      \
 +	for (r = rdt_resources_all; r < rdt_resources_all + RDT_NUM_RESOURCES;\
 +	     r++)							      \
  		if (r->mon_enabled)
  
  /* CPUID.(EAX=10H, ECX=ResID=1).EAX */
diff --cc arch/x86/kernel/cpu/resctrl/rdtgroup.c
index a8731279ffbf,526eb933333b..000000000000
--- a/arch/x86/kernel/cpu/resctrl/rdtgroup.c
+++ b/arch/x86/kernel/cpu/resctrl/rdtgroup.c
@@@ -1822,9 -1756,11 +1822,15 @@@ static int rdtgroup_create_info_dir(str
  	if (ret)
  		goto out_destroy;
  
++<<<<<<< HEAD
 +	for_each_alloc_enabled_rdt_resource(r) {
++=======
+ 	/* loop over enabled controls, these are all alloc_capable */
+ 	list_for_each_entry(s, &resctrl_schema_all, list) {
+ 		r = s->res;
++>>>>>>> 4d269ed48529 (x86/resctrl: Kill off alloc_enabled)
  		fflags =  r->fflags | RF_CTRL_INFO;
 -		ret = rdtgroup_mkdir_info_resdir(s, s->name, fflags);
 +		ret = rdtgroup_mkdir_info_resdir(r, r->name, fflags);
  		if (ret)
  			goto out_destroy;
  	}
@@@ -2122,6 -2048,92 +2128,95 @@@ static int rdt_enable_ctx(struct rdt_fs
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int schemata_list_add(struct rdt_resource *r, enum resctrl_conf_type type)
+ {
+ 	struct resctrl_schema *s;
+ 	const char *suffix = "";
+ 	int ret, cl;
+ 
+ 	s = kzalloc(sizeof(*s), GFP_KERNEL);
+ 	if (!s)
+ 		return -ENOMEM;
+ 
+ 	s->res = r;
+ 	s->num_closid = resctrl_arch_get_num_closid(r);
+ 	if (resctrl_arch_get_cdp_enabled(r->rid))
+ 		s->num_closid /= 2;
+ 
+ 	s->conf_type = type;
+ 	switch (type) {
+ 	case CDP_CODE:
+ 		suffix = "CODE";
+ 		break;
+ 	case CDP_DATA:
+ 		suffix = "DATA";
+ 		break;
+ 	case CDP_NONE:
+ 		suffix = "";
+ 		break;
+ 	}
+ 
+ 	ret = snprintf(s->name, sizeof(s->name), "%s%s", r->name, suffix);
+ 	if (ret >= sizeof(s->name)) {
+ 		kfree(s);
+ 		return -EINVAL;
+ 	}
+ 
+ 	cl = strlen(s->name);
+ 
+ 	/*
+ 	 * If CDP is supported by this resource, but not enabled,
+ 	 * include the suffix. This ensures the tabular format of the
+ 	 * schemata file does not change between mounts of the filesystem.
+ 	 */
+ 	if (r->cdp_capable && !resctrl_arch_get_cdp_enabled(r->rid))
+ 		cl += 4;
+ 
+ 	if (cl > max_name_width)
+ 		max_name_width = cl;
+ 
+ 	INIT_LIST_HEAD(&s->list);
+ 	list_add(&s->list, &resctrl_schema_all);
+ 
+ 	return 0;
+ }
+ 
+ static int schemata_list_create(void)
+ {
+ 	struct rdt_resource *r;
+ 	int ret = 0;
+ 
+ 	for_each_alloc_capable_rdt_resource(r) {
+ 		if (resctrl_arch_get_cdp_enabled(r->rid)) {
+ 			ret = schemata_list_add(r, CDP_CODE);
+ 			if (ret)
+ 				break;
+ 
+ 			ret = schemata_list_add(r, CDP_DATA);
+ 		} else {
+ 			ret = schemata_list_add(r, CDP_NONE);
+ 		}
+ 
+ 		if (ret)
+ 			break;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static void schemata_list_destroy(void)
+ {
+ 	struct resctrl_schema *s, *tmp;
+ 
+ 	list_for_each_entry_safe(s, tmp, &resctrl_schema_all, list) {
+ 		list_del(&s->list);
+ 		kfree(s);
+ 	}
+ }
+ 
++>>>>>>> 4d269ed48529 (x86/resctrl: Kill off alloc_enabled)
  static int rdt_get_tree(struct fs_context *fc)
  {
  	struct rdt_fs_context *ctx = rdt_fc2context(fc);
diff --cc include/linux/resctrl.h
index 9b05af9b3e28,386ab3a41500..000000000000
--- a/include/linux/resctrl.h
+++ b/include/linux/resctrl.h
@@@ -13,4 -15,184 +13,187 @@@ int proc_resctrl_show(struct seq_file *
  
  #endif
  
++<<<<<<< HEAD
++=======
+ /**
+  * enum resctrl_conf_type - The type of configuration.
+  * @CDP_NONE:	No prioritisation, both code and data are controlled or monitored.
+  * @CDP_CODE:	Configuration applies to instruction fetches.
+  * @CDP_DATA:	Configuration applies to reads and writes.
+  */
+ enum resctrl_conf_type {
+ 	CDP_NONE,
+ 	CDP_CODE,
+ 	CDP_DATA,
+ };
+ 
+ #define CDP_NUM_TYPES	(CDP_DATA + 1)
+ 
+ /**
+  * struct resctrl_staged_config - parsed configuration to be applied
+  * @new_ctrl:		new ctrl value to be loaded
+  * @have_new_ctrl:	whether the user provided new_ctrl is valid
+  */
+ struct resctrl_staged_config {
+ 	u32			new_ctrl;
+ 	bool			have_new_ctrl;
+ };
+ 
+ /**
+  * struct rdt_domain - group of CPUs sharing a resctrl resource
+  * @list:		all instances of this resource
+  * @id:			unique id for this instance
+  * @cpu_mask:		which CPUs share this resource
+  * @rmid_busy_llc:	bitmap of which limbo RMIDs are above threshold
+  * @mbm_total:		saved state for MBM total bandwidth
+  * @mbm_local:		saved state for MBM local bandwidth
+  * @mbm_over:		worker to periodically read MBM h/w counters
+  * @cqm_limbo:		worker to periodically read CQM h/w counters
+  * @mbm_work_cpu:	worker CPU for MBM h/w counters
+  * @cqm_work_cpu:	worker CPU for CQM h/w counters
+  * @plr:		pseudo-locked region (if any) associated with domain
+  * @staged_config:	parsed configuration to be applied
+  */
+ struct rdt_domain {
+ 	struct list_head		list;
+ 	int				id;
+ 	struct cpumask			cpu_mask;
+ 	unsigned long			*rmid_busy_llc;
+ 	struct mbm_state		*mbm_total;
+ 	struct mbm_state		*mbm_local;
+ 	struct delayed_work		mbm_over;
+ 	struct delayed_work		cqm_limbo;
+ 	int				mbm_work_cpu;
+ 	int				cqm_work_cpu;
+ 	struct pseudo_lock_region	*plr;
+ 	struct resctrl_staged_config	staged_config[CDP_NUM_TYPES];
+ };
+ 
+ /**
+  * struct resctrl_cache - Cache allocation related data
+  * @cbm_len:		Length of the cache bit mask
+  * @min_cbm_bits:	Minimum number of consecutive bits to be set
+  * @shareable_bits:	Bitmask of shareable resource with other
+  *			executing entities
+  * @arch_has_sparse_bitmaps:	True if a bitmap like f00f is valid.
+  * @arch_has_empty_bitmaps:	True if the '0' bitmap is valid.
+  * @arch_has_per_cpu_cfg:	True if QOS_CFG register for this cache
+  *				level has CPU scope.
+  */
+ struct resctrl_cache {
+ 	unsigned int	cbm_len;
+ 	unsigned int	min_cbm_bits;
+ 	unsigned int	shareable_bits;
+ 	bool		arch_has_sparse_bitmaps;
+ 	bool		arch_has_empty_bitmaps;
+ 	bool		arch_has_per_cpu_cfg;
+ };
+ 
+ /**
+  * enum membw_throttle_mode - System's memory bandwidth throttling mode
+  * @THREAD_THROTTLE_UNDEFINED:	Not relevant to the system
+  * @THREAD_THROTTLE_MAX:	Memory bandwidth is throttled at the core
+  *				always using smallest bandwidth percentage
+  *				assigned to threads, aka "max throttling"
+  * @THREAD_THROTTLE_PER_THREAD:	Memory bandwidth is throttled at the thread
+  */
+ enum membw_throttle_mode {
+ 	THREAD_THROTTLE_UNDEFINED = 0,
+ 	THREAD_THROTTLE_MAX,
+ 	THREAD_THROTTLE_PER_THREAD,
+ };
+ 
+ /**
+  * struct resctrl_membw - Memory bandwidth allocation related data
+  * @min_bw:		Minimum memory bandwidth percentage user can request
+  * @bw_gran:		Granularity at which the memory bandwidth is allocated
+  * @delay_linear:	True if memory B/W delay is in linear scale
+  * @arch_needs_linear:	True if we can't configure non-linear resources
+  * @throttle_mode:	Bandwidth throttling mode when threads request
+  *			different memory bandwidths
+  * @mba_sc:		True if MBA software controller(mba_sc) is enabled
+  * @mb_map:		Mapping of memory B/W percentage to memory B/W delay
+  */
+ struct resctrl_membw {
+ 	u32				min_bw;
+ 	u32				bw_gran;
+ 	u32				delay_linear;
+ 	bool				arch_needs_linear;
+ 	enum membw_throttle_mode	throttle_mode;
+ 	bool				mba_sc;
+ 	u32				*mb_map;
+ };
+ 
+ struct rdt_parse_data;
+ struct resctrl_schema;
+ 
+ /**
+  * struct rdt_resource - attributes of a resctrl resource
+  * @rid:		The index of the resource
+  * @mon_enabled:	Is monitoring enabled for this feature
+  * @alloc_capable:	Is allocation available on this machine
+  * @mon_capable:	Is monitor feature available on this machine
+  * @num_rmid:		Number of RMIDs available
+  * @cache_level:	Which cache level defines scope of this resource
+  * @cache:		Cache allocation related data
+  * @membw:		If the component has bandwidth controls, their properties.
+  * @domains:		All domains for this resource
+  * @name:		Name to use in "schemata" file.
+  * @data_width:		Character width of data when displaying
+  * @default_ctrl:	Specifies default cache cbm or memory B/W percent.
+  * @format_str:		Per resource format string to show domain value
+  * @parse_ctrlval:	Per resource function pointer to parse control values
+  * @evt_list:		List of monitoring events
+  * @fflags:		flags to choose base and info files
+  * @cdp_capable:	Is the CDP feature available on this resource
+  */
+ struct rdt_resource {
+ 	int			rid;
+ 	bool			mon_enabled;
+ 	bool			alloc_capable;
+ 	bool			mon_capable;
+ 	int			num_rmid;
+ 	int			cache_level;
+ 	struct resctrl_cache	cache;
+ 	struct resctrl_membw	membw;
+ 	struct list_head	domains;
+ 	char			*name;
+ 	int			data_width;
+ 	u32			default_ctrl;
+ 	const char		*format_str;
+ 	int			(*parse_ctrlval)(struct rdt_parse_data *data,
+ 						 struct resctrl_schema *s,
+ 						 struct rdt_domain *d);
+ 	struct list_head	evt_list;
+ 	unsigned long		fflags;
+ 	bool			cdp_capable;
+ };
+ 
+ /**
+  * struct resctrl_schema - configuration abilities of a resource presented to
+  *			   user-space
+  * @list:	Member of resctrl_schema_all.
+  * @name:	The name to use in the "schemata" file.
+  * @conf_type:	Whether this schema is specific to code/data.
+  * @res:	The resource structure exported by the architecture to describe
+  *		the hardware that is configured by this schema.
+  * @num_closid:	The number of closid that can be used with this schema. When
+  *		features like CDP are enabled, this will be lower than the
+  *		hardware supports for the resource.
+  */
+ struct resctrl_schema {
+ 	struct list_head		list;
+ 	char				name[8];
+ 	enum resctrl_conf_type		conf_type;
+ 	struct rdt_resource		*res;
+ 	u32				num_closid;
+ };
+ 
+ /* The number of closid supported by this resource regardless of CDP */
+ u32 resctrl_arch_get_num_closid(struct rdt_resource *r);
+ int resctrl_arch_update_domains(struct rdt_resource *r, u32 closid);
+ u32 resctrl_arch_get_config(struct rdt_resource *r, struct rdt_domain *d,
+ 			    u32 closid, enum resctrl_conf_type type);
+ 
++>>>>>>> 4d269ed48529 (x86/resctrl: Kill off alloc_enabled)
  #endif /* _RESCTRL_H */
diff --git a/arch/x86/kernel/cpu/resctrl/core.c b/arch/x86/kernel/cpu/resctrl/core.c
index 296d8b9fc18a..f40942fb84db 100644
--- a/arch/x86/kernel/cpu/resctrl/core.c
+++ b/arch/x86/kernel/cpu/resctrl/core.c
@@ -225,7 +225,6 @@ static inline void cache_alloc_hsw_probe(void)
 	r->cache.shareable_bits = 0xc0000;
 	r->cache.min_cbm_bits = 2;
 	r->alloc_capable = true;
-	r->alloc_enabled = true;
 
 	rdt_alloc_capable = true;
 }
@@ -288,7 +287,6 @@ static bool __get_mem_config_intel(struct rdt_resource *r)
 	thread_throttle_mode_init();
 
 	r->alloc_capable = true;
-	r->alloc_enabled = true;
 
 	return true;
 }
@@ -318,7 +316,6 @@ static bool __rdt_get_mem_config_amd(struct rdt_resource *r)
 	r->data_width = 4;
 
 	r->alloc_capable = true;
-	r->alloc_enabled = true;
 
 	return true;
 }
@@ -336,7 +333,6 @@ static void rdt_get_cache_alloc_cfg(int idx, struct rdt_resource *r)
 	r->cache.shareable_bits = ebx & r->default_ctrl;
 	r->data_width = (r->cache.cbm_len + 3) / 4;
 	r->alloc_capable = true;
-	r->alloc_enabled = true;
 }
 
 static void rdt_get_cdp_config(int level, int type)
* Unmerged path arch/x86/kernel/cpu/resctrl/internal.h
diff --git a/arch/x86/kernel/cpu/resctrl/pseudo_lock.c b/arch/x86/kernel/cpu/resctrl/pseudo_lock.c
index 4c3e0462db5e..b36697db92b8 100644
--- a/arch/x86/kernel/cpu/resctrl/pseudo_lock.c
+++ b/arch/x86/kernel/cpu/resctrl/pseudo_lock.c
@@ -837,7 +837,7 @@ bool rdtgroup_pseudo_locked_in_hierarchy(struct rdt_domain *d)
 	 * First determine which cpus have pseudo-locked regions
 	 * associated with them.
 	 */
-	for_each_alloc_enabled_rdt_resource(r) {
+	for_each_alloc_capable_rdt_resource(r) {
 		list_for_each_entry(d_i, &r->domains, list) {
 			if (d_i->plr)
 				cpumask_or(cpu_with_psl, cpu_with_psl,
* Unmerged path arch/x86/kernel/cpu/resctrl/rdtgroup.c
* Unmerged path include/linux/resctrl.h
