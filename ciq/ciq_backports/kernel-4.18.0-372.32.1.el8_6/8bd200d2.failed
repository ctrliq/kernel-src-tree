KVM: VMX: Flatten __vmx_vcpu_run()

jira LE-1907
cve CVE-2022-23825
cve CVE-2022-29901
cve CVE-2022-29900
cve CVE-2022-23816
Rebuild_History Non-Buildable kernel-4.18.0-372.32.1.el8_6
commit-author Josh Poimboeuf <jpoimboe@kernel.org>
commit 8bd200d23ec42d66ccd517a72dd0b9cc6132d2fd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.32.1.el8_6/8bd200d2.failed

Move the vmx_vm{enter,exit}() functionality into __vmx_vcpu_run().  This
will make it easier to do the spec_ctrl handling before the first RET.

	Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit 8bd200d23ec42d66ccd517a72dd0b9cc6132d2fd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/vmenter.S
diff --cc arch/x86/kvm/vmx/vmenter.S
index fd0a4aadb374,c83163fb2e9c..000000000000
--- a/arch/x86/kvm/vmx/vmenter.S
+++ b/arch/x86/kvm/vmx/vmenter.S
@@@ -31,68 -31,6 +31,71 @@@
  .section .noinstr.text, "ax"
  
  /**
++<<<<<<< HEAD
 + * vmx_vmenter - VM-Enter the current loaded VMCS
 + *
 + * %RFLAGS.ZF:	!VMCS.LAUNCHED, i.e. controls VMLAUNCH vs. VMRESUME
 + *
 + * Returns:
 + *	%RFLAGS.CF is set on VM-Fail Invalid
 + *	%RFLAGS.ZF is set on VM-Fail Valid
 + *	%RFLAGS.{CF,ZF} are cleared on VM-Success, i.e. VM-Exit
 + *
 + * Note that VMRESUME/VMLAUNCH fall-through and return directly if
 + * they VM-Fail, whereas a successful VM-Enter + VM-Exit will jump
 + * to vmx_vmexit.
 + */
 +SYM_FUNC_START_LOCAL(vmx_vmenter)
 +	/* EFLAGS.ZF is set if VMCS.LAUNCHED == 0 */
 +	je 2f
 +
 +1:	vmresume
 +	ret
 +
 +2:	vmlaunch
 +	ret
 +
 +3:	cmpb $0, kvm_rebooting
 +	je 4f
 +	ret
 +4:	ud2
 +
 +	_ASM_EXTABLE(1b, 3b)
 +	_ASM_EXTABLE(2b, 3b)
 +
 +SYM_FUNC_END(vmx_vmenter)
 +
 +/**
 + * vmx_vmexit - Handle a VMX VM-Exit
 + *
 + * Returns:
 + *	%RFLAGS.{CF,ZF} are cleared on VM-Success, i.e. VM-Exit
 + *
 + * This is vmx_vmenter's partner in crime.  On a VM-Exit, control will jump
 + * here after hardware loads the host's state, i.e. this is the destination
 + * referred to by VMCS.HOST_RIP.
 + */
 +SYM_FUNC_START(vmx_vmexit)
 +#ifdef CONFIG_RETPOLINE
 +	ALTERNATIVE "jmp .Lvmexit_skip_rsb", "", X86_FEATURE_RETPOLINE
 +	/* Preserve guest's RAX, it's used to stuff the RSB. */
 +	push %_ASM_AX
 +
 +	/* IMPORTANT: Stuff the RSB immediately after VM-Exit, before RET! */
 +	FILL_RETURN_BUFFER %_ASM_AX, RSB_CLEAR_LOOPS, X86_FEATURE_RETPOLINE
 +
 +	/* Clear RFLAGS.CF and RFLAGS.ZF to preserve VM-Exit, i.e. !VM-Fail. */
 +	or $1, %_ASM_AX
 +
 +	pop %_ASM_AX
 +.Lvmexit_skip_rsb:
 +#endif
 +	ret
 +SYM_FUNC_END(vmx_vmexit)
 +
 +/**
++=======
++>>>>>>> 8bd200d23ec4 (KVM: VMX: Flatten __vmx_vcpu_run())
   * __vmx_vcpu_run - Run a vCPU via a transition to VMX guest mode
   * @vmx:	struct vcpu_vmx * (forwarded to vmx_update_host_rsp)
   * @regs:	unsigned long * (to guest registers)
@@@ -228,11 -195,17 +260,17 @@@ SYM_INNER_LABEL(vmx_vmexit, SYM_L_GLOBA
  	pop %edi
  #endif
  	pop %_ASM_BP
 -	RET
 +	ret
  
- 	/* VM-Fail.  Out-of-line to avoid a taken Jcc after VM-Exit. */
- 2:	mov $1, %eax
- 	jmp 1b
+ .Lfixup:
+ 	cmpb $0, kvm_rebooting
+ 	jne .Lvmfail
+ 	ud2
+ .Lvmfail:
+ 	/* VM-Fail: set return value to 1 */
+ 	mov $1, %eax
+ 	jmp .Lclear_regs
+ 
  SYM_FUNC_END(__vmx_vcpu_run)
  
  
* Unmerged path arch/x86/kvm/vmx/vmenter.S
