x86/bugs: Optimize SPEC_CTRL MSR writes

jira LE-1907
cve CVE-2022-23825
cve CVE-2022-29901
cve CVE-2022-29900
cve CVE-2022-23816
Rebuild_History Non-Buildable kernel-4.18.0-372.32.1.el8_6
commit-author Peter Zijlstra <peterz@infradead.org>
commit c779bc1a9002fa474175b80e72b85c9bf628abb0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.32.1.el8_6/c779bc1a.failed

When changing SPEC_CTRL for user control, the WRMSR can be delayed
until return-to-user when KERNEL_IBRS has been enabled.

This avoids an MSR write during context switch.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit c779bc1a9002fa474175b80e72b85c9bf628abb0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/nospec-branch.h
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/process.c
diff --cc arch/x86/include/asm/nospec-branch.h
index 12722d2e7709,b6abf0c6b41d..000000000000
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@@ -267,6 -253,7 +267,10 @@@ static inline void indirect_branch_pred
  
  /* The Intel SPEC CTRL MSR base value cache */
  extern u64 x86_spec_ctrl_base;
++<<<<<<< HEAD
++=======
+ extern void write_spec_ctrl_current(u64 val, bool force);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  
  /*
   * With retpoline, we must use IBRS to restrict branch prediction
diff --cc arch/x86/kernel/cpu/bugs.c
index ff842ff87312,8f7c8dfbdbb4..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -54,6 -55,30 +54,28 @@@ EXPORT_SYMBOL_GPL(x86_spec_ctrl_base)
  static DEFINE_MUTEX(spec_ctrl_mutex);
  
  /*
++<<<<<<< HEAD
++=======
+  * Keep track of the SPEC_CTRL MSR value for the current task, which may differ
+  * from x86_spec_ctrl_base due to STIBP/SSB in __speculation_ctrl_update().
+  */
+ void write_spec_ctrl_current(u64 val, bool force)
+ {
+ 	if (this_cpu_read(x86_spec_ctrl_current) == val)
+ 		return;
+ 
+ 	this_cpu_write(x86_spec_ctrl_current, val);
+ 
+ 	/*
+ 	 * When KERNEL_IBRS this MSR is written on return-to-user, unless
+ 	 * forced the update can be delayed until that time.
+ 	 */
+ 	if (force || !cpu_feature_enabled(X86_FEATURE_KERNEL_IBRS))
+ 		wrmsrl(MSR_IA32_SPEC_CTRL, val);
+ }
+ 
+ /*
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
   * The vendor and possibly platform specific bits which can be modified in
   * x86_spec_ctrl_base.
   */
@@@ -1182,7 -1303,7 +1204,11 @@@ static void __init spectre_v2_select_mi
  	if (spectre_v2_in_eibrs_mode(mode)) {
  		/* Force it so VMEXIT will restore correctly */
  		x86_spec_ctrl_base |= SPEC_CTRL_IBRS;
++<<<<<<< HEAD
 +		wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base);
++=======
+ 		write_spec_ctrl_current(x86_spec_ctrl_base, true);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  	}
  
  	switch (mode) {
@@@ -1239,7 -1358,7 +1265,11 @@@
  
  static void update_stibp_msr(void * __unused)
  {
++<<<<<<< HEAD
 +	wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base);
++=======
+ 	write_spec_ctrl_current(x86_spec_ctrl_base, true);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  }
  
  /* Update x86_spec_ctrl_base in case SMT state changed. */
@@@ -1483,7 -1601,7 +1513,11 @@@ static enum ssb_mitigation __init __ssb
  			x86_amd_ssb_disable();
  		} else {
  			x86_spec_ctrl_base |= SPEC_CTRL_SSBD;
++<<<<<<< HEAD
 +			wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base);
++=======
+ 			write_spec_ctrl_current(x86_spec_ctrl_base, true);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  		}
  	}
  
@@@ -1701,7 -1852,7 +1735,11 @@@ int arch_prctl_spec_ctrl_get(struct tas
  void x86_spec_ctrl_setup_ap(void)
  {
  	if (boot_cpu_has(X86_FEATURE_MSR_SPEC_CTRL))
++<<<<<<< HEAD
 +		wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base);
++=======
+ 		write_spec_ctrl_current(x86_spec_ctrl_base, true);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  
  	if (ssb_mode == SPEC_STORE_BYPASS_DISABLE)
  		x86_amd_ssb_disable();
diff --cc arch/x86/kernel/process.c
index 4872353b9865,d456ce21c255..000000000000
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@@ -582,11 -599,8 +582,16 @@@ static __always_inline void __speculati
  		msr |= stibp_tif_to_spec_ctrl(tifn);
  	}
  
++<<<<<<< HEAD
 +	if (updmsr) {
 +		if (static_cpu_has(X86_FEATURE_SPEC_CTRL_ENTRY))
 +			spec_ctrl_update(msr);
 +		wrmsrl(MSR_IA32_SPEC_CTRL, msr);
 +	}
++=======
+ 	if (updmsr)
+ 		write_spec_ctrl_current(msr, false);
++>>>>>>> c779bc1a9002 (x86/bugs: Optimize SPEC_CTRL MSR writes)
  }
  
  static unsigned long speculation_ctrl_update_tif(struct task_struct *tsk)
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/process.c
