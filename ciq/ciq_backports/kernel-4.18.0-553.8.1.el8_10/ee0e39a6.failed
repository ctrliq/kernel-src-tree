x86/mm: Move is_vsyscall_vaddr() into asm/vsyscall.h

jira LE-1907
cve CVE-2024-26906
Rebuild_History Non-Buildable kernel-4.18.0-553.8.1.el8_10
commit-author Hou Tao <houtao1@huawei.com>
commit ee0e39a63b78849f8abbef268b13e4838569f646
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.8.1.el8_10/ee0e39a6.failed

Move is_vsyscall_vaddr() into asm/vsyscall.h to make it available for
copy_from_kernel_nofault_allowed() in arch/x86/mm/maccess.c.

	Reviewed-by: Sohil Mehta <sohil.mehta@intel.com>
	Signed-off-by: Hou Tao <houtao1@huawei.com>
Link: https://lore.kernel.org/r/20240202103935.3154011-2-houtao@huaweicloud.com
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit ee0e39a63b78849f8abbef268b13e4838569f646)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/fault.c
diff --cc arch/x86/mm/fault.c
index 929bfb03e31a,d6375b3c633b..000000000000
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@@ -823,15 -798,6 +823,18 @@@ show_signal_msg(struct pt_regs *regs, u
  	show_opcodes(regs, loglvl);
  }
  
++<<<<<<< HEAD
 +/*
 + * The (legacy) vsyscall page is the long page in the kernel portion
 + * of the address space that has user-accessible permissions.
 + */
 +static bool is_vsyscall_vaddr(unsigned long vaddr)
 +{
 +	return (vaddr & PAGE_MASK) == VSYSCALL_ADDR;
 +}
 +
++=======
++>>>>>>> ee0e39a63b78 (x86/mm: Move is_vsyscall_vaddr() into asm/vsyscall.h)
  static void
  __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
  		       unsigned long address, u32 pkey, int si_code)
diff --git a/arch/x86/include/asm/vsyscall.h b/arch/x86/include/asm/vsyscall.h
index b986b2ca688a..8154b25cb975 100644
--- a/arch/x86/include/asm/vsyscall.h
+++ b/arch/x86/include/asm/vsyscall.h
@@ -4,6 +4,7 @@
 
 #include <linux/seqlock.h>
 #include <uapi/asm/vsyscall.h>
+#include <asm/page_types.h>
 
 #ifdef CONFIG_X86_VSYSCALL_EMULATION
 extern void map_vsyscall(void);
@@ -22,4 +23,13 @@ static inline bool emulate_vsyscall(struct pt_regs *regs, unsigned long address)
 }
 #endif
 
+/*
+ * The (legacy) vsyscall page is the long page in the kernel portion
+ * of the address space that has user-accessible permissions.
+ */
+static inline bool is_vsyscall_vaddr(unsigned long vaddr)
+{
+	return unlikely((vaddr & PAGE_MASK) == VSYSCALL_ADDR);
+}
+
 #endif /* _ASM_X86_VSYSCALL_H */
* Unmerged path arch/x86/mm/fault.c
