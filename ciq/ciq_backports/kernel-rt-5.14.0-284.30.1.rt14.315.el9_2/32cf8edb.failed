rxrpc: Trace/count transmission underflows and cwnd resets

jira LE-1907
Rebuild_History Non-Buildable kernel-rt-5.14.0-284.30.1.rt14.315.el9_2
commit-author David Howells <dhowells@redhat.com>
commit 32cf8edb079a6a687a2b5dba39a813a0bbd0ddf9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-rt-5.14.0-284.30.1.rt14.315.el9_2/32cf8edb.failed

Add a tracepoint to log when a cwnd reset occurs due to lack of
transmission on a call.

Add stat counters to count transmission underflows (ie. when we have tx
window space, but sendmsg doesn't manage to keep up), cwnd resets and
transmission failures.

	Signed-off-by: David Howells <dhowells@redhat.com>
cc: Marc Dionne <marc.dionne@auristor.com>
cc: linux-afs@lists.infradead.org
(cherry picked from commit 32cf8edb079a6a687a2b5dba39a813a0bbd0ddf9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/rxrpc/call_event.c
diff --cc net/rxrpc/call_event.c
index a95f4604cb29,9f1e490ab976..000000000000
--- a/net/rxrpc/call_event.c
+++ b/net/rxrpc/call_event.c
@@@ -291,6 -260,87 +291,90 @@@ out
  	_leave("");
  }
  
++<<<<<<< HEAD
++=======
+ static bool rxrpc_tx_window_has_space(struct rxrpc_call *call)
+ {
+ 	unsigned int winsize = min_t(unsigned int, call->tx_winsize,
+ 				     call->cong_cwnd + call->cong_extra);
+ 	rxrpc_seq_t window = call->acks_hard_ack, wtop = window + winsize;
+ 	rxrpc_seq_t tx_top = call->tx_top;
+ 	int space;
+ 
+ 	space = wtop - tx_top;
+ 	return space > 0;
+ }
+ 
+ /*
+  * Decant some if the sendmsg prepared queue into the transmission buffer.
+  */
+ static void rxrpc_decant_prepared_tx(struct rxrpc_call *call)
+ {
+ 	struct rxrpc_txbuf *txb;
+ 
+ 	if (rxrpc_is_client_call(call) &&
+ 	    !test_bit(RXRPC_CALL_EXPOSED, &call->flags))
+ 		rxrpc_expose_client_call(call);
+ 
+ 	while ((txb = list_first_entry_or_null(&call->tx_sendmsg,
+ 					       struct rxrpc_txbuf, call_link))) {
+ 		spin_lock(&call->tx_lock);
+ 		list_del(&txb->call_link);
+ 		spin_unlock(&call->tx_lock);
+ 
+ 		call->tx_top = txb->seq;
+ 		list_add_tail(&txb->call_link, &call->tx_buffer);
+ 
+ 		rxrpc_transmit_one(call, txb);
+ 
+ 		// TODO: Drain the transmission buffers.  Do this somewhere better
+ 		if (after(call->acks_hard_ack, call->tx_bottom + 16))
+ 			rxrpc_shrink_call_tx_buffer(call);
+ 
+ 		if (!rxrpc_tx_window_has_space(call))
+ 			break;
+ 	}
+ }
+ 
+ static void rxrpc_transmit_some_data(struct rxrpc_call *call)
+ {
+ 	switch (call->state) {
+ 	case RXRPC_CALL_SERVER_ACK_REQUEST:
+ 		if (list_empty(&call->tx_sendmsg))
+ 			return;
+ 		fallthrough;
+ 
+ 	case RXRPC_CALL_SERVER_SEND_REPLY:
+ 	case RXRPC_CALL_SERVER_AWAIT_ACK:
+ 	case RXRPC_CALL_CLIENT_SEND_REQUEST:
+ 	case RXRPC_CALL_CLIENT_AWAIT_REPLY:
+ 		if (!rxrpc_tx_window_has_space(call))
+ 			return;
+ 		if (list_empty(&call->tx_sendmsg)) {
+ 			rxrpc_inc_stat(call->rxnet, stat_tx_data_underflow);
+ 			return;
+ 		}
+ 		rxrpc_decant_prepared_tx(call);
+ 		break;
+ 	default:
+ 		return;
+ 	}
+ }
+ 
+ /*
+  * Ping the other end to fill our RTT cache and to retrieve the rwind
+  * and MTU parameters.
+  */
+ static void rxrpc_send_initial_ping(struct rxrpc_call *call)
+ {
+ 	if (call->peer->rtt_count < 3 ||
+ 	    ktime_before(ktime_add_ms(call->peer->rtt_last_req, 1000),
+ 			 ktime_get_real()))
+ 		rxrpc_send_ACK(call, RXRPC_ACK_PING, 0,
+ 			       rxrpc_propose_ack_ping_for_params);
+ }
+ 
++>>>>>>> 32cf8edb079a (rxrpc: Trace/count transmission underflows and cwnd resets)
  /*
   * Handle retransmission and deferred ACK/abort generation.
   */
diff --git a/include/trace/events/rxrpc.h b/include/trace/events/rxrpc.h
index 2a52121d73a0..0a7323ec111c 100644
--- a/include/trace/events/rxrpc.h
+++ b/include/trace/events/rxrpc.h
@@ -1353,6 +1353,44 @@ TRACE_EVENT(rxrpc_congest,
 		      __entry->sum.retrans_timeo ? " rTxTo" : "")
 	    );
 
+TRACE_EVENT(rxrpc_reset_cwnd,
+	    TP_PROTO(struct rxrpc_call *call, ktime_t now),
+
+	    TP_ARGS(call, now),
+
+	    TP_STRUCT__entry(
+		    __field(unsigned int,			call		)
+		    __field(enum rxrpc_congest_mode,		mode		)
+		    __field(unsigned short,			cwnd		)
+		    __field(unsigned short,			extra		)
+		    __field(rxrpc_seq_t,			hard_ack	)
+		    __field(rxrpc_seq_t,			prepared	)
+		    __field(ktime_t,				since_last_tx	)
+		    __field(bool,				has_data	)
+			     ),
+
+	    TP_fast_assign(
+		    __entry->call	= call->debug_id;
+		    __entry->mode	= call->cong_mode;
+		    __entry->cwnd	= call->cong_cwnd;
+		    __entry->extra	= call->cong_extra;
+		    __entry->hard_ack	= call->acks_hard_ack;
+		    __entry->prepared	= call->tx_prepared - call->tx_bottom;
+		    __entry->since_last_tx = ktime_sub(now, call->tx_last_sent);
+		    __entry->has_data	= !list_empty(&call->tx_sendmsg);
+			   ),
+
+	    TP_printk("c=%08x q=%08x %s cw=%u+%u pr=%u tm=%llu d=%u",
+		      __entry->call,
+		      __entry->hard_ack,
+		      __print_symbolic(__entry->mode, rxrpc_congest_modes),
+		      __entry->cwnd,
+		      __entry->extra,
+		      __entry->prepared,
+		      ktime_to_ns(__entry->since_last_tx),
+		      __entry->has_data)
+	    );
+
 TRACE_EVENT(rxrpc_disconnect_call,
 	    TP_PROTO(struct rxrpc_call *call),
 
diff --git a/net/rxrpc/ar-internal.h b/net/rxrpc/ar-internal.h
index 46ce41afb431..ffedeb321fea 100644
--- a/net/rxrpc/ar-internal.h
+++ b/net/rxrpc/ar-internal.h
@@ -99,6 +99,9 @@ struct rxrpc_net {
 	atomic_t		stat_tx_data_retrans;
 	atomic_t		stat_tx_data_send;
 	atomic_t		stat_tx_data_send_frag;
+	atomic_t		stat_tx_data_send_fail;
+	atomic_t		stat_tx_data_underflow;
+	atomic_t		stat_tx_data_cwnd_reset;
 	atomic_t		stat_rx_data;
 	atomic_t		stat_rx_data_reqack;
 	atomic_t		stat_rx_data_jumbo;
* Unmerged path net/rxrpc/call_event.c
diff --git a/net/rxrpc/input.c b/net/rxrpc/input.c
index b5326e160685..8c7700e96426 100644
--- a/net/rxrpc/input.c
+++ b/net/rxrpc/input.c
@@ -29,6 +29,7 @@ static void rxrpc_congestion_management(struct rxrpc_call *call,
 	enum rxrpc_congest_change change = rxrpc_cong_no_change;
 	unsigned int cumulative_acks = call->cong_cumul_acks;
 	unsigned int cwnd = call->cong_cwnd;
+	ktime_t now;
 	bool resend = false;
 
 	summary->flight_size =
@@ -61,13 +62,15 @@ static void rxrpc_congestion_management(struct rxrpc_call *call,
 	/* If we haven't transmitted anything for >1RTT, we should reset the
 	 * congestion management state.
 	 */
+	now = ktime_get_real();
 	if ((call->cong_mode == RXRPC_CALL_SLOW_START ||
 	     call->cong_mode == RXRPC_CALL_CONGEST_AVOIDANCE) &&
 	    ktime_before(ktime_add_us(call->tx_last_sent,
-				      call->peer->srtt_us >> 3),
-			 ktime_get_real())
+				      call->peer->srtt_us >> 3), now)
 	    ) {
+		trace_rxrpc_reset_cwnd(call, now);
 		change = rxrpc_cong_idle_reset;
+		rxrpc_inc_stat(call->rxnet, stat_tx_data_cwnd_reset);
 		summary->mode = RXRPC_CALL_SLOW_START;
 		if (RXRPC_TX_SMSS > 2190)
 			summary->cwnd = 2;
diff --git a/net/rxrpc/output.c b/net/rxrpc/output.c
index 71b6fea4598b..e50f112fd4fe 100644
--- a/net/rxrpc/output.c
+++ b/net/rxrpc/output.c
@@ -491,6 +491,7 @@ int rxrpc_send_data_packet(struct rxrpc_call *call, struct rxrpc_txbuf *txb)
 
 	up_read(&conn->params.local->defrag_sem);
 	if (ret < 0) {
+		rxrpc_inc_stat(call->rxnet, stat_tx_data_send_fail);
 		rxrpc_cancel_rtt_probe(call, serial, rtt_slot);
 		trace_rxrpc_tx_fail(call->debug_id, serial, ret,
 				    rxrpc_tx_point_call_data_nofrag);
@@ -573,6 +574,7 @@ int rxrpc_send_data_packet(struct rxrpc_call *call, struct rxrpc_txbuf *txb)
 	}
 
 	if (ret < 0) {
+		rxrpc_inc_stat(call->rxnet, stat_tx_data_send_fail);
 		rxrpc_cancel_rtt_probe(call, serial, rtt_slot);
 		trace_rxrpc_tx_fail(call->debug_id, serial, ret,
 				    rxrpc_tx_point_call_data_frag);
diff --git a/net/rxrpc/proc.c b/net/rxrpc/proc.c
index fae22a8b38d6..04ac6773a383 100644
--- a/net/rxrpc/proc.c
+++ b/net/rxrpc/proc.c
@@ -407,13 +407,16 @@ int rxrpc_stats_show(struct seq_file *seq, void *v)
 	struct rxrpc_net *rxnet = rxrpc_net(seq_file_single_net(seq));
 
 	seq_printf(seq,
-		   "Data     : send=%u sendf=%u\n",
+		   "Data     : send=%u sendf=%u fail=%u\n",
 		   atomic_read(&rxnet->stat_tx_data_send),
-		   atomic_read(&rxnet->stat_tx_data_send_frag));
+		   atomic_read(&rxnet->stat_tx_data_send_frag),
+		   atomic_read(&rxnet->stat_tx_data_send_fail));
 	seq_printf(seq,
-		   "Data-Tx  : nr=%u retrans=%u\n",
+		   "Data-Tx  : nr=%u retrans=%u uf=%u cwr=%u\n",
 		   atomic_read(&rxnet->stat_tx_data),
-		   atomic_read(&rxnet->stat_tx_data_retrans));
+		   atomic_read(&rxnet->stat_tx_data_retrans),
+		   atomic_read(&rxnet->stat_tx_data_underflow),
+		   atomic_read(&rxnet->stat_tx_data_cwnd_reset));
 	seq_printf(seq,
 		   "Data-Rx  : nr=%u reqack=%u jumbo=%u\n",
 		   atomic_read(&rxnet->stat_rx_data),
@@ -478,8 +481,11 @@ int rxrpc_stats_clear(struct file *file, char *buf, size_t size)
 
 	atomic_set(&rxnet->stat_tx_data, 0);
 	atomic_set(&rxnet->stat_tx_data_retrans, 0);
+	atomic_set(&rxnet->stat_tx_data_underflow, 0);
+	atomic_set(&rxnet->stat_tx_data_cwnd_reset, 0);
 	atomic_set(&rxnet->stat_tx_data_send, 0);
 	atomic_set(&rxnet->stat_tx_data_send_frag, 0);
+	atomic_set(&rxnet->stat_tx_data_send_fail, 0);
 	atomic_set(&rxnet->stat_rx_data, 0);
 	atomic_set(&rxnet->stat_rx_data_reqack, 0);
 	atomic_set(&rxnet->stat_rx_data_jumbo, 0);
