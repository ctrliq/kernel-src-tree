KVM: arm64: mixed-width check should be skipped for uninitialized vCPUs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Reiji Watanabe <reijiw@google.com>
commit 26bf74bd9f6ff0f1545b4f0c92a37c232d076014
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/26bf74bd.failed

KVM allows userspace to configure either all EL1 32bit or 64bit vCPUs
for a guest.  At vCPU reset, vcpu_allowed_register_width() checks
if the vcpu's register width is consistent with all other vCPUs'.
Since the checking is done even against vCPUs that are not initialized
(KVM_ARM_VCPU_INIT has not been done) yet, the uninitialized vCPUs
are erroneously treated as 64bit vCPU, which causes the function to
incorrectly detect a mixed-width VM.

Introduce KVM_ARCH_FLAG_EL1_32BIT and KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED
bits for kvm->arch.flags.  A value of the EL1_32BIT bit indicates that
the guest needs to be configured with all 32bit or 64bit vCPUs, and
a value of the REG_WIDTH_CONFIGURED bit indicates if a value of the
EL1_32BIT bit is valid (already set up). Values in those bits are set at
the first KVM_ARM_VCPU_INIT for the guest based on KVM_ARM_VCPU_EL1_32BIT
configuration for the vCPU.

Check vcpu's register width against those new bits at the vcpu's
KVM_ARM_VCPU_INIT (instead of against other vCPUs' register width).

Fixes: 66e94d5cafd4 ("KVM: arm64: Prevent mixed-width VM creation")
	Signed-off-by: Reiji Watanabe <reijiw@google.com>
	Reviewed-by: Oliver Upton <oupton@google.com>
	Signed-off-by: Marc Zyngier <maz@kernel.org>
Link: https://lore.kernel.org/r/20220329031924.619453-2-reijiw@google.com
(cherry picked from commit 26bf74bd9f6ff0f1545b4f0c92a37c232d076014)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/kvm_host.h
#	arch/arm64/kvm/reset.c
diff --cc arch/arm64/include/asm/kvm_host.h
index 904c61e9d332,94a27a7520f4..000000000000
--- a/arch/arm64/include/asm/kvm_host.h
+++ b/arch/arm64/include/asm/kvm_host.h
@@@ -105,7 -122,34 +105,38 @@@ struct kvm_arch 
  	 * should) opt in to this feature if KVM_CAP_ARM_NISV_TO_USER is
  	 * supported.
  	 */
++<<<<<<< HEAD
 +	bool return_nisv_io_abort_to_user;
++=======
+ #define KVM_ARCH_FLAG_RETURN_NISV_IO_ABORT_TO_USER	0
+ 	/* Memory Tagging Extension enabled for the guest */
+ #define KVM_ARCH_FLAG_MTE_ENABLED			1
+ 	/* At least one vCPU has ran in the VM */
+ #define KVM_ARCH_FLAG_HAS_RAN_ONCE			2
+ 	/*
+ 	 * The following two bits are used to indicate the guest's EL1
+ 	 * register width configuration. A value of KVM_ARCH_FLAG_EL1_32BIT
+ 	 * bit is valid only when KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED is set.
+ 	 * Otherwise, the guest's EL1 register width has not yet been
+ 	 * determined yet.
+ 	 */
+ #define KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED		3
+ #define KVM_ARCH_FLAG_EL1_32BIT				4
+ 
+ 	unsigned long flags;
+ 
+ 	/*
+ 	 * VM-wide PMU filter, implemented as a bitmap and big enough for
+ 	 * up to 2^10 events (ARMv8.0) or 2^16 events (ARMv8.1+).
+ 	 */
+ 	unsigned long *pmu_filter;
+ 	struct arm_pmu *arm_pmu;
+ 
+ 	cpumask_var_t supported_cpus;
+ 
+ 	u8 pfr0_csv2;
+ 	u8 pfr0_csv3;
++>>>>>>> 26bf74bd9f6f (KVM: arm64: mixed-width check should be skipped for uninitialized vCPUs)
  };
  
  struct kvm_vcpu_fault_info {
diff --cc arch/arm64/kvm/reset.c
index 69cea0d2d759,6c70c6f61c70..000000000000
--- a/arch/arm64/kvm/reset.c
+++ b/arch/arm64/kvm/reset.c
@@@ -235,23 -181,51 +235,58 @@@ static int kvm_vcpu_enable_ptrauth(stru
  	return 0;
  }
  
- static bool vcpu_allowed_register_width(struct kvm_vcpu *vcpu)
+ /**
+  * kvm_set_vm_width() - set the register width for the guest
+  * @vcpu: Pointer to the vcpu being configured
+  *
+  * Set both KVM_ARCH_FLAG_EL1_32BIT and KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED
+  * in the VM flags based on the vcpu's requested register width, the HW
+  * capabilities and other options (such as MTE).
+  * When REG_WIDTH_CONFIGURED is already set, the vcpu settings must be
+  * consistent with the value of the FLAG_EL1_32BIT bit in the flags.
+  *
+  * Return: 0 on success, negative error code on failure.
+  */
+ static int kvm_set_vm_width(struct kvm_vcpu *vcpu)
  {
- 	struct kvm_vcpu *tmp;
+ 	struct kvm *kvm = vcpu->kvm;
  	bool is32bit;
- 	unsigned long i;
  
  	is32bit = vcpu_has_feature(vcpu, KVM_ARM_VCPU_EL1_32BIT);
- 	if (!cpus_have_const_cap(ARM64_HAS_32BIT_EL1) && is32bit)
- 		return false;
  
++<<<<<<< HEAD
 +	/* Check that the vcpus are either all 32bit or all 64bit */
 +	kvm_for_each_vcpu(i, tmp, vcpu->kvm) {
 +		if (vcpu_has_feature(tmp, KVM_ARM_VCPU_EL1_32BIT) != is32bit)
 +			return false;
++=======
+ 	lockdep_assert_held(&kvm->lock);
+ 
+ 	if (test_bit(KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED, &kvm->arch.flags)) {
+ 		/*
+ 		 * The guest's register width is already configured.
+ 		 * Make sure that the vcpu is consistent with it.
+ 		 */
+ 		if (is32bit == test_bit(KVM_ARCH_FLAG_EL1_32BIT, &kvm->arch.flags))
+ 			return 0;
+ 
+ 		return -EINVAL;
++>>>>>>> 26bf74bd9f6f (KVM: arm64: mixed-width check should be skipped for uninitialized vCPUs)
  	}
  
- 	return true;
+ 	if (!cpus_have_const_cap(ARM64_HAS_32BIT_EL1) && is32bit)
+ 		return -EINVAL;
+ 
+ 	/* MTE is incompatible with AArch32 */
+ 	if (kvm_has_mte(kvm) && is32bit)
+ 		return -EINVAL;
+ 
+ 	if (is32bit)
+ 		set_bit(KVM_ARCH_FLAG_EL1_32BIT, &kvm->arch.flags);
+ 
+ 	set_bit(KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED, &kvm->arch.flags);
+ 
+ 	return 0;
  }
  
  /**
diff --git a/arch/arm64/include/asm/kvm_emulate.h b/arch/arm64/include/asm/kvm_emulate.h
index 83111f8afe45..a8ce14cb358c 100644
--- a/arch/arm64/include/asm/kvm_emulate.h
+++ b/arch/arm64/include/asm/kvm_emulate.h
@@ -47,10 +47,22 @@ void kvm_inject_undef32(struct kvm_vcpu *vcpu);
 void kvm_inject_dabt32(struct kvm_vcpu *vcpu, unsigned long addr);
 void kvm_inject_pabt32(struct kvm_vcpu *vcpu, unsigned long addr);
 
+#if defined(__KVM_VHE_HYPERVISOR__) || defined(__KVM_NVHE_HYPERVISOR__)
 static __always_inline bool vcpu_el1_is_32bit(struct kvm_vcpu *vcpu)
 {
 	return !(vcpu->arch.hcr_el2 & HCR_RW);
 }
+#else
+static __always_inline bool vcpu_el1_is_32bit(struct kvm_vcpu *vcpu)
+{
+	struct kvm *kvm = vcpu->kvm;
+
+	WARN_ON_ONCE(!test_bit(KVM_ARCH_FLAG_REG_WIDTH_CONFIGURED,
+			       &kvm->arch.flags));
+
+	return test_bit(KVM_ARCH_FLAG_EL1_32BIT, &kvm->arch.flags);
+}
+#endif
 
 static inline void vcpu_reset_hcr(struct kvm_vcpu *vcpu)
 {
@@ -76,15 +88,14 @@ static inline void vcpu_reset_hcr(struct kvm_vcpu *vcpu)
 		vcpu->arch.hcr_el2 |= HCR_TVM;
 	}
 
-	if (test_bit(KVM_ARM_VCPU_EL1_32BIT, vcpu->arch.features))
+	if (vcpu_el1_is_32bit(vcpu))
 		vcpu->arch.hcr_el2 &= ~HCR_RW;
-
-	/*
-	 * TID3: trap feature register accesses that we virtualise.
-	 * For now this is conditional, since no AArch32 feature regs
-	 * are currently virtualised.
-	 */
-	if (!vcpu_el1_is_32bit(vcpu))
+	else
+		/*
+		 * TID3: trap feature register accesses that we virtualise.
+		 * For now this is conditional, since no AArch32 feature regs
+		 * are currently virtualised.
+		 */
 		vcpu->arch.hcr_el2 |= HCR_TID3;
 
 	if (cpus_have_const_cap(ARM64_MISMATCHED_CACHE_TYPE) ||
* Unmerged path arch/arm64/include/asm/kvm_host.h
* Unmerged path arch/arm64/kvm/reset.c
