net/mlx5e: TC, Fix use after free in mlx5e_clone_flow_attr_for_post_act()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Dan Carpenter <dan.carpenter@oracle.com>
commit 371c2b349d927e81710f6ac2826d7fcb0374280f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/371c2b34.failed

This returns freed memory leading to a use after free.  It's supposed to
return NULL.

Fixes: 8300f225268b ("net/mlx5e: Create new flow attr for multi table actions")
	Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 371c2b349d927e81710f6ac2826d7fcb0374280f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index e11d6f95f302,e3fc15ae7bb1..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -3627,6 -3397,299 +3627,302 @@@ actions_prepare_mod_hdr_actions(struct 
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static struct mlx5_flow_attr*
+ mlx5e_clone_flow_attr_for_post_act(struct mlx5_flow_attr *attr,
+ 				   enum mlx5_flow_namespace_type ns_type)
+ {
+ 	struct mlx5e_tc_flow_parse_attr *parse_attr;
+ 	u32 attr_sz = ns_to_attr_sz(ns_type);
+ 	struct mlx5_flow_attr *attr2;
+ 
+ 	attr2 = mlx5_alloc_flow_attr(ns_type);
+ 	parse_attr = kvzalloc(sizeof(*parse_attr), GFP_KERNEL);
+ 	if (!attr2 || !parse_attr) {
+ 		kvfree(parse_attr);
+ 		kfree(attr2);
+ 		return NULL;
+ 	}
+ 
+ 	memcpy(attr2, attr, attr_sz);
+ 	INIT_LIST_HEAD(&attr2->list);
+ 	parse_attr->filter_dev = attr->parse_attr->filter_dev;
+ 	attr2->action = 0;
+ 	attr2->flags = 0;
+ 	attr2->parse_attr = parse_attr;
+ 	return attr2;
+ }
+ 
+ static struct mlx5_core_dev *
+ get_flow_counter_dev(struct mlx5e_tc_flow *flow)
+ {
+ 	return mlx5e_is_eswitch_flow(flow) ? flow->attr->esw_attr->counter_dev : flow->priv->mdev;
+ }
+ 
+ struct mlx5_flow_attr *
+ mlx5e_tc_get_encap_attr(struct mlx5e_tc_flow *flow)
+ {
+ 	struct mlx5_esw_flow_attr *esw_attr;
+ 	struct mlx5_flow_attr *attr;
+ 	int i;
+ 
+ 	list_for_each_entry(attr, &flow->attrs, list) {
+ 		esw_attr = attr->esw_attr;
+ 		for (i = 0; i < MLX5_MAX_FLOW_FWD_VPORTS; i++) {
+ 			if (esw_attr->dests[i].flags & MLX5_ESW_DEST_ENCAP)
+ 				return attr;
+ 		}
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ void
+ mlx5e_tc_unoffload_flow_post_acts(struct mlx5e_tc_flow *flow)
+ {
+ 	struct mlx5e_post_act *post_act = get_post_action(flow->priv);
+ 	struct mlx5_flow_attr *attr;
+ 
+ 	list_for_each_entry(attr, &flow->attrs, list) {
+ 		if (list_is_last(&attr->list, &flow->attrs))
+ 			break;
+ 
+ 		mlx5e_tc_post_act_unoffload(post_act, attr->post_act_handle);
+ 	}
+ }
+ 
+ static void
+ free_flow_post_acts(struct mlx5e_tc_flow *flow)
+ {
+ 	struct mlx5_core_dev *counter_dev = get_flow_counter_dev(flow);
+ 	struct mlx5e_post_act *post_act = get_post_action(flow->priv);
+ 	struct mlx5_flow_attr *attr, *tmp;
+ 	bool vf_tun;
+ 
+ 	list_for_each_entry_safe(attr, tmp, &flow->attrs, list) {
+ 		if (list_is_last(&attr->list, &flow->attrs))
+ 			break;
+ 
+ 		if (attr->post_act_handle)
+ 			mlx5e_tc_post_act_del(post_act, attr->post_act_handle);
+ 
+ 		clean_encap_dests(flow->priv, flow, attr, &vf_tun);
+ 
+ 		if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT)
+ 			mlx5_fc_destroy(counter_dev, attr->counter);
+ 
+ 		if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR) {
+ 			mlx5e_mod_hdr_dealloc(&attr->parse_attr->mod_hdr_acts);
+ 			if (attr->modify_hdr)
+ 				mlx5_modify_header_dealloc(flow->priv->mdev, attr->modify_hdr);
+ 		}
+ 
+ 		list_del(&attr->list);
+ 		kvfree(attr->parse_attr);
+ 		kfree(attr);
+ 	}
+ }
+ 
+ int
+ mlx5e_tc_offload_flow_post_acts(struct mlx5e_tc_flow *flow)
+ {
+ 	struct mlx5e_post_act *post_act = get_post_action(flow->priv);
+ 	struct mlx5_flow_attr *attr;
+ 	int err = 0;
+ 
+ 	list_for_each_entry(attr, &flow->attrs, list) {
+ 		if (list_is_last(&attr->list, &flow->attrs))
+ 			break;
+ 
+ 		err = mlx5e_tc_post_act_offload(post_act, attr->post_act_handle);
+ 		if (err)
+ 			break;
+ 	}
+ 
+ 	return err;
+ }
+ 
+ /* TC filter rule HW translation:
+  *
+  * +---------------------+
+  * + ft prio (tc chain)  +
+  * + original match      +
+  * +---------------------+
+  *           |
+  *           | if multi table action
+  *           |
+  *           v
+  * +---------------------+
+  * + post act ft         |<----.
+  * + match fte id        |     | split on multi table action
+  * + do actions          |-----'
+  * +---------------------+
+  *           |
+  *           |
+  *           v
+  * Do rest of the actions after last multi table action.
+  */
+ static int
+ alloc_flow_post_acts(struct mlx5e_tc_flow *flow, struct netlink_ext_ack *extack)
+ {
+ 	struct mlx5e_post_act *post_act = get_post_action(flow->priv);
+ 	struct mlx5_flow_attr *attr, *next_attr = NULL;
+ 	struct mlx5e_post_act_handle *handle;
+ 	bool vf_tun, encap_valid = true;
+ 	int err;
+ 
+ 	/* This is going in reverse order as needed.
+ 	 * The first entry is the last attribute.
+ 	 */
+ 	list_for_each_entry(attr, &flow->attrs, list) {
+ 		if (!next_attr) {
+ 			/* Set counter action on last post act rule. */
+ 			attr->action |= MLX5_FLOW_CONTEXT_ACTION_COUNT;
+ 		} else {
+ 			err = mlx5e_tc_act_set_next_post_act(flow, attr, next_attr);
+ 			if (err)
+ 				goto out_free;
+ 		}
+ 
+ 		/* Don't add post_act rule for first attr (last in the list).
+ 		 * It's being handled by the caller.
+ 		 */
+ 		if (list_is_last(&attr->list, &flow->attrs))
+ 			break;
+ 
+ 		err = set_encap_dests(flow->priv, flow, attr, extack, &encap_valid, &vf_tun);
+ 		if (err)
+ 			goto out_free;
+ 
+ 		if (!encap_valid)
+ 			flow_flag_set(flow, SLOW);
+ 
+ 		err = actions_prepare_mod_hdr_actions(flow->priv, flow, attr, extack);
+ 		if (err)
+ 			goto out_free;
+ 
+ 		if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR) {
+ 			err = mlx5e_tc_add_flow_mod_hdr(flow->priv, flow, attr);
+ 			if (err)
+ 				goto out_free;
+ 		}
+ 
+ 		if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT) {
+ 			err = alloc_flow_attr_counter(get_flow_counter_dev(flow), attr);
+ 			if (err)
+ 				goto out_free;
+ 		}
+ 
+ 		handle = mlx5e_tc_post_act_add(post_act, attr);
+ 		if (IS_ERR(handle)) {
+ 			err = PTR_ERR(handle);
+ 			goto out_free;
+ 		}
+ 
+ 		attr->post_act_handle = handle;
+ 		next_attr = attr;
+ 	}
+ 
+ 	if (flow_flag_test(flow, SLOW))
+ 		goto out;
+ 
+ 	err = mlx5e_tc_offload_flow_post_acts(flow);
+ 	if (err)
+ 		goto out_free;
+ 
+ out:
+ 	return 0;
+ 
+ out_free:
+ 	free_flow_post_acts(flow);
+ 	return err;
+ }
+ 
+ static int
+ parse_tc_actions(struct mlx5e_tc_act_parse_state *parse_state,
+ 		 struct flow_action *flow_action)
+ {
+ 	struct netlink_ext_ack *extack = parse_state->extack;
+ 	struct mlx5e_tc_flow_action flow_action_reorder;
+ 	struct mlx5e_tc_flow *flow = parse_state->flow;
+ 	struct mlx5_flow_attr *attr = flow->attr;
+ 	enum mlx5_flow_namespace_type ns_type;
+ 	struct mlx5e_priv *priv = flow->priv;
+ 	struct flow_action_entry *act, **_act;
+ 	struct mlx5e_tc_act *tc_act;
+ 	int err, i;
+ 
+ 	flow_action_reorder.num_entries = flow_action->num_entries;
+ 	flow_action_reorder.entries = kcalloc(flow_action->num_entries,
+ 					      sizeof(flow_action), GFP_KERNEL);
+ 	if (!flow_action_reorder.entries)
+ 		return -ENOMEM;
+ 
+ 	mlx5e_tc_act_reorder_flow_actions(flow_action, &flow_action_reorder);
+ 
+ 	ns_type = mlx5e_get_flow_namespace(flow);
+ 	list_add(&attr->list, &flow->attrs);
+ 
+ 	flow_action_for_each(i, _act, &flow_action_reorder) {
+ 		act = *_act;
+ 		tc_act = mlx5e_tc_act_get(act->id, ns_type);
+ 		if (!tc_act) {
+ 			NL_SET_ERR_MSG_MOD(extack, "Not implemented offload action");
+ 			err = -EOPNOTSUPP;
+ 			goto out_free;
+ 		}
+ 
+ 		if (!tc_act->can_offload(parse_state, act, i, attr)) {
+ 			err = -EOPNOTSUPP;
+ 			goto out_free;
+ 		}
+ 
+ 		err = tc_act->parse_action(parse_state, act, priv, attr);
+ 		if (err)
+ 			goto out_free;
+ 
+ 		parse_state->actions |= attr->action;
+ 
+ 		/* Split attr for multi table act if not the last act. */
+ 		if (tc_act->is_multi_table_act &&
+ 		    tc_act->is_multi_table_act(priv, act, attr) &&
+ 		    i < flow_action_reorder.num_entries - 1) {
+ 			err = mlx5e_tc_act_post_parse(parse_state, flow_action, attr, ns_type);
+ 			if (err)
+ 				goto out_free;
+ 
+ 			attr = mlx5e_clone_flow_attr_for_post_act(flow->attr, ns_type);
+ 			if (!attr) {
+ 				err = -ENOMEM;
+ 				goto out_free;
+ 			}
+ 
+ 			list_add(&attr->list, &flow->attrs);
+ 		}
+ 	}
+ 
+ 	kfree(flow_action_reorder.entries);
+ 
+ 	err = mlx5e_tc_act_post_parse(parse_state, flow_action, attr, ns_type);
+ 	if (err)
+ 		goto out_free_post_acts;
+ 
+ 	err = alloc_flow_post_acts(flow, extack);
+ 	if (err)
+ 		goto out_free_post_acts;
+ 
+ 	return 0;
+ 
+ out_free:
+ 	kfree(flow_action_reorder.entries);
+ out_free_post_acts:
+ 	free_flow_post_acts(flow);
+ 
+ 	return err;
+ }
+ 
++>>>>>>> 371c2b349d92 (net/mlx5e: TC, Fix use after free in mlx5e_clone_flow_attr_for_post_act())
  static int
  flow_action_supported(struct flow_action *flow_action,
  		      struct netlink_ext_ack *extack)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
