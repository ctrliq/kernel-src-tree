net/mlx5e: Add HW_GRO statistics

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Khalid Manaa <khalidm@nvidia.com>
commit def09e7bbc3d85844443cb4bf13faae969ea115f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/def09e7b.failed

This patch adds HW_GRO counters to RX packets statistics:
 - gro_match_packets: counter of received packets with set match flag.

 - gro_packets: counter of received packets over the HW_GRO feature,
                this counter is increased by one for every received
                HW_GRO cqe.

 - gro_bytes: counter of received bytes over the HW_GRO feature,
              this counter is increased by the received bytes for every
              received HW_GRO cqe.

 - gro_skbs: counter of built HW_GRO skbs,
             increased by one when we flush HW_GRO skb
             (when we call a napi_gro_receive with hw_gro skb).

 - gro_large_hds: counter of received packets with large headers size,
                  in case the packet needs new SKB, the driver will allocate
                  new one and will not use the headers entry to build it.

	Signed-off-by: Khalid Manaa <khalidm@nvidia.com>
	Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit def09e7bbc3d85844443cb4bf13faae969ea115f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index 66ea1cbed1c1,fe979edd96dc..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -1095,6 -1453,27 +1095,30 @@@ static inline void mlx5e_build_rx_skb(s
  		stats->mcast_packets++;
  }
  
++<<<<<<< HEAD
++=======
+ static void mlx5e_shampo_complete_rx_cqe(struct mlx5e_rq *rq,
+ 					 struct mlx5_cqe64 *cqe,
+ 					 u32 cqe_bcnt,
+ 					 struct sk_buff *skb)
+ {
+ 	struct mlx5e_rq_stats *stats = rq->stats;
+ 
+ 	stats->packets++;
+ 	stats->gro_packets++;
+ 	stats->bytes += cqe_bcnt;
+ 	stats->gro_bytes += cqe_bcnt;
+ 	if (NAPI_GRO_CB(skb)->count != 1)
+ 		return;
+ 	mlx5e_build_rx_skb(cqe, cqe_bcnt, rq, skb);
+ 	skb_reset_network_header(skb);
+ 	if (!skb_flow_dissect_flow_keys(skb, &rq->hw_gro_data->fk, 0)) {
+ 		napi_gro_receive(rq->cq.napi, skb);
+ 		rq->hw_gro_data->skb = NULL;
+ 	}
+ }
+ 
++>>>>>>> def09e7bbc3d (net/mlx5e: Add HW_GRO statistics)
  static inline void mlx5e_complete_rx_cqe(struct mlx5e_rq *rq,
  					 struct mlx5_cqe64 *cqe,
  					 u32 cqe_bcnt,
@@@ -1534,7 -1932,43 +1559,47 @@@ mlx5e_skb_from_cqe_shampo(struct mlx5e_
  		skb->tail += head_size;
  		skb->len  += head_size;
  	}
++<<<<<<< HEAD
 +	return skb;
++=======
+ 	rq->hw_gro_data->skb = skb;
+ 	NAPI_GRO_CB(skb)->count = 1;
+ 	skb_shinfo(skb)->gso_size = mpwrq_get_cqe_byte_cnt(cqe) - head_size;
+ }
+ 
+ static void
+ mlx5e_shampo_align_fragment(struct sk_buff *skb, u8 log_stride_sz)
+ {
+ 	skb_frag_t *last_frag = &skb_shinfo(skb)->frags[skb_shinfo(skb)->nr_frags - 1];
+ 	unsigned int frag_size = skb_frag_size(last_frag);
+ 	unsigned int frag_truesize;
+ 
+ 	frag_truesize = ALIGN(frag_size, BIT(log_stride_sz));
+ 	skb->truesize += frag_truesize - frag_size;
+ }
+ 
+ static void
+ mlx5e_shampo_flush_skb(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe, bool match)
+ {
+ 	struct sk_buff *skb = rq->hw_gro_data->skb;
+ 	struct mlx5e_rq_stats *stats = rq->stats;
+ 
+ 	stats->gro_skbs++;
+ 	if (likely(skb_shinfo(skb)->nr_frags))
+ 		mlx5e_shampo_align_fragment(skb, rq->mpwqe.log_stride_sz);
+ 	if (NAPI_GRO_CB(skb)->count > 1)
+ 		mlx5e_shampo_update_hdr(rq, cqe, match);
+ 	napi_gro_receive(rq->cq.napi, skb);
+ 	rq->hw_gro_data->skb = NULL;
+ }
+ 
+ static bool
+ mlx5e_hw_gro_skb_has_enough_space(struct sk_buff *skb, u16 data_bcnt)
+ {
+ 	int nr_frags = skb_shinfo(skb)->nr_frags;
+ 
+ 	return PAGE_SIZE * nr_frags + data_bcnt <= GSO_MAX_SIZE;
++>>>>>>> def09e7bbc3d (net/mlx5e: Add HW_GRO statistics)
  }
  
  static void
@@@ -1560,8 -1994,11 +1625,15 @@@ static void mlx5e_handle_rx_cqe_mpwrq_s
  	u32 cqe_bcnt		= mpwrq_get_cqe_byte_cnt(cqe);
  	u16 wqe_id		= be16_to_cpu(cqe->wqe_id);
  	u32 page_idx		= wqe_offset >> PAGE_SHIFT;
++<<<<<<< HEAD
++=======
+ 	struct sk_buff **skb	= &rq->hw_gro_data->skb;
+ 	bool flush		= cqe->shampo.flush;
+ 	bool match		= cqe->shampo.match;
+ 	struct mlx5e_rq_stats *stats = rq->stats;
++>>>>>>> def09e7bbc3d (net/mlx5e: Add HW_GRO statistics)
  	struct mlx5e_rx_wqe_ll *wqe;
 +	struct sk_buff *skb = NULL;
  	struct mlx5e_dma_info *di;
  	struct mlx5e_mpw_info *wi;
  	struct mlx5_wq_ll *wq;
@@@ -1583,16 -2018,36 +1653,25 @@@
  		goto mpwrq_cqe_out;
  	}
  
++<<<<<<< HEAD
 +	skb = mlx5e_skb_from_cqe_shampo(rq, wi, cqe, header_index);
++=======
+ 	stats->gro_match_packets += match;
+ 
+ 	if (*skb && (!match || !(mlx5e_hw_gro_skb_has_enough_space(*skb, data_bcnt)))) {
+ 		match = false;
+ 		mlx5e_shampo_flush_skb(rq, cqe, match);
+ 	}
++>>>>>>> def09e7bbc3d (net/mlx5e: Add HW_GRO statistics)
  
 -	if (!*skb) {
 -		mlx5e_skb_from_cqe_shampo(rq, wi, cqe, header_index);
 -		if (unlikely(!*skb))
 -			goto free_hd_entry;
 -	} else {
 -		NAPI_GRO_CB(*skb)->count++;
 -		if (NAPI_GRO_CB(*skb)->count == 2 &&
 -		    rq->hw_gro_data->fk.basic.n_proto == htons(ETH_P_IP)) {
 -			void *hd_addr = mlx5e_shampo_get_packet_hd(rq, header_index);
 -			int nhoff = ETH_HLEN + rq->hw_gro_data->fk.control.thoff -
 -				    sizeof(struct iphdr);
 -			struct iphdr *iph = (struct iphdr *)(hd_addr + nhoff);
 -
 -			rq->hw_gro_data->second_ip_id = ntohs(iph->id);
 -		}
 -	}
 +	if (unlikely(!skb))
 +		goto free_hd_entry;
  
  	di = &wi->umr.dma_info[page_idx];
 -	mlx5e_fill_skb_data(*skb, rq, di, data_bcnt, data_offset);
 +	mlx5e_fill_skb_data(skb, rq, di, data_bcnt, data_offset);
  
 -	mlx5e_shampo_complete_rx_cqe(rq, cqe, cqe_bcnt, *skb);
 -	if (flush)
 -		mlx5e_shampo_flush_skb(rq, cqe, match);
 +	mlx5e_complete_rx_cqe(rq, cqe, cqe_bcnt, skb);
 +	napi_gro_receive(rq->cq.napi, skb);
  free_hd_entry:
  	mlx5e_free_rx_shampo_hd_entry(rq, header_index);
  mpwrq_cqe_out:
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
index fbecfb5ccf26..3c91a11e27ad 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
@@ -128,6 +128,11 @@ static const struct counter_desc sw_stats_desc[] = {
 
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_lro_packets) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_lro_bytes) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_gro_packets) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_gro_bytes) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_gro_skbs) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_gro_match_packets) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_gro_large_hds) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_ecn_mark) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_removed_vlan_packets) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_csum_unnecessary) },
@@ -313,6 +318,11 @@ static void mlx5e_stats_grp_sw_update_stats_rq_stats(struct mlx5e_sw_stats *s,
 	s->rx_bytes                   += rq_stats->bytes;
 	s->rx_lro_packets             += rq_stats->lro_packets;
 	s->rx_lro_bytes               += rq_stats->lro_bytes;
+	s->rx_gro_packets             += rq_stats->gro_packets;
+	s->rx_gro_bytes               += rq_stats->gro_bytes;
+	s->rx_gro_skbs                += rq_stats->gro_skbs;
+	s->rx_gro_match_packets       += rq_stats->gro_match_packets;
+	s->rx_gro_large_hds           += rq_stats->gro_large_hds;
 	s->rx_ecn_mark                += rq_stats->ecn_mark;
 	s->rx_removed_vlan_packets    += rq_stats->removed_vlan_packets;
 	s->rx_csum_none               += rq_stats->csum_none;
@@ -1760,6 +1770,11 @@ static const struct counter_desc rq_stats_desc[] = {
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, xdp_redirect) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, lro_packets) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, lro_bytes) },
+	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, gro_packets) },
+	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, gro_bytes) },
+	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, gro_skbs) },
+	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, gro_match_packets) },
+	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, gro_large_hds) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, ecn_mark) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, removed_vlan_packets) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, wqe_err) },
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
index 139e59f30db0..2c1ed5b81be6 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
@@ -144,6 +144,11 @@ struct mlx5e_sw_stats {
 	u64 tx_mpwqe_pkts;
 	u64 rx_lro_packets;
 	u64 rx_lro_bytes;
+	u64 rx_gro_packets;
+	u64 rx_gro_bytes;
+	u64 rx_gro_skbs;
+	u64 rx_gro_match_packets;
+	u64 rx_gro_large_hds;
 	u64 rx_mcast_packets;
 	u64 rx_ecn_mark;
 	u64 rx_removed_vlan_packets;
@@ -322,6 +327,11 @@ struct mlx5e_rq_stats {
 	u64 csum_none;
 	u64 lro_packets;
 	u64 lro_bytes;
+	u64 gro_packets;
+	u64 gro_bytes;
+	u64 gro_skbs;
+	u64 gro_match_packets;
+	u64 gro_large_hds;
 	u64 mcast_packets;
 	u64 ecn_mark;
 	u64 removed_vlan_packets;
