dma-buf-map: Rename to iosys-map

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Lucas De Marchi <lucas.demarchi@intel.com>
commit 7938f4218168ae9fc4bdddb15976f9ebbae41999
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/7938f421.failed

Rename struct dma_buf_map to struct iosys_map and corresponding APIs.
Over time dma-buf-map grew up to more functionality than the one used by
dma-buf: in fact it's just a shim layer to abstract system memory, that
can be accessed via regular load and store, from IO memory that needs to
be acessed via arch helpers.

The idea is to extend this API so it can fulfill other needs, internal
to a single driver. Example: in the i915 driver it's desired to share
the implementation for integrated graphics, which uses mostly system
memory, with discrete graphics, which may need to access IO memory.

The conversion was mostly done with the following semantic patch:

	@r1@
	@@
	- struct dma_buf_map
	+ struct iosys_map

	@r2@
	@@
	(
	- DMA_BUF_MAP_INIT_VADDR
	+ IOSYS_MAP_INIT_VADDR
	|
	- dma_buf_map_set_vaddr
	+ iosys_map_set_vaddr
	|
	- dma_buf_map_set_vaddr_iomem
	+ iosys_map_set_vaddr_iomem
	|
	- dma_buf_map_is_equal
	+ iosys_map_is_equal
	|
	- dma_buf_map_is_null
	+ iosys_map_is_null
	|
	- dma_buf_map_is_set
	+ iosys_map_is_set
	|
	- dma_buf_map_clear
	+ iosys_map_clear
	|
	- dma_buf_map_memcpy_to
	+ iosys_map_memcpy_to
	|
	- dma_buf_map_incr
	+ iosys_map_incr
	)

	@@
	@@
	- #include <linux/dma-buf-map.h>
	+ #include <linux/iosys-map.h>

Then some files had their includes adjusted and some comments were
update to remove mentions to dma-buf-map.

Since this is not specific to dma-buf anymore, move the documentation to
the "Bus-Independent Device Accesses" section.

v2:
  - Squash patches

v3:
  - Fix wrong removal of dma-buf.h from MAINTAINERS
  - Move documentation from dma-buf.rst to device-io.rst

v4:
  - Change documentation title and level

	Signed-off-by: Lucas De Marchi <lucas.demarchi@intel.com>
	Acked-by: Christian KÃ¶nig <christian.koenig@amd.com>
	Acked-by: Sumit Semwal <sumit.semwal@linaro.org>
	Acked-by: Thomas Zimmermann <tzimmermann@suse.de>
Link: https://patchwork.freedesktop.org/patch/msgid/20220204170541.829227-1-lucas.demarchi@intel.com
(cherry picked from commit 7938f4218168ae9fc4bdddb15976f9ebbae41999)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/driver-api/device-io.rst
#	Documentation/gpu/todo.rst
#	MAINTAINERS
#	drivers/dma-buf/dma-buf.c
#	drivers/gpu/drm/ast/ast_mode.c
#	drivers/gpu/drm/drm_cache.c
#	drivers/gpu/drm/drm_gem_cma_helper.c
#	drivers/gpu/drm/drm_gem_framebuffer_helper.c
#	drivers/gpu/drm/drm_gem_shmem_helper.c
#	drivers/gpu/drm/drm_mipi_dbi.c
#	drivers/gpu/drm/etnaviv/etnaviv_drv.h
#	drivers/gpu/drm/etnaviv/etnaviv_gem_prime.c
#	drivers/gpu/drm/gud/gud_pipe.c
#	drivers/gpu/drm/lima/lima_gem.c
#	drivers/gpu/drm/lima/lima_sched.c
#	drivers/gpu/drm/mediatek/mtk_drm_gem.c
#	drivers/gpu/drm/mediatek/mtk_drm_gem.h
#	drivers/gpu/drm/msm/msm_drv.h
#	drivers/gpu/drm/msm/msm_gem_prime.c
#	drivers/gpu/drm/panfrost/panfrost_perfcnt.c
#	drivers/gpu/drm/qxl/qxl_drv.h
#	drivers/gpu/drm/rockchip/rockchip_drm_gem.c
#	drivers/gpu/drm/rockchip/rockchip_drm_gem.h
#	drivers/gpu/drm/tiny/cirrus.c
#	drivers/gpu/drm/ttm/ttm_bo_util.c
#	drivers/gpu/drm/vboxvideo/vbox_mode.c
#	drivers/gpu/drm/vkms/vkms_composer.c
#	drivers/gpu/drm/vkms/vkms_drv.h
#	drivers/gpu/drm/xen/xen_drm_front_gem.c
#	drivers/media/common/videobuf2/videobuf2-dma-contig.c
#	drivers/media/common/videobuf2/videobuf2-dma-sg.c
#	drivers/misc/fastrpc.c
#	include/drm/drm_gem_atomic_helper.h
#	include/drm/drm_gem_cma_helper.h
#	include/drm/drm_gem_framebuffer_helper.h
#	include/drm/drm_gem_shmem_helper.h
#	include/drm/drm_gem_vram_helper.h
#	include/drm/ttm/ttm_resource.h
#	include/linux/dma-buf.h
diff --cc Documentation/driver-api/device-io.rst
index 0e389378f71d,4d2baac0311c..000000000000
--- a/Documentation/driver-api/device-io.rst
+++ b/Documentation/driver-api/device-io.rst
@@@ -142,10 -142,375 +142,378 @@@ long. These functions are :c:func:`inb(
  Some variants are provided for these functions. Some devices require
  that accesses to their ports are slowed down. This functionality is
  provided by appending a ``_p`` to the end of the function.
 -There are also equivalents to memcpy. The ins() and
 -outs() functions copy bytes, words or longs to the given
 +There are also equivalents to memcpy. The :c:func:`ins()` and
 +:c:func:`outs()` functions copy bytes, words or longs to the given
  port.
  
++<<<<<<< HEAD
++=======
+ __iomem pointer tokens
+ ======================
+ 
+ The data type for an MMIO address is an ``__iomem`` qualified pointer, such as
+ ``void __iomem *reg``. On most architectures it is a regular pointer that
+ points to a virtual memory address and can be offset or dereferenced, but in
+ portable code, it must only be passed from and to functions that explicitly
+ operated on an ``__iomem`` token, in particular the ioremap() and
+ readl()/writel() functions. The 'sparse' semantic code checker can be used to
+ verify that this is done correctly.
+ 
+ While on most architectures, ioremap() creates a page table entry for an
+ uncached virtual address pointing to the physical MMIO address, some
+ architectures require special instructions for MMIO, and the ``__iomem`` pointer
+ just encodes the physical address or an offsettable cookie that is interpreted
+ by readl()/writel().
+ 
+ Differences between I/O access functions
+ ========================================
+ 
+ readq(), readl(), readw(), readb(), writeq(), writel(), writew(), writeb()
+ 
+   These are the most generic accessors, providing serialization against other
+   MMIO accesses and DMA accesses as well as fixed endianness for accessing
+   little-endian PCI devices and on-chip peripherals. Portable device drivers
+   should generally use these for any access to ``__iomem`` pointers.
+ 
+   Note that posted writes are not strictly ordered against a spinlock, see
+   Documentation/driver-api/io_ordering.rst.
+ 
+ readq_relaxed(), readl_relaxed(), readw_relaxed(), readb_relaxed(),
+ writeq_relaxed(), writel_relaxed(), writew_relaxed(), writeb_relaxed()
+ 
+   On architectures that require an expensive barrier for serializing against
+   DMA, these "relaxed" versions of the MMIO accessors only serialize against
+   each other, but contain a less expensive barrier operation. A device driver
+   might use these in a particularly performance sensitive fast path, with a
+   comment that explains why the usage in a specific location is safe without
+   the extra barriers.
+ 
+   See memory-barriers.txt for a more detailed discussion on the precise ordering
+   guarantees of the non-relaxed and relaxed versions.
+ 
+ ioread64(), ioread32(), ioread16(), ioread8(),
+ iowrite64(), iowrite32(), iowrite16(), iowrite8()
+ 
+   These are an alternative to the normal readl()/writel() functions, with almost
+   identical behavior, but they can also operate on ``__iomem`` tokens returned
+   for mapping PCI I/O space with pci_iomap() or ioport_map(). On architectures
+   that require special instructions for I/O port access, this adds a small
+   overhead for an indirect function call implemented in lib/iomap.c, while on
+   other architectures, these are simply aliases.
+ 
+ ioread64be(), ioread32be(), ioread16be()
+ iowrite64be(), iowrite32be(), iowrite16be()
+ 
+   These behave in the same way as the ioread32()/iowrite32() family, but with
+   reversed byte order, for accessing devices with big-endian MMIO registers.
+   Device drivers that can operate on either big-endian or little-endian
+   registers may have to implement a custom wrapper function that picks one or
+   the other depending on which device was found.
+ 
+   Note: On some architectures, the normal readl()/writel() functions
+   traditionally assume that devices are the same endianness as the CPU, while
+   using a hardware byte-reverse on the PCI bus when running a big-endian kernel.
+   Drivers that use readl()/writel() this way are generally not portable, but
+   tend to be limited to a particular SoC.
+ 
+ hi_lo_readq(), lo_hi_readq(), hi_lo_readq_relaxed(), lo_hi_readq_relaxed(),
+ ioread64_lo_hi(), ioread64_hi_lo(), ioread64be_lo_hi(), ioread64be_hi_lo(),
+ hi_lo_writeq(), lo_hi_writeq(), hi_lo_writeq_relaxed(), lo_hi_writeq_relaxed(),
+ iowrite64_lo_hi(), iowrite64_hi_lo(), iowrite64be_lo_hi(), iowrite64be_hi_lo()
+ 
+   Some device drivers have 64-bit registers that cannot be accessed atomically
+   on 32-bit architectures but allow two consecutive 32-bit accesses instead.
+   Since it depends on the particular device which of the two halves has to be
+   accessed first, a helper is provided for each combination of 64-bit accessors
+   with either low/high or high/low word ordering. A device driver must include
+   either <linux/io-64-nonatomic-lo-hi.h> or <linux/io-64-nonatomic-hi-lo.h> to
+   get the function definitions along with helpers that redirect the normal
+   readq()/writeq() to them on architectures that do not provide 64-bit access
+   natively.
+ 
+ __raw_readq(), __raw_readl(), __raw_readw(), __raw_readb(),
+ __raw_writeq(), __raw_writel(), __raw_writew(), __raw_writeb()
+ 
+   These are low-level MMIO accessors without barriers or byteorder changes and
+   architecture specific behavior. Accesses are usually atomic in the sense that
+   a four-byte __raw_readl() does not get split into individual byte loads, but
+   multiple consecutive accesses can be combined on the bus. In portable code, it
+   is only safe to use these to access memory behind a device bus but not MMIO
+   registers, as there are no ordering guarantees with regard to other MMIO
+   accesses or even spinlocks. The byte order is generally the same as for normal
+   memory, so unlike the other functions, these can be used to copy data between
+   kernel memory and device memory.
+ 
+ inl(), inw(), inb(), outl(), outw(), outb()
+ 
+   PCI I/O port resources traditionally require separate helpers as they are
+   implemented using special instructions on the x86 architecture. On most other
+   architectures, these are mapped to readl()/writel() style accessors
+   internally, usually pointing to a fixed area in virtual memory. Instead of an
+   ``__iomem`` pointer, the address is a 32-bit integer token to identify a port
+   number. PCI requires I/O port access to be non-posted, meaning that an outb()
+   must complete before the following code executes, while a normal writeb() may
+   still be in progress. On architectures that correctly implement this, I/O port
+   access is therefore ordered against spinlocks. Many non-x86 PCI host bridge
+   implementations and CPU architectures however fail to implement non-posted I/O
+   space on PCI, so they can end up being posted on such hardware.
+ 
+   In some architectures, the I/O port number space has a 1:1 mapping to
+   ``__iomem`` pointers, but this is not recommended and device drivers should
+   not rely on that for portability. Similarly, an I/O port number as described
+   in a PCI base address register may not correspond to the port number as seen
+   by a device driver. Portable drivers need to read the port number for the
+   resource provided by the kernel.
+ 
+   There are no direct 64-bit I/O port accessors, but pci_iomap() in combination
+   with ioread64/iowrite64 can be used instead.
+ 
+ inl_p(), inw_p(), inb_p(), outl_p(), outw_p(), outb_p()
+ 
+   On ISA devices that require specific timing, the _p versions of the I/O
+   accessors add a small delay. On architectures that do not have ISA buses,
+   these are aliases to the normal inb/outb helpers.
+ 
+ readsq, readsl, readsw, readsb
+ writesq, writesl, writesw, writesb
+ ioread64_rep, ioread32_rep, ioread16_rep, ioread8_rep
+ iowrite64_rep, iowrite32_rep, iowrite16_rep, iowrite8_rep
+ insl, insw, insb, outsl, outsw, outsb
+ 
+   These are helpers that access the same address multiple times, usually to copy
+   data between kernel memory byte stream and a FIFO buffer. Unlike the normal
+   MMIO accessors, these do not perform a byteswap on big-endian kernels, so the
+   first byte in the FIFO register corresponds to the first byte in the memory
+   buffer regardless of the architecture.
+ 
+ Device memory mapping modes
+ ===========================
+ 
+ Some architectures support multiple modes for mapping device memory.
+ ioremap_*() variants provide a common abstraction around these
+ architecture-specific modes, with a shared set of semantics.
+ 
+ ioremap() is the most common mapping type, and is applicable to typical device
+ memory (e.g. I/O registers). Other modes can offer weaker or stronger
+ guarantees, if supported by the architecture. From most to least common, they
+ are as follows:
+ 
+ ioremap()
+ ---------
+ 
+ The default mode, suitable for most memory-mapped devices, e.g. control
+ registers. Memory mapped using ioremap() has the following characteristics:
+ 
+ * Uncached - CPU-side caches are bypassed, and all reads and writes are handled
+   directly by the device
+ * No speculative operations - the CPU may not issue a read or write to this
+   memory, unless the instruction that does so has been reached in committed
+   program flow.
+ * No reordering - The CPU may not reorder accesses to this memory mapping with
+   respect to each other. On some architectures, this relies on barriers in
+   readl_relaxed()/writel_relaxed().
+ * No repetition - The CPU may not issue multiple reads or writes for a single
+   program instruction.
+ * No write-combining - Each I/O operation results in one discrete read or write
+   being issued to the device, and multiple writes are not combined into larger
+   writes. This may or may not be enforced when using __raw I/O accessors or
+   pointer dereferences.
+ * Non-executable - The CPU is not allowed to speculate instruction execution
+   from this memory (it probably goes without saying, but you're also not
+   allowed to jump into device memory).
+ 
+ On many platforms and buses (e.g. PCI), writes issued through ioremap()
+ mappings are posted, which means that the CPU does not wait for the write to
+ actually reach the target device before retiring the write instruction.
+ 
+ On many platforms, I/O accesses must be aligned with respect to the access
+ size; failure to do so will result in an exception or unpredictable results.
+ 
+ ioremap_wc()
+ ------------
+ 
+ Maps I/O memory as normal memory with write combining. Unlike ioremap(),
+ 
+ * The CPU may speculatively issue reads from the device that the program
+   didn't actually execute, and may choose to basically read whatever it wants.
+ * The CPU may reorder operations as long as the result is consistent from the
+   program's point of view.
+ * The CPU may write to the same location multiple times, even when the program
+   issued a single write.
+ * The CPU may combine several writes into a single larger write.
+ 
+ This mode is typically used for video framebuffers, where it can increase
+ performance of writes. It can also be used for other blocks of memory in
+ devices (e.g. buffers or shared memory), but care must be taken as accesses are
+ not guaranteed to be ordered with respect to normal ioremap() MMIO register
+ accesses without explicit barriers.
+ 
+ On a PCI bus, it is usually safe to use ioremap_wc() on MMIO areas marked as
+ ``IORESOURCE_PREFETCH``, but it may not be used on those without the flag.
+ For on-chip devices, there is no corresponding flag, but a driver can use
+ ioremap_wc() on a device that is known to be safe.
+ 
+ ioremap_wt()
+ ------------
+ 
+ Maps I/O memory as normal memory with write-through caching. Like ioremap_wc(),
+ but also,
+ 
+ * The CPU may cache writes issued to and reads from the device, and serve reads
+   from that cache.
+ 
+ This mode is sometimes used for video framebuffers, where drivers still expect
+ writes to reach the device in a timely manner (and not be stuck in the CPU
+ cache), but reads may be served from the cache for efficiency. However, it is
+ rarely useful these days, as framebuffer drivers usually perform writes only,
+ for which ioremap_wc() is more efficient (as it doesn't needlessly trash the
+ cache). Most drivers should not use this.
+ 
+ ioremap_np()
+ ------------
+ 
+ Like ioremap(), but explicitly requests non-posted write semantics. On some
+ architectures and buses, ioremap() mappings have posted write semantics, which
+ means that writes can appear to "complete" from the point of view of the
+ CPU before the written data actually arrives at the target device. Writes are
+ still ordered with respect to other writes and reads from the same device, but
+ due to the posted write semantics, this is not the case with respect to other
+ devices. ioremap_np() explicitly requests non-posted semantics, which means
+ that the write instruction will not appear to complete until the device has
+ received (and to some platform-specific extent acknowledged) the written data.
+ 
+ This mapping mode primarily exists to cater for platforms with bus fabrics that
+ require this particular mapping mode to work correctly. These platforms set the
+ ``IORESOURCE_MEM_NONPOSTED`` flag for a resource that requires ioremap_np()
+ semantics and portable drivers should use an abstraction that automatically
+ selects it where appropriate (see the `Higher-level ioremap abstractions`_
+ section below).
+ 
+ The bare ioremap_np() is only available on some architectures; on others, it
+ always returns NULL. Drivers should not normally use it, unless they are
+ platform-specific or they derive benefit from non-posted writes where
+ supported, and can fall back to ioremap() otherwise. The normal approach to
+ ensure posted write completion is to do a dummy read after a write as
+ explained in `Accessing the device`_, which works with ioremap() on all
+ platforms.
+ 
+ ioremap_np() should never be used for PCI drivers. PCI memory space writes are
+ always posted, even on architectures that otherwise implement ioremap_np().
+ Using ioremap_np() for PCI BARs will at best result in posted write semantics,
+ and at worst result in complete breakage.
+ 
+ Note that non-posted write semantics are orthogonal to CPU-side ordering
+ guarantees. A CPU may still choose to issue other reads or writes before a
+ non-posted write instruction retires. See the previous section on MMIO access
+ functions for details on the CPU side of things.
+ 
+ ioremap_uc()
+ ------------
+ 
+ ioremap_uc() behaves like ioremap() except that on the x86 architecture without
+ 'PAT' mode, it marks memory as uncached even when the MTRR has designated
+ it as cacheable, see Documentation/x86/pat.rst.
+ 
+ Portable drivers should avoid the use of ioremap_uc().
+ 
+ ioremap_cache()
+ ---------------
+ 
+ ioremap_cache() effectively maps I/O memory as normal RAM. CPU write-back
+ caches can be used, and the CPU is free to treat the device as if it were a
+ block of RAM. This should never be used for device memory which has side
+ effects of any kind, or which does not return the data previously written on
+ read.
+ 
+ It should also not be used for actual RAM, as the returned pointer is an
+ ``__iomem`` token. memremap() can be used for mapping normal RAM that is outside
+ of the linear kernel memory area to a regular pointer.
+ 
+ Portable drivers should avoid the use of ioremap_cache().
+ 
+ Architecture example
+ --------------------
+ 
+ Here is how the above modes map to memory attribute settings on the ARM64
+ architecture:
+ 
+ +------------------------+--------------------------------------------+
+ | API                    | Memory region type and cacheability        |
+ +------------------------+--------------------------------------------+
+ | ioremap_np()           | Device-nGnRnE                              |
+ +------------------------+--------------------------------------------+
+ | ioremap()              | Device-nGnRE                               |
+ +------------------------+--------------------------------------------+
+ | ioremap_uc()           | (not implemented)                          |
+ +------------------------+--------------------------------------------+
+ | ioremap_wc()           | Normal-Non Cacheable                       |
+ +------------------------+--------------------------------------------+
+ | ioremap_wt()           | (not implemented; fallback to ioremap)     |
+ +------------------------+--------------------------------------------+
+ | ioremap_cache()        | Normal-Write-Back Cacheable                |
+ +------------------------+--------------------------------------------+
+ 
+ Higher-level ioremap abstractions
+ =================================
+ 
+ Instead of using the above raw ioremap() modes, drivers are encouraged to use
+ higher-level APIs. These APIs may implement platform-specific logic to
+ automatically choose an appropriate ioremap mode on any given bus, allowing for
+ a platform-agnostic driver to work on those platforms without any special
+ cases. At the time of this writing, the following ioremap() wrappers have such
+ logic:
+ 
+ devm_ioremap_resource()
+ 
+   Can automatically select ioremap_np() over ioremap() according to platform
+   requirements, if the ``IORESOURCE_MEM_NONPOSTED`` flag is set on the struct
+   resource. Uses devres to automatically unmap the resource when the driver
+   probe() function fails or a device in unbound from its driver.
+ 
+   Documented in Documentation/driver-api/driver-model/devres.rst.
+ 
+ of_address_to_resource()
+ 
+   Automatically sets the ``IORESOURCE_MEM_NONPOSTED`` flag for platforms that
+   require non-posted writes for certain buses (see the nonposted-mmio and
+   posted-mmio device tree properties).
+ 
+ of_iomap()
+ 
+   Maps the resource described in a ``reg`` property in the device tree, doing
+   all required translations. Automatically selects ioremap_np() according to
+   platform requirements, as above.
+ 
+ pci_ioremap_bar(), pci_ioremap_wc_bar()
+ 
+   Maps the resource described in a PCI base address without having to extract
+   the physical address first.
+ 
+ pci_iomap(), pci_iomap_wc()
+ 
+   Like pci_ioremap_bar()/pci_ioremap_bar(), but also works on I/O space when
+   used together with ioread32()/iowrite32() and similar accessors
+ 
+ pcim_iomap()
+ 
+   Like pci_iomap(), but uses devres to automatically unmap the resource when
+   the driver probe() function fails or a device in unbound from its driver
+ 
+   Documented in Documentation/driver-api/driver-model/devres.rst.
+ 
+ Not using these wrappers may make drivers unusable on certain platforms with
+ stricter rules for mapping I/O memory.
+ 
+ Generalizing Access to System and I/O Memory
+ ============================================
+ 
+ .. kernel-doc:: include/linux/iosys-map.h
+    :doc: overview
+ 
+ .. kernel-doc:: include/linux/iosys-map.h
+    :internal:
+ 
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  Public Functions Provided
  =========================
  
diff --cc Documentation/gpu/todo.rst
index 033141565363,c8f39c1ef1ee..000000000000
--- a/Documentation/gpu/todo.rst
+++ b/Documentation/gpu/todo.rst
@@@ -194,30 -214,55 +194,75 @@@ drm_mode_config_helper_suspend/resume()
  
  Contact: Maintainer of the driver you plan to convert
  
 -Level: Intermediate
 +Convert drivers to use drm_fb_helper_fbdev_setup/teardown()
 +-----------------------------------------------------------
 +
 +Most drivers can use drm_fb_helper_fbdev_setup() except maybe:
 +
++<<<<<<< HEAD
 +- amdgpu which has special logic to decide whether to call
 +  drm_helper_disable_unused_functions()
 +
 +- armada which isn't atomic and doesn't call
 +  drm_helper_disable_unused_functions()
  
 -Convert drivers to use drm_fbdev_generic_setup()
 -------------------------------------------------
 +- i915 which calls drm_fb_helper_initial_config() in a worker
  
 +Drivers that use drm_framebuffer_remove() to clean up the fbdev framebuffer can
 +probably use drm_fb_helper_fbdev_teardown().
++=======
+ Most drivers can use drm_fbdev_generic_setup(). Driver have to implement
+ atomic modesetting and GEM vmap support. Historically, generic fbdev emulation
+ expected the framebuffer in system memory or system-like memory. By employing
+ struct iosys_map, drivers with frambuffers in I/O memory can be supported
+ as well.
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  Contact: Maintainer of the driver you plan to convert
  
 -Level: Intermediate
 +Clean up mmap forwarding
 +------------------------
  
++<<<<<<< HEAD
 +A lot of drivers forward gem mmap calls to dma-buf mmap for imported buffers.
 +And also a lot of them forward dma-buf mmap to the gem mmap implementations.
 +Would be great to refactor this all into a set of small common helpers.
++=======
+ Reimplement functions in drm_fbdev_fb_ops without fbdev
+ -------------------------------------------------------
+ 
+ A number of callback functions in drm_fbdev_fb_ops could benefit from
+ being rewritten without dependencies on the fbdev module. Some of the
+ helpers could further benefit from using struct iosys_map instead of
+ raw pointers.
+ 
+ Contact: Thomas Zimmermann <tzimmermann@suse.de>, Daniel Vetter
+ 
+ Level: Advanced
+ 
+ 
+ drm_framebuffer_funcs and drm_mode_config_funcs.fb_create cleanup
+ -----------------------------------------------------------------
+ 
+ A lot more drivers could be switched over to the drm_gem_framebuffer helpers.
+ Various hold-ups:
+ 
+ - Need to switch over to the generic dirty tracking code using
+   drm_atomic_helper_dirtyfb first (e.g. qxl).
+ 
+ - Need to switch to drm_fbdev_generic_setup(), otherwise a lot of the custom fb
+   setup code can't be deleted.
+ 
+ - Many drivers wrap drm_gem_fb_create() only to check for valid formats. For
+   atomic drivers we could check for valid formats by calling
+   drm_plane_check_pixel_format() against all planes, and pass if any plane
+   supports the format. For non-atomic that's not possible since like the format
+   list for the primary plane is fake and we'd therefor reject valid formats.
+ 
+ - Many drivers subclass drm_framebuffer, we'd need a embedding compatible
+   version of the varios drm_gem_fb_create functions. Maybe called
+   drm_gem_fb_create/_with_dirty/_with_funcs as needed.
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  Contact: Daniel Vetter
  
@@@ -265,38 -387,89 +310,77 @@@ In the end no .c file should need to in
  
  Contact: Daniel Vetter
  
 -Level: Intermediate
 -
 -Replace drm_detect_hdmi_monitor() with drm_display_info.is_hdmi
 ----------------------------------------------------------------
 -
 -Once EDID is parsed, the monitor HDMI support information is available through
 -drm_display_info.is_hdmi. Many drivers still call drm_detect_hdmi_monitor() to
 -retrieve the same information, which is less efficient.
 -
 -Audit each individual driver calling drm_detect_hdmi_monitor() and switch to
 -drm_display_info.is_hdmi if applicable.
 -
 -Contact: Laurent Pinchart, respective driver maintainers
 -
 -Level: Intermediate
 -
 -Consolidate custom driver modeset properties
 +Add missing kerneldoc for exported functions
  --------------------------------------------
  
 -Before atomic modeset took place, many drivers where creating their own
 -properties. Among other things, atomic brought the requirement that custom,
 -driver specific properties should not be used.
 +The DRM reference documentation is still lacking kerneldoc in a few areas. The
 +task would be to clean up interfaces like moving functions around between
 +files to better group them and improving the interfaces like dropping return
 +values for functions that never fail. Then write kerneldoc for all exported
 +functions and an overview section and integrate it all into the drm book.
  
 -For this task, we aim to introduce core helpers or reuse the existing ones
 -if available:
 +See https://dri.freedesktop.org/docs/drm/ for what's there already.
  
 -A quick, unconfirmed, examples list.
 +Contact: Daniel Vetter
  
 -Introduce core helpers:
 -- audio (amdgpu, intel, gma500, radeon)
 -- brightness, contrast, etc (armada, nouveau) - overlay only (?)
 -- broadcast rgb (gma500, intel)
 -- colorkey (armada, nouveau, rcar) - overlay only (?)
 -- dither (amdgpu, nouveau, radeon) - varies across drivers
 -- underscan family (amdgpu, radeon, nouveau)
 +Hide legacy cruft better
 +------------------------
  
 -Already in core:
 -- colorspace (sti)
 -- tv format names, enhancements (gma500, intel)
 -- tv overscan, margins, etc. (gma500, intel)
 -- zorder (omapdrm) - same as zpos (?)
 +Way back DRM supported only drivers which shadow-attached to PCI devices with
 +userspace or fbdev drivers setting up outputs. Modern DRM drivers take charge
 +of the entire device, you can spot them with the DRIVER_MODESET flag.
  
 +Unfortunately there's still large piles of legacy code around which needs to
 +be hidden so that driver writers don't accidentally end up using it. And to
 +prevent security issues in those legacy IOCTLs from being exploited on modern
 +drivers. This has multiple possible subtasks:
  
 -Contact: Emil Velikov, respective driver maintainers
 +* Extract support code for legacy features into a ``drm-legacy.ko`` kernel
 +  module and compile it only when one of the legacy drivers is enabled.
  
 -Level: Intermediate
 +This is mostly done, the only thing left is to split up ``drm_irq.c`` into
 +legacy cruft and the parts needed by modern KMS drivers.
  
++<<<<<<< HEAD
 +Contact: Daniel Vetter
++=======
+ Use struct iosys_map throughout codebase
+ ----------------------------------------
+ 
+ Pointers to shared device memory are stored in struct iosys_map. Each
+ instance knows whether it refers to system or I/O memory. Most of the DRM-wide
+ interface have been converted to use struct iosys_map, but implementations
+ often still use raw pointers.
+ 
+ The task is to use struct iosys_map where it makes sense.
+ 
+ * Memory managers should use struct iosys_map for dma-buf-imported buffers.
+ * TTM might benefit from using struct iosys_map internally.
+ * Framebuffer copying and blitting helpers should operate on struct iosys_map.
+ 
+ Contact: Thomas Zimmermann <tzimmermann@suse.de>, Christian KÃ¶nig, Daniel Vetter
+ 
+ Level: Intermediate
+ 
+ Review all drivers for setting struct drm_mode_config.{max_width,max_height} correctly
+ --------------------------------------------------------------------------------------
+ 
+ The values in struct drm_mode_config.{max_width,max_height} describe the
+ maximum supported framebuffer size. It's the virtual screen size, but many
+ drivers treat it like limitations of the physical resolution.
+ 
+ The maximum width depends on the hardware's maximum scanline pitch. The
+ maximum height depends on the amount of addressable video memory. Review all
+ drivers to initialize the fields to the correct values.
+ 
+ Contact: Thomas Zimmermann <tzimmermann@suse.de>
+ 
+ Level: Intermediate
+ 
+ 
+ Core refactorings
+ =================
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  Make panic handling work
  ------------------------
diff --cc MAINTAINERS
index 7e9998c4b475,1a18eafee497..000000000000
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@@ -4473,8 -5734,9 +4473,14 @@@ T:	git git://anongit.freedesktop.org/dr
  F:	Documentation/driver-api/dma-buf.rst
  F:	drivers/dma-buf/
  F:	include/linux/*fence.h
++<<<<<<< HEAD
 +F:	include/linux/dma-buf*
 +F:	include/linux/reservation.h
++=======
+ F:	include/linux/dma-buf.h
+ F:	include/linux/dma-resv.h
+ K:	\bdma_(?:buf|fence|resv)\b
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  DMA GENERIC OFFLOAD ENGINE SUBSYSTEM
  M:	Vinod Koul <vkoul@kernel.org>
@@@ -7731,20 -10050,26 +7737,27 @@@ F:	include/linux/iova.
  F:	include/linux/of_iommu.h
  F:	include/uapi/linux/iommu.h
  
+ IOSYS-MAP HELPERS
+ M:	Thomas Zimmermann <tzimmermann@suse.de>
+ L:	dri-devel@lists.freedesktop.org
+ S:	Maintained
+ T:	git git://anongit.freedesktop.org/drm/drm-misc
+ F:	include/linux/iosys-map.h
+ 
  IO_URING
  M:	Jens Axboe <axboe@kernel.dk>
 -R:	Pavel Begunkov <asml.silence@gmail.com>
 -L:	io-uring@vger.kernel.org
 -S:	Maintained
 +L:	linux-block@vger.kernel.org
 +L:	linux-fsdevel@vger.kernel.org
 +S:	Maintained
  T:	git git://git.kernel.dk/linux-block
  T:	git git://git.kernel.dk/liburing
 -F:	fs/io-wq.c
 -F:	fs/io-wq.h
  F:	fs/io_uring.c
 -F:	include/linux/io_uring.h
  F:	include/uapi/linux/io_uring.h
 -F:	tools/io_uring/
 +
 +IP MASQUERADING
 +M:	Juanjo Ciarlante <jjciarla@raiz.uncu.edu.ar>
 +S:	Maintained
 +F:	net/ipv4/netfilter/ipt_MASQUERADE.c
  
  IPMI SUBSYSTEM
  M:	Corey Minyard <minyard@acm.org>
diff --cc drivers/dma-buf/dma-buf.c
index 733c8b1c8467,df23239b04fc..000000000000
--- a/drivers/dma-buf/dma-buf.c
+++ b/drivers/dma-buf/dma-buf.c
@@@ -1071,8 -1047,8 +1071,13 @@@ EXPORT_SYMBOL_GPL(dma_buf_move_notify)
   *
   *   Interfaces::
   *
++<<<<<<< HEAD
 + *      void \*dma_buf_vmap(struct dma_buf \*dmabuf)
 + *      void dma_buf_vunmap(struct dma_buf \*dmabuf, void \*vaddr)
++=======
+  *      void \*dma_buf_vmap(struct dma_buf \*dmabuf, struct iosys_map \*map)
+  *      void dma_buf_vunmap(struct dma_buf \*dmabuf, struct iosys_map \*map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
   *
   *   The vmap call can fail if there is no vmap support in the exporter, or if
   *   it runs out of vmalloc space. Note that the dma-buf layer keeps a reference
diff --cc drivers/gpu/drm/ast/ast_mode.c
index 67c0e273b104,400845d4144c..000000000000
--- a/drivers/gpu/drm/ast/ast_mode.c
+++ b/drivers/gpu/drm/ast/ast_mode.c
@@@ -810,7 -805,7 +810,11 @@@ ast_cursor_plane_helper_atomic_update(s
  		ast_cursor_plane->hwc[ast_cursor_plane->next_hwc_index].map;
  	u64 dst_off =
  		ast_cursor_plane->hwc[ast_cursor_plane->next_hwc_index].off;
++<<<<<<< HEAD
 +	struct dma_buf_map src_map = shadow_plane_state->map[0];
++=======
+ 	struct iosys_map src_map = shadow_plane_state->data[0];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	unsigned int offset_x, offset_y;
  	u16 x, y;
  	u8 x_offset, y_offset;
diff --cc drivers/gpu/drm/drm_cache.c
index 546599f19a93,4bb093ccf1b8..000000000000
--- a/drivers/gpu/drm/drm_cache.c
+++ b/drivers/gpu/drm/drm_cache.c
@@@ -28,10 -28,10 +28,14 @@@
   * Authors: Thomas HellstrÃ¶m <thomas-at-tungstengraphics-dot-com>
   */
  
- #include <linux/dma-buf-map.h>
+ #include <linux/cc_platform.h>
  #include <linux/export.h>
  #include <linux/highmem.h>
++<<<<<<< HEAD
 +#include <linux/mem_encrypt.h>
++=======
+ #include <linux/iosys-map.h>
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  #include <xen/xen.h>
  
  #include <drm/drm_cache.h>
diff --cc drivers/gpu/drm/drm_gem_cma_helper.c
index 9d05674550a4,88c432a7cb3c..000000000000
--- a/drivers/gpu/drm/drm_gem_cma_helper.c
+++ b/drivers/gpu/drm/drm_gem_cma_helper.c
@@@ -197,13 -205,11 +197,18 @@@ drm_gem_cma_create_with_handle(struct d
   * This function frees the backing memory of the CMA GEM object, cleans up the
   * GEM object state and frees the memory used to store the object itself.
   * If the buffer is imported and the virtual address is set, it is released.
 + * Drivers using the CMA helpers should set this as their
 + * &drm_gem_object_funcs.free callback.
   */
 -void drm_gem_cma_free(struct drm_gem_cma_object *cma_obj)
 +void drm_gem_cma_free_object(struct drm_gem_object *gem_obj)
  {
++<<<<<<< HEAD
 +	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(gem_obj);
 +	struct dma_buf_map map = DMA_BUF_MAP_INIT_VADDR(cma_obj->vaddr);
++=======
+ 	struct drm_gem_object *gem_obj = &cma_obj->base;
+ 	struct iosys_map map = IOSYS_MAP_INIT_VADDR(cma_obj->vaddr);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  	if (gem_obj->import_attach) {
  		if (cma_obj->vaddr)
@@@ -480,11 -480,10 +485,18 @@@ EXPORT_SYMBOL_GPL(drm_gem_cma_prime_imp
   * Returns:
   * 0 on success, or a negative error code otherwise.
   */
++<<<<<<< HEAD
 +int drm_gem_cma_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
 +{
 +	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
 +
 +	dma_buf_map_set_vaddr(map, cma_obj->vaddr);
++=======
+ int drm_gem_cma_vmap(struct drm_gem_cma_object *cma_obj,
+ 		     struct iosys_map *map)
+ {
+ 	iosys_map_set_vaddr(map, cma_obj->vaddr);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  	return 0;
  }
diff --cc drivers/gpu/drm/drm_gem_framebuffer_helper.c
index e2c68822e05c,f4619803acd0..000000000000
--- a/drivers/gpu/drm/drm_gem_framebuffer_helper.c
+++ b/drivers/gpu/drm/drm_gem_framebuffer_helper.c
@@@ -306,6 -314,184 +306,187 @@@ drm_gem_fb_create_with_dirty(struct drm
  }
  EXPORT_SYMBOL_GPL(drm_gem_fb_create_with_dirty);
  
++<<<<<<< HEAD
++=======
+ /**
+  * drm_gem_fb_vmap - maps all framebuffer BOs into kernel address space
+  * @fb: the framebuffer
+  * @map: returns the mapping's address for each BO
+  * @data: returns the data address for each BO, can be NULL
+  *
+  * This function maps all buffer objects of the given framebuffer into
+  * kernel address space and stores them in struct iosys_map. If the
+  * mapping operation fails for one of the BOs, the function unmaps the
+  * already established mappings automatically.
+  *
+  * Callers that want to access a BO's stored data should pass @data.
+  * The argument returns the addresses of the data stored in each BO. This
+  * is different from @map if the framebuffer's offsets field is non-zero.
+  *
+  * See drm_gem_fb_vunmap() for unmapping.
+  *
+  * Returns:
+  * 0 on success, or a negative errno code otherwise.
+  */
+ int drm_gem_fb_vmap(struct drm_framebuffer *fb,
+ 		    struct iosys_map map[static DRM_FORMAT_MAX_PLANES],
+ 		    struct iosys_map data[DRM_FORMAT_MAX_PLANES])
+ {
+ 	struct drm_gem_object *obj;
+ 	unsigned int i;
+ 	int ret;
+ 
+ 	for (i = 0; i < DRM_FORMAT_MAX_PLANES; ++i) {
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj) {
+ 			iosys_map_clear(&map[i]);
+ 			continue;
+ 		}
+ 		ret = drm_gem_vmap(obj, &map[i]);
+ 		if (ret)
+ 			goto err_drm_gem_vunmap;
+ 	}
+ 
+ 	if (data) {
+ 		for (i = 0; i < DRM_FORMAT_MAX_PLANES; ++i) {
+ 			memcpy(&data[i], &map[i], sizeof(data[i]));
+ 			if (iosys_map_is_null(&data[i]))
+ 				continue;
+ 			iosys_map_incr(&data[i], fb->offsets[i]);
+ 		}
+ 	}
+ 
+ 	return 0;
+ 
+ err_drm_gem_vunmap:
+ 	while (i) {
+ 		--i;
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj)
+ 			continue;
+ 		drm_gem_vunmap(obj, &map[i]);
+ 	}
+ 	return ret;
+ }
+ EXPORT_SYMBOL(drm_gem_fb_vmap);
+ 
+ /**
+  * drm_gem_fb_vunmap - unmaps framebuffer BOs from kernel address space
+  * @fb: the framebuffer
+  * @map: mapping addresses as returned by drm_gem_fb_vmap()
+  *
+  * This function unmaps all buffer objects of the given framebuffer.
+  *
+  * See drm_gem_fb_vmap() for more information.
+  */
+ void drm_gem_fb_vunmap(struct drm_framebuffer *fb,
+ 		       struct iosys_map map[static DRM_FORMAT_MAX_PLANES])
+ {
+ 	unsigned int i = DRM_FORMAT_MAX_PLANES;
+ 	struct drm_gem_object *obj;
+ 
+ 	while (i) {
+ 		--i;
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj)
+ 			continue;
+ 		if (iosys_map_is_null(&map[i]))
+ 			continue;
+ 		drm_gem_vunmap(obj, &map[i]);
+ 	}
+ }
+ EXPORT_SYMBOL(drm_gem_fb_vunmap);
+ 
+ /**
+  * drm_gem_fb_begin_cpu_access - prepares GEM buffer objects for CPU access
+  * @fb: the framebuffer
+  * @dir: access mode
+  *
+  * Prepares a framebuffer's GEM buffer objects for CPU access. This function
+  * must be called before accessing the BO data within the kernel. For imported
+  * BOs, the function calls dma_buf_begin_cpu_access().
+  *
+  * See drm_gem_fb_end_cpu_access() for signalling the end of CPU access.
+  *
+  * Returns:
+  * 0 on success, or a negative errno code otherwise.
+  */
+ int drm_gem_fb_begin_cpu_access(struct drm_framebuffer *fb, enum dma_data_direction dir)
+ {
+ 	struct dma_buf_attachment *import_attach;
+ 	struct drm_gem_object *obj;
+ 	size_t i;
+ 	int ret, ret2;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(fb->obj); ++i) {
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj)
+ 			continue;
+ 		import_attach = obj->import_attach;
+ 		if (!import_attach)
+ 			continue;
+ 		ret = dma_buf_begin_cpu_access(import_attach->dmabuf, dir);
+ 		if (ret)
+ 			goto err_dma_buf_end_cpu_access;
+ 	}
+ 
+ 	return 0;
+ 
+ err_dma_buf_end_cpu_access:
+ 	while (i) {
+ 		--i;
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj)
+ 			continue;
+ 		import_attach = obj->import_attach;
+ 		if (!import_attach)
+ 			continue;
+ 		ret2 = dma_buf_end_cpu_access(import_attach->dmabuf, dir);
+ 		if (ret2) {
+ 			drm_err(fb->dev,
+ 				"dma_buf_end_cpu_access() failed during error handling: %d\n",
+ 				ret2);
+ 		}
+ 	}
+ 
+ 	return ret;
+ }
+ EXPORT_SYMBOL(drm_gem_fb_begin_cpu_access);
+ 
+ /**
+  * drm_gem_fb_end_cpu_access - signals end of CPU access to GEM buffer objects
+  * @fb: the framebuffer
+  * @dir: access mode
+  *
+  * Signals the end of CPU access to the given framebuffer's GEM buffer objects. This
+  * function must be paired with a corresponding call to drm_gem_fb_begin_cpu_access().
+  * For imported BOs, the function calls dma_buf_end_cpu_access().
+  *
+  * See also drm_gem_fb_begin_cpu_access().
+  */
+ void drm_gem_fb_end_cpu_access(struct drm_framebuffer *fb, enum dma_data_direction dir)
+ {
+ 	size_t i = ARRAY_SIZE(fb->obj);
+ 	struct dma_buf_attachment *import_attach;
+ 	struct drm_gem_object *obj;
+ 	int ret;
+ 
+ 	while (i) {
+ 		--i;
+ 		obj = drm_gem_fb_get_obj(fb, i);
+ 		if (!obj)
+ 			continue;
+ 		import_attach = obj->import_attach;
+ 		if (!import_attach)
+ 			continue;
+ 		ret = dma_buf_end_cpu_access(import_attach->dmabuf, dir);
+ 		if (ret)
+ 			drm_err(fb->dev, "dma_buf_end_cpu_access() failed: %d\n", ret);
+ 	}
+ }
+ EXPORT_SYMBOL(drm_gem_fb_end_cpu_access);
+ 
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  static __u32 drm_gem_afbc_get_bpp(struct drm_device *dev,
  				  const struct drm_mode_fb_cmd2 *mode_cmd)
  {
diff --cc drivers/gpu/drm/drm_gem_shmem_helper.c
index 1d4661df417d,3e738aea2664..000000000000
--- a/drivers/gpu/drm/drm_gem_shmem_helper.c
+++ b/drivers/gpu/drm/drm_gem_shmem_helper.c
@@@ -333,9 -354,9 +334,14 @@@ err_zero_use
   * Returns:
   * 0 on success or a negative error code on failure.
   */
++<<<<<<< HEAD
 +int drm_gem_shmem_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
++=======
+ int drm_gem_shmem_vmap(struct drm_gem_shmem_object *shmem,
+ 		       struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
 +	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
  	int ret;
  
  	ret = mutex_lock_interruptible(&shmem->vmap_lock);
@@@ -378,14 -399,12 +384,19 @@@ static void drm_gem_shmem_vunmap_locked
   * drm_gem_shmem_vmap(). The mapping is only removed when the use count drops to
   * zero.
   *
 - * This function hides the differences between dma-buf imported and natively
 - * allocated objects.
 + * This function can be used to implement &drm_gem_object_funcs.vmap. But it can
 + * also be called by drivers directly, in which case it will hide the
 + * differences between dma-buf imported and natively allocated objects.
   */
++<<<<<<< HEAD
 +void drm_gem_shmem_vunmap(struct drm_gem_object *obj, struct dma_buf_map *map)
++=======
+ void drm_gem_shmem_vunmap(struct drm_gem_shmem_object *shmem,
+ 			  struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
 +	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
 +
  	mutex_lock(&shmem->vmap_lock);
  	drm_gem_shmem_vunmap_locked(shmem, map);
  	mutex_unlock(&shmem->vmap_lock);
diff --cc drivers/gpu/drm/drm_mipi_dbi.c
index 43a9b739bba7,9314f2ead79f..000000000000
--- a/drivers/gpu/drm/drm_mipi_dbi.c
+++ b/drivers/gpu/drm/drm_mipi_dbi.c
@@@ -201,17 -201,19 +201,24 @@@ int mipi_dbi_buf_copy(void *dst, struc
  		      struct drm_rect *clip, bool swap)
  {
  	struct drm_gem_object *gem = drm_gem_fb_get_obj(fb, 0);
++<<<<<<< HEAD
 +	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(gem);
 +	struct dma_buf_attachment *import_attach = gem->import_attach;
 +	void *src = cma_obj->vaddr;
 +	int ret = 0;
++=======
+ 	struct iosys_map map[DRM_FORMAT_MAX_PLANES];
+ 	struct iosys_map data[DRM_FORMAT_MAX_PLANES];
+ 	void *src;
+ 	int ret;
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 -	ret = drm_gem_fb_begin_cpu_access(fb, DMA_FROM_DEVICE);
 -	if (ret)
 -		return ret;
 -
 -	ret = drm_gem_fb_vmap(fb, map, data);
 -	if (ret)
 -		goto out_drm_gem_fb_end_cpu_access;
 -	src = data[0].vaddr; /* TODO: Use mapping abstraction properly */
 +	if (import_attach) {
 +		ret = dma_buf_begin_cpu_access(import_attach->dmabuf,
 +					       DMA_FROM_DEVICE);
 +		if (ret)
 +			return ret;
 +	}
  
  	switch (fb->format->format) {
  	case DRM_FORMAT_RGB565:
@@@ -255,8 -258,8 +262,13 @@@ static void mipi_dbi_set_window_address
  
  static void mipi_dbi_fb_dirty(struct drm_framebuffer *fb, struct drm_rect *rect)
  {
++<<<<<<< HEAD
 +	struct drm_gem_object *gem = drm_gem_fb_get_obj(fb, 0);
 +	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(gem);
++=======
+ 	struct iosys_map map[DRM_FORMAT_MAX_PLANES];
+ 	struct iosys_map data[DRM_FORMAT_MAX_PLANES];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	struct mipi_dbi_dev *dbidev = drm_to_mipi_dbi_dev(fb->dev);
  	unsigned int height = rect->y2 - rect->y1;
  	unsigned int width = rect->x2 - rect->x1;
diff --cc drivers/gpu/drm/etnaviv/etnaviv_drv.h
index d36c7bbe66db,f32f4771dada..000000000000
--- a/drivers/gpu/drm/etnaviv/etnaviv_drv.h
+++ b/drivers/gpu/drm/etnaviv/etnaviv_drv.h
@@@ -52,15 -47,9 +52,19 @@@ struct etnaviv_drm_private 
  int etnaviv_ioctl_gem_submit(struct drm_device *dev, void *data,
  		struct drm_file *file);
  
 +int etnaviv_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 +int etnaviv_gem_fault(struct vm_fault *vmf);
  int etnaviv_gem_mmap_offset(struct drm_gem_object *obj, u64 *offset);
  struct sg_table *etnaviv_gem_prime_get_sg_table(struct drm_gem_object *obj);
++<<<<<<< HEAD
 +void *etnaviv_gem_prime_vmap(struct drm_gem_object *obj);
 +void etnaviv_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 +int etnaviv_gem_prime_mmap(struct drm_gem_object *obj,
 +			   struct vm_area_struct *vma);
 +struct reservation_object *etnaviv_gem_prime_res_obj(struct drm_gem_object *obj);
++=======
+ int etnaviv_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  struct drm_gem_object *etnaviv_gem_prime_import_sg_table(struct drm_device *dev,
  	struct dma_buf_attachment *attach, struct sg_table *sg);
  int etnaviv_gem_prime_pin(struct drm_gem_object *obj);
diff --cc drivers/gpu/drm/etnaviv/etnaviv_gem_prime.c
index 57201ee8577f,3fa2da149639..000000000000
--- a/drivers/gpu/drm/etnaviv/etnaviv_gem_prime.c
+++ b/drivers/gpu/drm/etnaviv/etnaviv_gem_prime.c
@@@ -20,27 -25,16 +20,38 @@@ struct sg_table *etnaviv_gem_prime_get_
  	return drm_prime_pages_to_sg(obj->dev, etnaviv_obj->pages, npages);
  }
  
++<<<<<<< HEAD
 +void *etnaviv_gem_prime_vmap(struct drm_gem_object *obj)
++=======
+ int etnaviv_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
 -	void *vaddr;
 +	return etnaviv_gem_vmap(obj);
 +}
  
++<<<<<<< HEAD
 +void etnaviv_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr)
 +{
 +	/* TODO msm_gem_vunmap() */
 +}
++=======
+ 	vaddr = etnaviv_gem_vmap(obj);
+ 	if (!vaddr)
+ 		return -ENOMEM;
+ 	iosys_map_set_vaddr(map, vaddr);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 -	return 0;
 +int etnaviv_gem_prime_mmap(struct drm_gem_object *obj,
 +			   struct vm_area_struct *vma)
 +{
 +	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 +	int ret;
 +
 +	ret = drm_gem_mmap_obj(obj, obj->size, vma);
 +	if (ret < 0)
 +		return ret;
 +
 +	return etnaviv_obj->ops->mmap(etnaviv_obj, vma);
  }
  
  int etnaviv_gem_prime_pin(struct drm_gem_object *obj)
diff --cc drivers/gpu/drm/gud/gud_pipe.c
index 2f83ab6b8e61,4873f9799f41..000000000000
--- a/drivers/gpu/drm/gud/gud_pipe.c
+++ b/drivers/gpu/drm/gud/gud_pipe.c
@@@ -139,7 -152,8 +139,12 @@@ static int gud_prep_flush(struct gud_de
  {
  	struct dma_buf_attachment *import_attach = fb->obj[0]->import_attach;
  	u8 compression = gdrm->compression;
++<<<<<<< HEAD
 +	struct dma_buf_map map;
++=======
+ 	struct iosys_map map[DRM_FORMAT_MAX_PLANES];
+ 	struct iosys_map map_data[DRM_FORMAT_MAX_PLANES];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	void *vaddr, *buf;
  	size_t pitch, len;
  	int ret = 0;
diff --cc drivers/gpu/drm/mediatek/mtk_drm_gem.c
index 259b7b0de1d2,139d7724c6d0..000000000000
--- a/drivers/gpu/drm/mediatek/mtk_drm_gem.c
+++ b/drivers/gpu/drm/mediatek/mtk_drm_gem.c
@@@ -236,8 -218,50 +236,57 @@@ struct drm_gem_object *mtk_gem_prime_im
  	mtk_gem->sg = sg;
  
  	return &mtk_gem->base;
++<<<<<<< HEAD
 +
 +err_gem_free:
 +	kfree(mtk_gem);
 +	return ERR_PTR(ret);
++=======
+ }
+ 
+ int mtk_drm_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)
+ {
+ 	struct mtk_drm_gem_obj *mtk_gem = to_mtk_gem_obj(obj);
+ 	struct sg_table *sgt = NULL;
+ 	unsigned int npages;
+ 
+ 	if (mtk_gem->kvaddr)
+ 		goto out;
+ 
+ 	sgt = mtk_gem_prime_get_sg_table(obj);
+ 	if (IS_ERR(sgt))
+ 		return PTR_ERR(sgt);
+ 
+ 	npages = obj->size >> PAGE_SHIFT;
+ 	mtk_gem->pages = kcalloc(npages, sizeof(*mtk_gem->pages), GFP_KERNEL);
+ 	if (!mtk_gem->pages) {
+ 		kfree(sgt);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	drm_prime_sg_to_page_array(sgt, mtk_gem->pages, npages);
+ 
+ 	mtk_gem->kvaddr = vmap(mtk_gem->pages, npages, VM_MAP,
+ 			       pgprot_writecombine(PAGE_KERNEL));
+ 
+ out:
+ 	kfree(sgt);
+ 	iosys_map_set_vaddr(map, mtk_gem->kvaddr);
+ 
+ 	return 0;
+ }
+ 
+ void mtk_drm_gem_prime_vunmap(struct drm_gem_object *obj,
+ 			      struct iosys_map *map)
+ {
+ 	struct mtk_drm_gem_obj *mtk_gem = to_mtk_gem_obj(obj);
+ 	void *vaddr = map->vaddr;
+ 
+ 	if (!mtk_gem->pages)
+ 		return;
+ 
+ 	vunmap(vaddr);
+ 	mtk_gem->kvaddr = 0;
+ 	kfree(mtk_gem->pages);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  }
diff --cc drivers/gpu/drm/mediatek/mtk_drm_gem.h
index 534639b43a1c,78f23b07a02e..000000000000
--- a/drivers/gpu/drm/mediatek/mtk_drm_gem.h
+++ b/drivers/gpu/drm/mediatek/mtk_drm_gem.h
@@@ -52,5 -42,8 +52,11 @@@ int mtk_drm_gem_mmap_buf(struct drm_gem
  struct sg_table *mtk_gem_prime_get_sg_table(struct drm_gem_object *obj);
  struct drm_gem_object *mtk_gem_prime_import_sg_table(struct drm_device *dev,
  			struct dma_buf_attachment *attach, struct sg_table *sg);
++<<<<<<< HEAD
++=======
+ int mtk_drm_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map);
+ void mtk_drm_gem_prime_vunmap(struct drm_gem_object *obj,
+ 			      struct iosys_map *map);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  #endif
diff --cc drivers/gpu/drm/msm/msm_drv.h
index b2da1fbf81e0,ae52412d529a..000000000000
--- a/drivers/gpu/drm/msm/msm_drv.h
+++ b/drivers/gpu/drm/msm/msm_drv.h
@@@ -181,28 -304,13 +181,33 @@@ int msm_ioctl_gem_submit(struct drm_dev
  void msm_gem_shrinker_init(struct drm_device *dev);
  void msm_gem_shrinker_cleanup(struct drm_device *dev);
  
 +int msm_gem_mmap_obj(struct drm_gem_object *obj,
 +			struct vm_area_struct *vma);
 +int msm_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 +int msm_gem_fault(struct vm_fault *vmf);
 +uint64_t msm_gem_mmap_offset(struct drm_gem_object *obj);
 +int msm_gem_get_iova(struct drm_gem_object *obj,
 +		struct msm_gem_address_space *aspace, uint64_t *iova);
 +uint64_t msm_gem_iova(struct drm_gem_object *obj,
 +		struct msm_gem_address_space *aspace);
 +struct page **msm_gem_get_pages(struct drm_gem_object *obj);
 +void msm_gem_put_pages(struct drm_gem_object *obj);
 +void msm_gem_put_iova(struct drm_gem_object *obj,
 +		struct msm_gem_address_space *aspace);
 +int msm_gem_dumb_create(struct drm_file *file, struct drm_device *dev,
 +		struct drm_mode_create_dumb *args);
 +int msm_gem_dumb_map_offset(struct drm_file *file, struct drm_device *dev,
 +		uint32_t handle, uint64_t *offset);
  struct sg_table *msm_gem_prime_get_sg_table(struct drm_gem_object *obj);
++<<<<<<< HEAD
 +void *msm_gem_prime_vmap(struct drm_gem_object *obj);
 +void msm_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 +int msm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
 +struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj);
++=======
+ int msm_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map);
+ void msm_gem_prime_vunmap(struct drm_gem_object *obj, struct iosys_map *map);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  struct drm_gem_object *msm_gem_prime_import_sg_table(struct drm_device *dev,
  		struct dma_buf_attachment *attach, struct sg_table *sg);
  int msm_gem_prime_pin(struct drm_gem_object *obj);
diff --cc drivers/gpu/drm/msm/msm_gem_prime.c
index 4d34bfb107a6,e8f1b7a2ca9c..000000000000
--- a/drivers/gpu/drm/msm/msm_gem_prime.c
+++ b/drivers/gpu/drm/msm/msm_gem_prime.c
@@@ -31,12 -22,19 +31,28 @@@ struct sg_table *msm_gem_prime_get_sg_t
  	return drm_prime_pages_to_sg(obj->dev, msm_obj->pages, npages);
  }
  
++<<<<<<< HEAD
 +void *msm_gem_prime_vmap(struct drm_gem_object *obj)
 +{
 +	return msm_gem_get_vaddr(obj);
 +}
 +
 +void msm_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr)
++=======
+ int msm_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)
+ {
+ 	void *vaddr;
+ 
+ 	vaddr = msm_gem_get_vaddr(obj);
+ 	if (IS_ERR(vaddr))
+ 		return PTR_ERR(vaddr);
+ 	iosys_map_set_vaddr(map, vaddr);
+ 
+ 	return 0;
+ }
+ 
+ void msm_gem_prime_vunmap(struct drm_gem_object *obj, struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
  	msm_gem_put_vaddr(obj);
  }
diff --cc drivers/gpu/drm/qxl/qxl_drv.h
index dd6abee55f56,9796099ff18f..000000000000
--- a/drivers/gpu/drm/qxl/qxl_drv.h
+++ b/drivers/gpu/drm/qxl/qxl_drv.h
@@@ -431,11 -431,9 +431,15 @@@ struct sg_table *qxl_gem_prime_get_sg_t
  struct drm_gem_object *qxl_gem_prime_import_sg_table(
  	struct drm_device *dev, struct dma_buf_attachment *attach,
  	struct sg_table *sgt);
- int qxl_gem_prime_vmap(struct drm_gem_object *obj, struct dma_buf_map *map);
+ int qxl_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map);
  void qxl_gem_prime_vunmap(struct drm_gem_object *obj,
++<<<<<<< HEAD
 +			  struct dma_buf_map *map);
 +int qxl_gem_prime_mmap(struct drm_gem_object *obj,
 +				struct vm_area_struct *vma);
++=======
+ 			  struct iosys_map *map);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  /* qxl_irq.c */
  int qxl_irq_init(struct qxl_device *qdev);
diff --cc drivers/gpu/drm/rockchip/rockchip_drm_gem.c
index 6858dbcaa230,985584147da1..000000000000
--- a/drivers/gpu/drm/rockchip/rockchip_drm_gem.c
+++ b/drivers/gpu/drm/rockchip/rockchip_drm_gem.c
@@@ -561,21 -510,28 +561,45 @@@ err_free_rk_obj
  	return ERR_PTR(ret);
  }
  
++<<<<<<< HEAD
 +void *rockchip_gem_prime_vmap(struct drm_gem_object *obj)
 +{
 +	struct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);
 +
 +	if (rk_obj->pages)
 +		return vmap(rk_obj->pages, rk_obj->num_pages, VM_MAP,
 +			    pgprot_writecombine(PAGE_KERNEL));
 +
 +	if (rk_obj->dma_attrs & DMA_ATTR_NO_KERNEL_MAPPING)
 +		return NULL;
++=======
+ int rockchip_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)
+ {
+ 	struct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);
+ 
+ 	if (rk_obj->pages) {
+ 		void *vaddr = vmap(rk_obj->pages, rk_obj->num_pages, VM_MAP,
+ 				  pgprot_writecombine(PAGE_KERNEL));
+ 		if (!vaddr)
+ 			return -ENOMEM;
+ 		iosys_map_set_vaddr(map, vaddr);
+ 		return 0;
+ 	}
+ 
+ 	if (rk_obj->dma_attrs & DMA_ATTR_NO_KERNEL_MAPPING)
+ 		return -ENOMEM;
+ 	iosys_map_set_vaddr(map, rk_obj->kvaddr);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 -	return 0;
 +	return rk_obj->kvaddr;
  }
  
++<<<<<<< HEAD
 +void rockchip_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr)
++=======
+ void rockchip_gem_prime_vunmap(struct drm_gem_object *obj,
+ 			       struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
  	struct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);
  
diff --cc drivers/gpu/drm/rockchip/rockchip_drm_gem.h
index d41fa65219d2,72f59ac6d258..000000000000
--- a/drivers/gpu/drm/rockchip/rockchip_drm_gem.h
+++ b/drivers/gpu/drm/rockchip/rockchip_drm_gem.h
@@@ -39,15 -31,9 +39,21 @@@ struct drm_gem_object 
  rockchip_gem_prime_import_sg_table(struct drm_device *dev,
  				   struct dma_buf_attachment *attach,
  				   struct sg_table *sg);
++<<<<<<< HEAD
 +void *rockchip_gem_prime_vmap(struct drm_gem_object *obj);
 +void rockchip_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 +
 +/* drm driver mmap file operations */
 +int rockchip_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 +
 +/* mmap a gem object to userspace. */
 +int rockchip_gem_mmap_buf(struct drm_gem_object *obj,
 +			  struct vm_area_struct *vma);
++=======
+ int rockchip_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map);
+ void rockchip_gem_prime_vunmap(struct drm_gem_object *obj,
+ 			       struct iosys_map *map);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  struct rockchip_gem_object *
  	rockchip_gem_create_object(struct drm_device *drm, unsigned int size,
diff --cc drivers/gpu/drm/tiny/cirrus.c
index 42611dacde88,2dc5ffecf191..000000000000
--- a/drivers/gpu/drm/tiny/cirrus.c
+++ b/drivers/gpu/drm/tiny/cirrus.c
@@@ -16,8 -16,7 +16,12 @@@
   * Copyright 1999-2001 Jeff Garzik <jgarzik@pobox.com>
   */
  
++<<<<<<< HEAD
 +#include <linux/console.h>
 +#include <linux/dma-buf-map.h>
++=======
+ #include <linux/iosys-map.h>
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  #include <linux/module.h>
  #include <linux/pci.h>
  
diff --cc drivers/gpu/drm/ttm/ttm_bo_util.c
index abf2d7a4fdf1,4bf72470abef..000000000000
--- a/drivers/gpu/drm/ttm/ttm_bo_util.c
+++ b/drivers/gpu/drm/ttm/ttm_bo_util.c
@@@ -93,8 -93,7 +93,12 @@@ void ttm_move_memcpy(struct ttm_buffer_
  {
  	const struct ttm_kmap_iter_ops *dst_ops = dst_iter->ops;
  	const struct ttm_kmap_iter_ops *src_ops = src_iter->ops;
++<<<<<<< HEAD
 +	struct ttm_tt *ttm = bo->ttm;
 +	struct dma_buf_map src_map, dst_map;
++=======
+ 	struct iosys_map src_map, dst_map;
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	pgoff_t i;
  
  	/* Single TTM move. NOP */
diff --cc drivers/gpu/drm/vboxvideo/vbox_mode.c
index 964381d55fc1,4017b0a621fc..000000000000
--- a/drivers/gpu/drm/vboxvideo/vbox_mode.c
+++ b/drivers/gpu/drm/vboxvideo/vbox_mode.c
@@@ -398,7 -398,7 +398,11 @@@ static void vbox_cursor_atomic_update(s
  	u32 height = new_state->crtc_h;
  	struct drm_shadow_plane_state *shadow_plane_state =
  		to_drm_shadow_plane_state(new_state);
++<<<<<<< HEAD
 +	struct dma_buf_map map = shadow_plane_state->map[0];
++=======
+ 	struct iosys_map map = shadow_plane_state->data[0];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	u8 *src = map.vaddr; /* TODO: Use mapping abstraction properly */
  	size_t data_size, mask_size;
  	u32 flags;
diff --cc drivers/gpu/drm/vkms/vkms_composer.c
index e49523866e1d,c6a1036bf2ea..000000000000
--- a/drivers/gpu/drm/vkms/vkms_composer.c
+++ b/drivers/gpu/drm/vkms/vkms_composer.c
@@@ -154,16 -153,14 +154,21 @@@ static void compose_plane(struct vkms_c
  			  struct vkms_composer *plane_composer,
  			  void *vaddr_out)
  {
 +	struct drm_gem_object *plane_obj;
 +	struct drm_gem_shmem_object *plane_shmem_obj;
  	struct drm_framebuffer *fb = &plane_composer->fb;
 -	void *vaddr;
  	void (*pixel_blend)(const u8 *p_src, u8 *p_dst);
  
++<<<<<<< HEAD
 +	plane_obj = drm_gem_fb_get_obj(&plane_composer->fb, 0);
 +	plane_shmem_obj = to_drm_gem_shmem_obj(plane_obj);
++=======
+ 	if (WARN_ON(iosys_map_is_null(&primary_composer->map[0])))
+ 		return;
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 -	vaddr = plane_composer->map[0].vaddr;
 +	if (WARN_ON(!plane_shmem_obj->vaddr))
 +		return;
  
  	if (fb->format->format == DRM_FORMAT_ARGB8888)
  		pixel_blend = &alpha_blend;
@@@ -191,10 -187,12 +196,14 @@@ static int compose_active_planes(void *
  		}
  	}
  
++<<<<<<< HEAD
 +	if (WARN_ON(!shmem_obj->vaddr))
++=======
+ 	if (WARN_ON(iosys_map_is_null(&primary_composer->map[0])))
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  		return -EINVAL;
  
 -	vaddr = primary_composer->map[0].vaddr;
 -
 -	memcpy(*vaddr_out, vaddr, gem_obj->size);
 +	memcpy(*vaddr_out, shmem_obj->vaddr, shmem_obj->base.size);
  
  	/* If there are other planes besides primary, we consider the active
  	 * planes should be in z-order and compose them associatively:
diff --cc drivers/gpu/drm/vkms/vkms_drv.h
index ac8c9c2fa4ed,18d944c57883..000000000000
--- a/drivers/gpu/drm/vkms/vkms_drv.h
+++ b/drivers/gpu/drm/vkms/vkms_drv.h
@@@ -19,9 -20,15 +19,21 @@@
  #define XRES_MAX  8192
  #define YRES_MAX  8192
  
++<<<<<<< HEAD
 +struct vkms_composer {
 +	struct drm_framebuffer fb;
 +	struct drm_rect src, dst;
++=======
+ struct vkms_writeback_job {
+ 	struct iosys_map map[DRM_FORMAT_MAX_PLANES];
+ 	struct iosys_map data[DRM_FORMAT_MAX_PLANES];
+ };
+ 
+ struct vkms_composer {
+ 	struct drm_framebuffer fb;
+ 	struct drm_rect src, dst;
+ 	struct iosys_map map[4];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	unsigned int offset;
  	unsigned int pitch;
  	unsigned int cpp;
diff --cc drivers/gpu/drm/xen/xen_drm_front_gem.c
index b293c67230ef,5a5bf4e5b717..000000000000
--- a/drivers/gpu/drm/xen/xen_drm_front_gem.c
+++ b/drivers/gpu/drm/xen/xen_drm_front_gem.c
@@@ -238,59 -280,8 +238,64 @@@ xen_drm_front_gem_import_sg_table(struc
  	return &xen_obj->base;
  }
  
++<<<<<<< HEAD
 +static int gem_mmap_obj(struct xen_gem_object *xen_obj,
 +			struct vm_area_struct *vma)
 +{
 +	int ret;
 +
 +	/*
 +	 * clear the VM_PFNMAP flag that was set by drm_gem_mmap(), and set the
 +	 * vm_pgoff (used as a fake buffer offset by DRM) to 0 as we want to map
 +	 * the whole buffer.
 +	 */
 +	vma->vm_flags &= ~VM_PFNMAP;
 +	vma->vm_flags |= VM_MIXEDMAP;
 +	vma->vm_pgoff = 0;
 +	/*
 +	 * According to Xen on ARM ABI (xen/include/public/arch-arm.h):
 +	 * all memory which is shared with other entities in the system
 +	 * (including the hypervisor and other guests) must reside in memory
 +	 * which is mapped as Normal Inner Write-Back Outer Write-Back
 +	 * Inner-Shareable.
 +	 */
 +	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 +
 +	/*
 +	 * vm_operations_struct.fault handler will be called if CPU access
 +	 * to VM is here. For GPUs this isn't the case, because CPU
 +	 * doesn't touch the memory. Insert pages now, so both CPU and GPU are
 +	 * happy.
 +	 * FIXME: as we insert all the pages now then no .fault handler must
 +	 * be called, so don't provide one
 +	 */
 +	ret = vm_map_pages(vma, xen_obj->pages, xen_obj->num_pages);
 +	if (ret < 0)
 +		DRM_ERROR("Failed to map pages into vma: %d\n", ret);
 +
 +	return ret;
 +}
 +
 +int xen_drm_front_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 +{
 +	struct xen_gem_object *xen_obj;
 +	struct drm_gem_object *gem_obj;
 +	int ret;
 +
 +	ret = drm_gem_mmap(filp, vma);
 +	if (ret < 0)
 +		return ret;
 +
 +	gem_obj = vma->vm_private_data;
 +	xen_obj = to_xen_gem_obj(gem_obj);
 +	return gem_mmap_obj(xen_obj, vma);
 +}
 +
 +int xen_drm_front_gem_prime_vmap(struct drm_gem_object *gem_obj, struct dma_buf_map *map)
++=======
+ int xen_drm_front_gem_prime_vmap(struct drm_gem_object *gem_obj,
+ 				 struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
  	struct xen_gem_object *xen_obj = to_xen_gem_obj(gem_obj);
  	void *vaddr;
diff --cc drivers/media/common/videobuf2/videobuf2-dma-contig.c
index f430218f86f7,ecf065cd4a67..000000000000
--- a/drivers/media/common/videobuf2/videobuf2-dma-contig.c
+++ b/drivers/media/common/videobuf2/videobuf2-dma-contig.c
@@@ -73,17 -77,39 +73,30 @@@ static void *vb2_dc_cookie(void *buf_pr
  	return &buf->dma_addr;
  }
  
 -/*
 - * This function may fail if:
 - *
 - * - dma_buf_vmap() fails
 - *   E.g. due to lack of virtual mapping address space, or due to
 - *   dmabuf->ops misconfiguration.
 - *
 - * - dma_vmap_noncontiguous() fails
 - *   For instance, when requested buffer size is larger than totalram_pages().
 - *   Relevant for buffers that use non-coherent memory.
 - *
 - * - Queue DMA attrs have DMA_ATTR_NO_KERNEL_MAPPING set
 - *   Relevant for buffers that use coherent memory.
 - */
 -static void *vb2_dc_vaddr(struct vb2_buffer *vb, void *buf_priv)
 +static void *vb2_dc_vaddr(void *buf_priv)
  {
  	struct vb2_dc_buf *buf = buf_priv;
 +	struct dma_buf_map map;
 +	int ret;
  
++<<<<<<< HEAD
 +	if (!buf->vaddr && buf->db_attach) {
 +		ret = dma_buf_vmap(buf->db_attach->dmabuf, &map);
 +		buf->vaddr = ret ? NULL : map.vaddr;
++=======
+ 	if (buf->vaddr)
+ 		return buf->vaddr;
+ 
+ 	if (buf->db_attach) {
+ 		struct iosys_map map;
+ 
+ 		if (!dma_buf_vmap(buf->db_attach->dmabuf, &map))
+ 			buf->vaddr = map.vaddr;
+ 
+ 		return buf->vaddr;
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	}
  
 -	if (buf->non_coherent_mem)
 -		buf->vaddr = dma_vmap_noncontiguous(buf->dev, buf->size,
 -						    buf->dma_sgt);
  	return buf->vaddr;
  }
  
@@@ -336,11 -432,31 +349,38 @@@ static void vb2_dc_dmabuf_ops_release(s
  	vb2_dc_put(dbuf->priv);
  }
  
++<<<<<<< HEAD
 +static int vb2_dc_dmabuf_ops_vmap(struct dma_buf *dbuf, struct dma_buf_map *map)
++=======
+ static int
+ vb2_dc_dmabuf_ops_begin_cpu_access(struct dma_buf *dbuf,
+ 				   enum dma_data_direction direction)
+ {
+ 	return 0;
+ }
+ 
+ static int
+ vb2_dc_dmabuf_ops_end_cpu_access(struct dma_buf *dbuf,
+ 				 enum dma_data_direction direction)
+ {
+ 	return 0;
+ }
+ 
+ static int vb2_dc_dmabuf_ops_vmap(struct dma_buf *dbuf, struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
 -	struct vb2_dc_buf *buf;
 -	void *vaddr;
 +	struct vb2_dc_buf *buf = dbuf->priv;
  
++<<<<<<< HEAD
 +	dma_buf_map_set_vaddr(map, buf->vaddr);
++=======
+ 	buf = dbuf->priv;
+ 	vaddr = vb2_dc_vaddr(buf->vb, buf);
+ 	if (!vaddr)
+ 		return -EINVAL;
+ 
+ 	iosys_map_set_vaddr(map, vaddr);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  	return 0;
  }
diff --cc drivers/media/common/videobuf2/videobuf2-dma-sg.c
index 676d4eb8f23e,f8a21c560ad2..000000000000
--- a/drivers/media/common/videobuf2/videobuf2-dma-sg.c
+++ b/drivers/media/common/videobuf2/videobuf2-dma-sg.c
@@@ -299,10 -300,10 +299,10 @@@ static void vb2_dma_sg_put_userptr(voi
  	kfree(buf);
  }
  
 -static void *vb2_dma_sg_vaddr(struct vb2_buffer *vb, void *buf_priv)
 +static void *vb2_dma_sg_vaddr(void *buf_priv)
  {
  	struct vb2_dma_sg_buf *buf = buf_priv;
- 	struct dma_buf_map map;
+ 	struct iosys_map map;
  	int ret;
  
  	BUG_ON(!buf);
@@@ -483,7 -470,30 +483,34 @@@ static void vb2_dma_sg_dmabuf_ops_relea
  	vb2_dma_sg_put(dbuf->priv);
  }
  
++<<<<<<< HEAD
 +static int vb2_dma_sg_dmabuf_ops_vmap(struct dma_buf *dbuf, struct dma_buf_map *map)
++=======
+ static int
+ vb2_dma_sg_dmabuf_ops_begin_cpu_access(struct dma_buf *dbuf,
+ 				       enum dma_data_direction direction)
+ {
+ 	struct vb2_dma_sg_buf *buf = dbuf->priv;
+ 	struct sg_table *sgt = buf->dma_sgt;
+ 
+ 	dma_sync_sg_for_cpu(buf->dev, sgt->sgl, sgt->nents, buf->dma_dir);
+ 	return 0;
+ }
+ 
+ static int
+ vb2_dma_sg_dmabuf_ops_end_cpu_access(struct dma_buf *dbuf,
+ 				     enum dma_data_direction direction)
+ {
+ 	struct vb2_dma_sg_buf *buf = dbuf->priv;
+ 	struct sg_table *sgt = buf->dma_sgt;
+ 
+ 	dma_sync_sg_for_device(buf->dev, sgt->sgl, sgt->nents, buf->dma_dir);
+ 	return 0;
+ }
+ 
+ static int vb2_dma_sg_dmabuf_ops_vmap(struct dma_buf *dbuf,
+ 				      struct iosys_map *map)
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  {
  	struct vb2_dma_sg_buf *buf = dbuf->priv;
  
diff --cc include/drm/drm_gem_atomic_helper.h
index cfc5adee3d13,6e3319e9001a..000000000000
--- a/include/drm/drm_gem_atomic_helper.h
+++ b/include/drm/drm_gem_atomic_helper.h
@@@ -3,8 -3,9 +3,8 @@@
  #ifndef __DRM_GEM_ATOMIC_HELPER_H__
  #define __DRM_GEM_ATOMIC_HELPER_H__
  
- #include <linux/dma-buf-map.h>
+ #include <linux/iosys-map.h>
  
 -#include <drm/drm_fourcc.h>
  #include <drm/drm_plane.h>
  
  struct drm_simple_display_pipe;
@@@ -40,7 -59,15 +40,19 @@@ struct drm_shadow_plane_state 
  	 * The memory mappings stored in map should be established in the plane's
  	 * prepare_fb callback and removed in the cleanup_fb callback.
  	 */
++<<<<<<< HEAD
 +	struct dma_buf_map map[4];
++=======
+ 	struct iosys_map map[DRM_FORMAT_MAX_PLANES];
+ 
+ 	/**
+ 	 * @data: Address of each framebuffer BO's data
+ 	 *
+ 	 * The address of the data stored in each mapping. This is different
+ 	 * for framebuffers with non-zero offset fields.
+ 	 */
+ 	struct iosys_map data[DRM_FORMAT_MAX_PLANES];
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  };
  
  /**
diff --cc include/drm/drm_gem_cma_helper.h
index cd13508acbc1,fbda4ce5d5fb..000000000000
--- a/include/drm/drm_gem_cma_helper.h
+++ b/include/drm/drm_gem_cma_helper.h
@@@ -32,42 -32,110 +32,140 @@@ struct drm_gem_cma_object 
  #define to_drm_gem_cma_obj(gem_obj) \
  	container_of(gem_obj, struct drm_gem_cma_object, base)
  
++<<<<<<< HEAD
 +#ifndef CONFIG_MMU
 +#define DRM_GEM_CMA_UNMAPPED_AREA_FOPS \
 +	.get_unmapped_area	= drm_gem_cma_get_unmapped_area,
 +#else
 +#define DRM_GEM_CMA_UNMAPPED_AREA_FOPS
 +#endif
++=======
+ struct drm_gem_cma_object *drm_gem_cma_create(struct drm_device *drm,
+ 					      size_t size);
+ void drm_gem_cma_free(struct drm_gem_cma_object *cma_obj);
+ void drm_gem_cma_print_info(const struct drm_gem_cma_object *cma_obj,
+ 			    struct drm_printer *p, unsigned int indent);
+ struct sg_table *drm_gem_cma_get_sg_table(struct drm_gem_cma_object *cma_obj);
+ int drm_gem_cma_vmap(struct drm_gem_cma_object *cma_obj,
+ 		     struct iosys_map *map);
+ int drm_gem_cma_mmap(struct drm_gem_cma_object *cma_obj, struct vm_area_struct *vma);
+ 
+ extern const struct vm_operations_struct drm_gem_cma_vm_ops;
+ 
+ /*
+  * GEM object functions
+  */
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  /**
 - * drm_gem_cma_object_free - GEM object function for drm_gem_cma_free()
 - * @obj: GEM object to free
 + * DEFINE_DRM_GEM_CMA_FOPS() - macro to generate file operations for CMA drivers
 + * @name: name for the generated structure
 + *
 + * This macro autogenerates a suitable &struct file_operations for CMA based
 + * drivers, which can be assigned to &drm_driver.fops. Note that this structure
 + * cannot be shared between drivers, because it contains a reference to the
 + * current module using THIS_MODULE.
   *
 - * This function wraps drm_gem_cma_free_object(). Drivers that employ the CMA helpers
 - * should use it as their &drm_gem_object_funcs.free handler.
 + * Note that the declaration is already marked as static - if you need a
 + * non-static version of this you're probably doing it wrong and will break the
 + * THIS_MODULE reference by accident.
   */
 -static inline void drm_gem_cma_object_free(struct drm_gem_object *obj)
 -{
 -	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
 +#define DEFINE_DRM_GEM_CMA_FOPS(name) \
 +	static const struct file_operations name = {\
 +		.owner		= THIS_MODULE,\
 +		.open		= drm_open,\
 +		.release	= drm_release,\
 +		.unlocked_ioctl	= drm_ioctl,\
 +		.compat_ioctl	= drm_compat_ioctl,\
 +		.poll		= drm_poll,\
 +		.read		= drm_read,\
 +		.llseek		= noop_llseek,\
 +		.mmap		= drm_gem_mmap,\
 +		DRM_GEM_CMA_UNMAPPED_AREA_FOPS \
 +	}
  
++<<<<<<< HEAD
 +/* free GEM object */
 +void drm_gem_cma_free_object(struct drm_gem_object *gem_obj);
++=======
+ 	drm_gem_cma_free(cma_obj);
+ }
+ 
+ /**
+  * drm_gem_cma_object_print_info() - Print &drm_gem_cma_object info for debugfs
+  * @p: DRM printer
+  * @indent: Tab indentation level
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_cma_print_info(). Drivers that employ the CMA helpers
+  * should use this function as their &drm_gem_object_funcs.print_info handler.
+  */
+ static inline void drm_gem_cma_object_print_info(struct drm_printer *p, unsigned int indent,
+ 						 const struct drm_gem_object *obj)
+ {
+ 	const struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
+ 
+ 	drm_gem_cma_print_info(cma_obj, p, indent);
+ }
+ 
+ /**
+  * drm_gem_cma_object_get_sg_table - GEM object function for drm_gem_cma_get_sg_table()
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_cma_get_sg_table(). Drivers that employ the CMA helpers should
+  * use it as their &drm_gem_object_funcs.get_sg_table handler.
+  *
+  * Returns:
+  * A pointer to the scatter/gather table of pinned pages or NULL on failure.
+  */
+ static inline struct sg_table *drm_gem_cma_object_get_sg_table(struct drm_gem_object *obj)
+ {
+ 	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
+ 
+ 	return drm_gem_cma_get_sg_table(cma_obj);
+ }
+ 
+ /*
+  * drm_gem_cma_object_vmap - GEM object function for drm_gem_cma_vmap()
+  * @obj: GEM object
+  * @map: Returns the kernel virtual address of the CMA GEM object's backing store.
+  *
+  * This function wraps drm_gem_cma_vmap(). Drivers that employ the CMA helpers should
+  * use it as their &drm_gem_object_funcs.vmap handler.
+  *
+  * Returns:
+  * 0 on success or a negative error code on failure.
+  */
+ static inline int drm_gem_cma_object_vmap(struct drm_gem_object *obj,
+ 					  struct iosys_map *map)
+ {
+ 	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
+ 
+ 	return drm_gem_cma_vmap(cma_obj, map);
+ }
+ 
+ /**
+  * drm_gem_cma_object_mmap - GEM object function for drm_gem_cma_mmap()
+  * @obj: GEM object
+  * @vma: VMA for the area to be mapped
+  *
+  * This function wraps drm_gem_cma_mmap(). Drivers that employ the cma helpers should
+  * use it as their &drm_gem_object_funcs.mmap handler.
+  *
+  * Returns:
+  * 0 on success or a negative error code on failure.
+  */
+ static inline int drm_gem_cma_object_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma)
+ {
+ 	struct drm_gem_cma_object *cma_obj = to_drm_gem_cma_obj(obj);
+ 
+ 	return drm_gem_cma_mmap(cma_obj, vma);
+ }
+ 
+ /*
+  * Driver ops
+  */
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  /* create memory region for DRM framebuffer */
  int drm_gem_cma_dumb_create_internal(struct drm_file *file_priv,
diff --cc include/drm/drm_gem_framebuffer_helper.h
index 6bdffc7aa124,1091e4fa08cb..000000000000
--- a/include/drm/drm_gem_framebuffer_helper.h
+++ b/include/drm/drm_gem_framebuffer_helper.h
@@@ -1,6 -1,11 +1,14 @@@
  #ifndef __DRM_GEM_FB_HELPER_H__
  #define __DRM_GEM_FB_HELPER_H__
  
++<<<<<<< HEAD
++=======
+ #include <linux/dma-buf.h>
+ #include <linux/iosys-map.h>
+ 
+ #include <drm/drm_fourcc.h>
+ 
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  struct drm_afbc_framebuffer;
  struct drm_device;
  struct drm_fb_helper_surface_size;
@@@ -34,6 -39,14 +42,17 @@@ struct drm_framebuffer 
  drm_gem_fb_create_with_dirty(struct drm_device *dev, struct drm_file *file,
  			     const struct drm_mode_fb_cmd2 *mode_cmd);
  
++<<<<<<< HEAD
++=======
+ int drm_gem_fb_vmap(struct drm_framebuffer *fb,
+ 		    struct iosys_map map[static DRM_FORMAT_MAX_PLANES],
+ 		    struct iosys_map data[DRM_FORMAT_MAX_PLANES]);
+ void drm_gem_fb_vunmap(struct drm_framebuffer *fb,
+ 		       struct iosys_map map[static DRM_FORMAT_MAX_PLANES]);
+ int drm_gem_fb_begin_cpu_access(struct drm_framebuffer *fb, enum dma_data_direction dir);
+ void drm_gem_fb_end_cpu_access(struct drm_framebuffer *fb, enum dma_data_direction dir);
+ 
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  #define drm_is_afbc(modifier) \
  	(((modifier) & AFBC_VENDOR_AND_TYPE_MASK) == DRM_FORMAT_MOD_ARM_AFBC(0))
  
diff --cc include/drm/drm_gem_shmem_helper.h
index 434328d8a0d9,68347b63fc71..000000000000
--- a/include/drm/drm_gem_shmem_helper.h
+++ b/include/drm/drm_gem_shmem_helper.h
@@@ -111,12 -111,15 +111,22 @@@ void drm_gem_shmem_free_object(struct d
  
  int drm_gem_shmem_get_pages(struct drm_gem_shmem_object *shmem);
  void drm_gem_shmem_put_pages(struct drm_gem_shmem_object *shmem);
++<<<<<<< HEAD
 +int drm_gem_shmem_pin(struct drm_gem_object *obj);
 +void drm_gem_shmem_unpin(struct drm_gem_object *obj);
 +int drm_gem_shmem_vmap(struct drm_gem_object *obj, struct dma_buf_map *map);
 +void drm_gem_shmem_vunmap(struct drm_gem_object *obj, struct dma_buf_map *map);
++=======
+ int drm_gem_shmem_pin(struct drm_gem_shmem_object *shmem);
+ void drm_gem_shmem_unpin(struct drm_gem_shmem_object *shmem);
+ int drm_gem_shmem_vmap(struct drm_gem_shmem_object *shmem,
+ 		       struct iosys_map *map);
+ void drm_gem_shmem_vunmap(struct drm_gem_shmem_object *shmem,
+ 			  struct iosys_map *map);
+ int drm_gem_shmem_mmap(struct drm_gem_shmem_object *shmem, struct vm_area_struct *vma);
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 -int drm_gem_shmem_madvise(struct drm_gem_shmem_object *shmem, int madv);
 +int drm_gem_shmem_madvise(struct drm_gem_object *obj, int madv);
  
  static inline bool drm_gem_shmem_is_purgeable(struct drm_gem_shmem_object *shmem)
  {
@@@ -125,23 -128,152 +135,158 @@@
  		!shmem->base.dma_buf && !shmem->base.import_attach;
  }
  
 -void drm_gem_shmem_purge_locked(struct drm_gem_shmem_object *shmem);
 -bool drm_gem_shmem_purge(struct drm_gem_shmem_object *shmem);
 +void drm_gem_shmem_purge_locked(struct drm_gem_object *obj);
 +bool drm_gem_shmem_purge(struct drm_gem_object *obj);
  
 -struct sg_table *drm_gem_shmem_get_sg_table(struct drm_gem_shmem_object *shmem);
 -struct sg_table *drm_gem_shmem_get_pages_sgt(struct drm_gem_shmem_object *shmem);
 +struct drm_gem_shmem_object *
 +drm_gem_shmem_create_with_handle(struct drm_file *file_priv,
 +				 struct drm_device *dev, size_t size,
 +				 uint32_t *handle);
  
 -void drm_gem_shmem_print_info(const struct drm_gem_shmem_object *shmem,
 -			      struct drm_printer *p, unsigned int indent);
 +int drm_gem_shmem_dumb_create(struct drm_file *file, struct drm_device *dev,
 +			      struct drm_mode_create_dumb *args);
  
 -/*
 - * GEM object functions
 - */
 +int drm_gem_shmem_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
  
++<<<<<<< HEAD
 +void drm_gem_shmem_print_info(struct drm_printer *p, unsigned int indent,
 +			      const struct drm_gem_object *obj);
++=======
+ /**
+  * drm_gem_shmem_object_free - GEM object function for drm_gem_shmem_free()
+  * @obj: GEM object to free
+  *
+  * This function wraps drm_gem_shmem_free(). Drivers that employ the shmem helpers
+  * should use it as their &drm_gem_object_funcs.free handler.
+  */
+ static inline void drm_gem_shmem_object_free(struct drm_gem_object *obj)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	drm_gem_shmem_free(shmem);
+ }
+ 
+ /**
+  * drm_gem_shmem_object_print_info() - Print &drm_gem_shmem_object info for debugfs
+  * @p: DRM printer
+  * @indent: Tab indentation level
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_shmem_print_info(). Drivers that employ the shmem helpers should
+  * use this function as their &drm_gem_object_funcs.print_info handler.
+  */
+ static inline void drm_gem_shmem_object_print_info(struct drm_printer *p, unsigned int indent,
+ 						   const struct drm_gem_object *obj)
+ {
+ 	const struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	drm_gem_shmem_print_info(shmem, p, indent);
+ }
+ 
+ /**
+  * drm_gem_shmem_object_pin - GEM object function for drm_gem_shmem_pin()
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_shmem_pin(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.pin handler.
+  */
+ static inline int drm_gem_shmem_object_pin(struct drm_gem_object *obj)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	return drm_gem_shmem_pin(shmem);
+ }
+ 
+ /**
+  * drm_gem_shmem_object_unpin - GEM object function for drm_gem_shmem_unpin()
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_shmem_unpin(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.unpin handler.
+  */
+ static inline void drm_gem_shmem_object_unpin(struct drm_gem_object *obj)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	drm_gem_shmem_unpin(shmem);
+ }
+ 
+ /**
+  * drm_gem_shmem_object_get_sg_table - GEM object function for drm_gem_shmem_get_sg_table()
+  * @obj: GEM object
+  *
+  * This function wraps drm_gem_shmem_get_sg_table(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.get_sg_table handler.
+  *
+  * Returns:
+  * A pointer to the scatter/gather table of pinned pages or NULL on failure.
+  */
+ static inline struct sg_table *drm_gem_shmem_object_get_sg_table(struct drm_gem_object *obj)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	return drm_gem_shmem_get_sg_table(shmem);
+ }
+ 
+ /*
+  * drm_gem_shmem_object_vmap - GEM object function for drm_gem_shmem_vmap()
+  * @obj: GEM object
+  * @map: Returns the kernel virtual address of the SHMEM GEM object's backing store.
+  *
+  * This function wraps drm_gem_shmem_vmap(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.vmap handler.
+  *
+  * Returns:
+  * 0 on success or a negative error code on failure.
+  */
+ static inline int drm_gem_shmem_object_vmap(struct drm_gem_object *obj,
+ 					    struct iosys_map *map)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	return drm_gem_shmem_vmap(shmem, map);
+ }
+ 
+ /*
+  * drm_gem_shmem_object_vunmap - GEM object function for drm_gem_shmem_vunmap()
+  * @obj: GEM object
+  * @map: Kernel virtual address where the SHMEM GEM object was mapped
+  *
+  * This function wraps drm_gem_shmem_vunmap(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.vunmap handler.
+  */
+ static inline void drm_gem_shmem_object_vunmap(struct drm_gem_object *obj,
+ 					       struct iosys_map *map)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	drm_gem_shmem_vunmap(shmem, map);
+ }
+ 
+ /**
+  * drm_gem_shmem_object_mmap - GEM object function for drm_gem_shmem_mmap()
+  * @obj: GEM object
+  * @vma: VMA for the area to be mapped
+  *
+  * This function wraps drm_gem_shmem_mmap(). Drivers that employ the shmem helpers should
+  * use it as their &drm_gem_object_funcs.mmap handler.
+  *
+  * Returns:
+  * 0 on success or a negative error code on failure.
+  */
+ static inline int drm_gem_shmem_object_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma)
+ {
+ 	struct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);
+ 
+ 	return drm_gem_shmem_mmap(shmem, vma);
+ }
+ 
+ /*
+  * Driver ops
+  */
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
 +struct sg_table *drm_gem_shmem_get_sg_table(struct drm_gem_object *obj);
  struct drm_gem_object *
  drm_gem_shmem_prime_import_sg_table(struct drm_device *dev,
  				    struct dma_buf_attachment *attach,
diff --cc include/drm/drm_gem_vram_helper.h
index 27ed7e9243b9,c083a1d71cf4..000000000000
--- a/include/drm/drm_gem_vram_helper.h
+++ b/include/drm/drm_gem_vram_helper.h
@@@ -11,8 -11,8 +11,13 @@@
  #include <drm/ttm/ttm_bo_api.h>
  #include <drm/ttm/ttm_bo_driver.h>
  
++<<<<<<< HEAD
 +#include <linux/dma-buf-map.h>
 +#include <linux/kernel.h> /* for container_of() */
++=======
+ #include <linux/container_of.h>
+ #include <linux/iosys-map.h>
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  
  struct drm_mode_create_dumb;
  struct drm_plane;
diff --cc include/drm/ttm/ttm_resource.h
index 140b6b9a8bbe,6eae09e382d2..000000000000
--- a/include/drm/ttm/ttm_resource.h
+++ b/include/drm/ttm/ttm_resource.h
@@@ -40,7 -40,8 +40,12 @@@ struct ttm_resource_manager
  struct ttm_resource;
  struct ttm_place;
  struct ttm_buffer_object;
++<<<<<<< HEAD
 +struct dma_buf_map;
++=======
+ struct ttm_placement;
+ struct iosys_map;
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  struct io_mapping;
  struct sg_table;
  struct scatterlist;
diff --cc include/linux/dma-buf.h
index efdc56b9d95f,2097760e8e95..000000000000
--- a/include/linux/dma-buf.h
+++ b/include/linux/dma-buf.h
@@@ -306,24 -300,141 +306,40 @@@ struct dma_buf_ops 
   * Device DMA access is handled by the separate &struct dma_buf_attachment.
   */
  struct dma_buf {
 -	/**
 -	 * @size:
 -	 *
 -	 * Size of the buffer; invariant over the lifetime of the buffer.
 -	 */
  	size_t size;
 -
 -	/**
 -	 * @file:
 -	 *
 -	 * File pointer used for sharing buffers across, and for refcounting.
 -	 * See dma_buf_get() and dma_buf_put().
 -	 */
  	struct file *file;
 -
 -	/**
 -	 * @attachments:
 -	 *
 -	 * List of dma_buf_attachment that denotes all devices attached,
 -	 * protected by &dma_resv lock @resv.
 -	 */
  	struct list_head attachments;
 -
 -	/** @ops: dma_buf_ops associated with this buffer object. */
  	const struct dma_buf_ops *ops;
 -
 -	/**
 -	 * @lock:
 -	 *
 -	 * Used internally to serialize list manipulation, attach/detach and
 -	 * vmap/unmap. Note that in many cases this is superseeded by
 -	 * dma_resv_lock() on @resv.
 -	 */
  	struct mutex lock;
 -
 -	/**
 -	 * @vmapping_counter:
 -	 *
 -	 * Used internally to refcnt the vmaps returned by dma_buf_vmap().
 -	 * Protected by @lock.
 -	 */
  	unsigned vmapping_counter;
++<<<<<<< HEAD
 +	struct dma_buf_map vmap_ptr;
++=======
+ 
+ 	/**
+ 	 * @vmap_ptr:
+ 	 * The current vmap ptr if @vmapping_counter > 0. Protected by @lock.
+ 	 */
+ 	struct iosys_map vmap_ptr;
+ 
+ 	/**
+ 	 * @exp_name:
+ 	 *
+ 	 * Name of the exporter; useful for debugging. See the
+ 	 * DMA_BUF_SET_NAME IOCTL.
+ 	 */
++>>>>>>> 7938f4218168 (dma-buf-map: Rename to iosys-map)
  	const char *exp_name;
 -
 -	/**
 -	 * @name:
 -	 *
 -	 * Userspace-provided name; useful for accounting and debugging,
 -	 * protected by dma_resv_lock() on @resv and @name_lock for read access.
 -	 */
  	const char *name;
 -
 -	/** @name_lock: Spinlock to protect name acces for read access. */
  	spinlock_t name_lock;
 -
 -	/**
 -	 * @owner:
 -	 *
 -	 * Pointer to exporter module; used for refcounting when exporter is a
 -	 * kernel module.
 -	 */
  	struct module *owner;
 -
 -	/** @list_node: node for dma_buf accounting and debugging. */
  	struct list_head list_node;
 -
 -	/** @priv: exporter specific private data for this buffer object. */
  	void *priv;
 -
 -	/**
 -	 * @resv:
 -	 *
 -	 * Reservation object linked to this dma-buf.
 -	 *
 -	 * IMPLICIT SYNCHRONIZATION RULES:
 -	 *
 -	 * Drivers which support implicit synchronization of buffer access as
 -	 * e.g. exposed in `Implicit Fence Poll Support`_ must follow the
 -	 * below rules.
 -	 *
 -	 * - Drivers must add a shared fence through dma_resv_add_shared_fence()
 -	 *   for anything the userspace API considers a read access. This highly
 -	 *   depends upon the API and window system.
 -	 *
 -	 * - Similarly drivers must set the exclusive fence through
 -	 *   dma_resv_add_excl_fence() for anything the userspace API considers
 -	 *   write access.
 -	 *
 -	 * - Drivers may just always set the exclusive fence, since that only
 -	 *   causes unecessarily synchronization, but no correctness issues.
 -	 *
 -	 * - Some drivers only expose a synchronous userspace API with no
 -	 *   pipelining across drivers. These do not set any fences for their
 -	 *   access. An example here is v4l.
 -	 *
 -	 * DYNAMIC IMPORTER RULES:
 -	 *
 -	 * Dynamic importers, see dma_buf_attachment_is_dynamic(), have
 -	 * additional constraints on how they set up fences:
 -	 *
 -	 * - Dynamic importers must obey the exclusive fence and wait for it to
 -	 *   signal before allowing access to the buffer's underlying storage
 -	 *   through the device.
 -	 *
 -	 * - Dynamic importers should set fences for any access that they can't
 -	 *   disable immediately from their &dma_buf_attach_ops.move_notify
 -	 *   callback.
 -	 *
 -	 * IMPORTANT:
 -	 *
 -	 * All drivers must obey the struct dma_resv rules, specifically the
 -	 * rules for updating fences, see &dma_resv.fence_excl and
 -	 * &dma_resv.fence. If these dependency rules are broken access tracking
 -	 * can be lost resulting in use after free issues.
 -	 */
  	struct dma_resv *resv;
  
 -	/** @poll: for userspace poll support */
 +	/* poll support */
  	wait_queue_head_t poll;
  
 -	/** @cb_in: for userspace poll support */
 -	/** @cb_out: for userspace poll support */
  	struct dma_buf_poll_cb_t {
  		struct dma_fence_cb cb;
  		wait_queue_head_t *poll;
* Unmerged path drivers/gpu/drm/lima/lima_gem.c
* Unmerged path drivers/gpu/drm/lima/lima_sched.c
* Unmerged path drivers/gpu/drm/panfrost/panfrost_perfcnt.c
* Unmerged path drivers/misc/fastrpc.c
* Unmerged path Documentation/driver-api/device-io.rst
* Unmerged path Documentation/gpu/todo.rst
* Unmerged path MAINTAINERS
* Unmerged path drivers/dma-buf/dma-buf.c
diff --git a/drivers/dma-buf/heaps/cma_heap.c b/drivers/dma-buf/heaps/cma_heap.c
index 83f02bd51dda..28fb04eccdd0 100644
--- a/drivers/dma-buf/heaps/cma_heap.c
+++ b/drivers/dma-buf/heaps/cma_heap.c
@@ -202,7 +202,7 @@ static void *cma_heap_do_vmap(struct cma_heap_buffer *buffer)
 	return vaddr;
 }
 
-static int cma_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
+static int cma_heap_vmap(struct dma_buf *dmabuf, struct iosys_map *map)
 {
 	struct cma_heap_buffer *buffer = dmabuf->priv;
 	void *vaddr;
@@ -211,7 +211,7 @@ static int cma_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 	mutex_lock(&buffer->lock);
 	if (buffer->vmap_cnt) {
 		buffer->vmap_cnt++;
-		dma_buf_map_set_vaddr(map, buffer->vaddr);
+		iosys_map_set_vaddr(map, buffer->vaddr);
 		goto out;
 	}
 
@@ -222,14 +222,14 @@ static int cma_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 	}
 	buffer->vaddr = vaddr;
 	buffer->vmap_cnt++;
-	dma_buf_map_set_vaddr(map, buffer->vaddr);
+	iosys_map_set_vaddr(map, buffer->vaddr);
 out:
 	mutex_unlock(&buffer->lock);
 
 	return ret;
 }
 
-static void cma_heap_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
+static void cma_heap_vunmap(struct dma_buf *dmabuf, struct iosys_map *map)
 {
 	struct cma_heap_buffer *buffer = dmabuf->priv;
 
@@ -239,7 +239,7 @@ static void cma_heap_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 		buffer->vaddr = NULL;
 	}
 	mutex_unlock(&buffer->lock);
-	dma_buf_map_clear(map);
+	iosys_map_clear(map);
 }
 
 static void cma_heap_dma_buf_release(struct dma_buf *dmabuf)
diff --git a/drivers/dma-buf/heaps/system_heap.c b/drivers/dma-buf/heaps/system_heap.c
index 8660508f3684..cc2d62c4f42f 100644
--- a/drivers/dma-buf/heaps/system_heap.c
+++ b/drivers/dma-buf/heaps/system_heap.c
@@ -240,7 +240,7 @@ static void *system_heap_do_vmap(struct system_heap_buffer *buffer)
 	return vaddr;
 }
 
-static int system_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
+static int system_heap_vmap(struct dma_buf *dmabuf, struct iosys_map *map)
 {
 	struct system_heap_buffer *buffer = dmabuf->priv;
 	void *vaddr;
@@ -249,7 +249,7 @@ static int system_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 	mutex_lock(&buffer->lock);
 	if (buffer->vmap_cnt) {
 		buffer->vmap_cnt++;
-		dma_buf_map_set_vaddr(map, buffer->vaddr);
+		iosys_map_set_vaddr(map, buffer->vaddr);
 		goto out;
 	}
 
@@ -261,14 +261,14 @@ static int system_heap_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 
 	buffer->vaddr = vaddr;
 	buffer->vmap_cnt++;
-	dma_buf_map_set_vaddr(map, buffer->vaddr);
+	iosys_map_set_vaddr(map, buffer->vaddr);
 out:
 	mutex_unlock(&buffer->lock);
 
 	return ret;
 }
 
-static void system_heap_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
+static void system_heap_vunmap(struct dma_buf *dmabuf, struct iosys_map *map)
 {
 	struct system_heap_buffer *buffer = dmabuf->priv;
 
@@ -278,7 +278,7 @@ static void system_heap_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 		buffer->vaddr = NULL;
 	}
 	mutex_unlock(&buffer->lock);
-	dma_buf_map_clear(map);
+	iosys_map_clear(map);
 }
 
 static void system_heap_dma_buf_release(struct dma_buf *dmabuf)
diff --git a/drivers/gpu/drm/ast/ast_drv.h b/drivers/gpu/drm/ast/ast_drv.h
index 39ca338eb80b..84bdef6be815 100644
--- a/drivers/gpu/drm/ast/ast_drv.h
+++ b/drivers/gpu/drm/ast/ast_drv.h
@@ -107,7 +107,7 @@ struct ast_cursor_plane {
 
 	struct {
 		struct drm_gem_vram_object *gbo;
-		struct dma_buf_map map;
+		struct iosys_map map;
 		u64 off;
 	} hwc[AST_DEFAULT_HWC_NUM];
 
* Unmerged path drivers/gpu/drm/ast/ast_mode.c
* Unmerged path drivers/gpu/drm/drm_cache.c
diff --git a/drivers/gpu/drm/drm_client.c b/drivers/gpu/drm/drm_client.c
index ce45e380f4a2..af3b7395bf69 100644
--- a/drivers/gpu/drm/drm_client.c
+++ b/drivers/gpu/drm/drm_client.c
@@ -3,7 +3,7 @@
  * Copyright 2018 Noralf TrÃ¸nnes
  */
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/list.h>
 #include <linux/module.h>
 #include <linux/mutex.h>
@@ -309,9 +309,10 @@ drm_client_buffer_create(struct drm_client_dev *client, u32 width, u32 height, u
  *	0 on success, or a negative errno code otherwise.
  */
 int
-drm_client_buffer_vmap(struct drm_client_buffer *buffer, struct dma_buf_map *map_copy)
+drm_client_buffer_vmap(struct drm_client_buffer *buffer,
+		       struct iosys_map *map_copy)
 {
-	struct dma_buf_map *map = &buffer->map;
+	struct iosys_map *map = &buffer->map;
 	int ret;
 
 	/*
@@ -342,7 +343,7 @@ EXPORT_SYMBOL(drm_client_buffer_vmap);
  */
 void drm_client_buffer_vunmap(struct drm_client_buffer *buffer)
 {
-	struct dma_buf_map *map = &buffer->map;
+	struct iosys_map *map = &buffer->map;
 
 	drm_gem_vunmap(buffer->gem, map);
 }
diff --git a/drivers/gpu/drm/drm_fb_helper.c b/drivers/gpu/drm/drm_fb_helper.c
index 338304a52115..d01eb4a67187 100644
--- a/drivers/gpu/drm/drm_fb_helper.c
+++ b/drivers/gpu/drm/drm_fb_helper.c
@@ -373,7 +373,7 @@ static void drm_fb_helper_resume_worker(struct work_struct *work)
 
 static void drm_fb_helper_damage_blit_real(struct drm_fb_helper *fb_helper,
 					   struct drm_clip_rect *clip,
-					   struct dma_buf_map *dst)
+					   struct iosys_map *dst)
 {
 	struct drm_framebuffer *fb = fb_helper->fb;
 	unsigned int cpp = fb->format->cpp[0];
@@ -382,11 +382,11 @@ static void drm_fb_helper_damage_blit_real(struct drm_fb_helper *fb_helper,
 	size_t len = (clip->x2 - clip->x1) * cpp;
 	unsigned int y;
 
-	dma_buf_map_incr(dst, offset); /* go to first pixel within clip rect */
+	iosys_map_incr(dst, offset); /* go to first pixel within clip rect */
 
 	for (y = clip->y1; y < clip->y2; y++) {
-		dma_buf_map_memcpy_to(dst, src, len);
-		dma_buf_map_incr(dst, fb->pitches[0]);
+		iosys_map_memcpy_to(dst, src, len);
+		iosys_map_incr(dst, fb->pitches[0]);
 		src += fb->pitches[0];
 	}
 }
@@ -395,7 +395,7 @@ static int drm_fb_helper_damage_blit(struct drm_fb_helper *fb_helper,
 				     struct drm_clip_rect *clip)
 {
 	struct drm_client_buffer *buffer = fb_helper->buffer;
-	struct dma_buf_map map, dst;
+	struct iosys_map map, dst;
 	int ret;
 
 	/*
@@ -2322,7 +2322,7 @@ static int drm_fb_helper_generic_probe(struct drm_fb_helper *fb_helper,
 	struct drm_framebuffer *fb;
 	struct fb_info *fbi;
 	u32 format;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	int ret;
 
 	drm_dbg_kms(dev, "surface width(%d), height(%d) and bpp(%d)\n",
diff --git a/drivers/gpu/drm/drm_gem.c b/drivers/gpu/drm/drm_gem.c
index d62fb1a3c916..052dc7544ac7 100644
--- a/drivers/gpu/drm/drm_gem.c
+++ b/drivers/gpu/drm/drm_gem.c
@@ -36,7 +36,7 @@
 #include <linux/pagemap.h>
 #include <linux/shmem_fs.h>
 #include <linux/dma-buf.h>
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/mem_encrypt.h>
 #include <linux/pagevec.h>
 
@@ -1196,7 +1196,7 @@ void drm_gem_unpin(struct drm_gem_object *obj)
 		obj->funcs->unpin(obj);
 }
 
-int drm_gem_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
+int drm_gem_vmap(struct drm_gem_object *obj, struct iosys_map *map)
 {
 	int ret;
 
@@ -1206,23 +1206,23 @@ int drm_gem_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
 	ret = obj->funcs->vmap(obj, map);
 	if (ret)
 		return ret;
-	else if (dma_buf_map_is_null(map))
+	else if (iosys_map_is_null(map))
 		return -ENOMEM;
 
 	return 0;
 }
 EXPORT_SYMBOL(drm_gem_vmap);
 
-void drm_gem_vunmap(struct drm_gem_object *obj, struct dma_buf_map *map)
+void drm_gem_vunmap(struct drm_gem_object *obj, struct iosys_map *map)
 {
-	if (dma_buf_map_is_null(map))
+	if (iosys_map_is_null(map))
 		return;
 
 	if (obj->funcs->vunmap)
 		obj->funcs->vunmap(obj, map);
 
 	/* Always set the mapping to NULL. Callers may rely on this. */
-	dma_buf_map_clear(map);
+	iosys_map_clear(map);
 }
 EXPORT_SYMBOL(drm_gem_vunmap);
 
* Unmerged path drivers/gpu/drm/drm_gem_cma_helper.c
* Unmerged path drivers/gpu/drm/drm_gem_framebuffer_helper.c
* Unmerged path drivers/gpu/drm/drm_gem_shmem_helper.c
diff --git a/drivers/gpu/drm/drm_gem_ttm_helper.c b/drivers/gpu/drm/drm_gem_ttm_helper.c
index ecf3d2a54a98..d5962a34c01d 100644
--- a/drivers/gpu/drm/drm_gem_ttm_helper.c
+++ b/drivers/gpu/drm/drm_gem_ttm_helper.c
@@ -61,7 +61,7 @@ EXPORT_SYMBOL(drm_gem_ttm_print_info);
  * 0 on success, or a negative errno code otherwise.
  */
 int drm_gem_ttm_vmap(struct drm_gem_object *gem,
-		     struct dma_buf_map *map)
+		     struct iosys_map *map)
 {
 	struct ttm_buffer_object *bo = drm_gem_ttm_of_gem(gem);
 
@@ -78,7 +78,7 @@ EXPORT_SYMBOL(drm_gem_ttm_vmap);
  * &drm_gem_object_funcs.vmap callback.
  */
 void drm_gem_ttm_vunmap(struct drm_gem_object *gem,
-			struct dma_buf_map *map)
+			struct iosys_map *map)
 {
 	struct ttm_buffer_object *bo = drm_gem_ttm_of_gem(gem);
 
diff --git a/drivers/gpu/drm/drm_gem_vram_helper.c b/drivers/gpu/drm/drm_gem_vram_helper.c
index 2a1229b8364e..aa49c2394810 100644
--- a/drivers/gpu/drm/drm_gem_vram_helper.c
+++ b/drivers/gpu/drm/drm_gem_vram_helper.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0-or-later
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/module.h>
 
 #include <drm/drm_debugfs.h>
@@ -116,7 +116,7 @@ static void drm_gem_vram_cleanup(struct drm_gem_vram_object *gbo)
 	 */
 
 	WARN_ON(gbo->vmap_use_count);
-	WARN_ON(dma_buf_map_is_set(&gbo->map));
+	WARN_ON(iosys_map_is_set(&gbo->map));
 
 	drm_gem_object_release(&gbo->bo.base);
 }
@@ -365,7 +365,7 @@ int drm_gem_vram_unpin(struct drm_gem_vram_object *gbo)
 EXPORT_SYMBOL(drm_gem_vram_unpin);
 
 static int drm_gem_vram_kmap_locked(struct drm_gem_vram_object *gbo,
-				    struct dma_buf_map *map)
+				    struct iosys_map *map)
 {
 	int ret;
 
@@ -377,7 +377,7 @@ static int drm_gem_vram_kmap_locked(struct drm_gem_vram_object *gbo,
 	 * page mapping might still be around. Only vmap if the there's
 	 * no mapping present.
 	 */
-	if (dma_buf_map_is_null(&gbo->map)) {
+	if (iosys_map_is_null(&gbo->map)) {
 		ret = ttm_bo_vmap(&gbo->bo, &gbo->map);
 		if (ret)
 			return ret;
@@ -391,14 +391,14 @@ static int drm_gem_vram_kmap_locked(struct drm_gem_vram_object *gbo,
 }
 
 static void drm_gem_vram_kunmap_locked(struct drm_gem_vram_object *gbo,
-				       struct dma_buf_map *map)
+				       struct iosys_map *map)
 {
 	struct drm_device *dev = gbo->bo.base.dev;
 
 	if (drm_WARN_ON_ONCE(dev, !gbo->vmap_use_count))
 		return;
 
-	if (drm_WARN_ON_ONCE(dev, !dma_buf_map_is_equal(&gbo->map, map)))
+	if (drm_WARN_ON_ONCE(dev, !iosys_map_is_equal(&gbo->map, map)))
 		return; /* BUG: map not mapped from this BO */
 
 	if (--gbo->vmap_use_count > 0)
@@ -428,7 +428,7 @@ static void drm_gem_vram_kunmap_locked(struct drm_gem_vram_object *gbo,
  * Returns:
  * 0 on success, or a negative error code otherwise.
  */
-int drm_gem_vram_vmap(struct drm_gem_vram_object *gbo, struct dma_buf_map *map)
+int drm_gem_vram_vmap(struct drm_gem_vram_object *gbo, struct iosys_map *map)
 {
 	int ret;
 
@@ -463,7 +463,8 @@ EXPORT_SYMBOL(drm_gem_vram_vmap);
  * A call to drm_gem_vram_vunmap() unmaps and unpins a GEM VRAM buffer. See
  * the documentation for drm_gem_vram_vmap() for more information.
  */
-void drm_gem_vram_vunmap(struct drm_gem_vram_object *gbo, struct dma_buf_map *map)
+void drm_gem_vram_vunmap(struct drm_gem_vram_object *gbo,
+			 struct iosys_map *map)
 {
 	int ret;
 
@@ -567,7 +568,7 @@ static void drm_gem_vram_bo_driver_move_notify(struct drm_gem_vram_object *gbo)
 		return;
 
 	ttm_bo_vunmap(bo, &gbo->map);
-	dma_buf_map_clear(&gbo->map); /* explicitly clear mapping for next vmap call */
+	iosys_map_clear(&gbo->map); /* explicitly clear mapping for next vmap call */
 }
 
 static int drm_gem_vram_bo_driver_move(struct drm_gem_vram_object *gbo,
@@ -802,7 +803,8 @@ static void drm_gem_vram_object_unpin(struct drm_gem_object *gem)
  * Returns:
  * 0 on success, or a negative error code otherwise.
  */
-static int drm_gem_vram_object_vmap(struct drm_gem_object *gem, struct dma_buf_map *map)
+static int drm_gem_vram_object_vmap(struct drm_gem_object *gem,
+				    struct iosys_map *map)
 {
 	struct drm_gem_vram_object *gbo = drm_gem_vram_of_gem(gem);
 
@@ -815,7 +817,8 @@ static int drm_gem_vram_object_vmap(struct drm_gem_object *gem, struct dma_buf_m
  * @gem: The GEM object to unmap
  * @map: Kernel virtual address where the VRAM GEM object was mapped
  */
-static void drm_gem_vram_object_vunmap(struct drm_gem_object *gem, struct dma_buf_map *map)
+static void drm_gem_vram_object_vunmap(struct drm_gem_object *gem,
+				       struct iosys_map *map)
 {
 	struct drm_gem_vram_object *gbo = drm_gem_vram_of_gem(gem);
 
diff --git a/drivers/gpu/drm/drm_internal.h b/drivers/gpu/drm/drm_internal.h
index 17f3548c8ed2..1fbbc19f1ac0 100644
--- a/drivers/gpu/drm/drm_internal.h
+++ b/drivers/gpu/drm/drm_internal.h
@@ -33,7 +33,7 @@
 
 struct dentry;
 struct dma_buf;
-struct dma_buf_map;
+struct iosys_map;
 struct drm_connector;
 struct drm_crtc;
 struct drm_framebuffer;
@@ -174,8 +174,8 @@ void drm_gem_print_info(struct drm_printer *p, unsigned int indent,
 
 int drm_gem_pin(struct drm_gem_object *obj);
 void drm_gem_unpin(struct drm_gem_object *obj);
-int drm_gem_vmap(struct drm_gem_object *obj, struct dma_buf_map *map);
-void drm_gem_vunmap(struct drm_gem_object *obj, struct dma_buf_map *map);
+int drm_gem_vmap(struct drm_gem_object *obj, struct iosys_map *map);
+void drm_gem_vunmap(struct drm_gem_object *obj, struct iosys_map *map);
 
 int drm_gem_dumb_destroy(struct drm_file *file, struct drm_device *dev,
 			 u32 handle);
* Unmerged path drivers/gpu/drm/drm_mipi_dbi.c
diff --git a/drivers/gpu/drm/drm_prime.c b/drivers/gpu/drm/drm_prime.c
index a18ce0c1c6ae..aa2eeec5d799 100644
--- a/drivers/gpu/drm/drm_prime.c
+++ b/drivers/gpu/drm/drm_prime.c
@@ -671,7 +671,7 @@ EXPORT_SYMBOL(drm_gem_unmap_dma_buf);
  *
  * Returns 0 on success or a negative errno code otherwise.
  */
-int drm_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+int drm_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct iosys_map *map)
 {
 	struct drm_gem_object *obj = dma_buf->priv;
 
@@ -687,7 +687,7 @@ EXPORT_SYMBOL(drm_gem_dmabuf_vmap);
  * Releases a kernel virtual mapping. This can be used as the
  * &dma_buf_ops.vunmap callback. Calls into &drm_gem_object_funcs.vunmap for device specific handling.
  */
-void drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+void drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct iosys_map *map)
 {
 	struct drm_gem_object *obj = dma_buf->priv;
 
* Unmerged path drivers/gpu/drm/etnaviv/etnaviv_drv.h
* Unmerged path drivers/gpu/drm/etnaviv/etnaviv_gem_prime.c
* Unmerged path drivers/gpu/drm/gud/gud_pipe.c
diff --git a/drivers/gpu/drm/hyperv/hyperv_drm_modeset.c b/drivers/gpu/drm/hyperv/hyperv_drm_modeset.c
index 3aaee4730ec6..f9050bdc0149 100644
--- a/drivers/gpu/drm/hyperv/hyperv_drm_modeset.c
+++ b/drivers/gpu/drm/hyperv/hyperv_drm_modeset.c
@@ -19,7 +19,7 @@
 #include "hyperv_drm.h"
 
 static int hyperv_blit_to_vram_rect(struct drm_framebuffer *fb,
-				    const struct dma_buf_map *map,
+				    const struct iosys_map *map,
 				    struct drm_rect *rect)
 {
 	struct hyperv_drm_device *hv = to_hv(fb->dev);
@@ -35,7 +35,8 @@ static int hyperv_blit_to_vram_rect(struct drm_framebuffer *fb,
 	return 0;
 }
 
-static int hyperv_blit_to_vram_fullscreen(struct drm_framebuffer *fb, const struct dma_buf_map *map)
+static int hyperv_blit_to_vram_fullscreen(struct drm_framebuffer *fb,
+					  const struct iosys_map *map)
 {
 	struct drm_rect fullscreen = {
 		.x1 = 0,
diff --git a/drivers/gpu/drm/i915/gem/i915_gem_dmabuf.c b/drivers/gpu/drm/i915/gem/i915_gem_dmabuf.c
index 616c3a2f1baf..46b0b900ffbe 100644
--- a/drivers/gpu/drm/i915/gem/i915_gem_dmabuf.c
+++ b/drivers/gpu/drm/i915/gem/i915_gem_dmabuf.c
@@ -77,7 +77,8 @@ static void i915_gem_unmap_dma_buf(struct dma_buf_attachment *attachment,
 	i915_gem_object_unpin_pages(obj);
 }
 
-static int i915_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+static int i915_gem_dmabuf_vmap(struct dma_buf *dma_buf,
+				struct iosys_map *map)
 {
 	struct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);
 	void *vaddr;
@@ -86,12 +87,13 @@ static int i915_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map
 	if (IS_ERR(vaddr))
 		return PTR_ERR(vaddr);
 
-	dma_buf_map_set_vaddr(map, vaddr);
+	iosys_map_set_vaddr(map, vaddr);
 
 	return 0;
 }
 
-static void i915_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+static void i915_gem_dmabuf_vunmap(struct dma_buf *dma_buf,
+				   struct iosys_map *map)
 {
 	struct drm_i915_gem_object *obj = dma_buf_to_obj(dma_buf);
 
diff --git a/drivers/gpu/drm/i915/gem/selftests/i915_gem_dmabuf.c b/drivers/gpu/drm/i915/gem/selftests/i915_gem_dmabuf.c
index dd74bc09ec88..0a5aa21a0dde 100644
--- a/drivers/gpu/drm/i915/gem/selftests/i915_gem_dmabuf.c
+++ b/drivers/gpu/drm/i915/gem/selftests/i915_gem_dmabuf.c
@@ -82,7 +82,7 @@ static int igt_dmabuf_import(void *arg)
 	struct drm_i915_gem_object *obj;
 	struct dma_buf *dmabuf;
 	void *obj_map, *dma_map;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	u32 pattern[] = { 0, 0xaa, 0xcc, 0x55, 0xff };
 	int err, i;
 
@@ -165,7 +165,7 @@ static int igt_dmabuf_import_ownership(void *arg)
 	struct drm_i915_private *i915 = arg;
 	struct drm_i915_gem_object *obj;
 	struct dma_buf *dmabuf;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	void *ptr;
 	int err;
 
@@ -216,7 +216,7 @@ static int igt_dmabuf_export_vmap(void *arg)
 	struct drm_i915_private *i915 = arg;
 	struct drm_i915_gem_object *obj;
 	struct dma_buf *dmabuf;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	void *ptr;
 	int err;
 
diff --git a/drivers/gpu/drm/i915/gem/selftests/mock_dmabuf.c b/drivers/gpu/drm/i915/gem/selftests/mock_dmabuf.c
index 2855d11c7a51..b2a5882b8f81 100644
--- a/drivers/gpu/drm/i915/gem/selftests/mock_dmabuf.c
+++ b/drivers/gpu/drm/i915/gem/selftests/mock_dmabuf.c
@@ -61,7 +61,7 @@ static void mock_dmabuf_release(struct dma_buf *dma_buf)
 	kfree(mock);
 }
 
-static int mock_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+static int mock_dmabuf_vmap(struct dma_buf *dma_buf, struct iosys_map *map)
 {
 	struct mock_dmabuf *mock = to_mock(dma_buf);
 	void *vaddr;
@@ -69,12 +69,12 @@ static int mock_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
 	vaddr = vm_map_ram(mock->pages, mock->npages, 0);
 	if (!vaddr)
 		return -ENOMEM;
-	dma_buf_map_set_vaddr(map, vaddr);
+	iosys_map_set_vaddr(map, vaddr);
 
 	return 0;
 }
 
-static void mock_dmabuf_vunmap(struct dma_buf *dma_buf, struct dma_buf_map *map)
+static void mock_dmabuf_vunmap(struct dma_buf *dma_buf, struct iosys_map *map)
 {
 	struct mock_dmabuf *mock = to_mock(dma_buf);
 
* Unmerged path drivers/gpu/drm/lima/lima_gem.c
* Unmerged path drivers/gpu/drm/lima/lima_sched.c
* Unmerged path drivers/gpu/drm/mediatek/mtk_drm_gem.c
* Unmerged path drivers/gpu/drm/mediatek/mtk_drm_gem.h
diff --git a/drivers/gpu/drm/mgag200/mgag200_mode.c b/drivers/gpu/drm/mgag200/mgag200_mode.c
index 555e3181e52b..ff2c6044a0e5 100644
--- a/drivers/gpu/drm/mgag200/mgag200_mode.c
+++ b/drivers/gpu/drm/mgag200/mgag200_mode.c
@@ -9,7 +9,7 @@
  */
 
 #include <linux/delay.h>
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 
 #include <drm/drm_atomic_helper.h>
 #include <drm/drm_atomic_state_helper.h>
@@ -1556,7 +1556,7 @@ mgag200_simple_display_pipe_mode_valid(struct drm_simple_display_pipe *pipe,
 
 static void
 mgag200_handle_damage(struct mga_device *mdev, struct drm_framebuffer *fb,
-		      struct drm_rect *clip, const struct dma_buf_map *map)
+		      struct drm_rect *clip, const struct iosys_map *map)
 {
 	void *vmap = map->vaddr; /* TODO: Use mapping abstraction properly */
 
* Unmerged path drivers/gpu/drm/msm/msm_drv.h
* Unmerged path drivers/gpu/drm/msm/msm_gem_prime.c
* Unmerged path drivers/gpu/drm/panfrost/panfrost_perfcnt.c
diff --git a/drivers/gpu/drm/qxl/qxl_display.c b/drivers/gpu/drm/qxl/qxl_display.c
index 9e0a1e836011..9a9c29b1d3e1 100644
--- a/drivers/gpu/drm/qxl/qxl_display.c
+++ b/drivers/gpu/drm/qxl/qxl_display.c
@@ -25,7 +25,7 @@
 
 #include <linux/crc32.h>
 #include <linux/delay.h>
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 
 #include <drm/drm_drv.h>
 #include <drm/drm_atomic.h>
@@ -566,8 +566,8 @@ static struct qxl_bo *qxl_create_cursor(struct qxl_device *qdev,
 {
 	static const u32 size = 64 * 64 * 4;
 	struct qxl_bo *cursor_bo;
-	struct dma_buf_map cursor_map;
-	struct dma_buf_map user_map;
+	struct iosys_map cursor_map;
+	struct iosys_map user_map;
 	struct qxl_cursor cursor;
 	int ret;
 
@@ -1183,7 +1183,7 @@ int qxl_create_monitors_object(struct qxl_device *qdev)
 {
 	int ret;
 	struct drm_gem_object *gobj;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	int monitors_config_size = sizeof(struct qxl_monitors_config) +
 		qxl_num_crtc * sizeof(struct qxl_head);
 
diff --git a/drivers/gpu/drm/qxl/qxl_draw.c b/drivers/gpu/drm/qxl/qxl_draw.c
index 7d27891e87fa..a93de9e1977a 100644
--- a/drivers/gpu/drm/qxl/qxl_draw.c
+++ b/drivers/gpu/drm/qxl/qxl_draw.c
@@ -20,7 +20,7 @@
  * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
  */
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 
 #include <drm/drm_fourcc.h>
 
@@ -44,7 +44,7 @@ static struct qxl_rect *drawable_set_clipping(struct qxl_device *qdev,
 					      unsigned int num_clips,
 					      struct qxl_bo *clips_bo)
 {
-	struct dma_buf_map map;
+	struct iosys_map map;
 	struct qxl_clip_rects *dev_clips;
 	int ret;
 
@@ -146,7 +146,7 @@ void qxl_draw_dirty_fb(struct qxl_device *qdev,
 	int stride = fb->pitches[0];
 	/* depth is not actually interesting, we don't mask with it */
 	int depth = fb->format->cpp[0] * 8;
-	struct dma_buf_map surface_map;
+	struct iosys_map surface_map;
 	uint8_t *surface_base;
 	struct qxl_release *release;
 	struct qxl_bo *clips_bo;
* Unmerged path drivers/gpu/drm/qxl/qxl_drv.h
diff --git a/drivers/gpu/drm/qxl/qxl_object.c b/drivers/gpu/drm/qxl/qxl_object.c
index fbb36e3e8564..b42a657e4c2f 100644
--- a/drivers/gpu/drm/qxl/qxl_object.c
+++ b/drivers/gpu/drm/qxl/qxl_object.c
@@ -23,7 +23,7 @@
  *          Alon Levy
  */
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/io-mapping.h>
 
 #include "qxl_drv.h"
@@ -158,7 +158,7 @@ int qxl_bo_create(struct qxl_device *qdev, unsigned long size,
 	return 0;
 }
 
-int qxl_bo_vmap_locked(struct qxl_bo *bo, struct dma_buf_map *map)
+int qxl_bo_vmap_locked(struct qxl_bo *bo, struct iosys_map *map)
 {
 	int r;
 
@@ -184,7 +184,7 @@ int qxl_bo_vmap_locked(struct qxl_bo *bo, struct dma_buf_map *map)
 	return 0;
 }
 
-int qxl_bo_vmap(struct qxl_bo *bo, struct dma_buf_map *map)
+int qxl_bo_vmap(struct qxl_bo *bo, struct iosys_map *map)
 {
 	int r;
 
@@ -210,7 +210,7 @@ void *qxl_bo_kmap_atomic_page(struct qxl_device *qdev,
 	void *rptr;
 	int ret;
 	struct io_mapping *map;
-	struct dma_buf_map bo_map;
+	struct iosys_map bo_map;
 
 	if (bo->tbo.resource->mem_type == TTM_PL_VRAM)
 		map = qdev->vram_mapping;
diff --git a/drivers/gpu/drm/qxl/qxl_object.h b/drivers/gpu/drm/qxl/qxl_object.h
index cee4b52b75dd..53392cb90eec 100644
--- a/drivers/gpu/drm/qxl/qxl_object.h
+++ b/drivers/gpu/drm/qxl/qxl_object.h
@@ -59,8 +59,8 @@ extern int qxl_bo_create(struct qxl_device *qdev,
 			 u32 priority,
 			 struct qxl_surface *surf,
 			 struct qxl_bo **bo_ptr);
-int qxl_bo_vmap(struct qxl_bo *bo, struct dma_buf_map *map);
-int qxl_bo_vmap_locked(struct qxl_bo *bo, struct dma_buf_map *map);
+int qxl_bo_vmap(struct qxl_bo *bo, struct iosys_map *map);
+int qxl_bo_vmap_locked(struct qxl_bo *bo, struct iosys_map *map);
 int qxl_bo_vunmap(struct qxl_bo *bo);
 void qxl_bo_vunmap_locked(struct qxl_bo *bo);
 void *qxl_bo_kmap_atomic_page(struct qxl_device *qdev, struct qxl_bo *bo, int page_offset);
diff --git a/drivers/gpu/drm/qxl/qxl_prime.c b/drivers/gpu/drm/qxl/qxl_prime.c
index 0628d1cc91fe..6da7dde3695f 100644
--- a/drivers/gpu/drm/qxl/qxl_prime.c
+++ b/drivers/gpu/drm/qxl/qxl_prime.c
@@ -54,7 +54,7 @@ struct drm_gem_object *qxl_gem_prime_import_sg_table(
 	return ERR_PTR(-ENOSYS);
 }
 
-int qxl_gem_prime_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
+int qxl_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)
 {
 	struct qxl_bo *bo = gem_to_qxl_bo(obj);
 	int ret;
@@ -67,7 +67,7 @@ int qxl_gem_prime_vmap(struct drm_gem_object *obj, struct dma_buf_map *map)
 }
 
 void qxl_gem_prime_vunmap(struct drm_gem_object *obj,
-			  struct dma_buf_map *map)
+			  struct iosys_map *map)
 {
 	struct qxl_bo *bo = gem_to_qxl_bo(obj);
 
diff --git a/drivers/gpu/drm/radeon/radeon_gem.c b/drivers/gpu/drm/radeon/radeon_gem.c
index a36a4f2c76b0..f563284a7fac 100644
--- a/drivers/gpu/drm/radeon/radeon_gem.c
+++ b/drivers/gpu/drm/radeon/radeon_gem.c
@@ -26,6 +26,7 @@
  *          Jerome Glisse
  */
 
+#include <linux/iosys-map.h>
 #include <linux/pci.h>
 
 #include <drm/drm_device.h>
* Unmerged path drivers/gpu/drm/rockchip/rockchip_drm_gem.c
* Unmerged path drivers/gpu/drm/rockchip/rockchip_drm_gem.h
diff --git a/drivers/gpu/drm/tegra/gem.c b/drivers/gpu/drm/tegra/gem.c
index a37a1cfe120a..ba0a1efc0e03 100644
--- a/drivers/gpu/drm/tegra/gem.c
+++ b/drivers/gpu/drm/tegra/gem.c
@@ -43,7 +43,7 @@ static void tegra_bo_unpin(struct host1x_bo *bo, struct sg_table *sgt)
 static void *tegra_bo_mmap(struct host1x_bo *bo)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-	struct dma_buf_map map;
+	struct iosys_map map;
 	int ret;
 
 	if (obj->vaddr) {
@@ -60,7 +60,7 @@ static void *tegra_bo_mmap(struct host1x_bo *bo)
 static void tegra_bo_munmap(struct host1x_bo *bo, void *addr)
 {
 	struct tegra_bo *obj = host1x_to_tegra_bo(bo);
-	struct dma_buf_map map = DMA_BUF_MAP_INIT_VADDR(addr);
+	struct iosys_map map = IOSYS_MAP_INIT_VADDR(addr);
 
 	if (obj->vaddr)
 		return;
@@ -571,17 +571,17 @@ static int tegra_gem_prime_mmap(struct dma_buf *buf, struct vm_area_struct *vma)
 	return __tegra_gem_mmap(gem, vma);
 }
 
-static int tegra_gem_prime_vmap(struct dma_buf *buf, struct dma_buf_map *map)
+static int tegra_gem_prime_vmap(struct dma_buf *buf, struct iosys_map *map)
 {
 	struct drm_gem_object *gem = buf->priv;
 	struct tegra_bo *bo = to_tegra_bo(gem);
 
-	dma_buf_map_set_vaddr(map, bo->vaddr);
+	iosys_map_set_vaddr(map, bo->vaddr);
 
 	return 0;
 }
 
-static void tegra_gem_prime_vunmap(struct dma_buf *buf, struct dma_buf_map *map)
+static void tegra_gem_prime_vunmap(struct dma_buf *buf, struct iosys_map *map)
 {
 }
 
* Unmerged path drivers/gpu/drm/tiny/cirrus.c
diff --git a/drivers/gpu/drm/tiny/gm12u320.c b/drivers/gpu/drm/tiny/gm12u320.c
index a233c86d428b..48051cbd23fd 100644
--- a/drivers/gpu/drm/tiny/gm12u320.c
+++ b/drivers/gpu/drm/tiny/gm12u320.c
@@ -96,7 +96,7 @@ struct gm12u320_device {
 		struct drm_rect          rect;
 		int frame;
 		int draw_status_timeout;
-		struct dma_buf_map src_map;
+		struct iosys_map src_map;
 	} fb_update;
 };
 
@@ -404,7 +404,8 @@ static void gm12u320_fb_update_work(struct work_struct *work)
 		GM12U320_ERR("Frame update error: %d\n", ret);
 }
 
-static void gm12u320_fb_mark_dirty(struct drm_framebuffer *fb, const struct dma_buf_map *map,
+static void gm12u320_fb_mark_dirty(struct drm_framebuffer *fb,
+				   const struct iosys_map *map,
 				   struct drm_rect *dirty)
 {
 	struct gm12u320_device *gm12u320 = to_gm12u320(fb->dev);
@@ -447,7 +448,7 @@ static void gm12u320_stop_fb_update(struct gm12u320_device *gm12u320)
 	mutex_lock(&gm12u320->fb_update.lock);
 	old_fb = gm12u320->fb_update.fb;
 	gm12u320->fb_update.fb = NULL;
-	dma_buf_map_clear(&gm12u320->fb_update.src_map);
+	iosys_map_clear(&gm12u320->fb_update.src_map);
 	mutex_unlock(&gm12u320->fb_update.lock);
 
 	drm_framebuffer_put(old_fb);
* Unmerged path drivers/gpu/drm/ttm/ttm_bo_util.c
diff --git a/drivers/gpu/drm/ttm/ttm_resource.c b/drivers/gpu/drm/ttm/ttm_resource.c
index 2431717376e7..a046cc4a0662 100644
--- a/drivers/gpu/drm/ttm/ttm_resource.c
+++ b/drivers/gpu/drm/ttm/ttm_resource.c
@@ -22,7 +22,7 @@
  * Authors: Christian KÃ¶nig
  */
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/io-mapping.h>
 #include <linux/scatterlist.h>
 
@@ -160,7 +160,7 @@ void ttm_resource_manager_debug(struct ttm_resource_manager *man,
 EXPORT_SYMBOL(ttm_resource_manager_debug);
 
 static void ttm_kmap_iter_iomap_map_local(struct ttm_kmap_iter *iter,
-					  struct dma_buf_map *dmap,
+					  struct iosys_map *dmap,
 					  pgoff_t i)
 {
 	struct ttm_kmap_iter_iomap *iter_io =
@@ -187,11 +187,11 @@ static void ttm_kmap_iter_iomap_map_local(struct ttm_kmap_iter *iter,
 	addr = io_mapping_map_local_wc(iter_io->iomap, iter_io->cache.offs +
 				       (((resource_size_t)i - iter_io->cache.i)
 					<< PAGE_SHIFT));
-	dma_buf_map_set_vaddr_iomem(dmap, addr);
+	iosys_map_set_vaddr_iomem(dmap, addr);
 }
 
 static void ttm_kmap_iter_iomap_unmap_local(struct ttm_kmap_iter *iter,
-					    struct dma_buf_map *map)
+					    struct iosys_map *map)
 {
 	io_mapping_unmap_local(map->vaddr_iomem);
 }
@@ -242,14 +242,14 @@ EXPORT_SYMBOL(ttm_kmap_iter_iomap_init);
  */
 
 static void ttm_kmap_iter_linear_io_map_local(struct ttm_kmap_iter *iter,
-					      struct dma_buf_map *dmap,
+					      struct iosys_map *dmap,
 					      pgoff_t i)
 {
 	struct ttm_kmap_iter_linear_io *iter_io =
 		container_of(iter, typeof(*iter_io), base);
 
 	*dmap = iter_io->dmap;
-	dma_buf_map_incr(dmap, i * PAGE_SIZE);
+	iosys_map_incr(dmap, i * PAGE_SIZE);
 }
 
 static const struct ttm_kmap_iter_ops ttm_kmap_iter_linear_io_ops = {
@@ -285,7 +285,7 @@ ttm_kmap_iter_linear_io_init(struct ttm_kmap_iter_linear_io *iter_io,
 	}
 
 	if (mem->bus.addr) {
-		dma_buf_map_set_vaddr(&iter_io->dmap, mem->bus.addr);
+		iosys_map_set_vaddr(&iter_io->dmap, mem->bus.addr);
 		iter_io->needs_unmap = false;
 	} else {
 		size_t bus_size = (size_t)mem->num_pages << PAGE_SHIFT;
@@ -293,23 +293,23 @@ ttm_kmap_iter_linear_io_init(struct ttm_kmap_iter_linear_io *iter_io,
 		iter_io->needs_unmap = true;
 		memset(&iter_io->dmap, 0, sizeof(iter_io->dmap));
 		if (mem->bus.caching == ttm_write_combined)
-			dma_buf_map_set_vaddr_iomem(&iter_io->dmap,
-						    ioremap_wc(mem->bus.offset,
-							       bus_size));
+			iosys_map_set_vaddr_iomem(&iter_io->dmap,
+						  ioremap_wc(mem->bus.offset,
+							     bus_size));
 		else if (mem->bus.caching == ttm_cached)
-			dma_buf_map_set_vaddr(&iter_io->dmap,
-					      memremap(mem->bus.offset, bus_size,
-						       MEMREMAP_WB |
-						       MEMREMAP_WT |
-						       MEMREMAP_WC));
+			iosys_map_set_vaddr(&iter_io->dmap,
+					    memremap(mem->bus.offset, bus_size,
+						     MEMREMAP_WB |
+						     MEMREMAP_WT |
+						     MEMREMAP_WC));
 
 		/* If uncached requested or if mapping cached or wc failed */
-		if (dma_buf_map_is_null(&iter_io->dmap))
-			dma_buf_map_set_vaddr_iomem(&iter_io->dmap,
-						    ioremap(mem->bus.offset,
-							    bus_size));
+		if (iosys_map_is_null(&iter_io->dmap))
+			iosys_map_set_vaddr_iomem(&iter_io->dmap,
+						  ioremap(mem->bus.offset,
+							  bus_size));
 
-		if (dma_buf_map_is_null(&iter_io->dmap)) {
+		if (iosys_map_is_null(&iter_io->dmap)) {
 			ret = -ENOMEM;
 			goto out_io_free;
 		}
@@ -338,7 +338,7 @@ ttm_kmap_iter_linear_io_fini(struct ttm_kmap_iter_linear_io *iter_io,
 			     struct ttm_device *bdev,
 			     struct ttm_resource *mem)
 {
-	if (iter_io->needs_unmap && dma_buf_map_is_set(&iter_io->dmap)) {
+	if (iter_io->needs_unmap && iosys_map_is_set(&iter_io->dmap)) {
 		if (iter_io->dmap.is_iomem)
 			iounmap(iter_io->dmap.vaddr_iomem);
 		else
diff --git a/drivers/gpu/drm/ttm/ttm_tt.c b/drivers/gpu/drm/ttm/ttm_tt.c
index 24031a8acd2d..c934003c5872 100644
--- a/drivers/gpu/drm/ttm/ttm_tt.c
+++ b/drivers/gpu/drm/ttm/ttm_tt.c
@@ -435,18 +435,18 @@ void ttm_tt_mgr_init(unsigned long num_pages, unsigned long num_dma32_pages)
 }
 
 static void ttm_kmap_iter_tt_map_local(struct ttm_kmap_iter *iter,
-				       struct dma_buf_map *dmap,
+				       struct iosys_map *dmap,
 				       pgoff_t i)
 {
 	struct ttm_kmap_iter_tt *iter_tt =
 		container_of(iter, typeof(*iter_tt), base);
 
-	dma_buf_map_set_vaddr(dmap, kmap_local_page_prot(iter_tt->tt->pages[i],
-							 iter_tt->prot));
+	iosys_map_set_vaddr(dmap, kmap_local_page_prot(iter_tt->tt->pages[i],
+						       iter_tt->prot));
 }
 
 static void ttm_kmap_iter_tt_unmap_local(struct ttm_kmap_iter *iter,
-					 struct dma_buf_map *map)
+					 struct iosys_map *map)
 {
 	kunmap_local(map->vaddr);
 }
diff --git a/drivers/gpu/drm/udl/udl_modeset.c b/drivers/gpu/drm/udl/udl_modeset.c
index 8d98bf69d075..b131928d6d05 100644
--- a/drivers/gpu/drm/udl/udl_modeset.c
+++ b/drivers/gpu/drm/udl/udl_modeset.c
@@ -267,7 +267,8 @@ static int udl_aligned_damage_clip(struct drm_rect *clip, int x, int y,
 	return 0;
 }
 
-static int udl_handle_damage(struct drm_framebuffer *fb, const struct dma_buf_map *map,
+static int udl_handle_damage(struct drm_framebuffer *fb,
+			     const struct iosys_map *map,
 			     int x, int y, int width, int height)
 {
 	struct drm_device *dev = fb->dev;
* Unmerged path drivers/gpu/drm/vboxvideo/vbox_mode.c
* Unmerged path drivers/gpu/drm/vkms/vkms_composer.c
* Unmerged path drivers/gpu/drm/vkms/vkms_drv.h
diff --git a/drivers/gpu/drm/vkms/vkms_plane.c b/drivers/gpu/drm/vkms/vkms_plane.c
index 092514a2155f..2dea68e2036b 100644
--- a/drivers/gpu/drm/vkms/vkms_plane.c
+++ b/drivers/gpu/drm/vkms/vkms_plane.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0+
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 
 #include <drm/drm_atomic.h>
 #include <drm/drm_atomic_helper.h>
diff --git a/drivers/gpu/drm/vkms/vkms_writeback.c b/drivers/gpu/drm/vkms/vkms_writeback.c
index 0935686475a0..0562059ab579 100644
--- a/drivers/gpu/drm/vkms/vkms_writeback.c
+++ b/drivers/gpu/drm/vkms/vkms_writeback.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0+
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 
 #include <drm/drm_atomic.h>
 #include <drm/drm_fourcc.h>
* Unmerged path drivers/gpu/drm/xen/xen_drm_front_gem.c
diff --git a/drivers/gpu/drm/xen/xen_drm_front_gem.h b/drivers/gpu/drm/xen/xen_drm_front_gem.h
index a4e67d0a149c..b961a2200ca0 100644
--- a/drivers/gpu/drm/xen/xen_drm_front_gem.h
+++ b/drivers/gpu/drm/xen/xen_drm_front_gem.h
@@ -12,7 +12,7 @@
 #define __XEN_DRM_FRONT_GEM_H
 
 struct dma_buf_attachment;
-struct dma_buf_map;
+struct iosys_map;
 struct drm_device;
 struct drm_gem_object;
 struct file;
@@ -36,10 +36,10 @@ void xen_drm_front_gem_free_object_unlocked(struct drm_gem_object *gem_obj);
 int xen_drm_front_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 
 int xen_drm_front_gem_prime_vmap(struct drm_gem_object *gem_obj,
-				 struct dma_buf_map *map);
+				 struct iosys_map *map);
 
 void xen_drm_front_gem_prime_vunmap(struct drm_gem_object *gem_obj,
-				    struct dma_buf_map *map);
+				    struct iosys_map *map);
 
 int xen_drm_front_gem_prime_mmap(struct drm_gem_object *gem_obj,
 				 struct vm_area_struct *vma);
* Unmerged path drivers/media/common/videobuf2/videobuf2-dma-contig.c
* Unmerged path drivers/media/common/videobuf2/videobuf2-dma-sg.c
diff --git a/drivers/media/common/videobuf2/videobuf2-vmalloc.c b/drivers/media/common/videobuf2/videobuf2-vmalloc.c
index dd7e9a58b11e..4ee35e9f180d 100644
--- a/drivers/media/common/videobuf2/videobuf2-vmalloc.c
+++ b/drivers/media/common/videobuf2/videobuf2-vmalloc.c
@@ -318,11 +318,12 @@ static void vb2_vmalloc_dmabuf_ops_release(struct dma_buf *dbuf)
 	vb2_vmalloc_put(dbuf->priv);
 }
 
-static int vb2_vmalloc_dmabuf_ops_vmap(struct dma_buf *dbuf, struct dma_buf_map *map)
+static int vb2_vmalloc_dmabuf_ops_vmap(struct dma_buf *dbuf,
+				       struct iosys_map *map)
 {
 	struct vb2_vmalloc_buf *buf = dbuf->priv;
 
-	dma_buf_map_set_vaddr(map, buf->vaddr);
+	iosys_map_set_vaddr(map, buf->vaddr);
 
 	return 0;
 }
@@ -376,7 +377,7 @@ static struct dma_buf *vb2_vmalloc_get_dmabuf(void *buf_priv, unsigned long flag
 static int vb2_vmalloc_map_dmabuf(void *mem_priv)
 {
 	struct vb2_vmalloc_buf *buf = mem_priv;
-	struct dma_buf_map map;
+	struct iosys_map map;
 	int ret;
 
 	ret = dma_buf_vmap(buf->dbuf, &map);
@@ -390,7 +391,7 @@ static int vb2_vmalloc_map_dmabuf(void *mem_priv)
 static void vb2_vmalloc_unmap_dmabuf(void *mem_priv)
 {
 	struct vb2_vmalloc_buf *buf = mem_priv;
-	struct dma_buf_map map = DMA_BUF_MAP_INIT_VADDR(buf->vaddr);
+	struct iosys_map map = IOSYS_MAP_INIT_VADDR(buf->vaddr);
 
 	dma_buf_vunmap(buf->dbuf, &map);
 	buf->vaddr = NULL;
@@ -399,7 +400,7 @@ static void vb2_vmalloc_unmap_dmabuf(void *mem_priv)
 static void vb2_vmalloc_detach_dmabuf(void *mem_priv)
 {
 	struct vb2_vmalloc_buf *buf = mem_priv;
-	struct dma_buf_map map = DMA_BUF_MAP_INIT_VADDR(buf->vaddr);
+	struct iosys_map map = IOSYS_MAP_INIT_VADDR(buf->vaddr);
 
 	if (buf->vaddr)
 		dma_buf_vunmap(buf->dbuf, &map);
* Unmerged path drivers/misc/fastrpc.c
diff --git a/include/drm/drm_cache.h b/include/drm/drm_cache.h
index cc9de1632dd3..22deb216b59c 100644
--- a/include/drm/drm_cache.h
+++ b/include/drm/drm_cache.h
@@ -35,7 +35,7 @@
 
 #include <linux/scatterlist.h>
 
-struct dma_buf_map;
+struct iosys_map;
 
 void drm_clflush_pages(struct page *pages[], unsigned long num_pages);
 void drm_clflush_sg(struct sg_table *st);
@@ -74,7 +74,7 @@ static inline bool drm_arch_can_wc_memory(void)
 
 void drm_memcpy_init_early(void);
 
-void drm_memcpy_from_wc(struct dma_buf_map *dst,
-			const struct dma_buf_map *src,
+void drm_memcpy_from_wc(struct iosys_map *dst,
+			const struct iosys_map *src,
 			unsigned long len);
 #endif
diff --git a/include/drm/drm_client.h b/include/drm/drm_client.h
index f07f2fb02e75..4fc8018eddda 100644
--- a/include/drm/drm_client.h
+++ b/include/drm/drm_client.h
@@ -3,7 +3,7 @@
 #ifndef _DRM_CLIENT_H_
 #define _DRM_CLIENT_H_
 
-#include <linux/dma-buf-map.h>
+#include <linux/iosys-map.h>
 #include <linux/lockdep.h>
 #include <linux/mutex.h>
 #include <linux/types.h>
@@ -144,7 +144,7 @@ struct drm_client_buffer {
 	/**
 	 * @map: Virtual address for the buffer
 	 */
-	struct dma_buf_map map;
+	struct iosys_map map;
 
 	/**
 	 * @fb: DRM framebuffer
@@ -156,7 +156,8 @@ struct drm_client_buffer *
 drm_client_framebuffer_create(struct drm_client_dev *client, u32 width, u32 height, u32 format);
 void drm_client_framebuffer_delete(struct drm_client_buffer *buffer);
 int drm_client_framebuffer_flush(struct drm_client_buffer *buffer, struct drm_rect *rect);
-int drm_client_buffer_vmap(struct drm_client_buffer *buffer, struct dma_buf_map *map);
+int drm_client_buffer_vmap(struct drm_client_buffer *buffer,
+			   struct iosys_map *map);
 void drm_client_buffer_vunmap(struct drm_client_buffer *buffer);
 
 int drm_client_modeset_create(struct drm_client_dev *client);
diff --git a/include/drm/drm_gem.h b/include/drm/drm_gem.h
index 240049566592..f78e4edd7895 100644
--- a/include/drm/drm_gem.h
+++ b/include/drm/drm_gem.h
@@ -39,7 +39,7 @@
 
 #include <drm/drm_vma_manager.h>
 
-struct dma_buf_map;
+struct iosys_map;
 struct drm_gem_object;
 
 /**
@@ -139,7 +139,7 @@ struct drm_gem_object_funcs {
 	 *
 	 * This callback is optional.
 	 */
-	int (*vmap)(struct drm_gem_object *obj, struct dma_buf_map *map);
+	int (*vmap)(struct drm_gem_object *obj, struct iosys_map *map);
 
 	/**
 	 * @vunmap:
@@ -149,7 +149,7 @@ struct drm_gem_object_funcs {
 	 *
 	 * This callback is optional.
 	 */
-	void (*vunmap)(struct drm_gem_object *obj, struct dma_buf_map *map);
+	void (*vunmap)(struct drm_gem_object *obj, struct iosys_map *map);
 
 	/**
 	 * @mmap:
* Unmerged path include/drm/drm_gem_atomic_helper.h
* Unmerged path include/drm/drm_gem_cma_helper.h
* Unmerged path include/drm/drm_gem_framebuffer_helper.h
* Unmerged path include/drm/drm_gem_shmem_helper.h
diff --git a/include/drm/drm_gem_ttm_helper.h b/include/drm/drm_gem_ttm_helper.h
index c1aa02bd4c89..7f3abcd8d0f4 100644
--- a/include/drm/drm_gem_ttm_helper.h
+++ b/include/drm/drm_gem_ttm_helper.h
@@ -10,7 +10,7 @@
 #include <drm/ttm/ttm_bo_api.h>
 #include <drm/ttm/ttm_bo_driver.h>
 
-struct dma_buf_map;
+struct iosys_map;
 
 #define drm_gem_ttm_of_gem(gem_obj) \
 	container_of(gem_obj, struct ttm_buffer_object, base)
@@ -18,9 +18,9 @@ struct dma_buf_map;
 void drm_gem_ttm_print_info(struct drm_printer *p, unsigned int indent,
 			    const struct drm_gem_object *gem);
 int drm_gem_ttm_vmap(struct drm_gem_object *gem,
-		     struct dma_buf_map *map);
+		     struct iosys_map *map);
 void drm_gem_ttm_vunmap(struct drm_gem_object *gem,
-			struct dma_buf_map *map);
+			struct iosys_map *map);
 int drm_gem_ttm_mmap(struct drm_gem_object *gem,
 		     struct vm_area_struct *vma);
 
* Unmerged path include/drm/drm_gem_vram_helper.h
diff --git a/include/drm/drm_prime.h b/include/drm/drm_prime.h
index 54f2c58305d2..2a1d01e5b56b 100644
--- a/include/drm/drm_prime.h
+++ b/include/drm/drm_prime.h
@@ -54,7 +54,7 @@ struct device;
 struct dma_buf_export_info;
 struct dma_buf;
 struct dma_buf_attachment;
-struct dma_buf_map;
+struct iosys_map;
 
 enum dma_data_direction;
 
@@ -83,8 +83,8 @@ struct sg_table *drm_gem_map_dma_buf(struct dma_buf_attachment *attach,
 void drm_gem_unmap_dma_buf(struct dma_buf_attachment *attach,
 			   struct sg_table *sgt,
 			   enum dma_data_direction dir);
-int drm_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct dma_buf_map *map);
-void drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct dma_buf_map *map);
+int drm_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct iosys_map *map);
+void drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct iosys_map *map);
 
 int drm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
 int drm_gem_dmabuf_mmap(struct dma_buf *dma_buf, struct vm_area_struct *vma);
diff --git a/include/drm/ttm/ttm_bo_api.h b/include/drm/ttm/ttm_bo_api.h
index 36f7eb9d0663..b8bdc1163235 100644
--- a/include/drm/ttm/ttm_bo_api.h
+++ b/include/drm/ttm/ttm_bo_api.h
@@ -48,7 +48,7 @@ struct ttm_global;
 
 struct ttm_device;
 
-struct dma_buf_map;
+struct iosys_map;
 
 struct drm_mm_node;
 
@@ -492,17 +492,17 @@ void ttm_bo_kunmap(struct ttm_bo_kmap_obj *map);
  * ttm_bo_vmap
  *
  * @bo: The buffer object.
- * @map: pointer to a struct dma_buf_map representing the map.
+ * @map: pointer to a struct iosys_map representing the map.
  *
  * Sets up a kernel virtual mapping, using ioremap or vmap to the
  * data in the buffer object. The parameter @map returns the virtual
- * address as struct dma_buf_map. Unmap the buffer with ttm_bo_vunmap().
+ * address as struct iosys_map. Unmap the buffer with ttm_bo_vunmap().
  *
  * Returns
  * -ENOMEM: Out of memory.
  * -EINVAL: Invalid range.
  */
-int ttm_bo_vmap(struct ttm_buffer_object *bo, struct dma_buf_map *map);
+int ttm_bo_vmap(struct ttm_buffer_object *bo, struct iosys_map *map);
 
 /**
  * ttm_bo_vunmap
@@ -512,7 +512,7 @@ int ttm_bo_vmap(struct ttm_buffer_object *bo, struct dma_buf_map *map);
  *
  * Unmaps a kernel map set up by ttm_bo_vmap().
  */
-void ttm_bo_vunmap(struct ttm_buffer_object *bo, struct dma_buf_map *map);
+void ttm_bo_vunmap(struct ttm_buffer_object *bo, struct iosys_map *map);
 
 /**
  * ttm_bo_mmap_obj - mmap memory backed by a ttm buffer object.
diff --git a/include/drm/ttm/ttm_kmap_iter.h b/include/drm/ttm/ttm_kmap_iter.h
index 8bb00fd39d6c..cc5c09a211b4 100644
--- a/include/drm/ttm/ttm_kmap_iter.h
+++ b/include/drm/ttm/ttm_kmap_iter.h
@@ -8,7 +8,7 @@
 #include <linux/types.h>
 
 struct ttm_kmap_iter;
-struct dma_buf_map;
+struct iosys_map;
 
 /**
  * struct ttm_kmap_iter_ops - Ops structure for a struct
@@ -24,22 +24,22 @@ struct ttm_kmap_iter_ops {
 	 * kmap_local semantics.
 	 * @res_iter: Pointer to the struct ttm_kmap_iter representing
 	 * the resource.
-	 * @dmap: The struct dma_buf_map holding the virtual address after
+	 * @dmap: The struct iosys_map holding the virtual address after
 	 * the operation.
 	 * @i: The location within the resource to map. PAGE_SIZE granularity.
 	 */
 	void (*map_local)(struct ttm_kmap_iter *res_iter,
-			  struct dma_buf_map *dmap, pgoff_t i);
+			  struct iosys_map *dmap, pgoff_t i);
 	/**
 	 * unmap_local() - Unmap a PAGE_SIZE part of the resource previously
 	 * mapped using kmap_local.
 	 * @res_iter: Pointer to the struct ttm_kmap_iter representing
 	 * the resource.
-	 * @dmap: The struct dma_buf_map holding the virtual address after
+	 * @dmap: The struct iosys_map holding the virtual address after
 	 * the operation.
 	 */
 	void (*unmap_local)(struct ttm_kmap_iter *res_iter,
-			    struct dma_buf_map *dmap);
+			    struct iosys_map *dmap);
 	bool maps_tt;
 };
 
* Unmerged path include/drm/ttm/ttm_resource.h
diff --git a/include/linux/dma-buf-map.h b/include/linux/dma-buf-map.h
deleted file mode 100644
index 278d489e4bdd..000000000000
--- a/include/linux/dma-buf-map.h
+++ /dev/null
@@ -1,266 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0-only */
-/*
- * Pointer to dma-buf-mapped memory, plus helpers.
- */
-
-#ifndef __DMA_BUF_MAP_H__
-#define __DMA_BUF_MAP_H__
-
-#include <linux/io.h>
-#include <linux/string.h>
-
-/**
- * DOC: overview
- *
- * Calling dma-buf's vmap operation returns a pointer to the buffer's memory.
- * Depending on the location of the buffer, users may have to access it with
- * I/O operations or memory load/store operations. For example, copying to
- * system memory could be done with memcpy(), copying to I/O memory would be
- * done with memcpy_toio().
- *
- * .. code-block:: c
- *
- *	void *vaddr = ...; // pointer to system memory
- *	memcpy(vaddr, src, len);
- *
- *	void *vaddr_iomem = ...; // pointer to I/O memory
- *	memcpy_toio(vaddr, _iomem, src, len);
- *
- * When using dma-buf's vmap operation, the returned pointer is encoded as
- * :c:type:`struct dma_buf_map <dma_buf_map>`.
- * :c:type:`struct dma_buf_map <dma_buf_map>` stores the buffer's address in
- * system or I/O memory and a flag that signals the required method of
- * accessing the buffer. Use the returned instance and the helper functions
- * to access the buffer's memory in the correct way.
- *
- * The type :c:type:`struct dma_buf_map <dma_buf_map>` and its helpers are
- * actually independent from the dma-buf infrastructure. When sharing buffers
- * among devices, drivers have to know the location of the memory to access
- * the buffers in a safe way. :c:type:`struct dma_buf_map <dma_buf_map>`
- * solves this problem for dma-buf and its users. If other drivers or
- * sub-systems require similar functionality, the type could be generalized
- * and moved to a more prominent header file.
- *
- * Open-coding access to :c:type:`struct dma_buf_map <dma_buf_map>` is
- * considered bad style. Rather then accessing its fields directly, use one
- * of the provided helper functions, or implement your own. For example,
- * instances of :c:type:`struct dma_buf_map <dma_buf_map>` can be initialized
- * statically with DMA_BUF_MAP_INIT_VADDR(), or at runtime with
- * dma_buf_map_set_vaddr(). These helpers will set an address in system memory.
- *
- * .. code-block:: c
- *
- *	struct dma_buf_map map = DMA_BUF_MAP_INIT_VADDR(0xdeadbeaf);
- *
- *	dma_buf_map_set_vaddr(&map. 0xdeadbeaf);
- *
- * To set an address in I/O memory, use dma_buf_map_set_vaddr_iomem().
- *
- * .. code-block:: c
- *
- *	dma_buf_map_set_vaddr_iomem(&map. 0xdeadbeaf);
- *
- * Instances of struct dma_buf_map do not have to be cleaned up, but
- * can be cleared to NULL with dma_buf_map_clear(). Cleared mappings
- * always refer to system memory.
- *
- * .. code-block:: c
- *
- *	dma_buf_map_clear(&map);
- *
- * Test if a mapping is valid with either dma_buf_map_is_set() or
- * dma_buf_map_is_null().
- *
- * .. code-block:: c
- *
- *	if (dma_buf_map_is_set(&map) != dma_buf_map_is_null(&map))
- *		// always true
- *
- * Instances of :c:type:`struct dma_buf_map <dma_buf_map>` can be compared
- * for equality with dma_buf_map_is_equal(). Mappings the point to different
- * memory spaces, system or I/O, are never equal. That's even true if both
- * spaces are located in the same address space, both mappings contain the
- * same address value, or both mappings refer to NULL.
- *
- * .. code-block:: c
- *
- *	struct dma_buf_map sys_map; // refers to system memory
- *	struct dma_buf_map io_map; // refers to I/O memory
- *
- *	if (dma_buf_map_is_equal(&sys_map, &io_map))
- *		// always false
- *
- * A set up instance of struct dma_buf_map can be used to access or manipulate
- * the buffer memory. Depending on the location of the memory, the provided
- * helpers will pick the correct operations. Data can be copied into the memory
- * with dma_buf_map_memcpy_to(). The address can be manipulated with
- * dma_buf_map_incr().
- *
- * .. code-block:: c
- *
- *	const void *src = ...; // source buffer
- *	size_t len = ...; // length of src
- *
- *	dma_buf_map_memcpy_to(&map, src, len);
- *	dma_buf_map_incr(&map, len); // go to first byte after the memcpy
- */
-
-/**
- * struct dma_buf_map - Pointer to vmap'ed dma-buf memory.
- * @vaddr_iomem:	The buffer's address if in I/O memory
- * @vaddr:		The buffer's address if in system memory
- * @is_iomem:		True if the dma-buf memory is located in I/O
- *			memory, or false otherwise.
- */
-struct dma_buf_map {
-	union {
-		void __iomem *vaddr_iomem;
-		void *vaddr;
-	};
-	bool is_iomem;
-};
-
-/**
- * DMA_BUF_MAP_INIT_VADDR - Initializes struct dma_buf_map to an address in system memory
- * @vaddr_:	A system-memory address
- */
-#define DMA_BUF_MAP_INIT_VADDR(vaddr_) \
-	{ \
-		.vaddr = (vaddr_), \
-		.is_iomem = false, \
-	}
-
-/**
- * dma_buf_map_set_vaddr - Sets a dma-buf mapping structure to an address in system memory
- * @map:	The dma-buf mapping structure
- * @vaddr:	A system-memory address
- *
- * Sets the address and clears the I/O-memory flag.
- */
-static inline void dma_buf_map_set_vaddr(struct dma_buf_map *map, void *vaddr)
-{
-	map->vaddr = vaddr;
-	map->is_iomem = false;
-}
-
-/**
- * dma_buf_map_set_vaddr_iomem - Sets a dma-buf mapping structure to an address in I/O memory
- * @map:		The dma-buf mapping structure
- * @vaddr_iomem:	An I/O-memory address
- *
- * Sets the address and the I/O-memory flag.
- */
-static inline void dma_buf_map_set_vaddr_iomem(struct dma_buf_map *map,
-					       void __iomem *vaddr_iomem)
-{
-	map->vaddr_iomem = vaddr_iomem;
-	map->is_iomem = true;
-}
-
-/**
- * dma_buf_map_is_equal - Compares two dma-buf mapping structures for equality
- * @lhs:	The dma-buf mapping structure
- * @rhs:	A dma-buf mapping structure to compare with
- *
- * Two dma-buf mapping structures are equal if they both refer to the same type of memory
- * and to the same address within that memory.
- *
- * Returns:
- * True is both structures are equal, or false otherwise.
- */
-static inline bool dma_buf_map_is_equal(const struct dma_buf_map *lhs,
-					const struct dma_buf_map *rhs)
-{
-	if (lhs->is_iomem != rhs->is_iomem)
-		return false;
-	else if (lhs->is_iomem)
-		return lhs->vaddr_iomem == rhs->vaddr_iomem;
-	else
-		return lhs->vaddr == rhs->vaddr;
-}
-
-/**
- * dma_buf_map_is_null - Tests for a dma-buf mapping to be NULL
- * @map:	The dma-buf mapping structure
- *
- * Depending on the state of struct dma_buf_map.is_iomem, tests if the
- * mapping is NULL.
- *
- * Returns:
- * True if the mapping is NULL, or false otherwise.
- */
-static inline bool dma_buf_map_is_null(const struct dma_buf_map *map)
-{
-	if (map->is_iomem)
-		return !map->vaddr_iomem;
-	return !map->vaddr;
-}
-
-/**
- * dma_buf_map_is_set - Tests is the dma-buf mapping has been set
- * @map:	The dma-buf mapping structure
- *
- * Depending on the state of struct dma_buf_map.is_iomem, tests if the
- * mapping has been set.
- *
- * Returns:
- * True if the mapping is been set, or false otherwise.
- */
-static inline bool dma_buf_map_is_set(const struct dma_buf_map *map)
-{
-	return !dma_buf_map_is_null(map);
-}
-
-/**
- * dma_buf_map_clear - Clears a dma-buf mapping structure
- * @map:	The dma-buf mapping structure
- *
- * Clears all fields to zero; including struct dma_buf_map.is_iomem. So
- * mapping structures that were set to point to I/O memory are reset for
- * system memory. Pointers are cleared to NULL. This is the default.
- */
-static inline void dma_buf_map_clear(struct dma_buf_map *map)
-{
-	if (map->is_iomem) {
-		map->vaddr_iomem = NULL;
-		map->is_iomem = false;
-	} else {
-		map->vaddr = NULL;
-	}
-}
-
-/**
- * dma_buf_map_memcpy_to - Memcpy into dma-buf mapping
- * @dst:	The dma-buf mapping structure
- * @src:	The source buffer
- * @len:	The number of byte in src
- *
- * Copies data into a dma-buf mapping. The source buffer is in system
- * memory. Depending on the buffer's location, the helper picks the correct
- * method of accessing the memory.
- */
-static inline void dma_buf_map_memcpy_to(struct dma_buf_map *dst, const void *src, size_t len)
-{
-	if (dst->is_iomem)
-		memcpy_toio(dst->vaddr_iomem, src, len);
-	else
-		memcpy(dst->vaddr, src, len);
-}
-
-/**
- * dma_buf_map_incr - Increments the address stored in a dma-buf mapping
- * @map:	The dma-buf mapping structure
- * @incr:	The number of bytes to increment
- *
- * Increments the address stored in a dma-buf mapping. Depending on the
- * buffer's location, the correct value will be updated.
- */
-static inline void dma_buf_map_incr(struct dma_buf_map *map, size_t incr)
-{
-	if (map->is_iomem)
-		map->vaddr_iomem += incr;
-	else
-		map->vaddr += incr;
-}
-
-#endif /* __DMA_BUF_MAP_H__ */
* Unmerged path include/linux/dma-buf.h
diff --git a/include/linux/iosys-map.h b/include/linux/iosys-map.h
new file mode 100644
index 000000000000..f4186f91caa6
--- /dev/null
+++ b/include/linux/iosys-map.h
@@ -0,0 +1,257 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * Pointer abstraction for IO/system memory
+ */
+
+#ifndef __IOSYS_MAP_H__
+#define __IOSYS_MAP_H__
+
+#include <linux/io.h>
+#include <linux/string.h>
+
+/**
+ * DOC: overview
+ *
+ * When accessing a memory region, depending on its location, users may have to
+ * access it with I/O operations or memory load/store operations. For example,
+ * copying to system memory could be done with memcpy(), copying to I/O memory
+ * would be done with memcpy_toio().
+ *
+ * .. code-block:: c
+ *
+ *	void *vaddr = ...; // pointer to system memory
+ *	memcpy(vaddr, src, len);
+ *
+ *	void *vaddr_iomem = ...; // pointer to I/O memory
+ *	memcpy_toio(vaddr, _iomem, src, len);
+ *
+ * The user of such pointer may not have information about the mapping of that
+ * region or may want to have a single code path to handle operations on that
+ * buffer, regardless if it's located in system or IO memory. The type
+ * :c:type:`struct iosys_map <iosys_map>` and its helpers abstract that so the
+ * buffer can be passed around to other drivers or have separate duties inside
+ * the same driver for allocation, read and write operations.
+ *
+ * Open-coding access to :c:type:`struct iosys_map <iosys_map>` is considered
+ * bad style. Rather then accessing its fields directly, use one of the provided
+ * helper functions, or implement your own. For example, instances of
+ * :c:type:`struct iosys_map <iosys_map>` can be initialized statically with
+ * IOSYS_MAP_INIT_VADDR(), or at runtime with iosys_map_set_vaddr(). These
+ * helpers will set an address in system memory.
+ *
+ * .. code-block:: c
+ *
+ *	struct iosys_map map = IOSYS_MAP_INIT_VADDR(0xdeadbeaf);
+ *
+ *	iosys_map_set_vaddr(&map, 0xdeadbeaf);
+ *
+ * To set an address in I/O memory, use iosys_map_set_vaddr_iomem().
+ *
+ * .. code-block:: c
+ *
+ *	iosys_map_set_vaddr_iomem(&map, 0xdeadbeaf);
+ *
+ * Instances of struct iosys_map do not have to be cleaned up, but
+ * can be cleared to NULL with iosys_map_clear(). Cleared mappings
+ * always refer to system memory.
+ *
+ * .. code-block:: c
+ *
+ *	iosys_map_clear(&map);
+ *
+ * Test if a mapping is valid with either iosys_map_is_set() or
+ * iosys_map_is_null().
+ *
+ * .. code-block:: c
+ *
+ *	if (iosys_map_is_set(&map) != iosys_map_is_null(&map))
+ *		// always true
+ *
+ * Instances of :c:type:`struct iosys_map <iosys_map>` can be compared for
+ * equality with iosys_map_is_equal(). Mappings that point to different memory
+ * spaces, system or I/O, are never equal. That's even true if both spaces are
+ * located in the same address space, both mappings contain the same address
+ * value, or both mappings refer to NULL.
+ *
+ * .. code-block:: c
+ *
+ *	struct iosys_map sys_map; // refers to system memory
+ *	struct iosys_map io_map; // refers to I/O memory
+ *
+ *	if (iosys_map_is_equal(&sys_map, &io_map))
+ *		// always false
+ *
+ * A set up instance of struct iosys_map can be used to access or manipulate the
+ * buffer memory. Depending on the location of the memory, the provided helpers
+ * will pick the correct operations. Data can be copied into the memory with
+ * iosys_map_memcpy_to(). The address can be manipulated with iosys_map_incr().
+ *
+ * .. code-block:: c
+ *
+ *	const void *src = ...; // source buffer
+ *	size_t len = ...; // length of src
+ *
+ *	iosys_map_memcpy_to(&map, src, len);
+ *	iosys_map_incr(&map, len); // go to first byte after the memcpy
+ */
+
+/**
+ * struct iosys_map - Pointer to IO/system memory
+ * @vaddr_iomem:	The buffer's address if in I/O memory
+ * @vaddr:		The buffer's address if in system memory
+ * @is_iomem:		True if the buffer is located in I/O memory, or false
+ *			otherwise.
+ */
+struct iosys_map {
+	union {
+		void __iomem *vaddr_iomem;
+		void *vaddr;
+	};
+	bool is_iomem;
+};
+
+/**
+ * IOSYS_MAP_INIT_VADDR - Initializes struct iosys_map to an address in system memory
+ * @vaddr_:	A system-memory address
+ */
+#define IOSYS_MAP_INIT_VADDR(vaddr_)	\
+	{				\
+		.vaddr = (vaddr_),	\
+		.is_iomem = false,	\
+	}
+
+/**
+ * iosys_map_set_vaddr - Sets a iosys mapping structure to an address in system memory
+ * @map:	The iosys_map structure
+ * @vaddr:	A system-memory address
+ *
+ * Sets the address and clears the I/O-memory flag.
+ */
+static inline void iosys_map_set_vaddr(struct iosys_map *map, void *vaddr)
+{
+	map->vaddr = vaddr;
+	map->is_iomem = false;
+}
+
+/**
+ * iosys_map_set_vaddr_iomem - Sets a iosys mapping structure to an address in I/O memory
+ * @map:		The iosys_map structure
+ * @vaddr_iomem:	An I/O-memory address
+ *
+ * Sets the address and the I/O-memory flag.
+ */
+static inline void iosys_map_set_vaddr_iomem(struct iosys_map *map,
+					     void __iomem *vaddr_iomem)
+{
+	map->vaddr_iomem = vaddr_iomem;
+	map->is_iomem = true;
+}
+
+/**
+ * iosys_map_is_equal - Compares two iosys mapping structures for equality
+ * @lhs:	The iosys_map structure
+ * @rhs:	A iosys_map structure to compare with
+ *
+ * Two iosys mapping structures are equal if they both refer to the same type of memory
+ * and to the same address within that memory.
+ *
+ * Returns:
+ * True is both structures are equal, or false otherwise.
+ */
+static inline bool iosys_map_is_equal(const struct iosys_map *lhs,
+				      const struct iosys_map *rhs)
+{
+	if (lhs->is_iomem != rhs->is_iomem)
+		return false;
+	else if (lhs->is_iomem)
+		return lhs->vaddr_iomem == rhs->vaddr_iomem;
+	else
+		return lhs->vaddr == rhs->vaddr;
+}
+
+/**
+ * iosys_map_is_null - Tests for a iosys mapping to be NULL
+ * @map:	The iosys_map structure
+ *
+ * Depending on the state of struct iosys_map.is_iomem, tests if the
+ * mapping is NULL.
+ *
+ * Returns:
+ * True if the mapping is NULL, or false otherwise.
+ */
+static inline bool iosys_map_is_null(const struct iosys_map *map)
+{
+	if (map->is_iomem)
+		return !map->vaddr_iomem;
+	return !map->vaddr;
+}
+
+/**
+ * iosys_map_is_set - Tests if the iosys mapping has been set
+ * @map:	The iosys_map structure
+ *
+ * Depending on the state of struct iosys_map.is_iomem, tests if the
+ * mapping has been set.
+ *
+ * Returns:
+ * True if the mapping is been set, or false otherwise.
+ */
+static inline bool iosys_map_is_set(const struct iosys_map *map)
+{
+	return !iosys_map_is_null(map);
+}
+
+/**
+ * iosys_map_clear - Clears a iosys mapping structure
+ * @map:	The iosys_map structure
+ *
+ * Clears all fields to zero, including struct iosys_map.is_iomem, so
+ * mapping structures that were set to point to I/O memory are reset for
+ * system memory. Pointers are cleared to NULL. This is the default.
+ */
+static inline void iosys_map_clear(struct iosys_map *map)
+{
+	if (map->is_iomem) {
+		map->vaddr_iomem = NULL;
+		map->is_iomem = false;
+	} else {
+		map->vaddr = NULL;
+	}
+}
+
+/**
+ * iosys_map_memcpy_to - Memcpy into iosys mapping
+ * @dst:	The iosys_map structure
+ * @src:	The source buffer
+ * @len:	The number of byte in src
+ *
+ * Copies data into a iosys mapping. The source buffer is in system
+ * memory. Depending on the buffer's location, the helper picks the correct
+ * method of accessing the memory.
+ */
+static inline void iosys_map_memcpy_to(struct iosys_map *dst, const void *src,
+				       size_t len)
+{
+	if (dst->is_iomem)
+		memcpy_toio(dst->vaddr_iomem, src, len);
+	else
+		memcpy(dst->vaddr, src, len);
+}
+
+/**
+ * iosys_map_incr - Increments the address stored in a iosys mapping
+ * @map:	The iosys_map structure
+ * @incr:	The number of bytes to increment
+ *
+ * Increments the address stored in a iosys mapping. Depending on the
+ * buffer's location, the correct value will be updated.
+ */
+static inline void iosys_map_incr(struct iosys_map *map, size_t incr)
+{
+	if (map->is_iomem)
+		map->vaddr_iomem += incr;
+	else
+		map->vaddr += incr;
+}
+
+#endif /* __IOSYS_MAP_H__ */
