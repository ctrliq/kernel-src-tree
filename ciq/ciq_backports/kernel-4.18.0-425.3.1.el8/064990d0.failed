net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Maxim Mikityanskiy <maximmi@nvidia.com>
commit 064990d0b65fd99c6fb59006f928a8b631db5816
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/064990d0.failed

The len parameter of mlx5e_xdp_handle is used to output the new packet
length after XDP has processed the packet and returned XDP_PASS.
However, this value can be calculated on the caller site, as the caller
knows if it was an XDP_PASS.

This commit drops the len parameter and moves the calculation to the
caller, reducing the number of parameters passed to the function and
preparing for XDP support in non-linear legacy RQ.

	Signed-off-by: Maxim Mikityanskiy <maximmi@nvidia.com>
	Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 064990d0b65fd99c6fb59006f928a8b631db5816)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
#	drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
index 2daa4d0e5e21,6aa77f0e094e..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
@@@ -120,9 -120,8 +120,13 @@@ mlx5e_xmit_xdp_buff(struct mlx5e_xdpsq 
  
  /* returns true if packet was consumed by xdp */
  bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
++<<<<<<< HEAD
 +		      u32 *len, struct xdp_buff *xdp)
++=======
+ 		      struct bpf_prog *prog, struct xdp_buff *xdp)
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  {
 +	struct bpf_prog *prog = rcu_dereference(rq->xdp_prog);
  	u32 act;
  	int err;
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
index 8d991c3b7a50,20d8af66c072..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
@@@ -48,7 -48,7 +48,11 @@@
  struct mlx5e_xsk_param;
  int mlx5e_xdp_max_mtu(struct mlx5e_params *params, struct mlx5e_xsk_param *xsk);
  bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
++<<<<<<< HEAD
 +		      u32 *len, struct xdp_buff *xdp);
++=======
+ 		      struct bpf_prog *prog, struct xdp_buff *xdp);
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  void mlx5e_xdp_mpwqe_complete(struct mlx5e_xdpsq *sq);
  bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq);
  void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
index 8e7b877d8a12,021da085e603..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
@@@ -30,7 -31,7 +30,11 @@@ struct sk_buff *mlx5e_xsk_skb_from_cqe_
  						    u32 page_idx)
  {
  	struct xdp_buff *xdp = wi->umr.dma_info[page_idx].xsk;
++<<<<<<< HEAD
 +	u32 cqe_bcnt32 = cqe_bcnt;
++=======
+ 	struct bpf_prog *prog;
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  
  	/* Check packet size. Note LRO doesn't use linear SKB */
  	if (unlikely(cqe_bcnt > rq->hw_mtu)) {
@@@ -65,7 -66,8 +69,12 @@@
  	 * allocated first from the Reuse Ring, so it has enough space.
  	 */
  
++<<<<<<< HEAD
 +	if (likely(mlx5e_xdp_handle(rq, NULL, &cqe_bcnt32, xdp))) {
++=======
+ 	prog = rcu_dereference(rq->xdp_prog);
+ 	if (likely(prog && mlx5e_xdp_handle(rq, NULL, prog, xdp))) {
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  		if (likely(__test_and_clear_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags)))
  			__set_bit(page_idx, wi->xdp_xmit_bitmap); /* non-atomic */
  		return NULL; /* page/packet was consumed by XDP */
@@@ -101,7 -104,8 +110,12 @@@ struct sk_buff *mlx5e_xsk_skb_from_cqe_
  		return NULL;
  	}
  
++<<<<<<< HEAD
 +	if (likely(mlx5e_xdp_handle(rq, NULL, &cqe_bcnt, xdp)))
++=======
+ 	prog = rcu_dereference(rq->xdp_prog);
+ 	if (likely(prog && mlx5e_xdp_handle(rq, NULL, prog, xdp)))
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  		return NULL; /* page/packet was consumed by XDP */
  
  	/* XDP_PASS: copy the data from the UMEM to a new SKB. The frame reuse
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index b3f823cc73ba,7c490c0ca370..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -1157,16 -1536,22 +1157,28 @@@ mlx5e_skb_from_cqe_linear(struct mlx5e_
  
  	dma_sync_single_range_for_cpu(rq->pdev, di->addr, wi->offset,
  				      frag_size, DMA_FROM_DEVICE);
 +	net_prefetchw(va); /* xdp_frame data area */
  	net_prefetch(data);
  
 -	prog = rcu_dereference(rq->xdp_prog);
 -	if (prog) {
 -		struct xdp_buff xdp;
 +	mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt, &xdp);
 +	if (mlx5e_xdp_handle(rq, di, &cqe_bcnt, &xdp))
 +		return NULL; /* page/packet was consumed by XDP */
  
++<<<<<<< HEAD
 +	rx_headroom = xdp.data - xdp.data_hard_start;
++=======
+ 		net_prefetchw(va); /* xdp_frame data area */
+ 		mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt, &xdp);
+ 		if (mlx5e_xdp_handle(rq, di, prog, &xdp))
+ 			return NULL; /* page/packet was consumed by XDP */
+ 
+ 		rx_headroom = xdp.data - xdp.data_hard_start;
+ 		metasize = xdp.data - xdp.data_meta;
+ 		cqe_bcnt = xdp.data_end - xdp.data;
+ 	}
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  	frag_size = MLX5_SKB_FRAG_SZ(rx_headroom + cqe_bcnt);
 +	metasize = xdp.data - xdp.data_meta;
  	skb = mlx5e_build_linear_skb(rq, va, frag_size, rx_headroom, cqe_bcnt, metasize);
  	if (unlikely(!skb))
  		return NULL;
@@@ -1476,19 -1867,25 +1488,37 @@@ mlx5e_skb_from_cqe_mpwrq_linear(struct 
  
  	dma_sync_single_range_for_cpu(rq->pdev, di->addr, head_offset,
  				      frag_size, DMA_FROM_DEVICE);
 +	net_prefetchw(va); /* xdp_frame data area */
  	net_prefetch(data);
  
++<<<<<<< HEAD
 +	mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt32, &xdp);
 +	if (mlx5e_xdp_handle(rq, di, &cqe_bcnt32, &xdp)) {
 +		if (__test_and_clear_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags))
 +			__set_bit(page_idx, wi->xdp_xmit_bitmap); /* non-atomic */
 +		return NULL; /* page/packet was consumed by XDP */
++=======
+ 	prog = rcu_dereference(rq->xdp_prog);
+ 	if (prog) {
+ 		struct xdp_buff xdp;
+ 
+ 		net_prefetchw(va); /* xdp_frame data area */
+ 		mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt32, &xdp);
+ 		if (mlx5e_xdp_handle(rq, di, prog, &xdp)) {
+ 			if (__test_and_clear_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags))
+ 				__set_bit(page_idx, wi->xdp_xmit_bitmap); /* non-atomic */
+ 			return NULL; /* page/packet was consumed by XDP */
+ 		}
+ 
+ 		rx_headroom = xdp.data - xdp.data_hard_start;
+ 		metasize = xdp.data - xdp.data_meta;
+ 		cqe_bcnt32 = xdp.data_end - xdp.data;
++>>>>>>> 064990d0b65f (net/mlx5e: Drop the len output parameter from mlx5e_xdp_handle)
  	}
 +
 +	rx_headroom = xdp.data - xdp.data_hard_start;
  	frag_size = MLX5_SKB_FRAG_SZ(rx_headroom + cqe_bcnt32);
 +	metasize = xdp.data - xdp.data_meta;
  	skb = mlx5e_build_linear_skb(rq, va, frag_size, rx_headroom, cqe_bcnt32, metasize);
  	if (unlikely(!skb))
  		return NULL;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
