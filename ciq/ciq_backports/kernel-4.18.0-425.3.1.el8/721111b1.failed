gve: fix unmatched u64_stats_update_end()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Dan Carpenter <dan.carpenter@oracle.com>
commit 721111b1b29c67fd18ac2f69b3a48c06ba996762
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/721111b1.failed

The u64_stats_update_end() call is supposed to be inside the curly
braces so it pairs with the u64_stats_update_begin().

Fixes: 37149e9374bf ("gve: Implement packet continuation for RX.")
	Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 721111b1b29c67fd18ac2f69b3a48c06ba996762)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/google/gve/gve_rx.c
diff --cc drivers/net/ethernet/google/gve/gve_rx.c
index d81effa5cf87,3d04b5aff331..000000000000
--- a/drivers/net/ethernet/google/gve/gve_rx.c
+++ b/drivers/net/ethernet/google/gve/gve_rx.c
@@@ -403,44 -481,52 +403,55 @@@ static bool gve_rx(struct gve_rx_ring *
  		u64_stats_update_end(&rx->statss);
  		return false;
  	}
 -	return true;
 -}
  
 -static struct sk_buff *gve_rx_skb(struct gve_priv *priv, struct gve_rx_ring *rx,
 -				  struct gve_rx_slot_page_info *page_info, struct napi_struct *napi,
 -				  u16 len, union gve_rx_data_slot *data_slot)
 -{
 -	struct net_device *netdev = priv->dev;
 -	struct gve_rx_ctx *ctx = &rx->ctx;
 -	struct sk_buff *skb = NULL;
 +	len = be16_to_cpu(rx_desc->len) - GVE_RX_PAD;
 +	page_info = &rx->data.page_info[idx];
  
 -	if (len <= priv->rx_copybreak && ctx->expected_frag_cnt == 1) {
 +	data_slot = &rx->data.data_ring[idx];
 +	page_bus = (rx->data.raw_addressing) ?
 +			be64_to_cpu(data_slot->addr) & GVE_DATA_SLOT_ADDR_PAGE_MASK :
 +			rx->data.qpl->page_buses[idx];
 +	dma_sync_single_for_cpu(&priv->pdev->dev, page_bus,
 +				PAGE_SIZE, DMA_FROM_DEVICE);
 +
 +	if (len <= priv->rx_copybreak) {
  		/* Just copy small packets */
++<<<<<<< HEAD
 +		skb = gve_rx_copy(dev, napi, page_info, len, GVE_RX_PAD);
 +		u64_stats_update_begin(&rx->statss);
 +		rx->rx_copied_pkt++;
 +		rx->rx_copybreak_pkt++;
 +		u64_stats_update_end(&rx->statss);
++=======
+ 		skb = gve_rx_copy(netdev, napi, page_info, len, GVE_RX_PAD, ctx);
+ 		if (skb) {
+ 			u64_stats_update_begin(&rx->statss);
+ 			rx->rx_copied_pkt++;
+ 			rx->rx_frag_copy_cnt++;
+ 			rx->rx_copybreak_pkt++;
+ 			u64_stats_update_end(&rx->statss);
+ 		}
++>>>>>>> 721111b1b29c (gve: fix unmatched u64_stats_update_end())
  	} else {
 -		if (rx->data.raw_addressing) {
 -			int recycle = gve_rx_can_recycle_buffer(page_info);
 +		u8 can_flip = gve_rx_can_flip_buffers(dev);
 +		int recycle = 0;
  
 -			if (unlikely(recycle < 0)) {
 -				gve_schedule_reset(priv);
 -				return NULL;
 -			}
 -			page_info->can_flip = recycle;
 -			if (page_info->can_flip) {
 -				u64_stats_update_begin(&rx->statss);
 -				rx->rx_frag_flip_cnt++;
 -				u64_stats_update_end(&rx->statss);
 +		if (can_flip) {
 +			recycle = gve_rx_can_recycle_buffer(page_info);
 +			if (recycle < 0) {
 +				if (!rx->data.raw_addressing)
 +					gve_schedule_reset(priv);
 +				return false;
  			}
 -			skb = gve_rx_raw_addressing(&priv->pdev->dev, netdev,
 +		}
 +
 +		page_info->can_flip = can_flip && recycle;
 +		if (rx->data.raw_addressing) {
 +			skb = gve_rx_raw_addressing(&priv->pdev->dev, dev,
  						    page_info, len, napi,
 -						    data_slot,
 -						    rx->packet_buffer_size, ctx);
 +						    data_slot);
  		} else {
 -			if (ctx->reuse_frags) {
 -				u64_stats_update_begin(&rx->statss);
 -				rx->rx_frag_flip_cnt++;
 -				u64_stats_update_end(&rx->statss);
 -			}
 -			skb = gve_rx_qpl(&priv->pdev->dev, netdev, rx,
 +			skb = gve_rx_qpl(&priv->pdev->dev, dev, rx,
  					 page_info, len, napi, data_slot);
  		}
  	}
* Unmerged path drivers/net/ethernet/google/gve/gve_rx.c
