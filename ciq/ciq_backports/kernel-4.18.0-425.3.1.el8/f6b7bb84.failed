PCI: vmd: Offset Client VMD MSI-X vectors

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Jon Derrick <jonathan.derrick@intel.com>
commit f6b7bb847ca821a8aaa1b6da10ee65311e6f15bf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/f6b7bb84.failed

Client VMD platforms have a software-triggered MSI-X vector 0 that will
not forward hardware-remapped MSI from the sub-device domain. This
causes an issue with VMD platforms that use AHCI behind VMD and have a
single MSI-X vector remapped to VMD vector 0. Add a VMD MSI-X vector
offset for these platforms.

Link: https://lore.kernel.org/r/20201102222223.92978-1-jonathan.derrick@intel.com
	Tested-by: Jian-Hong Pan <jhp@endlessos.org>
	Signed-off-by: Jon Derrick <jonathan.derrick@intel.com>
	Signed-off-by: Lorenzo Pieralisi <lorenzo.pieralisi@arm.com>
(cherry picked from commit f6b7bb847ca821a8aaa1b6da10ee65311e6f15bf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/pci/controller/vmd.c
diff --cc drivers/pci/controller/vmd.c
index b16dbfce2e2e,c31e4d5cb146..000000000000
--- a/drivers/pci/controller/vmd.c
+++ b/drivers/pci/controller/vmd.c
@@@ -195,11 -206,11 +202,16 @@@ static irq_hw_number_t vmd_get_hwirq(st
   */
  static struct vmd_irq_list *vmd_next_irq(struct vmd_dev *vmd, struct msi_desc *desc)
  {
- 	int i, best = 1;
  	unsigned long flags;
+ 	int i, best;
  
++<<<<<<< HEAD
 +	if (vmd->msix_count == 1)
 +		return vmd->irqs[0];
++=======
+ 	if (vmd->msix_count == 1 + vmd->first_vec)
+ 		return &vmd->irqs[vmd->first_vec];
++>>>>>>> f6b7bb847ca8 (PCI: vmd: Offset Client VMD MSI-X vectors)
  
  	/*
  	 * White list for fast-interrupt handlers. All others will share the
@@@ -209,17 -220,18 +221,27 @@@
  	case PCI_CLASS_STORAGE_EXPRESS:
  		break;
  	default:
++<<<<<<< HEAD
 +		return vmd->irqs[0];
 +	}
 +
 +	raw_spin_lock_irqsave(&list_lock, flags);
 +	for (i = 1; i < vmd->msix_count; i++)
 +		if (vmd->irqs[i]->count < vmd->irqs[best]->count)
++=======
+ 		return &vmd->irqs[vmd->first_vec];
+ 	}
+ 
+ 	raw_spin_lock_irqsave(&list_lock, flags);
+ 	best = vmd->first_vec + 1;
+ 	for (i = best; i < vmd->msix_count; i++)
+ 		if (vmd->irqs[i].count < vmd->irqs[best].count)
++>>>>>>> f6b7bb847ca8 (PCI: vmd: Offset Client VMD MSI-X vectors)
  			best = i;
 -	vmd->irqs[best].count++;
 +	vmd->irqs[best]->count++;
  	raw_spin_unlock_irqrestore(&list_lock, flags);
  
 -	return &vmd->irqs[best];
 +	return vmd->irqs[best];
  }
  
  static int vmd_msi_init(struct irq_domain *domain, struct msi_domain_info *info,
@@@ -543,6 -535,55 +565,58 @@@ static int vmd_get_bus_number_start(str
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static irqreturn_t vmd_irq(int irq, void *data)
+ {
+ 	struct vmd_irq_list *irqs = data;
+ 	struct vmd_irq *vmdirq;
+ 	int idx;
+ 
+ 	idx = srcu_read_lock(&irqs->srcu);
+ 	list_for_each_entry_rcu(vmdirq, &irqs->irq_list, node)
+ 		generic_handle_irq(vmdirq->virq);
+ 	srcu_read_unlock(&irqs->srcu, idx);
+ 
+ 	return IRQ_HANDLED;
+ }
+ 
+ static int vmd_alloc_irqs(struct vmd_dev *vmd)
+ {
+ 	struct pci_dev *dev = vmd->dev;
+ 	int i, err;
+ 
+ 	vmd->msix_count = pci_msix_vec_count(dev);
+ 	if (vmd->msix_count < 0)
+ 		return -ENODEV;
+ 
+ 	vmd->msix_count = pci_alloc_irq_vectors(dev, vmd->first_vec + 1,
+ 						vmd->msix_count, PCI_IRQ_MSIX);
+ 	if (vmd->msix_count < 0)
+ 		return vmd->msix_count;
+ 
+ 	vmd->irqs = devm_kcalloc(&dev->dev, vmd->msix_count, sizeof(*vmd->irqs),
+ 				 GFP_KERNEL);
+ 	if (!vmd->irqs)
+ 		return -ENOMEM;
+ 
+ 	for (i = 0; i < vmd->msix_count; i++) {
+ 		err = init_srcu_struct(&vmd->irqs[i].srcu);
+ 		if (err)
+ 			return err;
+ 
+ 		INIT_LIST_HEAD(&vmd->irqs[i].irq_list);
+ 		err = devm_request_irq(&dev->dev, pci_irq_vector(dev, i),
+ 				       vmd_irq, IRQF_NO_THREAD,
+ 				       "vmd", &vmd->irqs[i]);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> f6b7bb847ca8 (PCI: vmd: Offset Client VMD MSI-X vectors)
  static int vmd_enable_domain(struct vmd_dev *vmd, unsigned long features)
  {
  	struct pci_sysdata *sd = &vmd->sysdata;
@@@ -697,24 -725,11 +771,25 @@@
  	return 0;
  }
  
 +static irqreturn_t vmd_irq(int irq, void *data)
 +{
 +	struct vmd_irq_list *irqs = data;
 +	struct vmd_irq *vmdirq;
 +	int idx;
 +
 +	idx = srcu_read_lock(&irqs->srcu);
 +	list_for_each_entry_rcu(vmdirq, &irqs->irq_list, node)
 +		generic_handle_irq(vmdirq->virq);
 +	srcu_read_unlock(&irqs->srcu, idx);
 +
 +	return IRQ_HANDLED;
 +}
 +
  static int vmd_probe(struct pci_dev *dev, const struct pci_device_id *id)
  {
+ 	unsigned long features = (unsigned long) id->driver_data;
  	struct vmd_dev *vmd;
 -	int err;
 +	int i, err;
  
  	if (resource_size(&dev->resource[VMD_CFGBAR]) < (1 << 20))
  		return -ENOMEM;
@@@ -737,40 -752,12 +812,49 @@@
  	    dma_set_mask_and_coherent(&dev->dev, DMA_BIT_MASK(32)))
  		return -ENODEV;
  
++<<<<<<< HEAD
 +	vmd->msix_count = pci_msix_vec_count(dev);
 +	if (vmd->msix_count < 0)
 +		return -ENODEV;
 +
 +	vmd->msix_count = pci_alloc_irq_vectors(dev, 1, vmd->msix_count,
 +					PCI_IRQ_MSIX);
 +	if (vmd->msix_count < 0)
 +		return vmd->msix_count;
 +
 +	vmd->irqs = devm_kcalloc(&dev->dev, vmd->msix_count, sizeof(*vmd->irqs),
 +				 GFP_KERNEL);
 +	if (!vmd->irqs)
 +		return -ENOMEM;
 +
 +	for (i = 0; i < vmd->msix_count; i++) {
 +		vmd->irqs[i] = devm_kzalloc(&dev->dev, sizeof(**vmd->irqs),
 +					    GFP_KERNEL);
 +		if (!vmd->irqs[i])
 +			return -ENOMEM;
 +	}
 +
 +	for (i = 0; i < vmd->msix_count; i++) {
 +		err = init_srcu_struct(&vmd->irqs[i]->srcu);
 +		if (err)
 +			return err;
 +
 +		INIT_LIST_HEAD(&vmd->irqs[i]->irq_list);
 +		vmd->irqs[i]->index = i;
 +		err = devm_request_irq(&dev->dev, pci_irq_vector(dev, i),
 +				       vmd_irq, IRQF_NO_THREAD,
 +				       "vmd", vmd->irqs[i]);
 +		if (err)
 +			return err;
 +	}
++=======
+ 	if (features & VMD_FEAT_OFFSET_FIRST_VECTOR)
+ 		vmd->first_vec = 1;
+ 
+ 	err = vmd_alloc_irqs(vmd);
+ 	if (err)
+ 		return err;
++>>>>>>> f6b7bb847ca8 (PCI: vmd: Offset Client VMD MSI-X vectors)
  
  	spin_lock_init(&vmd->cfg_lock);
  	pci_set_drvdata(dev, vmd);
* Unmerged path drivers/pci/controller/vmd.c
