arm64: Add percpu vectors for EL1

jira LE-1907
cve CVE-2022-23960
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author James Morse <james.morse@arm.com>
commit bd09128d16fac3c34b80bd6a29088ac632e8ce09
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/bd09128d.failed

The Spectre-BHB workaround adds a firmware call to the vectors. This
is needed on some CPUs, but not others. To avoid the unaffected CPU in
a big/little pair from making the firmware call, create per cpu vectors.

The per-cpu vectors only apply when returning from EL0.

Systems using KPTI can use the canonical 'full-fat' vectors directly at
EL1, the trampoline exit code will switch to this_cpu_vector on exit to
EL0. Systems not using KPTI should always use this_cpu_vector.

this_cpu_vector will point at a vector in tramp_vecs or
__bp_harden_el1_vectors, depending on whether KPTI is in use.

	Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
	Signed-off-by: James Morse <james.morse@arm.com>
(cherry picked from commit bd09128d16fac3c34b80bd6a29088ac632e8ce09)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/vectors.h
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/kernel/entry.S
#	arch/arm64/kvm/hyp/vhe/switch.c
diff --cc arch/arm64/kernel/cpufeature.c
index 0854c01dc6ba,45fed4974c44..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -78,17 -67,27 +78,24 @@@
  #include <linux/crash_dump.h>
  #include <linux/sort.h>
  #include <linux/stop_machine.h>
 -#include <linux/sysfs.h>
  #include <linux/types.h>
 -#include <linux/minmax.h>
  #include <linux/mm.h>
  #include <linux/cpu.h>
++<<<<<<< HEAD
++=======
+ #include <linux/kasan.h>
+ #include <linux/percpu.h>
+ 
++>>>>>>> bd09128d16fa (arm64: Add percpu vectors for EL1)
  #include <asm/cpu.h>
  #include <asm/cpufeature.h>
  #include <asm/cpu_ops.h>
  #include <asm/fpsimd.h>
 -#include <asm/insn.h>
 -#include <asm/kvm_host.h>
  #include <asm/mmu_context.h>
 -#include <asm/mte.h>
  #include <asm/processor.h>
 -#include <asm/smp.h>
  #include <asm/sysreg.h>
  #include <asm/traps.h>
+ #include <asm/vectors.h>
  #include <asm/virt.h>
  
  /* Kernel representation of AT_HWCAP and AT_HWCAP2 */
@@@ -114,6 -113,26 +121,8 @@@ DECLARE_BITMAP(boot_capabilities, ARM64
  bool arm64_use_ng_mappings = false;
  EXPORT_SYMBOL(arm64_use_ng_mappings);
  
+ DEFINE_PER_CPU_READ_MOSTLY(const char *, this_cpu_vector) = vectors;
+ 
 -/*
 - * Permit PER_LINUX32 and execve() of 32-bit binaries even if not all CPUs
 - * support it?
 - */
 -static bool __read_mostly allow_mismatched_32bit_el0;
 -
 -/*
 - * Static branch enabled only if allow_mismatched_32bit_el0 is set and we have
 - * seen at least one CPU capable of 32-bit EL0.
 - */
 -DEFINE_STATIC_KEY_FALSE(arm64_mismatched_32bit_el0);
 -
 -/*
 - * Mask of CPUs supporting 32-bit EL0.
 - * Only valid if arm64_mismatched_32bit_el0 is enabled.
 - */
 -static cpumask_var_t cpu_32bit_el0_mask __cpumask_var_read_mostly;
 -
  /*
   * Flag to indicate if we have computed the system wide
   * capabilities based on the boot time active CPUs. This
diff --cc arch/arm64/kernel/entry.S
index af24e27e2389,a62fee121138..000000000000
--- a/arch/arm64/kernel/entry.S
+++ b/arch/arm64/kernel/entry.S
@@@ -60,18 -35,9 +60,22 @@@
  	.endr
  	.endm
  
 -	.macro kernel_ventry, el:req, ht:req, regsize:req, label:req
 +/*
 + * Bad Abort numbers
 + *-----------------
 + */
 +#define BAD_SYNC	0
 +#define BAD_IRQ		1
 +#define BAD_FIQ		2
 +#define BAD_ERROR	3
 +
 +	.macro kernel_ventry, el, label, regsize = 64
  	.align 7
++<<<<<<< HEAD
 +#ifdef CONFIG_UNMAP_KERNEL_AT_EL0
++=======
+ .Lventry_start\@:
++>>>>>>> bd09128d16fa (arm64: Add percpu vectors for EL1)
  	.if	\el == 0
  	/*
  	 * This must be the first instruction of the EL0 vector entries. It is
@@@ -86,9 -52,8 +90,8 @@@
  	.endif
  .Lskip_tramp_vectors_cleanup\@:
  	.endif
- #endif
  
 -	sub	sp, sp, #PT_REGS_SIZE
 +	sub	sp, sp, #S_FRAME_SIZE
  #ifdef CONFIG_VMAP_STACK
  	/*
  	 * Test whether the SP has overflowed, without corrupting a GPR.
@@@ -839,12 -709,18 +842,19 @@@ alternative_else_nop_endi
  	.endm
  
  	.macro tramp_exit, regsize = 64
++<<<<<<< HEAD
 +	adr	x30, tramp_vectors
++=======
+ 	tramp_data_read_var	x30, this_cpu_vector
+ 	get_this_cpu_offset x29
+ 	ldr	x30, [x30, x29]
+ 
++>>>>>>> bd09128d16fa (arm64: Add percpu vectors for EL1)
  	msr	vbar_el1, x30
 -	ldr	lr, [sp, #S_LR]
 -	tramp_unmap_kernel	x29
 +	tramp_unmap_kernel	x30
  	.if	\regsize == 64
 -	mrs	x29, far_el1
 +	mrs	x30, far_el1
  	.endif
 -	add	sp, sp, #PT_REGS_SIZE		// restore sp
  	eret
  	sb
  	.endm
@@@ -880,7 -767,14 +890,16 @@@ SYM_CODE_END(tramp_exit_compat
  	.pushsection ".rodata", "a"
  	.align PAGE_SHIFT
  SYM_DATA_START(__entry_tramp_data_start)
 -__entry_tramp_data_vectors:
  	.quad	vectors
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ARM_SDE_INTERFACE
+ __entry_tramp_data___sdei_asm_handler:
+ 	.quad	__sdei_asm_handler
+ #endif /* CONFIG_ARM_SDE_INTERFACE */
+ __entry_tramp_data_this_cpu_vector:
+ 	.quad	this_cpu_vector
++>>>>>>> bd09128d16fa (arm64: Add percpu vectors for EL1)
  SYM_DATA_END(__entry_tramp_data_start)
  	.popsection				// .rodata
  #endif /* CONFIG_RANDOMIZE_BASE */
diff --cc arch/arm64/kvm/hyp/vhe/switch.c
index 049655fcf582,54af47005e45..000000000000
--- a/arch/arm64/kvm/hyp/vhe/switch.c
+++ b/arch/arm64/kvm/hyp/vhe/switch.c
@@@ -25,8 -26,12 +26,12 @@@
  #include <asm/debug-monitors.h>
  #include <asm/processor.h>
  #include <asm/thread_info.h>
++<<<<<<< HEAD
++=======
+ #include <asm/vectors.h>
++>>>>>>> bd09128d16fa (arm64: Add percpu vectors for EL1)
  
 -/* VHE specific context */
 -DEFINE_PER_CPU(struct kvm_host_data, kvm_host_data);
 -DEFINE_PER_CPU(struct kvm_cpu_context, kvm_hyp_ctxt);
 -DEFINE_PER_CPU(unsigned long, kvm_hyp_vector);
 +const char __hyp_panic_string[] = "HYP panic:\nPS:%08llx PC:%016llx ESR:%08llx\nFAR:%016llx HPFAR:%016llx PAR:%016llx\nVCPU:%p\n";
  
  static void __activate_traps(struct kvm_vcpu *vcpu)
  {
* Unmerged path arch/arm64/include/asm/vectors.h
* Unmerged path arch/arm64/include/asm/vectors.h
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/kernel/entry.S
* Unmerged path arch/arm64/kvm/hyp/vhe/switch.c
