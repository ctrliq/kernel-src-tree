net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-425.3.1.el8
commit-author Rongwei Liu <rongweil@nvidia.com>
commit f51bb51793008d559d45a5fb0d856b2deb87890a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-425.3.1.el8/f51bb517.failed

Target to reduce the memory consumption in large scale of flow rules.

They can be calculated quickly from buddy memory pool.
1. num_of_entries calls dr_icm_pool_get_chunk_num_of_entries().
2. byte_size calls dr_icm_pool_get_chunk_byte_size().

Use chunk size in dr_icm_chunk to speed up and the one in dr_ste_htbl
will be removed in the upcoming commit.

This commit reduce 8 bytes from struct mlx5_dr_icm_chunk and its
current size is 56 bytes.

	Signed-off-by: Rongwei Liu <rongweil@nvidia.com>
	Reviewed-by: Shun Hao <shunh@nvidia.com>
	Reviewed-by: Yevgeny Kliteynik <kliteyn@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit f51bb51793008d559d45a5fb0d856b2deb87890a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/steering/dr_icm_pool.c
#	drivers/net/ethernet/mellanox/mlx5/core/steering/dr_rule.c
#	drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c
#	drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/steering/dr_icm_pool.c
index 8ad8d73e17f0,4ca67fa24cc6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_icm_pool.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_icm_pool.c
@@@ -57,6 -57,36 +57,39 @@@ static int dr_icm_create_dm_mkey(struc
  	return mlx5_core_create_mkey(mdev, mkey, in, inlen);
  }
  
++<<<<<<< HEAD
++=======
+ u64 mlx5dr_icm_pool_get_chunk_mr_addr(struct mlx5dr_icm_chunk *chunk)
+ {
+ 	u32 offset = mlx5dr_icm_pool_dm_type_to_entry_size(chunk->buddy_mem->pool->icm_type);
+ 
+ 	return (u64)offset * chunk->seg;
+ }
+ 
+ u32 mlx5dr_icm_pool_get_chunk_rkey(struct mlx5dr_icm_chunk *chunk)
+ {
+ 	return chunk->buddy_mem->icm_mr->mkey;
+ }
+ 
+ u64 mlx5dr_icm_pool_get_chunk_icm_addr(struct mlx5dr_icm_chunk *chunk)
+ {
+ 	u32 size = mlx5dr_icm_pool_dm_type_to_entry_size(chunk->buddy_mem->pool->icm_type);
+ 
+ 	return (u64)chunk->buddy_mem->icm_mr->icm_start_addr + size * chunk->seg;
+ }
+ 
+ u32 mlx5dr_icm_pool_get_chunk_byte_size(struct mlx5dr_icm_chunk *chunk)
+ {
+ 	return mlx5dr_icm_pool_chunk_size_to_byte(chunk->size,
+ 			chunk->buddy_mem->pool->icm_type);
+ }
+ 
+ u32 mlx5dr_icm_pool_get_chunk_num_of_entries(struct mlx5dr_icm_chunk *chunk)
+ {
+ 	return mlx5dr_icm_pool_chunk_size_to_entries(chunk->size);
+ }
+ 
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  static struct mlx5dr_icm_mr *
  dr_icm_pool_mr_create(struct mlx5dr_icm_pool *pool)
  {
@@@ -298,15 -329,8 +332,19 @@@ dr_icm_chunk_create(struct mlx5dr_icm_p
  
  	offset = mlx5dr_icm_pool_dm_type_to_entry_size(pool->icm_type) * seg;
  
++<<<<<<< HEAD
 +	chunk->rkey = buddy_mem_pool->icm_mr->mkey.key;
 +	chunk->mr_addr = offset;
 +	chunk->icm_addr =
 +		(uintptr_t)buddy_mem_pool->icm_mr->icm_start_addr + offset;
 +	chunk->num_of_entries =
 +		mlx5dr_icm_pool_chunk_size_to_entries(chunk_size);
 +	chunk->byte_size =
 +		mlx5dr_icm_pool_chunk_size_to_byte(chunk_size, pool->icm_type);
++=======
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  	chunk->seg = seg;
+ 	chunk->size = chunk_size;
  	chunk->buddy_mem = buddy_mem_pool;
  
  	if (pool->icm_type == DR_ICM_TYPE_STE)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/steering/dr_rule.c
index b4374578425b,91be9d9d95a8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_rule.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_rule.c
@@@ -447,8 -449,8 +447,13 @@@ dr_rule_rehash_htbl(struct mlx5dr_rule 
  		 */
  		mlx5dr_ste_set_hit_addr(dmn->ste_ctx,
  					prev_htbl->ste_arr[0].hw_ste,
++<<<<<<< HEAD
 +					new_htbl->chunk->icm_addr,
 +					new_htbl->chunk->num_of_entries);
++=======
+ 					mlx5dr_icm_pool_get_chunk_icm_addr(new_htbl->chunk),
+ 					mlx5dr_icm_pool_get_chunk_num_of_entries(new_htbl->chunk));
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  
  		ste_to_update = &prev_htbl->ste_arr[0];
  	} else {
diff --cc drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c
index 518e949847a3,3ff568e80e0e..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c
@@@ -141,7 -143,8 +142,12 @@@ static void dr_ste_always_hit_htbl(stru
  
  	ste_ctx->set_byte_mask(hw_ste, next_htbl->byte_mask);
  	ste_ctx->set_next_lu_type(hw_ste, next_htbl->lu_type);
++<<<<<<< HEAD
 +	ste_ctx->set_hit_addr(hw_ste, chunk->icm_addr, chunk->num_of_entries);
++=======
+ 	ste_ctx->set_hit_addr(hw_ste, mlx5dr_icm_pool_get_chunk_icm_addr(chunk),
+ 			      mlx5dr_icm_pool_get_chunk_num_of_entries(chunk));
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  
  	dr_ste_set_always_hit((struct dr_hw_ste_format *)ste->hw_ste);
  }
@@@ -364,9 -367,11 +370,17 @@@ void mlx5dr_ste_set_hit_addr_by_next_ht
  					  u8 *hw_ste,
  					  struct mlx5dr_ste_htbl *next_htbl)
  {
++<<<<<<< HEAD
 +	struct mlx5dr_icm_chunk *chunk = next_htbl->chunk;
 +
 +	ste_ctx->set_hit_addr(hw_ste, chunk->icm_addr, chunk->num_of_entries);
++=======
+ 	u64 icm_addr = mlx5dr_icm_pool_get_chunk_icm_addr(next_htbl->chunk);
+ 	u32 num_entries =
+ 		mlx5dr_icm_pool_get_chunk_num_of_entries(next_htbl->chunk);
+ 
+ 	ste_ctx->set_hit_addr(hw_ste, icm_addr, num_entries);
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  }
  
  void mlx5dr_ste_prepare_for_postsend(struct mlx5dr_ste_ctx *ste_ctx,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h
index 40f78ab4676e,9660296d36aa..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h
@@@ -1097,11 -1097,6 +1097,14 @@@ int mlx5dr_rule_get_reverse_rule_member
  struct mlx5dr_icm_chunk {
  	struct mlx5dr_icm_buddy_mem *buddy_mem;
  	struct list_head chunk_list;
++<<<<<<< HEAD
 +	u32 rkey;
 +	u32 num_of_entries;
 +	u32 byte_size;
 +	u64 icm_addr;
 +	u64 mr_addr;
++=======
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  
  	/* indicates the index of this chunk in the whole memory,
  	 * used for deleting the chunk from the buddy
@@@ -1146,6 -1142,12 +1150,15 @@@ int mlx5dr_matcher_select_builders(stru
  				   enum mlx5dr_ipv outer_ipv,
  				   enum mlx5dr_ipv inner_ipv);
  
++<<<<<<< HEAD
++=======
+ u64 mlx5dr_icm_pool_get_chunk_mr_addr(struct mlx5dr_icm_chunk *chunk);
+ u32 mlx5dr_icm_pool_get_chunk_rkey(struct mlx5dr_icm_chunk *chunk);
+ u64 mlx5dr_icm_pool_get_chunk_icm_addr(struct mlx5dr_icm_chunk *chunk);
+ u32 mlx5dr_icm_pool_get_chunk_num_of_entries(struct mlx5dr_icm_chunk *chunk);
+ u32 mlx5dr_icm_pool_get_chunk_byte_size(struct mlx5dr_icm_chunk *chunk);
+ 
++>>>>>>> f51bb5179300 (net/mlx5: DR, Remove num_of_entries byte_size from struct mlx5_dr_icm_chunk)
  static inline int
  mlx5dr_icm_pool_dm_type_to_entry_size(enum mlx5dr_icm_type icm_type)
  {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/steering/dr_icm_pool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/steering/dr_rule.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_send.c b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_send.c
index bfb14b4b1906..c385e9cc7378 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_send.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_send.c
@@ -407,17 +407,17 @@ static int dr_get_tbl_copy_details(struct mlx5dr_domain *dmn,
 				   int *iterations,
 				   int *num_stes)
 {
+	u32 chunk_byte_size = mlx5dr_icm_pool_get_chunk_byte_size(htbl->chunk);
 	int alloc_size;
 
-	if (htbl->chunk->byte_size > dmn->send_ring->max_post_send_size) {
-		*iterations = htbl->chunk->byte_size /
-			dmn->send_ring->max_post_send_size;
+	if (chunk_byte_size > dmn->send_ring->max_post_send_size) {
+		*iterations = chunk_byte_size / dmn->send_ring->max_post_send_size;
 		*byte_size = dmn->send_ring->max_post_send_size;
 		alloc_size = *byte_size;
 		*num_stes = *byte_size / DR_STE_SIZE;
 	} else {
 		*iterations = 1;
-		*num_stes = htbl->chunk->num_of_entries;
+		*num_stes = mlx5dr_icm_pool_get_chunk_num_of_entries(htbl->chunk);
 		alloc_size = *num_stes * DR_STE_SIZE;
 	}
 
@@ -462,7 +462,7 @@ int mlx5dr_send_postsend_htbl(struct mlx5dr_domain *dmn,
 			      struct mlx5dr_ste_htbl *htbl,
 			      u8 *formatted_ste, u8 *mask)
 {
-	u32 byte_size = htbl->chunk->byte_size;
+	u32 byte_size = mlx5dr_icm_pool_get_chunk_byte_size(htbl->chunk);
 	int num_stes_per_iter;
 	int iterations;
 	u8 *data;
@@ -530,7 +530,7 @@ int mlx5dr_send_postsend_formatted_htbl(struct mlx5dr_domain *dmn,
 					u8 *ste_init_data,
 					bool update_hw_ste)
 {
-	u32 byte_size = htbl->chunk->byte_size;
+	u32 byte_size = mlx5dr_icm_pool_get_chunk_byte_size(htbl->chunk);
 	int iterations;
 	int num_stes;
 	u8 *copy_dst;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/steering/dr_types.h
