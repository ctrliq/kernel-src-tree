bpf, sock_map: Move cancel_work_sync() out of sock lock

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-499.el8
commit-author Cong Wang <cong.wang@bytedance.com>
commit 8bbabb3fddcd0f858be69ed5abc9b470a239d6f2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-499.el8/8bbabb3f.failed

Stanislav reported a lockdep warning, which is caused by the
cancel_work_sync() called inside sock_map_close(), as analyzed
below by Jakub:

psock->work.func = sk_psock_backlog()
  ACQUIRE psock->work_mutex
    sk_psock_handle_skb()
      skb_send_sock()
        __skb_send_sock()
          sendpage_unlocked()
            kernel_sendpage()
              sock->ops->sendpage = inet_sendpage()
                sk->sk_prot->sendpage = tcp_sendpage()
                  ACQUIRE sk->sk_lock
                    tcp_sendpage_locked()
                  RELEASE sk->sk_lock
  RELEASE psock->work_mutex

sock_map_close()
  ACQUIRE sk->sk_lock
  sk_psock_stop()
    sk_psock_clear_state(psock, SK_PSOCK_TX_ENABLED)
    cancel_work_sync()
      __cancel_work_timer()
        __flush_work()
          // wait for psock->work to finish
  RELEASE sk->sk_lock

We can move the cancel_work_sync() out of the sock lock protection,
but still before saved_close() was called.

Fixes: 799aa7f98d53 ("skmsg: Avoid lock_sock() in sk_psock_backlog()")
	Reported-by: Stanislav Fomichev <sdf@google.com>
	Signed-off-by: Cong Wang <cong.wang@bytedance.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Tested-by: Jakub Sitnicki <jakub@cloudflare.com>
	Acked-by: John Fastabend <john.fastabend@gmail.com>
	Acked-by: Jakub Sitnicki <jakub@cloudflare.com>
Link: https://lore.kernel.org/bpf/20221102043417.279409-1-xiyou.wangcong@gmail.com
(cherry picked from commit 8bbabb3fddcd0f858be69ed5abc9b470a239d6f2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/sock_map.c
diff --cc net/core/sock_map.c
index 531d545293f3,81beb16ab1eb..000000000000
--- a/net/core/sock_map.c
+++ b/net/core/sock_map.c
@@@ -1517,6 -1577,30 +1517,33 @@@ void sock_map_unhash(struct sock *sk
  	rcu_read_unlock();
  	saved_unhash(sk);
  }
++<<<<<<< HEAD
++=======
+ EXPORT_SYMBOL_GPL(sock_map_unhash);
+ 
+ void sock_map_destroy(struct sock *sk)
+ {
+ 	void (*saved_destroy)(struct sock *sk);
+ 	struct sk_psock *psock;
+ 
+ 	rcu_read_lock();
+ 	psock = sk_psock_get(sk);
+ 	if (unlikely(!psock)) {
+ 		rcu_read_unlock();
+ 		if (sk->sk_prot->destroy)
+ 			sk->sk_prot->destroy(sk);
+ 		return;
+ 	}
+ 
+ 	saved_destroy = psock->saved_destroy;
+ 	sock_map_remove_links(sk, psock);
+ 	rcu_read_unlock();
+ 	sk_psock_stop(psock);
+ 	sk_psock_put(sk, psock);
+ 	saved_destroy(sk);
+ }
+ EXPORT_SYMBOL_GPL(sock_map_destroy);
++>>>>>>> 8bbabb3fddcd (bpf, sock_map: Move cancel_work_sync() out of sock lock)
  
  void sock_map_close(struct sock *sk, long timeout)
  {
@@@ -1535,11 -1619,13 +1562,12 @@@
  	saved_close = psock->saved_close;
  	sock_map_remove_links(sk, psock);
  	rcu_read_unlock();
- 	sk_psock_stop(psock, true);
- 	sk_psock_put(sk, psock);
+ 	sk_psock_stop(psock);
  	release_sock(sk);
+ 	cancel_work_sync(&psock->work);
+ 	sk_psock_put(sk, psock);
  	saved_close(sk, timeout);
  }
 -EXPORT_SYMBOL_GPL(sock_map_close);
  
  static int sock_map_iter_attach_target(struct bpf_prog *prog,
  				       union bpf_iter_link_info *linfo,
diff --git a/include/linux/skmsg.h b/include/linux/skmsg.h
index 94e2a1f6e58d..5737b8a4a902 100644
--- a/include/linux/skmsg.h
+++ b/include/linux/skmsg.h
@@ -384,7 +384,7 @@ static inline void sk_psock_report_error(struct sk_psock *psock, int err)
 }
 
 struct sk_psock *sk_psock_init(struct sock *sk, int node);
-void sk_psock_stop(struct sk_psock *psock, bool wait);
+void sk_psock_stop(struct sk_psock *psock);
 
 #if IS_ENABLED(CONFIG_BPF_STREAM_PARSER)
 int sk_psock_init_strp(struct sock *sk, struct sk_psock *psock);
diff --git a/net/core/skmsg.c b/net/core/skmsg.c
index dd2378dab23a..b4d6b6a3d27c 100644
--- a/net/core/skmsg.c
+++ b/net/core/skmsg.c
@@ -767,16 +767,13 @@ static void sk_psock_link_destroy(struct sk_psock *psock)
 	}
 }
 
-void sk_psock_stop(struct sk_psock *psock, bool wait)
+void sk_psock_stop(struct sk_psock *psock)
 {
 	spin_lock_bh(&psock->ingress_lock);
 	sk_psock_clear_state(psock, SK_PSOCK_TX_ENABLED);
 	sk_psock_cork_free(psock);
 	__sk_psock_zap_ingress(psock);
 	spin_unlock_bh(&psock->ingress_lock);
-
-	if (wait)
-		cancel_work_sync(&psock->work);
 }
 
 static void sk_psock_done_strp(struct sk_psock *psock);
@@ -814,7 +811,7 @@ void sk_psock_drop(struct sock *sk, struct sk_psock *psock)
 		sk_psock_stop_verdict(sk, psock);
 	write_unlock_bh(&sk->sk_callback_lock);
 
-	sk_psock_stop(psock, false);
+	sk_psock_stop(psock);
 
 	INIT_RCU_WORK(&psock->rwork, sk_psock_destroy);
 	queue_rcu_work(system_wq, &psock->rwork);
* Unmerged path net/core/sock_map.c
