nfs: fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests

jira KERNEL-186
cve CVE-2025-39697
Rebuild_History Non-Buildable kernel-4.18.0-553.85.1.el8_10
commit-author Christoph Hellwig <hch@lst.de>
commit 25edbcac6e32eab345e470d56ca9974a577b878b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.85.1.el8_10/25edbcac.failed

Fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests to
prepare for future changes to this code, and move the helpers to write.c
as well.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit 25edbcac6e32eab345e470d56ca9974a577b878b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/nfs/pagelist.c
#	fs/nfs/write.c
#	include/linux/nfs_page.h
diff --cc fs/nfs/pagelist.c
index 9f10091ad777,fa7971072900..000000000000
--- a/fs/nfs/pagelist.c
+++ b/fs/nfs/pagelist.c
@@@ -148,102 -188,6 +148,105 @@@ nfs_async_iocounter_wait(struct rpc_tas
  EXPORT_SYMBOL_GPL(nfs_async_iocounter_wait);
  
  /*
++<<<<<<< HEAD
 + * nfs_page_lock_head_request - page lock the head of the page group
 + * @req: any member of the page group
 + */
 +struct nfs_page *
 +nfs_page_group_lock_head(struct nfs_page *req)
 +{
 +	struct nfs_page *head = req->wb_head;
 +
 +	while (!nfs_lock_request(head)) {
 +		int ret = nfs_wait_on_request(head);
 +		if (ret < 0)
 +			return ERR_PTR(ret);
 +	}
 +	if (head != req)
 +		kref_get(&head->wb_kref);
 +	return head;
 +}
 +
 +/*
 + * nfs_unroll_locks -  unlock all newly locked reqs and wait on @req
 + * @head: head request of page group, must be holding head lock
 + * @req: request that couldn't lock and needs to wait on the req bit lock
 + *
 + * This is a helper function for nfs_lock_and_join_requests
 + * returns 0 on success, < 0 on error.
 + */
 +static void
 +nfs_unroll_locks(struct nfs_page *head, struct nfs_page *req)
 +{
 +	struct nfs_page *tmp;
 +
 +	/* relinquish all the locks successfully grabbed this run */
 +	for (tmp = head->wb_this_page ; tmp != req; tmp = tmp->wb_this_page) {
 +		if (!kref_read(&tmp->wb_kref))
 +			continue;
 +		nfs_unlock_and_release_request(tmp);
 +	}
 +}
 +
 +/*
 + * nfs_page_group_lock_subreq -  try to lock a subrequest
 + * @head: head request of page group
 + * @subreq: request to lock
 + *
 + * This is a helper function for nfs_lock_and_join_requests which
 + * must be called with the head request and page group both locked.
 + * On error, it returns with the page group unlocked.
 + */
 +static int
 +nfs_page_group_lock_subreq(struct nfs_page *head, struct nfs_page *subreq)
 +{
 +	int ret;
 +
 +	if (!kref_get_unless_zero(&subreq->wb_kref))
 +		return 0;
 +	while (!nfs_lock_request(subreq)) {
 +		nfs_page_group_unlock(head);
 +		ret = nfs_wait_on_request(subreq);
 +		if (!ret)
 +			ret = nfs_page_group_lock(head);
 +		if (ret < 0) {
 +			nfs_unroll_locks(head, subreq);
 +			nfs_release_request(subreq);
 +			return ret;
 +		}
 +	}
 +	return 0;
 +}
 +
 +/*
 + * nfs_page_group_lock_subrequests -  try to lock the subrequests
 + * @head: head request of page group
 + *
 + * This is a helper function for nfs_lock_and_join_requests which
 + * must be called with the head request locked.
 + */
 +int nfs_page_group_lock_subrequests(struct nfs_page *head)
 +{
 +	struct nfs_page *subreq;
 +	int ret;
 +
 +	ret = nfs_page_group_lock(head);
 +	if (ret < 0)
 +		return ret;
 +	/* lock each request in the page group */
 +	for (subreq = head->wb_this_page; subreq != head;
 +			subreq = subreq->wb_this_page) {
 +		ret = nfs_page_group_lock_subreq(head, subreq);
 +		if (ret < 0)
 +			return ret;
 +	}
 +	nfs_page_group_unlock(head);
 +	return 0;
 +}
 +
 +/*
++=======
++>>>>>>> 25edbcac6e32 (nfs: fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests)
   * nfs_page_set_headlock - set the request PG_HEADLOCK
   * @req: request that is to be locked
   *
diff --cc fs/nfs/write.c
index 320ba093a736,0fe9d7bf34db..000000000000
--- a/fs/nfs/write.c
+++ b/fs/nfs/write.c
@@@ -536,9 -478,60 +536,60 @@@ nfs_join_page_group(struct nfs_page *he
  	nfs_destroy_unlinked_subrequests(destroy_list, head, inode);
  }
  
+ /*
+  * nfs_unroll_locks -  unlock all newly locked reqs and wait on @req
+  * @head: head request of page group, must be holding head lock
+  * @req: request that couldn't lock and needs to wait on the req bit lock
+  *
+  * This is a helper function for nfs_lock_and_join_requests
+  * returns 0 on success, < 0 on error.
+  */
+ static void
+ nfs_unroll_locks(struct nfs_page *head, struct nfs_page *req)
+ {
+ 	struct nfs_page *tmp;
+ 
+ 	/* relinquish all the locks successfully grabbed this run */
+ 	for (tmp = head->wb_this_page ; tmp != req; tmp = tmp->wb_this_page) {
+ 		if (!kref_read(&tmp->wb_kref))
+ 			continue;
+ 		nfs_unlock_and_release_request(tmp);
+ 	}
+ }
+ 
+ /*
+  * nfs_page_group_lock_subreq -  try to lock a subrequest
+  * @head: head request of page group
+  * @subreq: request to lock
+  *
+  * This is a helper function for nfs_lock_and_join_requests which
+  * must be called with the head request and page group both locked.
+  * On error, it returns with the page group unlocked.
+  */
+ static int
+ nfs_page_group_lock_subreq(struct nfs_page *head, struct nfs_page *subreq)
+ {
+ 	int ret;
+ 
+ 	if (!kref_get_unless_zero(&subreq->wb_kref))
+ 		return 0;
+ 	while (!nfs_lock_request(subreq)) {
+ 		nfs_page_group_unlock(head);
+ 		ret = nfs_wait_on_request(subreq);
+ 		if (!ret)
+ 			ret = nfs_page_group_lock(head);
+ 		if (ret < 0) {
+ 			nfs_unroll_locks(head, subreq);
+ 			nfs_release_request(subreq);
+ 			return ret;
+ 		}
+ 	}
+ 	return 0;
+ }
+ 
  /*
   * nfs_lock_and_join_requests - join all subreqs to the head req
 - * @folio: the folio used to lookup the "page group" of nfs_page structures
 + * @page: the page used to lookup the "page group" of nfs_page structures
   *
   * This function joins all sub requests to the head request by first
   * locking all requests in the group, cancelling any pending operations
@@@ -548,14 -541,14 +599,20 @@@
   *
   * Returns a locked, referenced pointer to the head request - which after
   * this call is guaranteed to be the only request associated with the page.
 - * Returns NULL if no requests are found for @folio, or a ERR_PTR if an
 + * Returns NULL if no requests are found for @page, or a ERR_PTR if an
   * error was encountered.
   */
 -static struct nfs_page *nfs_lock_and_join_requests(struct folio *folio)
 +static struct nfs_page *
 +nfs_lock_and_join_requests(struct page *page)
  {
++<<<<<<< HEAD
 +	struct inode *inode = page_file_mapping(page)->host;
 +	struct nfs_page *head;
++=======
+ 	struct inode *inode = folio->mapping->host;
+ 	struct nfs_page *head, *subreq;
+ 	struct nfs_commit_info cinfo;
++>>>>>>> 25edbcac6e32 (nfs: fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests)
  	int ret;
  
  	/*
@@@ -563,20 -556,49 +620,40 @@@
  	 * reference to the whole page group - the group will not be destroyed
  	 * until the head reference is released.
  	 */
 -retry:
 -	head = nfs_folio_find_head_request(folio);
 -	if (!head)
 -		return NULL;
 +	head = nfs_find_and_lock_page_request(page);
 +	if (IS_ERR_OR_NULL(head))
 +		return head;
  
 -	while (!nfs_lock_request(head)) {
 -		ret = nfs_wait_on_request(head);
 -		if (ret < 0)
 -			return ERR_PTR(ret);
 -	}
 -
 -	/* Ensure that nobody removed the request before we locked it */
 -	if (head != folio->private) {
++<<<<<<< HEAD
 +	/* lock each request in the page group */
 +	ret = nfs_page_group_lock_subrequests(head);
 +	if (ret < 0) {
  		nfs_unlock_and_release_request(head);
 -		goto retry;
 +		return ERR_PTR(ret);
  	}
  
 -	ret = nfs_cancel_remove_inode(head, inode);
 -	if (ret < 0)
 -		goto out_unlock;
 +	nfs_join_page_group(head, inode);
  
++=======
+ 	ret = nfs_page_group_lock(head);
+ 	if (ret < 0)
+ 		goto out_unlock;
+ 
+ 	/* lock each request in the page group */
+ 	for (subreq = head->wb_this_page;
+ 	     subreq != head;
+ 	     subreq = subreq->wb_this_page) {
+ 		ret = nfs_page_group_lock_subreq(head, subreq);
+ 		if (ret < 0)
+ 			goto out_unlock;
+ 	}
+ 
+ 	nfs_page_group_unlock(head);
+ 
+ 	nfs_init_cinfo_from_inode(&cinfo, inode);
+ 	nfs_join_page_group(head, &cinfo, inode);
++>>>>>>> 25edbcac6e32 (nfs: fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests)
  	return head;
 -
 -out_unlock:
 -	nfs_unlock_and_release_request(head);
 -	return ERR_PTR(ret);
  }
  
  static void nfs_write_error(struct nfs_page *req, int error)
diff --cc include/linux/nfs_page.h
index f0373a6cb5fb,63eed97a18ad..000000000000
--- a/include/linux/nfs_page.h
+++ b/include/linux/nfs_page.h
@@@ -143,9 -155,9 +143,15 @@@ extern size_t nfs_generic_pg_test(struc
  extern  int nfs_wait_on_request(struct nfs_page *);
  extern	void nfs_unlock_request(struct nfs_page *req);
  extern	void nfs_unlock_and_release_request(struct nfs_page *);
++<<<<<<< HEAD
 +extern	struct nfs_page *nfs_page_group_lock_head(struct nfs_page *req);
 +extern	int nfs_page_group_lock_subrequests(struct nfs_page *head);
 +extern	void nfs_join_page_group(struct nfs_page *head, struct inode *inode);
++=======
+ extern void nfs_join_page_group(struct nfs_page *head,
+ 				struct nfs_commit_info *cinfo,
+ 				struct inode *inode);
++>>>>>>> 25edbcac6e32 (nfs: fold nfs_page_group_lock_subrequests into nfs_lock_and_join_requests)
  extern int nfs_page_group_lock(struct nfs_page *);
  extern void nfs_page_group_unlock(struct nfs_page *);
  extern bool nfs_page_group_sync_on_bit(struct nfs_page *, unsigned int);
* Unmerged path fs/nfs/pagelist.c
* Unmerged path fs/nfs/write.c
* Unmerged path include/linux/nfs_page.h
