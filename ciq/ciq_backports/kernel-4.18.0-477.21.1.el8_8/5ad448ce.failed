iomap: iomap_read_inline_data cleanup

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-477.21.1.el8_8
commit-author Andreas Gruenbacher <agruenba@redhat.com>
commit 5ad448ce2976f829d95dcae5e6e91f6686b0e4de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-477.21.1.el8_8/5ad448ce.failed

Change iomap_read_inline_data to return 0 or an error code; this
simplifies the callers.  Add a description.

	Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
[djwong: document the return value of iomap_read_inline_data explicitly]
	Reviewed-by: Darrick J. Wong <djwong@kernel.org>
	Signed-off-by: Darrick J. Wong <djwong@kernel.org>
(cherry picked from commit 5ad448ce2976f829d95dcae5e6e91f6686b0e4de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/iomap/buffered-io.c
diff --cc fs/iomap/buffered-io.c
index a9fecbda715a,71a36ae120ee..000000000000
--- a/fs/iomap/buffered-io.c
+++ b/fs/iomap/buffered-io.c
@@@ -222,58 -205,72 +222,76 @@@ struct iomap_readpage_ctx 
  	struct readahead_control *rac;
  };
  
++<<<<<<< HEAD
 +static loff_t iomap_read_inline_data(struct inode *inode, struct page *page,
 +		const struct iomap *iomap)
++=======
+ /**
+  * iomap_read_inline_data - copy inline data into the page cache
+  * @iter: iteration structure
+  * @page: page to copy to
+  *
+  * Copy the inline data in @iter into @page and zero out the rest of the page.
+  * Only a single IOMAP_INLINE extent is allowed at the end of each file.
+  * Returns zero for success to complete the read, or the usual negative errno.
+  */
+ static int iomap_read_inline_data(const struct iomap_iter *iter,
+ 		struct page *page)
++>>>>>>> 5ad448ce2976 (iomap: iomap_read_inline_data cleanup)
  {
 -	const struct iomap *iomap = iomap_iter_srcmap(iter);
 -	size_t size = i_size_read(iter->inode) - iomap->offset;
 +	size_t size = i_size_read(inode) - iomap->offset;
  	size_t poff = offset_in_page(iomap->offset);
  	void *addr;
  
  	if (PageUptodate(page))
- 		return PAGE_SIZE - poff;
+ 		return 0;
  
 -	if (WARN_ON_ONCE(size > PAGE_SIZE - poff))
 -		return -EIO;
  	if (WARN_ON_ONCE(size > PAGE_SIZE -
  			 offset_in_page(iomap->inline_data)))
  		return -EIO;
  	if (WARN_ON_ONCE(size > iomap->length))
  		return -EIO;
  	if (poff > 0)
 -		iomap_page_create(iter->inode, page);
 +		iomap_page_create(inode, page);
  
 -	addr = kmap_local_page(page) + poff;
 +	addr = kmap_atomic(page) + poff;
  	memcpy(addr, iomap->inline_data, size);
  	memset(addr + size, 0, PAGE_SIZE - poff - size);
 -	kunmap_local(addr);
 +	kunmap_atomic(addr);
  	iomap_set_range_uptodate(page, poff, PAGE_SIZE - poff);
- 	return PAGE_SIZE - poff;
+ 	return 0;
  }
  
 -static inline bool iomap_block_needs_zeroing(const struct iomap_iter *iter,
 -		loff_t pos)
 +static inline bool iomap_block_needs_zeroing(struct inode *inode,
 +		struct iomap *iomap, loff_t pos)
  {
 -	const struct iomap *srcmap = iomap_iter_srcmap(iter);
 -
 -	return srcmap->type != IOMAP_MAPPED ||
 -		(srcmap->flags & IOMAP_F_NEW) ||
 -		pos >= i_size_read(iter->inode);
 +	return iomap->type != IOMAP_MAPPED ||
 +		(iomap->flags & IOMAP_F_NEW) ||
 +		pos >= i_size_read(inode);
  }
  
 -static loff_t iomap_readpage_iter(const struct iomap_iter *iter,
 -		struct iomap_readpage_ctx *ctx, loff_t offset)
 +static loff_t
 +iomap_readpage_actor(struct inode *inode, loff_t pos, loff_t length, void *data,
 +		struct iomap *iomap, struct iomap *srcmap)
  {
 -	const struct iomap *iomap = &iter->iomap;
 -	loff_t pos = iter->pos + offset;
 -	loff_t length = iomap_length(iter) - offset;
 +	struct iomap_readpage_ctx *ctx = data;
  	struct page *page = ctx->cur_page;
  	struct iomap_page *iop;
 +	bool is_contig = false;
  	loff_t orig_pos = pos;
  	unsigned poff, plen;
  	sector_t sector;
  
  	if (iomap->type == IOMAP_INLINE)
++<<<<<<< HEAD
 +		return min(iomap_read_inline_data(inode, page, iomap), length);
++=======
+ 		return iomap_read_inline_data(iter, page);
++>>>>>>> 5ad448ce2976 (iomap: iomap_read_inline_data cleanup)
  
  	/* zero post-eof blocks as the page may be mapped */
 -	iop = iomap_page_create(iter->inode, page);
 -	iomap_adjust_read_range(iter->inode, iop, &pos, length, &poff, &plen);
 +	iop = iomap_page_create(inode, page);
 +	iomap_adjust_read_range(inode, iop, &pos, length, &poff, &plen);
  	if (plen == 0)
  		goto done;
  
@@@ -622,38 -588,20 +640,40 @@@ __iomap_write_begin(struct inode *inode
  	return 0;
  }
  
 -static int iomap_write_begin_inline(const struct iomap_iter *iter,
 -		struct page *page)
 +static void __iomap_put_folio(struct iomap *iomap, struct inode *inode,
 +			      loff_t pos, size_t ret, struct page *page)
 +{
 +	const struct iomap_page_ops *page_ops = iomap->page_ops;
 +
 +	if (page_ops && page_ops->page_done)
 +		page_ops->page_done(inode, pos, ret, page);
 +	else if (page) {
 +		unlock_page(page);
 +		put_page(page);
 +	}
 +}
 +
 +static int iomap_write_begin_inline(struct inode *inode,
 +		struct page *page, struct iomap *srcmap)
  {
- 	int ret;
- 
  	/* needs more work for the tailpacking case; disable for now */
 -	if (WARN_ON_ONCE(iomap_iter_srcmap(iter)->offset != 0))
 +	if (WARN_ON_ONCE(srcmap->offset != 0))
  		return -EIO;
++<<<<<<< HEAD
 +	ret = iomap_read_inline_data(inode, page, srcmap);
 +	if (ret < 0)
 +		return ret;
 +	return 0;
++=======
+ 	return iomap_read_inline_data(iter, page);
++>>>>>>> 5ad448ce2976 (iomap: iomap_read_inline_data cleanup)
  }
  
 -static int iomap_write_begin(const struct iomap_iter *iter, loff_t pos,
 -		unsigned len, struct page **pagep)
 +static int
 +iomap_write_begin(struct inode *inode, loff_t pos, unsigned len, unsigned flags,
 +		struct page **pagep, struct iomap *iomap, struct iomap *srcmap)
  {
 -	const struct iomap_page_ops *page_ops = iter->iomap.page_ops;
 -	const struct iomap *srcmap = iomap_iter_srcmap(iter);
 +	const struct iomap_page_ops *page_ops = iomap->page_ops;
  	struct page *page;
  	int status = 0;
  
* Unmerged path fs/iomap/buffered-io.c
