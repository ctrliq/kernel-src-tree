s390/mm: add missing arch_set_page_dat() call to gmap allocations

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-537.el8
commit-author Heiko Carstens <hca@linux.ibm.com>
commit 1954da4a2b621a3328a63382cae7e5f5e2af502c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-537.el8/1954da4a.failed

If the cmma no-dat feature is available all pages that are not used for
dynamic address translation are marked as "no-dat" with the ESSA
instruction. This information is visible to the hypervisor, so that the
hypervisor can optimize purging of guest TLB entries. This also means that
pages which are used for dynamic address translation must not be marked as
"no-dat", since the hypervisor may then incorrectly not purge guest TLB
entries.

Region, segment, and page tables allocated within the gmap code are
incorrectly marked as "no-dat", since an explicit call to
arch_set_page_dat() is missing, which would remove the "no-dat" mark.

In order to fix this add a new gmap_alloc_crst() function which should
be used to allocate region and segment tables, and which also calls
arch_set_page_dat().

Also add the arch_set_page_dat() call to page_table_alloc_pgste().

	Cc: <stable@vger.kernel.org>
	Reviewed-by: Claudio Imbrenda <imbrenda@linux.ibm.com>
	Signed-off-by: Heiko Carstens <hca@linux.ibm.com>
	Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
(cherry picked from commit 1954da4a2b621a3328a63382cae7e5f5e2af502c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/mm/gmap.c
#	arch/s390/mm/pgalloc.c
diff --cc arch/s390/mm/gmap.c
index c4905100c15a,20786f6883b2..000000000000
--- a/arch/s390/mm/gmap.c
+++ b/arch/s390/mm/gmap.c
@@@ -17,10 -17,11 +17,11 @@@
  #include <linux/swapops.h>
  #include <linux/ksm.h>
  #include <linux/mman.h>
 -#include <linux/pgtable.h>
  
 +#include <asm/pgtable.h>
  #include <asm/pgalloc.h>
  #include <asm/gmap.h>
+ #include <asm/page.h>
  #include <asm/tlb.h>
  
  #define GMAP_SHADOW_FAKE_TABLE 1ULL
@@@ -308,10 -320,10 +320,10 @@@ static int gmap_alloc_table(struct gma
  	unsigned long *new;
  
  	/* since we dont free the gmap table until gmap_free we can unlock */
- 	page = alloc_pages(GFP_KERNEL_ACCOUNT, CRST_ALLOC_ORDER);
+ 	page = gmap_alloc_crst();
  	if (!page)
  		return -ENOMEM;
 -	new = page_to_virt(page);
 +	new = (unsigned long *) page_to_phys(page);
  	crst_table_init(new, init);
  	spin_lock(&gmap->guest_table_lock);
  	if (*table & _REGION_ENTRY_INVALID) {
@@@ -2799,7 -2863,11 +2811,15 @@@ int s390_replace_asce(struct gmap *gmap
  
  	s390_unlist_old_asce(gmap);
  
++<<<<<<< HEAD
 +	page = alloc_pages(GFP_KERNEL_ACCOUNT, CRST_ALLOC_ORDER);
++=======
+ 	/* Replacing segment type ASCEs would cause serious issues */
+ 	if ((gmap->asce & _ASCE_TYPE_MASK) == _ASCE_TYPE_SEGMENT)
+ 		return -EINVAL;
+ 
+ 	page = gmap_alloc_crst();
++>>>>>>> 1954da4a2b62 (s390/mm: add missing arch_set_page_dat() call to gmap allocations)
  	if (!page)
  		return -ENOMEM;
  	page->index = 0;
diff --cc arch/s390/mm/pgalloc.c
index b9b43808d886,a7e4b6e11cc5..000000000000
--- a/arch/s390/mm/pgalloc.c
+++ b/arch/s390/mm/pgalloc.c
@@@ -168,12 -140,13 +168,19 @@@ static inline unsigned int atomic_xor_b
  
  struct page *page_table_alloc_pgste(struct mm_struct *mm)
  {
 -	struct ptdesc *ptdesc;
 +	struct page *page;
  	u64 *table;
  
++<<<<<<< HEAD
 +	page = alloc_page(GFP_KERNEL);
 +	if (page) {
 +		table = (u64 *)page_to_virt(page);
++=======
+ 	ptdesc = pagetable_alloc(GFP_KERNEL, 0);
+ 	if (ptdesc) {
+ 		table = (u64 *)ptdesc_to_virt(ptdesc);
+ 		arch_set_page_dat(virt_to_page(table), 0);
++>>>>>>> 1954da4a2b62 (s390/mm: add missing arch_set_page_dat() call to gmap allocations)
  		memset64(table, _PAGE_INVALID, PTRS_PER_PTE);
  		memset64(table + PTRS_PER_PTE, 0, PTRS_PER_PTE);
  	}
* Unmerged path arch/s390/mm/gmap.c
* Unmerged path arch/s390/mm/pgalloc.c
