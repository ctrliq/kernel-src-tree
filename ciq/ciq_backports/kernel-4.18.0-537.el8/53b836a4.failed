net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-537.el8
commit-author Rahul Rameshbabu <rrameshbabu@nvidia.com>
commit 53b836a44db4259b94ffcfff321fb3d63f976b76
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-537.el8/53b836a4.failed

A new check for the tx devlink health reporter is introduced for
determining when the PTP port timestamping SQ is considered unhealthy. If
there are enough CQEs considered never to be delivered, the space that can
be utilized on the SQ decreases significantly, impacting performance and
usability of the SQ. The health reporter is triggered when the number of
likely never delivered port timestamping CQEs that utilize the space of the
PTP SQ is greater than 93.75% of the total capacity of the SQ. A devlink
health reporter recover method is also provided for this specific TX error
context that restarts the PTP SQ.

	Signed-off-by: Rahul Rameshbabu <rrameshbabu@nvidia.com>
	Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 53b836a44db4259b94ffcfff321fb3d63f976b76)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/networking/devlink/mlx5.rst
#	drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/ptp.h
diff --cc Documentation/networking/devlink/mlx5.rst
index 3321117cf605,702f204a3dbd..000000000000
--- a/Documentation/networking/devlink/mlx5.rst
+++ b/Documentation/networking/devlink/mlx5.rst
@@@ -92,3 -129,160 +92,163 @@@ The ``mlx5`` driver reports the followi
     * - ``fw.version``
       - stored, running
       - Three digit major.minor.subminor firmware version number.
++<<<<<<< HEAD
++=======
+ 
+ Health reporters
+ ================
+ 
+ tx reporter
+ -----------
+ The tx reporter is responsible for reporting and recovering of the following three error scenarios:
+ 
+ - tx timeout
+     Report on kernel tx timeout detection.
+     Recover by searching lost interrupts.
+ - tx error completion
+     Report on error tx completion.
+     Recover by flushing the tx queue and reset it.
+ - tx PTP port timestamping CQ unhealthy
+     Report too many CQEs never delivered on port ts CQ.
+     Recover by flushing and re-creating all PTP channels.
+ 
+ tx reporter also support on demand diagnose callback, on which it provides
+ real time information of its send queues status.
+ 
+ User commands examples:
+ 
+ - Diagnose send queues status::
+ 
+     $ devlink health diagnose pci/0000:82:00.0 reporter tx
+ 
+ .. note::
+    This command has valid output only when interface is up, otherwise the command has empty output.
+ 
+ - Show number of tx errors indicated, number of recover flows ended successfully,
+   is autorecover enabled and graceful period from last recover::
+ 
+     $ devlink health show pci/0000:82:00.0 reporter tx
+ 
+ rx reporter
+ -----------
+ The rx reporter is responsible for reporting and recovering of the following two error scenarios:
+ 
+ - rx queues' initialization (population) timeout
+     Population of rx queues' descriptors on ring initialization is done
+     in napi context via triggering an irq. In case of a failure to get
+     the minimum amount of descriptors, a timeout would occur, and
+     descriptors could be recovered by polling the EQ (Event Queue).
+ - rx completions with errors (reported by HW on interrupt context)
+     Report on rx completion error.
+     Recover (if needed) by flushing the related queue and reset it.
+ 
+ rx reporter also supports on demand diagnose callback, on which it
+ provides real time information of its receive queues' status.
+ 
+ - Diagnose rx queues' status and corresponding completion queue::
+ 
+     $ devlink health diagnose pci/0000:82:00.0 reporter rx
+ 
+ .. note::
+    This command has valid output only when interface is up. Otherwise, the command has empty output.
+ 
+ - Show number of rx errors indicated, number of recover flows ended successfully,
+   is autorecover enabled, and graceful period from last recover::
+ 
+     $ devlink health show pci/0000:82:00.0 reporter rx
+ 
+ fw reporter
+ -----------
+ The fw reporter implements `diagnose` and `dump` callbacks.
+ It follows symptoms of fw error such as fw syndrome by triggering
+ fw core dump and storing it into the dump buffer.
+ The fw reporter diagnose command can be triggered any time by the user to check
+ current fw status.
+ 
+ User commands examples:
+ 
+ - Check fw heath status::
+ 
+     $ devlink health diagnose pci/0000:82:00.0 reporter fw
+ 
+ - Read FW core dump if already stored or trigger new one::
+ 
+     $ devlink health dump show pci/0000:82:00.0 reporter fw
+ 
+ .. note::
+    This command can run only on the PF which has fw tracer ownership,
+    running it on other PF or any VF will return "Operation not permitted".
+ 
+ fw fatal reporter
+ -----------------
+ The fw fatal reporter implements `dump` and `recover` callbacks.
+ It follows fatal errors indications by CR-space dump and recover flow.
+ The CR-space dump uses vsc interface which is valid even if the FW command
+ interface is not functional, which is the case in most FW fatal errors.
+ The recover function runs recover flow which reloads the driver and triggers fw
+ reset if needed.
+ On firmware error, the health buffer is dumped into the dmesg. The log
+ level is derived from the error's severity (given in health buffer).
+ 
+ User commands examples:
+ 
+ - Run fw recover flow manually::
+ 
+     $ devlink health recover pci/0000:82:00.0 reporter fw_fatal
+ 
+ - Read FW CR-space dump if already stored or trigger new one::
+ 
+     $ devlink health dump show pci/0000:82:00.1 reporter fw_fatal
+ 
+ .. note::
+    This command can run only on PF.
+ 
+ vnic reporter
+ -------------
+ The vnic reporter implements only the `diagnose` callback.
+ It is responsible for querying the vnic diagnostic counters from fw and displaying
+ them in realtime.
+ 
+ Description of the vnic counters:
+ 
+ - total_q_under_processor_handle
+         number of queues in an error state due to
+         an async error or errored command.
+ - send_queue_priority_update_flow
+         number of QP/SQ priority/SL update events.
+ - cq_overrun
+         number of times CQ entered an error state due to an overflow.
+ - async_eq_overrun
+         number of times an EQ mapped to async events was overrun.
+         comp_eq_overrun number of times an EQ mapped to completion events was
+         overrun.
+ - quota_exceeded_command
+         number of commands issued and failed due to quota exceeded.
+ - invalid_command
+         number of commands issued and failed dues to any reason other than quota
+         exceeded.
+ - nic_receive_steering_discard
+         number of packets that completed RX flow
+         steering but were discarded due to a mismatch in flow table.
+ - generated_pkt_steering_fail
+ 	number of packets generated by the VNIC experiencing unexpected steering
+ 	failure (at any point in steering flow).
+ - handled_pkt_steering_fail
+ 	number of packets handled by the VNIC experiencing unexpected steering
+ 	failure (at any point in steering flow owned by the VNIC, including the FDB
+ 	for the eswitch owner).
+ 
+ User commands examples:
+ 
+ - Diagnose PF/VF vnic counters::
+ 
+         $ devlink health diagnose pci/0000:82:00.1 reporter vnic
+ 
+ - Diagnose representor vnic counters (performed by supplying devlink port of the
+   representor, which can be obtained via devlink port command)::
+ 
+         $ devlink health diagnose pci/0000:82:00.1/65537 reporter vnic
+ 
+ .. note::
+    This command can run over all interfaces such as PF/VF and representor ports.
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
index b0b429a0321e,bb11e644d24f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
@@@ -79,42 -124,57 +80,76 @@@ void mlx5e_skb_cb_hwtstamp_handler(stru
  	memset(skb->cb, 0, sizeof(struct mlx5e_skb_cb_hwtstamp));
  }
  
 -static struct sk_buff *
 -mlx5e_ptp_metadata_map_lookup(struct mlx5e_ptp_metadata_map *map, u16 metadata)
 +#define PTP_WQE_CTR2IDX(val) ((val) & ptpsq->ts_cqe_ctr_mask)
 +
 +static bool mlx5e_ptp_ts_cqe_drop(struct mlx5e_ptpsq *ptpsq, u16 skb_ci, u16 skb_id)
  {
 -	return map->data[metadata];
 +	return (ptpsq->ts_cqe_ctr_mask && (skb_ci != skb_id));
  }
  
 -static struct sk_buff *
 -mlx5e_ptp_metadata_map_remove(struct mlx5e_ptp_metadata_map *map, u16 metadata)
 +static bool mlx5e_ptp_ts_cqe_ooo(struct mlx5e_ptpsq *ptpsq, u16 skb_id)
  {
 -	struct sk_buff *skb;
 +	u16 skb_ci = PTP_WQE_CTR2IDX(ptpsq->skb_fifo_cc);
 +	u16 skb_pi = PTP_WQE_CTR2IDX(ptpsq->skb_fifo_pc);
  
 -	skb = map->data[metadata];
 -	map->data[metadata] = NULL;
 +	if (PTP_WQE_CTR2IDX(skb_id - skb_ci) >= PTP_WQE_CTR2IDX(skb_pi - skb_ci))
 +		return true;
  
 +	return false;
 +}
 +
 +static void mlx5e_ptp_skb_fifo_ts_cqe_resync(struct mlx5e_ptpsq *ptpsq, u16 skb_ci,
 +					     u16 skb_id, int budget)
 +{
 +	struct skb_shared_hwtstamps hwts = {};
 +	struct sk_buff *skb;
 +
 +	ptpsq->cq_stats->resync_event++;
 +
++<<<<<<< HEAD
 +	while (skb_ci != skb_id) {
 +		skb = mlx5e_skb_fifo_pop(&ptpsq->skb_fifo);
 +		hwts.hwtstamp = mlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp;
 +		skb_tstamp_tx(skb, &hwts);
 +		ptpsq->cq_stats->resync_cqe++;
 +		napi_consume_skb(skb, budget);
 +		skb_ci = PTP_WQE_CTR2IDX(ptpsq->skb_fifo_cc);
++=======
+ 	return skb;
+ }
+ 
+ static bool mlx5e_ptp_metadata_map_unhealthy(struct mlx5e_ptp_metadata_map *map)
+ {
+ 	/* Considered beginning unhealthy state if size * 15 / 2^4 cannot be reclaimed. */
+ 	return map->undelivered_counter > (map->capacity >> 4) * 15;
+ }
+ 
+ static void mlx5e_ptpsq_mark_ts_cqes_undelivered(struct mlx5e_ptpsq *ptpsq,
+ 						 ktime_t port_tstamp)
+ {
+ 	struct mlx5e_ptp_port_ts_cqe_list *cqe_list = ptpsq->ts_cqe_pending_list;
+ 	ktime_t timeout = ns_to_ktime(MLX5E_PTP_TS_CQE_UNDELIVERED_TIMEOUT);
+ 	struct mlx5e_ptp_metadata_map *metadata_map = &ptpsq->metadata_map;
+ 	struct mlx5e_ptp_port_ts_cqe_tracker *pos, *n;
+ 
+ 	spin_lock(&cqe_list->tracker_list_lock);
+ 	list_for_each_entry_safe(pos, n, &cqe_list->tracker_list_head, entry) {
+ 		struct sk_buff *skb =
+ 			mlx5e_ptp_metadata_map_lookup(metadata_map, pos->metadata_id);
+ 		ktime_t dma_tstamp = mlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp;
+ 
+ 		if (!dma_tstamp ||
+ 		    ktime_after(ktime_add(dma_tstamp, timeout), port_tstamp))
+ 			break;
+ 
+ 		metadata_map->undelivered_counter++;
+ 		WARN_ON_ONCE(!pos->inuse);
+ 		pos->inuse = false;
+ 		list_del(&pos->entry);
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
  	}
 -	spin_unlock(&cqe_list->tracker_list_lock);
  }
  
 -#define PTP_WQE_CTR2IDX(val) ((val) & ptpsq->ts_cqe_ctr_mask)
 -
  static void mlx5e_ptp_handle_ts_cqe(struct mlx5e_ptpsq *ptpsq,
  				    struct mlx5_cqe64 *cqe,
  				    int budget)
@@@ -146,8 -208,13 +181,15 @@@
  				      hwtstamp, ptpsq->cq_stats);
  	ptpsq->cq_stats->cqe++;
  
 -	mlx5e_ptpsq_mark_ts_cqes_undelivered(ptpsq, hwtstamp);
  out:
  	napi_consume_skb(skb, budget);
++<<<<<<< HEAD
++=======
+ 	mlx5e_ptp_metadata_fifo_push(&ptpsq->metadata_freelist, metadata_id);
+ 	if (unlikely(mlx5e_ptp_metadata_map_unhealthy(&ptpsq->metadata_map)) &&
+ 	    !test_and_set_bit(MLX5E_SQ_STATE_RECOVERING, &sq->state))
+ 		queue_work(ptpsq->txqsq.priv->wq, &ptpsq->report_unhealthy_work);
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
  }
  
  static bool mlx5e_ptp_poll_ts_cq(struct mlx5e_cq *cq, int budget)
@@@ -317,12 -423,23 +359,20 @@@ static void mlx5e_ptp_drain_skb_fifo(st
  	}
  }
  
 -static void mlx5e_ptp_free_traffic_db(struct mlx5e_ptpsq *ptpsq)
 +static void mlx5e_ptp_free_traffic_db(struct mlx5e_skb_fifo *skb_fifo)
  {
 -	mlx5e_ptp_drain_metadata_map(&ptpsq->metadata_map);
 -	kvfree(ptpsq->metadata_map.data);
 -	kvfree(ptpsq->metadata_freelist.data);
 -	kvfree(ptpsq->ts_cqe_pending_list->nodes);
 -	kvfree(ptpsq->ts_cqe_pending_list);
 +	mlx5e_ptp_drain_skb_fifo(skb_fifo);
 +	kvfree(skb_fifo->fifo);
  }
  
+ static void mlx5e_ptpsq_unhealthy_work(struct work_struct *work)
+ {
+ 	struct mlx5e_ptpsq *ptpsq =
+ 		container_of(work, struct mlx5e_ptpsq, report_unhealthy_work);
+ 
+ 	mlx5e_reporter_tx_ptpsq_unhealthy(ptpsq);
+ }
+ 
  static int mlx5e_ptp_open_txqsq(struct mlx5e_ptp *c, u32 tisn,
  				int txq_ix, struct mlx5e_ptp_params *cparams,
  				int tc, struct mlx5e_ptpsq *ptpsq)
@@@ -366,7 -484,9 +418,13 @@@ static void mlx5e_ptp_close_txqsq(struc
  	struct mlx5e_txqsq *sq = &ptpsq->txqsq;
  	struct mlx5_core_dev *mdev = sq->mdev;
  
++<<<<<<< HEAD
 +	mlx5e_ptp_free_traffic_db(&ptpsq->skb_fifo);
++=======
+ 	if (current_work() != &ptpsq->report_unhealthy_work)
+ 		cancel_work_sync(&ptpsq->report_unhealthy_work);
+ 	mlx5e_ptp_free_traffic_db(ptpsq);
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
  	cancel_work_sync(&sq->recover_work);
  	mlx5e_ptp_destroy_sq(mdev, sq->sqn);
  	mlx5e_free_txqsq_descs(sq);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/ptp.h
index cc7efde88ac3,7b700d0f956a..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.h
@@@ -7,18 -7,38 +7,31 @@@
  #include "en.h"
  #include "en_stats.h"
  #include "en/txrx.h"
 -#include <linux/ktime.h>
  #include <linux/ptp_classify.h>
++<<<<<<< HEAD
++=======
+ #include <linux/time64.h>
+ #include <linux/workqueue.h>
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
  
  #define MLX5E_PTP_CHANNEL_IX 0
 -#define MLX5E_PTP_MAX_LOG_SQ_SIZE (8U)
 -#define MLX5E_PTP_TS_CQE_UNDELIVERED_TIMEOUT (1 * NSEC_PER_SEC)
 -
 -struct mlx5e_ptp_metadata_fifo {
 -	u8  cc;
 -	u8  pc;
 -	u8  mask;
 -	u8  *data;
 -};
 -
 -struct mlx5e_ptp_metadata_map {
 -	u16             undelivered_counter;
 -	u16             capacity;
 -	struct sk_buff  **data;
 -};
  
  struct mlx5e_ptpsq {
  	struct mlx5e_txqsq       txqsq;
  	struct mlx5e_cq          ts_cq;
 +	u16                      skb_fifo_cc;
 +	u16                      skb_fifo_pc;
 +	struct mlx5e_skb_fifo    skb_fifo;
  	struct mlx5e_ptp_cq_stats *cq_stats;
  	u16                      ts_cqe_ctr_mask;
++<<<<<<< HEAD
++=======
+ 
+ 	struct work_struct                 report_unhealthy_work;
+ 	struct mlx5e_ptp_port_ts_cqe_list  *ts_cqe_pending_list;
+ 	struct mlx5e_ptp_metadata_fifo     metadata_freelist;
+ 	struct mlx5e_ptp_metadata_map      metadata_map;
++>>>>>>> 53b836a44db4 (net/mlx5e: Add recovery flow for tx devlink health reporter for unhealthy PTP SQ)
  };
  
  enum {
* Unmerged path Documentation/networking/devlink/mlx5.rst
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/health.h b/drivers/net/ethernet/mellanox/mlx5/core/en/health.h
index 0107e4e73bb0..415840c3ef84 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/health.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/health.h
@@ -18,6 +18,7 @@ void mlx5e_reporter_tx_create(struct mlx5e_priv *priv);
 void mlx5e_reporter_tx_destroy(struct mlx5e_priv *priv);
 void mlx5e_reporter_tx_err_cqe(struct mlx5e_txqsq *sq);
 int mlx5e_reporter_tx_timeout(struct mlx5e_txqsq *sq);
+void mlx5e_reporter_tx_ptpsq_unhealthy(struct mlx5e_ptpsq *ptpsq);
 
 int mlx5e_health_cq_diag_fmsg(struct mlx5e_cq *cq, struct devlink_fmsg *fmsg);
 int mlx5e_health_cq_common_diag_fmsg(struct mlx5e_cq *cq, struct devlink_fmsg *fmsg);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/ptp.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/reporter_tx.c b/drivers/net/ethernet/mellanox/mlx5/core/en/reporter_tx.c
index a3826c6a29a2..fd3d582fed08 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/reporter_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/reporter_tx.c
@@ -129,6 +129,43 @@ static int mlx5e_tx_reporter_timeout_recover(void *ctx)
 	return err;
 }
 
+static int mlx5e_tx_reporter_ptpsq_unhealthy_recover(void *ctx)
+{
+	struct mlx5e_ptpsq *ptpsq = ctx;
+	struct mlx5e_channels *chs;
+	struct net_device *netdev;
+	struct mlx5e_priv *priv;
+	int carrier_ok;
+	int err;
+
+	if (!test_bit(MLX5E_SQ_STATE_RECOVERING, &ptpsq->txqsq.state))
+		return 0;
+
+	priv = ptpsq->txqsq.priv;
+
+	mutex_lock(&priv->state_lock);
+	chs = &priv->channels;
+	netdev = priv->netdev;
+
+	carrier_ok = netif_carrier_ok(netdev);
+	netif_carrier_off(netdev);
+
+	mlx5e_deactivate_priv_channels(priv);
+
+	mlx5e_ptp_close(chs->ptp);
+	err = mlx5e_ptp_open(priv, &chs->params, chs->c[0]->lag_port, &chs->ptp);
+
+	mlx5e_activate_priv_channels(priv);
+
+	/* return carrier back if needed */
+	if (carrier_ok)
+		netif_carrier_on(netdev);
+
+	mutex_unlock(&priv->state_lock);
+
+	return err;
+}
+
 /* state lock cannot be grabbed within this function.
  * It can cause a dead lock or a read-after-free.
  */
@@ -477,6 +514,15 @@ static int mlx5e_tx_reporter_timeout_dump(struct mlx5e_priv *priv, struct devlin
 	return mlx5e_tx_reporter_dump_sq(priv, fmsg, to_ctx->sq);
 }
 
+static int mlx5e_tx_reporter_ptpsq_unhealthy_dump(struct mlx5e_priv *priv,
+						  struct devlink_fmsg *fmsg,
+						  void *ctx)
+{
+	struct mlx5e_ptpsq *ptpsq = ctx;
+
+	return mlx5e_tx_reporter_dump_sq(priv, fmsg, &ptpsq->txqsq);
+}
+
 static int mlx5e_tx_reporter_dump_all_sqs(struct mlx5e_priv *priv,
 					  struct devlink_fmsg *fmsg)
 {
@@ -582,6 +628,25 @@ int mlx5e_reporter_tx_timeout(struct mlx5e_txqsq *sq)
 	return to_ctx.status;
 }
 
+void mlx5e_reporter_tx_ptpsq_unhealthy(struct mlx5e_ptpsq *ptpsq)
+{
+	struct mlx5e_ptp_metadata_map *map = &ptpsq->metadata_map;
+	char err_str[MLX5E_REPORTER_PER_Q_MAX_LEN];
+	struct mlx5e_txqsq *txqsq = &ptpsq->txqsq;
+	struct mlx5e_cq *ts_cq = &ptpsq->ts_cq;
+	struct mlx5e_priv *priv = txqsq->priv;
+	struct mlx5e_err_ctx err_ctx = {};
+
+	err_ctx.ctx = ptpsq;
+	err_ctx.recover = mlx5e_tx_reporter_ptpsq_unhealthy_recover;
+	err_ctx.dump = mlx5e_tx_reporter_ptpsq_unhealthy_dump;
+	snprintf(err_str, sizeof(err_str),
+		 "Unhealthy TX port TS queue: %d, SQ: 0x%x, CQ: 0x%x, Undelivered CQEs: %u Map Capacity: %u",
+		 txqsq->ch_ix, txqsq->sqn, ts_cq->mcq.cqn, map->undelivered_counter, map->capacity);
+
+	mlx5e_health_report(priv, priv->tx_reporter, err_str, &err_ctx);
+}
+
 static const struct devlink_health_reporter_ops mlx5_tx_reporter_ops = {
 		.name = "tx",
 		.recover = mlx5e_tx_reporter_recover,
