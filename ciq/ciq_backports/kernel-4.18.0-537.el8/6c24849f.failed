sched/cpuset: Keep track of SCHED_DEADLINE task in cpusets

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-537.el8
commit-author Juri Lelli <juri.lelli@redhat.com>
commit 6c24849f5515e4966d94fa5279bdff4acf2e9489
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-537.el8/6c24849f.failed

Qais reported that iterating over all tasks when rebuilding root domains
for finding out which ones are DEADLINE and need their bandwidth
correctly restored on such root domains can be a costly operation (10+
ms delays on suspend-resume).

To fix the problem keep track of the number of DEADLINE tasks belonging
to each cpuset and then use this information (followup patch) to only
perform the above iteration if DEADLINE tasks are actually present in
the cpuset for which a corresponding root domain is being rebuilt.

	Reported-by: Qais Yousef <qyousef@layalina.io>
Link: https://lore.kernel.org/lkml/20230206221428.2125324-1-qyousef@layalina.io/
	Signed-off-by: Juri Lelli <juri.lelli@redhat.com>
	Reviewed-by: Waiman Long <longman@redhat.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 6c24849f5515e4966d94fa5279bdff4acf2e9489)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/cpuset.h
#	kernel/sched/deadline.c
diff --cc include/linux/cpuset.h
index 495e93904dbe,d629094fac6e..000000000000
--- a/include/linux/cpuset.h
+++ b/include/linux/cpuset.h
@@@ -70,10 -71,12 +70,17 @@@ extern void cpuset_init_smp(void)
  extern void cpuset_force_rebuild(void);
  extern void cpuset_update_active_cpus(void);
  extern void cpuset_wait_for_hotplug(void);
++<<<<<<< HEAD
 +extern void cpuset_read_lock(void);
 +extern void cpuset_read_unlock(void);
++=======
+ extern void inc_dl_tasks_cs(struct task_struct *task);
+ extern void dec_dl_tasks_cs(struct task_struct *task);
+ extern void cpuset_lock(void);
+ extern void cpuset_unlock(void);
++>>>>>>> 6c24849f5515 (sched/cpuset: Keep track of SCHED_DEADLINE task in cpusets)
  extern void cpuset_cpus_allowed(struct task_struct *p, struct cpumask *mask);
 -extern bool cpuset_cpus_allowed_fallback(struct task_struct *p);
 +extern void cpuset_cpus_allowed_fallback(struct task_struct *p);
  extern nodemask_t cpuset_mems_allowed(struct task_struct *p);
  #define cpuset_current_mems_allowed (current->mems_allowed)
  void cpuset_init_current_mems_allowed(void);
@@@ -195,8 -191,10 +202,15 @@@ static inline void cpuset_update_active
  
  static inline void cpuset_wait_for_hotplug(void) { }
  
++<<<<<<< HEAD
 +static inline void cpuset_read_lock(void) { }
 +static inline void cpuset_read_unlock(void) { }
++=======
+ static inline void inc_dl_tasks_cs(struct task_struct *task) { }
+ static inline void dec_dl_tasks_cs(struct task_struct *task) { }
+ static inline void cpuset_lock(void) { }
+ static inline void cpuset_unlock(void) { }
++>>>>>>> 6c24849f5515 (sched/cpuset: Keep track of SCHED_DEADLINE task in cpusets)
  
  static inline void cpuset_cpus_allowed(struct task_struct *p,
  				       struct cpumask *mask)
diff --cc kernel/sched/deadline.c
index 954ffa5bd7c8,e11de074a6fd..000000000000
--- a/kernel/sched/deadline.c
+++ b/kernel/sched/deadline.c
@@@ -15,10 -15,44 +15,50 @@@
   *                    Michael Trimarchi <michael@amarulasolutions.com>,
   *                    Fabio Checconi <fchecconi@gmail.com>
   */
 +#include "sched.h"
 +#include "pelt.h"
  
++<<<<<<< HEAD
 +struct dl_bandwidth def_dl_bandwidth;
++=======
+ #include <linux/cpuset.h>
+ 
+ /*
+  * Default limits for DL period; on the top end we guard against small util
+  * tasks still getting ridiculously long effective runtimes, on the bottom end we
+  * guard against timer DoS.
+  */
+ static unsigned int sysctl_sched_dl_period_max = 1 << 22; /* ~4 seconds */
+ static unsigned int sysctl_sched_dl_period_min = 100;     /* 100 us */
+ #ifdef CONFIG_SYSCTL
+ static struct ctl_table sched_dl_sysctls[] = {
+ 	{
+ 		.procname       = "sched_deadline_period_max_us",
+ 		.data           = &sysctl_sched_dl_period_max,
+ 		.maxlen         = sizeof(unsigned int),
+ 		.mode           = 0644,
+ 		.proc_handler   = proc_douintvec_minmax,
+ 		.extra1         = (void *)&sysctl_sched_dl_period_min,
+ 	},
+ 	{
+ 		.procname       = "sched_deadline_period_min_us",
+ 		.data           = &sysctl_sched_dl_period_min,
+ 		.maxlen         = sizeof(unsigned int),
+ 		.mode           = 0644,
+ 		.proc_handler   = proc_douintvec_minmax,
+ 		.extra2         = (void *)&sysctl_sched_dl_period_max,
+ 	},
+ 	{}
+ };
+ 
+ static int __init sched_dl_sysctl_init(void)
+ {
+ 	register_sysctl_init("kernel", sched_dl_sysctls);
+ 	return 0;
+ }
+ late_initcall(sched_dl_sysctl_init);
+ #endif
++>>>>>>> 6c24849f5515 (sched/cpuset: Keep track of SCHED_DEADLINE task in cpusets)
  
  static inline struct task_struct *dl_task_of(struct sched_dl_entity *dl_se)
  {
* Unmerged path include/linux/cpuset.h
diff --git a/kernel/cgroup/cgroup.c b/kernel/cgroup/cgroup.c
index 4d619f1695c9..6927e89b31a5 100644
--- a/kernel/cgroup/cgroup.c
+++ b/kernel/cgroup/cgroup.c
@@ -56,6 +56,7 @@
 #include <linux/file.h>
 #include <linux/fs_parser.h>
 #include <linux/sched/cputime.h>
+#include <linux/sched/deadline.h>
 #include <linux/psi.h>
 #include <net/sock.h>
 
@@ -6236,6 +6237,9 @@ void cgroup_exit(struct task_struct *tsk)
 	list_add_tail(&tsk->cg_list, &cset->dying_tasks);
 	cset->nr_tasks--;
 
+	if (dl_task(tsk))
+		dec_dl_tasks_cs(tsk);
+
 	WARN_ON_ONCE(cgroup_task_frozen(tsk));
 	if (unlikely(cgroup_task_freeze(tsk)))
 		cgroup_update_frozen(task_dfl_cgroup(tsk));
diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c
index a1280d02c8f3..32e873bb8060 100644
--- a/kernel/cgroup/cpuset.c
+++ b/kernel/cgroup/cpuset.c
@@ -193,6 +193,12 @@ struct cpuset {
 	int use_parent_ecpus;
 	int child_ecpus_count;
 
+	/*
+	 * number of SCHED_DEADLINE tasks attached to this cpuset, so that we
+	 * know when to rebuild associated root domain bandwidth information.
+	 */
+	int nr_deadline_tasks;
+
 	/* Invalid partition error code, not lock protected */
 	enum prs_errcode prs_err;
 
@@ -245,6 +251,20 @@ static inline struct cpuset *parent_cs(struct cpuset *cs)
 	return css_cs(cs->css.parent);
 }
 
+void inc_dl_tasks_cs(struct task_struct *p)
+{
+	struct cpuset *cs = task_cs(p);
+
+	cs->nr_deadline_tasks++;
+}
+
+void dec_dl_tasks_cs(struct task_struct *p)
+{
+	struct cpuset *cs = task_cs(p);
+
+	cs->nr_deadline_tasks--;
+}
+
 /* bits in struct cpuset flags field */
 typedef enum {
 	CS_ONLINE,
@@ -2460,6 +2480,11 @@ static int cpuset_can_attach(struct cgroup_taskset *tset)
 		ret = security_task_setscheduler(task);
 		if (ret)
 			goto out_unlock;
+
+		if (dl_task(task)) {
+			cs->nr_deadline_tasks++;
+			cpuset_attach_old_cs->nr_deadline_tasks--;
+		}
 	}
 
 	/*
* Unmerged path kernel/sched/deadline.c
