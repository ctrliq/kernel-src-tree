PCI: add an API to get node from vector

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Shaohua Li <shli@fb.com>
commit 27ddb689909cd0bab30524a5f720ae3a3e55acac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/27ddb689.failed

Next patch will use the API to get the node from vector for nvme device

	Signed-off-by: Shaohua Li <shli@fb.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Bjorn Helgaas <bhelgaas@google.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 27ddb689909cd0bab30524a5f720ae3a3e55acac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/pci/msi.c
#	include/linux/pci.h
diff --cc drivers/pci/msi.c
index 0a99aff13490,d571bc330686..000000000000
--- a/drivers/pci/msi.c
+++ b/drivers/pci/msi.c
@@@ -1144,25 -1145,392 +1144,412 @@@ EXPORT_SYMBOL(pci_enable_msi_range)
   * with new allocated MSI-X interrupts.
   **/
  int pci_enable_msix_range(struct pci_dev *dev, struct msix_entry *entries,
 -		int minvec, int maxvec)
 +			       int minvec, int maxvec)
  {
 -	return __pci_enable_msix_range(dev, entries, minvec, maxvec, NULL);
 +	int nvec = maxvec;
 +	int rc;
 +
 +	if (maxvec < minvec)
 +		return -ERANGE;
 +
 +	do {
 +		rc = pci_enable_msix(dev, entries, nvec);
 +		if (rc < 0) {
 +			return rc;
 +		} else if (rc > 0) {
 +			if (rc < minvec)
 +				return -ENOSPC;
 +			nvec = rc;
 +		}
 +	} while (rc);
 +
 +	return nvec;
  }
  EXPORT_SYMBOL(pci_enable_msix_range);
++<<<<<<< HEAD
++=======
+ 
+ /**
+  * pci_alloc_irq_vectors_affinity - allocate multiple IRQs for a device
+  * @dev:		PCI device to operate on
+  * @min_vecs:		minimum number of vectors required (must be >= 1)
+  * @max_vecs:		maximum (desired) number of vectors
+  * @flags:		flags or quirks for the allocation
+  * @affd:		optional description of the affinity requirements
+  *
+  * Allocate up to @max_vecs interrupt vectors for @dev, using MSI-X or MSI
+  * vectors if available, and fall back to a single legacy vector
+  * if neither is available.  Return the number of vectors allocated,
+  * (which might be smaller than @max_vecs) if successful, or a negative
+  * error code on error. If less than @min_vecs interrupt vectors are
+  * available for @dev the function will fail with -ENOSPC.
+  *
+  * To get the Linux IRQ number used for a vector that can be passed to
+  * request_irq() use the pci_irq_vector() helper.
+  */
+ int pci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,
+ 				   unsigned int max_vecs, unsigned int flags,
+ 				   const struct irq_affinity *affd)
+ {
+ 	static const struct irq_affinity msi_default_affd;
+ 	int vecs = -ENOSPC;
+ 
+ 	if (flags & PCI_IRQ_AFFINITY) {
+ 		if (!affd)
+ 			affd = &msi_default_affd;
+ 
+ 		if (affd->pre_vectors + affd->post_vectors > min_vecs)
+ 			return -EINVAL;
+ 
+ 		/*
+ 		 * If there aren't any vectors left after applying the pre/post
+ 		 * vectors don't bother with assigning affinity.
+ 		 */
+ 		if (affd->pre_vectors + affd->post_vectors == min_vecs)
+ 			affd = NULL;
+ 	} else {
+ 		if (WARN_ON(affd))
+ 			affd = NULL;
+ 	}
+ 
+ 	if (flags & PCI_IRQ_MSIX) {
+ 		vecs = __pci_enable_msix_range(dev, NULL, min_vecs, max_vecs,
+ 				affd);
+ 		if (vecs > 0)
+ 			return vecs;
+ 	}
+ 
+ 	if (flags & PCI_IRQ_MSI) {
+ 		vecs = __pci_enable_msi_range(dev, min_vecs, max_vecs, affd);
+ 		if (vecs > 0)
+ 			return vecs;
+ 	}
+ 
+ 	/* use legacy irq if allowed */
+ 	if (flags & PCI_IRQ_LEGACY) {
+ 		if (min_vecs == 1 && dev->irq) {
+ 			pci_intx(dev, 1);
+ 			return 1;
+ 		}
+ 	}
+ 
+ 	return vecs;
+ }
+ EXPORT_SYMBOL(pci_alloc_irq_vectors_affinity);
+ 
+ /**
+  * pci_free_irq_vectors - free previously allocated IRQs for a device
+  * @dev:		PCI device to operate on
+  *
+  * Undoes the allocations and enabling in pci_alloc_irq_vectors().
+  */
+ void pci_free_irq_vectors(struct pci_dev *dev)
+ {
+ 	pci_disable_msix(dev);
+ 	pci_disable_msi(dev);
+ }
+ EXPORT_SYMBOL(pci_free_irq_vectors);
+ 
+ /**
+  * pci_irq_vector - return Linux IRQ number of a device vector
+  * @dev: PCI device to operate on
+  * @nr: device-relative interrupt vector index (0-based).
+  */
+ int pci_irq_vector(struct pci_dev *dev, unsigned int nr)
+ {
+ 	if (dev->msix_enabled) {
+ 		struct msi_desc *entry;
+ 		int i = 0;
+ 
+ 		for_each_pci_msi_entry(entry, dev) {
+ 			if (i == nr)
+ 				return entry->irq;
+ 			i++;
+ 		}
+ 		WARN_ON_ONCE(1);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (dev->msi_enabled) {
+ 		struct msi_desc *entry = first_pci_msi_entry(dev);
+ 
+ 		if (WARN_ON_ONCE(nr >= entry->nvec_used))
+ 			return -EINVAL;
+ 	} else {
+ 		if (WARN_ON_ONCE(nr > 0))
+ 			return -EINVAL;
+ 	}
+ 
+ 	return dev->irq + nr;
+ }
+ EXPORT_SYMBOL(pci_irq_vector);
+ 
+ /**
+  * pci_irq_get_affinity - return the affinity of a particular msi vector
+  * @dev:	PCI device to operate on
+  * @nr:		device-relative interrupt vector index (0-based).
+  */
+ const struct cpumask *pci_irq_get_affinity(struct pci_dev *dev, int nr)
+ {
+ 	if (dev->msix_enabled) {
+ 		struct msi_desc *entry;
+ 		int i = 0;
+ 
+ 		for_each_pci_msi_entry(entry, dev) {
+ 			if (i == nr)
+ 				return entry->affinity;
+ 			i++;
+ 		}
+ 		WARN_ON_ONCE(1);
+ 		return NULL;
+ 	} else if (dev->msi_enabled) {
+ 		struct msi_desc *entry = first_pci_msi_entry(dev);
+ 
+ 		if (WARN_ON_ONCE(!entry || !entry->affinity ||
+ 				 nr >= entry->nvec_used))
+ 			return NULL;
+ 
+ 		return &entry->affinity[nr];
+ 	} else {
+ 		return cpu_possible_mask;
+ 	}
+ }
+ EXPORT_SYMBOL(pci_irq_get_affinity);
+ 
+ /**
+  * pci_irq_get_node - return the numa node of a particular msi vector
+  * @pdev:	PCI device to operate on
+  * @vec:	device-relative interrupt vector index (0-based).
+  */
+ int pci_irq_get_node(struct pci_dev *pdev, int vec)
+ {
+ 	const struct cpumask *mask;
+ 
+ 	mask = pci_irq_get_affinity(pdev, vec);
+ 	if (mask)
+ 		return local_memory_node(cpu_to_node(cpumask_first(mask)));
+ 	return dev_to_node(&pdev->dev);
+ }
+ EXPORT_SYMBOL(pci_irq_get_node);
+ 
+ struct pci_dev *msi_desc_to_pci_dev(struct msi_desc *desc)
+ {
+ 	return to_pci_dev(desc->dev);
+ }
+ EXPORT_SYMBOL(msi_desc_to_pci_dev);
+ 
+ void *msi_desc_to_pci_sysdata(struct msi_desc *desc)
+ {
+ 	struct pci_dev *dev = msi_desc_to_pci_dev(desc);
+ 
+ 	return dev->bus->sysdata;
+ }
+ EXPORT_SYMBOL_GPL(msi_desc_to_pci_sysdata);
+ 
+ #ifdef CONFIG_PCI_MSI_IRQ_DOMAIN
+ /**
+  * pci_msi_domain_write_msg - Helper to write MSI message to PCI config space
+  * @irq_data:	Pointer to interrupt data of the MSI interrupt
+  * @msg:	Pointer to the message
+  */
+ void pci_msi_domain_write_msg(struct irq_data *irq_data, struct msi_msg *msg)
+ {
+ 	struct msi_desc *desc = irq_data_get_msi_desc(irq_data);
+ 
+ 	/*
+ 	 * For MSI-X desc->irq is always equal to irq_data->irq. For
+ 	 * MSI only the first interrupt of MULTI MSI passes the test.
+ 	 */
+ 	if (desc->irq == irq_data->irq)
+ 		__pci_write_msi_msg(desc, msg);
+ }
+ 
+ /**
+  * pci_msi_domain_calc_hwirq - Generate a unique ID for an MSI source
+  * @dev:	Pointer to the PCI device
+  * @desc:	Pointer to the msi descriptor
+  *
+  * The ID number is only used within the irqdomain.
+  */
+ irq_hw_number_t pci_msi_domain_calc_hwirq(struct pci_dev *dev,
+ 					  struct msi_desc *desc)
+ {
+ 	return (irq_hw_number_t)desc->msi_attrib.entry_nr |
+ 		PCI_DEVID(dev->bus->number, dev->devfn) << 11 |
+ 		(pci_domain_nr(dev->bus) & 0xFFFFFFFF) << 27;
+ }
+ 
+ static inline bool pci_msi_desc_is_multi_msi(struct msi_desc *desc)
+ {
+ 	return !desc->msi_attrib.is_msix && desc->nvec_used > 1;
+ }
+ 
+ /**
+  * pci_msi_domain_check_cap - Verify that @domain supports the capabilities for @dev
+  * @domain:	The interrupt domain to check
+  * @info:	The domain info for verification
+  * @dev:	The device to check
+  *
+  * Returns:
+  *  0 if the functionality is supported
+  *  1 if Multi MSI is requested, but the domain does not support it
+  *  -ENOTSUPP otherwise
+  */
+ int pci_msi_domain_check_cap(struct irq_domain *domain,
+ 			     struct msi_domain_info *info, struct device *dev)
+ {
+ 	struct msi_desc *desc = first_pci_msi_entry(to_pci_dev(dev));
+ 
+ 	/* Special handling to support __pci_enable_msi_range() */
+ 	if (pci_msi_desc_is_multi_msi(desc) &&
+ 	    !(info->flags & MSI_FLAG_MULTI_PCI_MSI))
+ 		return 1;
+ 	else if (desc->msi_attrib.is_msix && !(info->flags & MSI_FLAG_PCI_MSIX))
+ 		return -ENOTSUPP;
+ 
+ 	return 0;
+ }
+ 
+ static int pci_msi_domain_handle_error(struct irq_domain *domain,
+ 				       struct msi_desc *desc, int error)
+ {
+ 	/* Special handling to support __pci_enable_msi_range() */
+ 	if (pci_msi_desc_is_multi_msi(desc) && error == -ENOSPC)
+ 		return 1;
+ 
+ 	return error;
+ }
+ 
+ #ifdef GENERIC_MSI_DOMAIN_OPS
+ static void pci_msi_domain_set_desc(msi_alloc_info_t *arg,
+ 				    struct msi_desc *desc)
+ {
+ 	arg->desc = desc;
+ 	arg->hwirq = pci_msi_domain_calc_hwirq(msi_desc_to_pci_dev(desc),
+ 					       desc);
+ }
+ #else
+ #define pci_msi_domain_set_desc		NULL
+ #endif
+ 
+ static struct msi_domain_ops pci_msi_domain_ops_default = {
+ 	.set_desc	= pci_msi_domain_set_desc,
+ 	.msi_check	= pci_msi_domain_check_cap,
+ 	.handle_error	= pci_msi_domain_handle_error,
+ };
+ 
+ static void pci_msi_domain_update_dom_ops(struct msi_domain_info *info)
+ {
+ 	struct msi_domain_ops *ops = info->ops;
+ 
+ 	if (ops == NULL) {
+ 		info->ops = &pci_msi_domain_ops_default;
+ 	} else {
+ 		if (ops->set_desc == NULL)
+ 			ops->set_desc = pci_msi_domain_set_desc;
+ 		if (ops->msi_check == NULL)
+ 			ops->msi_check = pci_msi_domain_check_cap;
+ 		if (ops->handle_error == NULL)
+ 			ops->handle_error = pci_msi_domain_handle_error;
+ 	}
+ }
+ 
+ static void pci_msi_domain_update_chip_ops(struct msi_domain_info *info)
+ {
+ 	struct irq_chip *chip = info->chip;
+ 
+ 	BUG_ON(!chip);
+ 	if (!chip->irq_write_msi_msg)
+ 		chip->irq_write_msi_msg = pci_msi_domain_write_msg;
+ 	if (!chip->irq_mask)
+ 		chip->irq_mask = pci_msi_mask_irq;
+ 	if (!chip->irq_unmask)
+ 		chip->irq_unmask = pci_msi_unmask_irq;
+ }
+ 
+ /**
+  * pci_msi_create_irq_domain - Create a MSI interrupt domain
+  * @fwnode:	Optional fwnode of the interrupt controller
+  * @info:	MSI domain info
+  * @parent:	Parent irq domain
+  *
+  * Updates the domain and chip ops and creates a MSI interrupt domain.
+  *
+  * Returns:
+  * A domain pointer or NULL in case of failure.
+  */
+ struct irq_domain *pci_msi_create_irq_domain(struct fwnode_handle *fwnode,
+ 					     struct msi_domain_info *info,
+ 					     struct irq_domain *parent)
+ {
+ 	struct irq_domain *domain;
+ 
+ 	if (info->flags & MSI_FLAG_USE_DEF_DOM_OPS)
+ 		pci_msi_domain_update_dom_ops(info);
+ 	if (info->flags & MSI_FLAG_USE_DEF_CHIP_OPS)
+ 		pci_msi_domain_update_chip_ops(info);
+ 
+ 	info->flags |= MSI_FLAG_ACTIVATE_EARLY;
+ 
+ 	domain = msi_create_irq_domain(fwnode, info, parent);
+ 	if (!domain)
+ 		return NULL;
+ 
+ 	domain->bus_token = DOMAIN_BUS_PCI_MSI;
+ 	return domain;
+ }
+ EXPORT_SYMBOL_GPL(pci_msi_create_irq_domain);
+ 
+ static int get_msi_id_cb(struct pci_dev *pdev, u16 alias, void *data)
+ {
+ 	u32 *pa = data;
+ 
+ 	*pa = alias;
+ 	return 0;
+ }
+ /**
+  * pci_msi_domain_get_msi_rid - Get the MSI requester id (RID)
+  * @domain:	The interrupt domain
+  * @pdev:	The PCI device.
+  *
+  * The RID for a device is formed from the alias, with a firmware
+  * supplied mapping applied
+  *
+  * Returns: The RID.
+  */
+ u32 pci_msi_domain_get_msi_rid(struct irq_domain *domain, struct pci_dev *pdev)
+ {
+ 	struct device_node *of_node;
+ 	u32 rid = 0;
+ 
+ 	pci_for_each_dma_alias(pdev, get_msi_id_cb, &rid);
+ 
+ 	of_node = irq_domain_get_of_node(domain);
+ 	rid = of_node ? of_msi_map_rid(&pdev->dev, of_node, rid) :
+ 			iort_msi_map_rid(&pdev->dev, rid);
+ 
+ 	return rid;
+ }
+ 
+ /**
+  * pci_msi_get_device_domain - Get the MSI domain for a given PCI device
+  * @pdev:	The PCI device
+  *
+  * Use the firmware data to find a device-specific MSI domain
+  * (i.e. not one that is ste as a default).
+  *
+  * Returns: The coresponding MSI domain or NULL if none has been found.
+  */
+ struct irq_domain *pci_msi_get_device_domain(struct pci_dev *pdev)
+ {
+ 	struct irq_domain *dom;
+ 	u32 rid = 0;
+ 
+ 	pci_for_each_dma_alias(pdev, get_msi_id_cb, &rid);
+ 	dom = of_msi_map_get_device_domain(&pdev->dev, rid);
+ 	if (!dom)
+ 		dom = iort_get_device_domain(&pdev->dev, rid);
+ 	return dom;
+ }
+ #endif /* CONFIG_PCI_MSI_IRQ_DOMAIN */
++>>>>>>> 27ddb689909c (PCI: add an API to get node from vector)
diff --cc include/linux/pci.h
index fa38dd95cea5,eb3da1a04e6c..000000000000
--- a/include/linux/pci.h
+++ b/include/linux/pci.h
@@@ -1304,10 -1316,17 +1304,22 @@@ static inline int pci_enable_msix_exact
  		return rc;
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ int pci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,
+ 				   unsigned int max_vecs, unsigned int flags,
+ 				   const struct irq_affinity *affd);
+ 
+ void pci_free_irq_vectors(struct pci_dev *dev);
+ int pci_irq_vector(struct pci_dev *dev, unsigned int nr);
+ const struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev, int vec);
+ int pci_irq_get_node(struct pci_dev *pdev, int vec);
+ 
++>>>>>>> 27ddb689909c (PCI: add an API to get node from vector)
  #else
  static inline int pci_msi_vec_count(struct pci_dev *dev) { return -ENOSYS; }
 +static inline int pci_enable_msi_block(struct pci_dev *dev, int nvec)
 +{ return -ENOSYS; }
  static inline void pci_msi_shutdown(struct pci_dev *dev) { }
  static inline void pci_disable_msi(struct pci_dev *dev) { }
  static inline int pci_msix_vec_count(struct pci_dev *dev) { return -ENOSYS; }
@@@ -1329,8 -1345,47 +1341,42 @@@ static inline int pci_enable_msix_range
  static inline int pci_enable_msix_exact(struct pci_dev *dev,
  		      struct msix_entry *entries, int nvec)
  { return -ENOSYS; }
++<<<<<<< HEAD
++=======
+ 
+ static inline int
+ pci_alloc_irq_vectors_affinity(struct pci_dev *dev, unsigned int min_vecs,
+ 			       unsigned int max_vecs, unsigned int flags,
+ 			       const struct irq_affinity *aff_desc)
+ {
+ 	if (min_vecs > 1)
+ 		return -EINVAL;
+ 	return 1;
+ }
+ 
+ static inline void pci_free_irq_vectors(struct pci_dev *dev)
+ {
+ }
+ 
+ static inline int pci_irq_vector(struct pci_dev *dev, unsigned int nr)
+ {
+ 	if (WARN_ON_ONCE(nr > 0))
+ 		return -EINVAL;
+ 	return dev->irq;
+ }
+ static inline const struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev,
+ 		int vec)
+ {
+ 	return cpu_possible_mask;
+ }
+ 
+ static inline int pci_irq_get_node(struct pci_dev *pdev, int vec)
+ {
+ 	return first_online_node;
+ }
++>>>>>>> 27ddb689909c (PCI: add an API to get node from vector)
  #endif
  
 -static inline int
 -pci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,
 -		      unsigned int max_vecs, unsigned int flags)
 -{
 -	return pci_alloc_irq_vectors_affinity(dev, min_vecs, max_vecs, flags,
 -					      NULL);
 -}
 -
  #ifdef CONFIG_PCIEPORTBUS
  extern bool pcie_ports_disabled;
  extern bool pcie_ports_auto;
* Unmerged path drivers/pci/msi.c
* Unmerged path include/linux/pci.h
