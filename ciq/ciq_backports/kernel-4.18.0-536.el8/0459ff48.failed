swiotlb: Remove bounce buffer remapping for Hyper-V

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-536.el8
commit-author Michael Kelley <mikelley@microsoft.com>
commit 0459ff4873739986dccafbb417cfc69e71bdacf4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-536.el8/0459ff48.failed

With changes to how Hyper-V guest VMs flip memory between private
(encrypted) and shared (decrypted), creating a second kernel virtual
mapping for shared memory is no longer necessary. Everything needed
for the transition to shared is handled by set_memory_decrypted().

As such, remove swiotlb_unencrypted_base and the associated
code.

	Signed-off-by: Michael Kelley <mikelley@microsoft.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Borislav Petkov (AMD) <bp@alien8.de>
Link: https://lore.kernel.org/r/1679838727-87310-8-git-send-email-mikelley@microsoft.com
	Signed-off-by: Wei Liu <wei.liu@kernel.org>
(cherry picked from commit 0459ff4873739986dccafbb417cfc69e71bdacf4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/mshyperv.c
diff --cc arch/x86/kernel/cpu/mshyperv.c
index 1189865ffc68,ac630ecde795..000000000000
--- a/arch/x86/kernel/cpu/mshyperv.c
+++ b/arch/x86/kernel/cpu/mshyperv.c
@@@ -385,17 -407,8 +384,20 @@@ static void __init ms_hyperv_init_platf
  		pr_info("Hyper-V: Isolation Config: Group A 0x%x, Group B 0x%x\n",
  			ms_hyperv.isolation_config_a, ms_hyperv.isolation_config_b);
  
- 		if (hv_get_isolation_type() == HV_ISOLATION_TYPE_SNP) {
+ 		if (hv_get_isolation_type() == HV_ISOLATION_TYPE_SNP)
  			static_branch_enable(&isolation_type_snp);
++<<<<<<< HEAD
 +#ifdef CONFIG_SWIOTLB
 +			swiotlb_unencrypted_base = ms_hyperv.shared_gpa_boundary;
 +#endif
 +		}
 +		/* Isolation VMs are unenlightened SEV-based VMs, thus this check: */
 +		if (IS_ENABLED(CONFIG_AMD_MEM_ENCRYPT)) {
 +			if (hv_get_isolation_type() != HV_ISOLATION_TYPE_NONE)
 +				cc_set_vendor(CC_VENDOR_HYPERV);
 +		}
++=======
++>>>>>>> 0459ff487373 (swiotlb: Remove bounce buffer remapping for Hyper-V)
  	}
  
  	if (hv_max_functions_eax >= HYPERV_CPUID_NESTED_FEATURES) {
* Unmerged path arch/x86/kernel/cpu/mshyperv.c
diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h
index bcef10e20ea4..2ef25e6fa1b4 100644
--- a/include/linux/swiotlb.h
+++ b/include/linux/swiotlb.h
@@ -180,6 +180,4 @@ static inline bool is_swiotlb_for_alloc(struct device *dev)
 }
 #endif /* CONFIG_DMA_RESTRICTED_POOL */
 
-extern phys_addr_t swiotlb_unencrypted_base;
-
 #endif /* __LINUX_SWIOTLB_H */
diff --git a/kernel/dma/swiotlb.c b/kernel/dma/swiotlb.c
index 8872878e4acc..2f75af589723 100644
--- a/kernel/dma/swiotlb.c
+++ b/kernel/dma/swiotlb.c
@@ -72,8 +72,6 @@ static bool swiotlb_force_disable;
 
 struct io_tlb_mem io_tlb_default_mem;
 
-phys_addr_t swiotlb_unencrypted_base;
-
 static unsigned long default_nslabs = IO_TLB_DEFAULT_SIZE >> IO_TLB_SHIFT;
 static unsigned long default_nareas;
 
@@ -197,34 +195,6 @@ static inline unsigned long nr_slots(u64 val)
 	return DIV_ROUND_UP(val, IO_TLB_SIZE);
 }
 
-/*
- * Remap swioltb memory in the unencrypted physical address space
- * when swiotlb_unencrypted_base is set. (e.g. for Hyper-V AMD SEV-SNP
- * Isolation VMs).
- */
-#ifdef CONFIG_HAS_IOMEM
-static void *swiotlb_mem_remap(struct io_tlb_mem *mem, unsigned long bytes)
-{
-	void *vaddr = NULL;
-
-	if (swiotlb_unencrypted_base) {
-		phys_addr_t paddr = mem->start + swiotlb_unencrypted_base;
-
-		vaddr = memremap(paddr, bytes, MEMREMAP_WB);
-		if (!vaddr)
-			pr_err("Failed to map the unencrypted memory %pa size %lx.\n",
-			       &paddr, bytes);
-	}
-
-	return vaddr;
-}
-#else
-static void *swiotlb_mem_remap(struct io_tlb_mem *mem, unsigned long bytes)
-{
-	return NULL;
-}
-#endif
-
 /*
  * Early SWIOTLB allocation may be too early to allow an architecture to
  * perform the desired operations.  This function allows the architecture to
@@ -234,18 +204,12 @@ static void *swiotlb_mem_remap(struct io_tlb_mem *mem, unsigned long bytes)
 void __init swiotlb_update_mem_attributes(void)
 {
 	struct io_tlb_mem *mem = &io_tlb_default_mem;
-	void *vaddr;
 	unsigned long bytes;
 
 	if (!mem->nslabs || mem->late_alloc)
 		return;
-	vaddr = phys_to_virt(mem->start);
 	bytes = PAGE_ALIGN(mem->nslabs << IO_TLB_SHIFT);
-	set_memory_decrypted((unsigned long)vaddr, bytes >> PAGE_SHIFT);
-
-	mem->vaddr = swiotlb_mem_remap(mem, bytes);
-	if (!mem->vaddr)
-		mem->vaddr = vaddr;
+	set_memory_decrypted((unsigned long)mem->vaddr, bytes >> PAGE_SHIFT);
 }
 
 static void swiotlb_init_io_tlb_mem(struct io_tlb_mem *mem, phys_addr_t start,
@@ -275,13 +239,6 @@ static void swiotlb_init_io_tlb_mem(struct io_tlb_mem *mem, phys_addr_t start,
 		mem->slots[i].alloc_size = 0;
 	}
 
-	/*
-	 * If swiotlb_unencrypted_base is set, the bounce buffer memory will
-	 * be remapped and cleared in swiotlb_update_mem_attributes.
-	 */
-	if (swiotlb_unencrypted_base)
-		return;
-
 	memset(vaddr, 0, bytes);
 	mem->vaddr = vaddr;
 	return;
