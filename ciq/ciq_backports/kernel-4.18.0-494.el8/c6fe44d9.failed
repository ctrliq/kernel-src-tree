list: add "list_del_init_careful()" to go with "list_empty_careful()"

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-494.el8
commit-author Linus Torvalds <torvalds@linux-foundation.org>
commit c6fe44d96fc1536af5b11cd859686453d1b7bfd1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-494.el8/c6fe44d9.failed

That gives us ordering guarantees around the pair.

	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit c6fe44d96fc1536af5b11cd859686453d1b7bfd1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/filemap.c
diff --cc mm/filemap.c
index a966e4ce0fd7,991503bbf922..000000000000
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@@ -1120,19 -1037,13 +1120,20 @@@ static int wake_page_function(wait_queu
  	 * Ok, we have successfully done what we're waiting for,
  	 * and we can unconditionally remove the wait entry.
  	 *
 -	 * Note that this has to be the absolute last thing we do,
 -	 * since after list_del_init(&wait->entry) the wait entry
 +	 * Note that this pairs with the "finish_wait()" in the
 +	 * waiter, and has to be the absolute last thing we do.
 +	 * After this list_del_init(&wait->entry) the wait entry
  	 * might be de-allocated and the process might even have
  	 * exited.
- 	 *
- 	 * We _really_ should have a "list_del_init_careful()" to
- 	 * properly pair with the unlocked "list_empty_careful()"
- 	 * in finish_wait().
  	 */
++<<<<<<< HEAD
 +	smp_mb();
 +	list_del_init(&wait->entry);
 +	return (flags & WQ_FLAG_EXCLUSIVE) != 0;
++=======
+ 	list_del_init_careful(&wait->entry);
+ 	return ret;
++>>>>>>> c6fe44d96fc1 (list: add "list_del_init_careful()" to go with "list_empty_careful()")
  }
  
  static void wake_up_page_bit(struct page *page, int bit_nr)
diff --git a/include/linux/list.h b/include/linux/list.h
index 1211a9574532..8febe7c7da35 100644
--- a/include/linux/list.h
+++ b/include/linux/list.h
@@ -282,6 +282,24 @@ static inline int list_empty(const struct list_head *head)
 	return READ_ONCE(head->next) == head;
 }
 
+/**
+ * list_del_init_careful - deletes entry from list and reinitialize it.
+ * @entry: the element to delete from the list.
+ *
+ * This is the same as list_del_init(), except designed to be used
+ * together with list_empty_careful() in a way to guarantee ordering
+ * of other memory operations.
+ *
+ * Any memory operations done before a list_del_init_careful() are
+ * guaranteed to be visible after a list_empty_careful() test.
+ */
+static inline void list_del_init_careful(struct list_head *entry)
+{
+	__list_del_entry(entry);
+	entry->prev = entry;
+	smp_store_release(&entry->next, entry);
+}
+
 /**
  * list_empty_careful - tests whether a list is empty and not being modified
  * @head: the list to test
@@ -297,7 +315,7 @@ static inline int list_empty(const struct list_head *head)
  */
 static inline int list_empty_careful(const struct list_head *head)
 {
-	struct list_head *next = head->next;
+	struct list_head *next = smp_load_acquire(&head->next);
 	return (next == head) && (next == head->prev);
 }
 
diff --git a/kernel/sched/wait.c b/kernel/sched/wait.c
index b44a54e15ded..8776211230a5 100644
--- a/kernel/sched/wait.c
+++ b/kernel/sched/wait.c
@@ -418,7 +418,7 @@ int autoremove_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, i
 	int ret = default_wake_function(wq_entry, mode, sync, key);
 
 	if (ret)
-		list_del_init(&wq_entry->entry);
+		list_del_init_careful(&wq_entry->entry);
 
 	return ret;
 }
* Unmerged path mm/filemap.c
