ext4: prevent stale extent cache entries caused by concurrent I/O writeback

jira LE-4669
Rebuild_History Non-Buildable kernel-4.18.0-553.82.1.el8_10
commit-author Zhang Yi <yi.zhang@huawei.com>
commit 402e38e6b71f5739119ca3107f375e112d63c7c5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.82.1.el8_10/402e38e6.failed

Currently, in the I/O writeback path, ext4_map_blocks() may attempt to
cache additional unrelated extents in the extent status tree without
holding the inode's i_rwsem and the mapping's invalidate_lock. This can
lead to stale extent status entries remaining in certain scenarios,
potentially causing data corruption.

For example, when performing a collapse range in ext4_collapse_range(),
it clears the extent cache and dirty pages before removing blocks and
shifting extents. It also holds the i_data_sem during these two
operations. However, both ext4_ext_remove_space() and
ext4_ext_shift_extents() may briefly release the i_data_sem if journal
credits are insufficient (ext4_datasem_ensure_credits()). If another
writeback process writes dirty pages from other regions during this
interval, it may cache extents that are about to be modified. Unless
ext4_collapse_range() explicitly clears the extent cache again, these
cached entries can become stale and inconsistent with the actual
extents.

     0 a  n       b      c         m
     | |  |       |      |         |
    [www][wwwwww][wwwwwwww]...[wwwww][wwww]...
          |                           |
          N                           M

Assume that block a is dirty. The collapse range operation is removing
data from n to m and drops i_data_sem immediately after removing the
extent from b to c. At the same time, a concurrent writeback begins to
write back block a; it will reloads the extent from [n, b) into the
extent status tree since it does not hold the i_rwsem or the
invalidate_lock. After the collapse range operation, it left the stale
extent [n, b), which points logical block n to N, but the actual
physical block of n should be M.

Similarly, both ext4_insert_range() and ext4_truncate() have the same
problem. ext4_punch_hole() survived since it re-add a hole extent entry
after removing space since commit 9f1118223aa0 ("ext4: add a hole extent
entry in cache after punch").

In most cases, during dirty page writeback, the block mapping
information is likely to be found in the extent cache, making it less
necessary to search for physical extents. Consequently, loading
unrelated extent caches during writeback appears to be ineffective.
Therefore, fix this by adds EXT4_EX_NOCACHE in the writeback path to
prevent caching of unrelated extents, eliminating this potential source
of corruption.

	Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
Link: https://patch.msgid.link/20250423085257.122685-4-yi.zhang@huaweicloud.com
	Signed-off-by: Theodore Ts'o <tytso@mit.edu>
(cherry picked from commit 402e38e6b71f5739119ca3107f375e112d63c7c5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ext4/fast_commit.c
#	fs/ext4/inode.c
diff --cc fs/ext4/inode.c
index 49ebe49ee7e4,8c0d6fa58f26..000000000000
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@@ -478,6 -462,118 +478,121 @@@ static void ext4_map_blocks_es_recheck(
  }
  #endif /* ES_AGGRESSIVE_TEST */
  
++<<<<<<< HEAD
++=======
+ static int ext4_map_query_blocks(handle_t *handle, struct inode *inode,
+ 				 struct ext4_map_blocks *map, int flags)
+ {
+ 	unsigned int status;
+ 	int retval;
+ 
+ 	flags &= EXT4_EX_FILTER;
+ 	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))
+ 		retval = ext4_ext_map_blocks(handle, inode, map, flags);
+ 	else
+ 		retval = ext4_ind_map_blocks(handle, inode, map, flags);
+ 
+ 	if (retval <= 0)
+ 		return retval;
+ 
+ 	if (unlikely(retval != map->m_len)) {
+ 		ext4_warning(inode->i_sb,
+ 			     "ES len assertion failed for inode "
+ 			     "%lu: retval %d != map->m_len %d",
+ 			     inode->i_ino, retval, map->m_len);
+ 		WARN_ON(1);
+ 	}
+ 
+ 	status = map->m_flags & EXT4_MAP_UNWRITTEN ?
+ 			EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
+ 	ext4_es_insert_extent(inode, map->m_lblk, map->m_len,
+ 			      map->m_pblk, status, false);
+ 	return retval;
+ }
+ 
+ static int ext4_map_create_blocks(handle_t *handle, struct inode *inode,
+ 				  struct ext4_map_blocks *map, int flags)
+ {
+ 	struct extent_status es;
+ 	unsigned int status;
+ 	int err, retval = 0;
+ 
+ 	/*
+ 	 * We pass in the magic EXT4_GET_BLOCKS_DELALLOC_RESERVE
+ 	 * indicates that the blocks and quotas has already been
+ 	 * checked when the data was copied into the page cache.
+ 	 */
+ 	if (map->m_flags & EXT4_MAP_DELAYED)
+ 		flags |= EXT4_GET_BLOCKS_DELALLOC_RESERVE;
+ 
+ 	/*
+ 	 * Here we clear m_flags because after allocating an new extent,
+ 	 * it will be set again.
+ 	 */
+ 	map->m_flags &= ~EXT4_MAP_FLAGS;
+ 
+ 	/*
+ 	 * We need to check for EXT4 here because migrate could have
+ 	 * changed the inode type in between.
+ 	 */
+ 	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {
+ 		retval = ext4_ext_map_blocks(handle, inode, map, flags);
+ 	} else {
+ 		retval = ext4_ind_map_blocks(handle, inode, map, flags);
+ 
+ 		/*
+ 		 * We allocated new blocks which will result in i_data's
+ 		 * format changing. Force the migrate to fail by clearing
+ 		 * migrate flags.
+ 		 */
+ 		if (retval > 0 && map->m_flags & EXT4_MAP_NEW)
+ 			ext4_clear_inode_state(inode, EXT4_STATE_EXT_MIGRATE);
+ 	}
+ 	if (retval <= 0)
+ 		return retval;
+ 
+ 	if (unlikely(retval != map->m_len)) {
+ 		ext4_warning(inode->i_sb,
+ 			     "ES len assertion failed for inode %lu: "
+ 			     "retval %d != map->m_len %d",
+ 			     inode->i_ino, retval, map->m_len);
+ 		WARN_ON(1);
+ 	}
+ 
+ 	/*
+ 	 * We have to zeroout blocks before inserting them into extent
+ 	 * status tree. Otherwise someone could look them up there and
+ 	 * use them before they are really zeroed. We also have to
+ 	 * unmap metadata before zeroing as otherwise writeback can
+ 	 * overwrite zeros with stale data from block device.
+ 	 */
+ 	if (flags & EXT4_GET_BLOCKS_ZERO &&
+ 	    map->m_flags & EXT4_MAP_MAPPED && map->m_flags & EXT4_MAP_NEW) {
+ 		err = ext4_issue_zeroout(inode, map->m_lblk, map->m_pblk,
+ 					 map->m_len);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	/*
+ 	 * If the extent has been zeroed out, we don't need to update
+ 	 * extent status tree.
+ 	 */
+ 	if (flags & EXT4_GET_BLOCKS_PRE_IO &&
+ 	    ext4_es_lookup_extent(inode, map->m_lblk, NULL, &es)) {
+ 		if (ext4_es_is_written(&es))
+ 			return retval;
+ 	}
+ 
+ 	status = map->m_flags & EXT4_MAP_UNWRITTEN ?
+ 			EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
+ 	ext4_es_insert_extent(inode, map->m_lblk, map->m_len, map->m_pblk,
+ 			      status, flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE);
+ 
+ 	return retval;
+ }
+ 
++>>>>>>> 402e38e6b71f (ext4: prevent stale extent cache entries caused by concurrent I/O writeback)
  /*
   * The ext4_map_blocks() function tries to look up the requested blocks,
   * and returns if the blocks are already mapped.
@@@ -526,8 -623,16 +641,15 @@@ int ext4_map_blocks(handle_t *handle, s
  	if (unlikely(map->m_lblk >= EXT_MAX_BLOCKS))
  		return -EFSCORRUPTED;
  
+ 	/*
+ 	 * Do not allow caching of unrelated ranges of extents during I/O
+ 	 * submission.
+ 	 */
+ 	if (flags & EXT4_GET_BLOCKS_IO_SUBMIT)
+ 		WARN_ON_ONCE(!(flags & EXT4_EX_NOCACHE));
+ 
  	/* Lookup extent status tree firstly */
 -	if (!(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY) &&
 -	    ext4_es_lookup_extent(inode, map->m_lblk, NULL, &es)) {
 +	if (ext4_es_lookup_extent(inode, map->m_lblk, &es)) {
  		if (ext4_es_is_written(&es) || ext4_es_is_unwritten(&es)) {
  			map->m_pblk = ext4_es_pblock(&es) +
  					map->m_lblk - es.es_lblk;
@@@ -559,36 -675,7 +681,40 @@@
  	 * file system block.
  	 */
  	down_read(&EXT4_I(inode)->i_data_sem);
++<<<<<<< HEAD
 +	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {
 +		retval = ext4_ext_map_blocks(handle, inode, map, flags &
 +					     EXT4_GET_BLOCKS_KEEP_SIZE);
 +	} else {
 +		retval = ext4_ind_map_blocks(handle, inode, map, flags &
 +					     EXT4_GET_BLOCKS_KEEP_SIZE);
 +	}
 +	if (retval > 0) {
 +		unsigned int status;
 +
 +		if (unlikely(retval != map->m_len)) {
 +			ext4_warning(inode->i_sb,
 +				     "ES len assertion failed for inode "
 +				     "%lu: retval %d != map->m_len %d",
 +				     inode->i_ino, retval, map->m_len);
 +			WARN_ON(1);
 +		}
 +
 +		status = map->m_flags & EXT4_MAP_UNWRITTEN ?
 +				EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
 +		if (!(flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE) &&
 +		    !(status & EXTENT_STATUS_WRITTEN) &&
 +		    ext4_es_scan_range(inode, &ext4_es_is_delayed, map->m_lblk,
 +				       map->m_lblk + map->m_len - 1))
 +			status |= EXTENT_STATUS_DELAYED;
 +		ret = ext4_es_insert_extent(inode, map->m_lblk,
 +					    map->m_len, map->m_pblk, status);
 +		if (ret < 0)
 +			retval = ret;
 +	}
++=======
+ 	retval = ext4_map_query_blocks(handle, inode, map, flags);
++>>>>>>> 402e38e6b71f (ext4: prevent stale extent cache entries caused by concurrent I/O writeback)
  	up_read((&EXT4_I(inode)->i_data_sem));
  
  found:
@@@ -1921,51 -1814,40 +2047,66 @@@ static int ext4_da_map_blocks(struct in
  	down_read(&EXT4_I(inode)->i_data_sem);
  	if (ext4_has_inline_data(inode))
  		retval = 0;
 +	else if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))
 +		retval = ext4_ext_map_blocks(NULL, inode, map, 0);
  	else
++<<<<<<< HEAD
 +		retval = ext4_ind_map_blocks(NULL, inode, map, 0);
++=======
+ 		retval = ext4_map_query_blocks(NULL, inode, map, 0);
+ 	up_read(&EXT4_I(inode)->i_data_sem);
+ 	if (retval)
+ 		return retval < 0 ? retval : 0;
++>>>>>>> 402e38e6b71f (ext4: prevent stale extent cache entries caused by concurrent I/O writeback)
  
  add_delayed:
 -	down_write(&EXT4_I(inode)->i_data_sem);
 -	/*
 -	 * Page fault path (ext4_page_mkwrite does not take i_rwsem)
 -	 * and fallocate path (no folio lock) can race. Make sure we
 -	 * lookup the extent status tree here again while i_data_sem
 -	 * is held in write mode, before inserting a new da entry in
 -	 * the extent status tree.
 -	 */
 -	if (ext4_es_lookup_extent(inode, map->m_lblk, NULL, &es)) {
 -		map->m_len = min_t(unsigned int, map->m_len,
 -				   es.es_len - (map->m_lblk - es.es_lblk));
 +	if (retval == 0) {
 +		int ret;
  
 -		if (!ext4_es_is_hole(&es)) {
 -			up_write(&EXT4_I(inode)->i_data_sem);
 -			goto found;
 +		/*
 +		 * XXX: __block_prepare_write() unmaps passed block,
 +		 * is it OK?
 +		 */
 +
 +		ret = ext4_insert_delayed_block(inode, map->m_lblk);
 +		if (ret != 0) {
 +			retval = ret;
 +			goto out_unlock;
  		}
++<<<<<<< HEAD
 +
 +		map_bh(bh, inode->i_sb, invalid_block);
 +		set_buffer_new(bh);
 +		set_buffer_delay(bh);
 +	} else if (retval > 0) {
 +		int ret;
 +		unsigned int status;
 +
 +		if (unlikely(retval != map->m_len)) {
 +			ext4_warning(inode->i_sb,
 +				     "ES len assertion failed for inode "
 +				     "%lu: retval %d != map->m_len %d",
 +				     inode->i_ino, retval, map->m_len);
 +			WARN_ON(1);
++=======
+ 	} else if (!ext4_has_inline_data(inode)) {
+ 		retval = ext4_map_query_blocks(NULL, inode, map, 0);
+ 		if (retval) {
+ 			up_write(&EXT4_I(inode)->i_data_sem);
+ 			return retval < 0 ? retval : 0;
++>>>>>>> 402e38e6b71f (ext4: prevent stale extent cache entries caused by concurrent I/O writeback)
  		}
 +
 +		status = map->m_flags & EXT4_MAP_UNWRITTEN ?
 +				EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
 +		ret = ext4_es_insert_extent(inode, map->m_lblk, map->m_len,
 +					    map->m_pblk, status);
 +		if (ret != 0)
 +			retval = ret;
  	}
  
 -	map->m_flags |= EXT4_MAP_DELAYED;
 -	retval = ext4_insert_delayed_blocks(inode, map->m_lblk, map->m_len);
 -	up_write(&EXT4_I(inode)->i_data_sem);
 +out_unlock:
 +	up_read((&EXT4_I(inode)->i_data_sem));
  
  	return retval;
  }
@@@ -2472,12 -2222,9 +2613,18 @@@ static int mpage_map_one_extent(handle_
  	 * previously reserved. However we must not fail because we're in
  	 * writeback and there is nothing we can do about it so it might result
  	 * in data loss.  So use reserved blocks to allocate metadata if
++<<<<<<< HEAD
 +	 * possible.
 +	 *
 +	 * We pass in the magic EXT4_GET_BLOCKS_DELALLOC_RESERVE if
 +	 * the blocks in question are delalloc blocks.  This indicates
 +	 * that the blocks and quotas has already been checked when
 +	 * the data was copied into the page cache.
++=======
+ 	 * possible. In addition, do not cache any unrelated extents, as it
+ 	 * only holds the folio lock but does not hold the i_rwsem or
+ 	 * invalidate_lock, which could corrupt the extent status tree.
++>>>>>>> 402e38e6b71f (ext4: prevent stale extent cache entries caused by concurrent I/O writeback)
  	 */
  	get_blocks_flags = EXT4_GET_BLOCKS_CREATE |
  			   EXT4_GET_BLOCKS_METADATA_NOFAIL |
* Unmerged path fs/ext4/fast_commit.c
diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 577e0a90ea41..5998c3303679 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -639,6 +639,7 @@ enum {
 #define EXT4_EX_NOCACHE				0x40000000
 #define EXT4_EX_FORCE_CACHE			0x20000000
 #define EXT4_EX_NOFAIL				0x10000000
+#define EXT4_EX_FILTER				0x70000000
 
 /*
  * Flags used by ext4_free_blocks
diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index c33bd5011cfd..485616b40788 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -4295,7 +4295,7 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 	trace_ext4_ext_map_blocks_enter(inode, map->m_lblk, map->m_len, flags);
 
 	/* find extent for this block */
-	path = ext4_find_extent(inode, map->m_lblk, NULL, 0);
+	path = ext4_find_extent(inode, map->m_lblk, NULL, flags);
 	if (IS_ERR(path)) {
 		err = PTR_ERR(path);
 		path = NULL;
@@ -4414,7 +4414,7 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 		goto out2;
 	ar.lright = map->m_lblk;
 	err = ext4_ext_search_right(inode, path, &ar.lright, &ar.pright,
-				    &ex2, 0);
+				    &ex2, flags);
 	if (err < 0)
 		goto out2;
 
@@ -5030,8 +5030,14 @@ int ext4_convert_unwritten_extents(handle_t *handle, struct inode *inode,
 				break;
 			}
 		}
+		/*
+		 * Do not cache any unrelated extents, as it does not hold the
+		 * i_rwsem or invalidate_lock, which could corrupt the extent
+		 * status tree.
+		 */
 		ret = ext4_map_blocks(handle, inode, &map,
-				      EXT4_GET_BLOCKS_IO_CONVERT_EXT);
+				      EXT4_GET_BLOCKS_IO_CONVERT_EXT |
+				      EXT4_EX_NOCACHE);
 		if (ret <= 0)
 			ext4_warning(inode->i_sb,
 				     "inode #%lu: block %u: len %u: "
* Unmerged path fs/ext4/fast_commit.c
* Unmerged path fs/ext4/inode.c
