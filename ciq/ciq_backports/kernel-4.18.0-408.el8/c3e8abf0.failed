KVM: x86: Remove defunct pre_block/post_block kvm_x86_ops hooks

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit c3e8abf0f3536a46a235b0533149c2b2c2bbac27
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/c3e8abf0.failed

Drop kvm_x86_ops' pre/post_block() now that all implementations are nops.

No functional change intended.

	Signed-off-by: Sean Christopherson <seanjc@google.com>
	Reviewed-by: Maxim Levitsky <mlevitsk@redhat.com>
Message-Id: <20211208015236.1616697-10-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit c3e8abf0f3536a46a235b0533149c2b2c2bbac27)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/vmx.c
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/vmx/vmx.c
index fa7a11f6f244,9ab98e1bd65a..000000000000
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@@ -7565,25 -7566,6 +7565,28 @@@ void vmx_update_cpu_dirty_logging(struc
  		secondary_exec_controls_clearbit(vmx, SECONDARY_EXEC_ENABLE_PML);
  }
  
++<<<<<<< HEAD
 +static int vmx_pre_block(struct kvm_vcpu *vcpu)
 +{
 +	if (pi_pre_block(vcpu))
 +		return 1;
 +
 +	if (kvm_lapic_hv_timer_in_use(vcpu))
 +		kvm_lapic_switch_to_sw_timer(vcpu);
 +
 +	return 0;
 +}
 +
 +static void vmx_post_block(struct kvm_vcpu *vcpu)
 +{
 +	if (kvm_x86_ops.set_hv_timer)
 +		kvm_lapic_switch_to_hv_timer(vcpu);
 +
 +	pi_post_block(vcpu);
 +}
 +
++=======
++>>>>>>> c3e8abf0f353 (KVM: x86: Remove defunct pre_block/post_block kvm_x86_ops hooks)
  static void vmx_setup_mce(struct kvm_vcpu *vcpu)
  {
  	if (vcpu->arch.mcg_cap & MCG_LMCE_P)
diff --cc arch/x86/kvm/x86.c
index d4fb9b5f6dc3,4b9728a53de6..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -10158,14 -10146,29 +10158,36 @@@ out
  
  static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	if (!kvm_arch_vcpu_runnable(vcpu) &&
 +	    (!kvm_x86_ops.pre_block || static_call(kvm_x86_pre_block)(vcpu) == 0)) {
++=======
+ 	bool hv_timer;
+ 
+ 	if (!kvm_arch_vcpu_runnable(vcpu)) {
+ 		/*
+ 		 * Switch to the software timer before halt-polling/blocking as
+ 		 * the guest's timer may be a break event for the vCPU, and the
+ 		 * hypervisor timer runs only when the CPU is in guest mode.
+ 		 * Switch before halt-polling so that KVM recognizes an expired
+ 		 * timer before blocking.
+ 		 */
+ 		hv_timer = kvm_lapic_hv_timer_in_use(vcpu);
+ 		if (hv_timer)
+ 			kvm_lapic_switch_to_sw_timer(vcpu);
+ 
++>>>>>>> c3e8abf0f353 (KVM: x86: Remove defunct pre_block/post_block kvm_x86_ops hooks)
  		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
 -		if (vcpu->arch.mp_state == KVM_MP_STATE_HALTED)
 -			kvm_vcpu_halt(vcpu);
 -		else
 -			kvm_vcpu_block(vcpu);
 +		kvm_vcpu_block(vcpu);
  		vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
  
++<<<<<<< HEAD
 +		if (kvm_x86_ops.post_block)
 +			static_call(kvm_x86_post_block)(vcpu);
++=======
+ 		if (hv_timer)
+ 			kvm_lapic_switch_to_hv_timer(vcpu);
++>>>>>>> c3e8abf0f353 (KVM: x86: Remove defunct pre_block/post_block kvm_x86_ops hooks)
  
  		if (!kvm_check_request(KVM_REQ_UNHALT, vcpu))
  			return 1;
diff --git a/arch/x86/include/asm/kvm-x86-ops.h b/arch/x86/include/asm/kvm-x86-ops.h
index 65c3f1857d6e..631d5040b31e 100644
--- a/arch/x86/include/asm/kvm-x86-ops.h
+++ b/arch/x86/include/asm/kvm-x86-ops.h
@@ -99,8 +99,6 @@ KVM_X86_OP(handle_exit_irqoff)
 KVM_X86_OP_NULL(request_immediate_exit)
 KVM_X86_OP(sched_in)
 KVM_X86_OP_NULL(update_cpu_dirty_logging)
-KVM_X86_OP_NULL(pre_block)
-KVM_X86_OP_NULL(post_block)
 KVM_X86_OP_NULL(vcpu_blocking)
 KVM_X86_OP_NULL(vcpu_unblocking)
 KVM_X86_OP_NULL(update_pi_irte)
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index dcdfec4f519c..aae0c5afc6b2 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1434,18 +1434,6 @@ struct kvm_x86_ops {
 	const struct kvm_pmu_ops *pmu_ops;
 	const struct kvm_x86_nested_ops *nested_ops;
 
-	/*
-	 * Architecture specific hooks for vCPU blocking due to
-	 * HLT instruction.
-	 * Returns for .pre_block():
-	 *    - 0 means continue to block the vCPU.
-	 *    - 1 means we cannot block the vCPU since some event
-	 *        happens during this period, such as, 'ON' bit in
-	 *        posted-interrupts descriptor is set.
-	 */
-	int (*pre_block)(struct kvm_vcpu *vcpu);
-	void (*post_block)(struct kvm_vcpu *vcpu);
-
 	void (*vcpu_blocking)(struct kvm_vcpu *vcpu);
 	void (*vcpu_unblocking)(struct kvm_vcpu *vcpu);
 
* Unmerged path arch/x86/kvm/vmx/vmx.c
* Unmerged path arch/x86/kvm/x86.c
