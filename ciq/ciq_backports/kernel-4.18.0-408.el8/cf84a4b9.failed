dmaengine: idxd: remove interrupt disable for dev_lock

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Dave Jiang <dave.jiang@intel.com>
commit cf84a4b968f38383534bcd0484385c9254828b2c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/cf84a4b9.failed

The spinlock is not being used in hard interrupt context. There is no need
to disable irq when acquiring the lock. The interrupt thread handler also
is not in bottom half context, therefore we can also remove disabling of
the bh. Convert all dev_lock acquisition to plain spin_lock() calls.

	Reviewed-by: Dan Williams <dan.j.williams@intel.com>
	Signed-off-by: Dave Jiang <dave.jiang@intel.com>
Link: https://lore.kernel.org/r/162984026772.1939166.11504067782824765879.stgit@djiang5-desk3.ch.intel.com
	Signed-off-by: Vinod Koul <vkoul@kernel.org>
(cherry picked from commit cf84a4b968f38383534bcd0484385c9254828b2c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/dma/idxd/device.c
#	drivers/dma/idxd/sysfs.c
diff --cc drivers/dma/idxd/device.c
index 9c4e69700bcc,83a5ff2ecf2a..000000000000
--- a/drivers/dma/idxd/device.c
+++ b/drivers/dma/idxd/device.c
@@@ -1128,3 -1154,203 +1123,206 @@@ int idxd_device_load_config(struct idxd
  
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ 
+ int __drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 	int rc = -ENXIO;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED) {
+ 		idxd->cmd_status = IDXD_SCMD_DEV_NOT_ENABLED;
+ 		goto err;
+ 	}
+ 
+ 	if (wq->state != IDXD_WQ_DISABLED) {
+ 		dev_dbg(dev, "wq %d already enabled.\n", wq->id);
+ 		idxd->cmd_status = IDXD_SCMD_WQ_ENABLED;
+ 		rc = -EBUSY;
+ 		goto err;
+ 	}
+ 
+ 	if (!wq->group) {
+ 		dev_dbg(dev, "wq %d not attached to group.\n", wq->id);
+ 		idxd->cmd_status = IDXD_SCMD_WQ_NO_GRP;
+ 		goto err;
+ 	}
+ 
+ 	if (strlen(wq->name) == 0) {
+ 		idxd->cmd_status = IDXD_SCMD_WQ_NO_NAME;
+ 		dev_dbg(dev, "wq %d name not set.\n", wq->id);
+ 		goto err;
+ 	}
+ 
+ 	/* Shared WQ checks */
+ 	if (wq_shared(wq)) {
+ 		if (!device_swq_supported(idxd)) {
+ 			idxd->cmd_status = IDXD_SCMD_WQ_NO_SVM;
+ 			dev_dbg(dev, "PASID not enabled and shared wq.\n");
+ 			goto err;
+ 		}
+ 		/*
+ 		 * Shared wq with the threshold set to 0 means the user
+ 		 * did not set the threshold or transitioned from a
+ 		 * dedicated wq but did not set threshold. A value
+ 		 * of 0 would effectively disable the shared wq. The
+ 		 * driver does not allow a value of 0 to be set for
+ 		 * threshold via sysfs.
+ 		 */
+ 		if (wq->threshold == 0) {
+ 			idxd->cmd_status = IDXD_SCMD_WQ_NO_THRESH;
+ 			dev_dbg(dev, "Shared wq and threshold 0.\n");
+ 			goto err;
+ 		}
+ 	}
+ 
+ 	rc = 0;
+ 	spin_lock(&idxd->dev_lock);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		rc = idxd_device_config(idxd);
+ 	spin_unlock(&idxd->dev_lock);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Writing wq %d config failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_enable(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq %d enabling failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_map_portal(wq);
+ 	if (rc < 0) {
+ 		idxd->cmd_status = IDXD_SCMD_WQ_PORTAL_ERR;
+ 		dev_dbg(dev, "wq %d portal mapping failed: %d\n", wq->id, rc);
+ 		goto err_map_portal;
+ 	}
+ 
+ 	wq->client_count = 0;
+ 	return 0;
+ 
+ err_map_portal:
+ 	rc = idxd_wq_disable(wq, false);
+ 	if (rc < 0)
+ 		dev_dbg(dev, "wq %s disable failed\n", dev_name(wq_confdev(wq)));
+ err:
+ 	return rc;
+ }
+ 
+ int drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	int rc;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	rc = __drv_enable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ void __drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (idxd_wq_refcount(wq))
+ 		dev_warn(dev, "Clients has claim on wq %d: %d\n",
+ 			 wq->id, idxd_wq_refcount(wq));
+ 
+ 	idxd_wq_unmap_portal(wq);
+ 
+ 	idxd_wq_drain(wq);
+ 	idxd_wq_reset(wq);
+ 
+ 	wq->client_count = 0;
+ }
+ 
+ void drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	mutex_lock(&wq->wq_lock);
+ 	__drv_disable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ }
+ 
+ int idxd_device_drv_probe(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_device *idxd = idxd_dev_to_idxd(idxd_dev);
+ 	int rc = 0;
+ 
+ 	/*
+ 	 * Device should be in disabled state for the idxd_drv to load. If it's in
+ 	 * enabled state, then the device was altered outside of driver's control.
+ 	 * If the state is in halted state, then we don't want to proceed.
+ 	 */
+ 	if (idxd->state != IDXD_DEV_DISABLED) {
+ 		idxd->cmd_status = IDXD_SCMD_DEV_ENABLED;
+ 		return -ENXIO;
+ 	}
+ 
+ 	/* Device configuration */
+ 	spin_lock(&idxd->dev_lock);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		rc = idxd_device_config(idxd);
+ 	spin_unlock(&idxd->dev_lock);
+ 	if (rc < 0)
+ 		return -ENXIO;
+ 
+ 	/* Start device */
+ 	rc = idxd_device_enable(idxd);
+ 	if (rc < 0)
+ 		return rc;
+ 
+ 	/* Setup DMA device without channels */
+ 	rc = idxd_register_dma_device(idxd);
+ 	if (rc < 0) {
+ 		idxd_device_disable(idxd);
+ 		idxd->cmd_status = IDXD_SCMD_DEV_DMA_ERR;
+ 		return rc;
+ 	}
+ 
+ 	idxd->cmd_status = 0;
+ 	return 0;
+ }
+ 
+ void idxd_device_drv_remove(struct idxd_dev *idxd_dev)
+ {
+ 	struct device *dev = &idxd_dev->conf_dev;
+ 	struct idxd_device *idxd = idxd_dev_to_idxd(idxd_dev);
+ 	int i;
+ 
+ 	for (i = 0; i < idxd->max_wqs; i++) {
+ 		struct idxd_wq *wq = idxd->wqs[i];
+ 		struct device *wq_dev = wq_confdev(wq);
+ 
+ 		if (wq->state == IDXD_WQ_DISABLED)
+ 			continue;
+ 		dev_warn(dev, "Active wq %d on disable %s.\n", i, dev_name(wq_dev));
+ 		device_release_driver(wq_dev);
+ 	}
+ 
+ 	idxd_unregister_dma_device(idxd);
+ 	idxd_device_disable(idxd);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		idxd_device_reset(idxd);
+ }
+ 
+ static enum idxd_dev_type dev_types[] = {
+ 	IDXD_DEV_DSA,
+ 	IDXD_DEV_IAX,
+ 	IDXD_DEV_NONE,
+ };
+ 
+ struct idxd_device_driver idxd_drv = {
+ 	.type = dev_types,
+ 	.probe = idxd_device_drv_probe,
+ 	.remove = idxd_device_drv_remove,
+ 	.name = "idxd",
+ };
+ EXPORT_SYMBOL_GPL(idxd_drv);
++>>>>>>> cf84a4b968f3 (dmaengine: idxd: remove interrupt disable for dev_lock)
diff --cc drivers/dma/idxd/sysfs.c
index 4cfaba0faeca,a9025be940db..000000000000
--- a/drivers/dma/idxd/sysfs.c
+++ b/drivers/dma/idxd/sysfs.c
@@@ -1413,12 -1098,10 +1413,16 @@@ static DEVICE_ATTR_RO(configurable)
  static ssize_t clients_show(struct device *dev,
  			    struct device_attribute *attr, char *buf)
  {
++<<<<<<< HEAD
 +	struct idxd_device *idxd =
 +		container_of(dev, struct idxd_device, conf_dev);
 +	unsigned long flags;
++=======
+ 	struct idxd_device *idxd = confdev_to_idxd(dev);
++>>>>>>> cf84a4b968f3 (dmaengine: idxd: remove interrupt disable for dev_lock)
  	int count = 0, i;
  
- 	spin_lock_irqsave(&idxd->dev_lock, flags);
+ 	spin_lock(&idxd->dev_lock);
  	for (i = 0; i < idxd->max_wqs; i++) {
  		struct idxd_wq *wq = idxd->wqs[i];
  
@@@ -1462,15 -1143,13 +1466,14 @@@ static DEVICE_ATTR_RO(state)
  static ssize_t errors_show(struct device *dev,
  			   struct device_attribute *attr, char *buf)
  {
 -	struct idxd_device *idxd = confdev_to_idxd(dev);
 +	struct idxd_device *idxd =
 +		container_of(dev, struct idxd_device, conf_dev);
  	int i, out = 0;
- 	unsigned long flags;
  
- 	spin_lock_irqsave(&idxd->dev_lock, flags);
+ 	spin_lock(&idxd->dev_lock);
  	for (i = 0; i < 4; i++)
  		out += sysfs_emit_at(buf, out, "%#018llx ", idxd->sw_err.bits[i]);
- 	spin_unlock_irqrestore(&idxd->dev_lock, flags);
+ 	spin_unlock(&idxd->dev_lock);
  	out--;
  	out += sysfs_emit_at(buf, out, "\n");
  	return out;
diff --git a/drivers/dma/idxd/cdev.c b/drivers/dma/idxd/cdev.c
index e9def577c697..71e0d9f989c6 100644
--- a/drivers/dma/idxd/cdev.c
+++ b/drivers/dma/idxd/cdev.c
@@ -218,14 +218,13 @@ static __poll_t idxd_cdev_poll(struct file *filp,
 	struct idxd_user_context *ctx = filp->private_data;
 	struct idxd_wq *wq = ctx->wq;
 	struct idxd_device *idxd = wq->idxd;
-	unsigned long flags;
 	__poll_t out = 0;
 
 	poll_wait(filp, &wq->err_queue, wait);
-	spin_lock_irqsave(&idxd->dev_lock, flags);
+	spin_lock(&idxd->dev_lock);
 	if (idxd->sw_err.valid)
 		out = EPOLLIN | EPOLLRDNORM;
-	spin_unlock_irqrestore(&idxd->dev_lock, flags);
+	spin_unlock(&idxd->dev_lock);
 
 	return out;
 }
* Unmerged path drivers/dma/idxd/device.c
diff --git a/drivers/dma/idxd/irq.c b/drivers/dma/idxd/irq.c
index 7a2cf0512501..ade72c16cc00 100644
--- a/drivers/dma/idxd/irq.c
+++ b/drivers/dma/idxd/irq.c
@@ -111,7 +111,7 @@ static int process_misc_interrupts(struct idxd_device *idxd, u32 cause)
 	bool err = false;
 
 	if (cause & IDXD_INTC_ERR) {
-		spin_lock_bh(&idxd->dev_lock);
+		spin_lock(&idxd->dev_lock);
 		for (i = 0; i < 4; i++)
 			idxd->sw_err.bits[i] = ioread64(idxd->reg_base +
 					IDXD_SWERR_OFFSET + i * sizeof(u64));
@@ -136,7 +136,7 @@ static int process_misc_interrupts(struct idxd_device *idxd, u32 cause)
 			}
 		}
 
-		spin_unlock_bh(&idxd->dev_lock);
+		spin_unlock(&idxd->dev_lock);
 		val |= IDXD_INTC_ERR;
 
 		for (i = 0; i < 4; i++)
@@ -189,7 +189,7 @@ static int process_misc_interrupts(struct idxd_device *idxd, u32 cause)
 			INIT_WORK(&idxd->work, idxd_device_reinit);
 			queue_work(idxd->wq, &idxd->work);
 		} else {
-			spin_lock_bh(&idxd->dev_lock);
+			spin_lock(&idxd->dev_lock);
 			idxd_wqs_quiesce(idxd);
 			idxd_wqs_unmap_portal(idxd);
 			idxd_device_clear_state(idxd);
@@ -197,7 +197,7 @@ static int process_misc_interrupts(struct idxd_device *idxd, u32 cause)
 				"idxd halted, need %s.\n",
 				gensts.reset_type == IDXD_DEVICE_RESET_FLR ?
 				"FLR" : "system reset");
-			spin_unlock_bh(&idxd->dev_lock);
+			spin_unlock(&idxd->dev_lock);
 			return -ENXIO;
 		}
 	}
* Unmerged path drivers/dma/idxd/sysfs.c
