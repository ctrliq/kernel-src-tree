KVM: x86/mmu: Rename __rmap_write_protect() to rmap_write_protect()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author David Matlack <dmatlack@google.com>
commit 1346bbb6b4189bc355417ef4d021011ac7e8d239
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/1346bbb6.failed

The function formerly known as rmap_write_protect() has been renamed to
kvm_vcpu_write_protect_gfn(), so we can get rid of the double
underscores in front of __rmap_write_protect().

No functional change intended.

	Reviewed-by: Ben Gardon <bgardon@google.com>
	Reviewed-by: Peter Xu <peterx@redhat.com>
	Reviewed-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: David Matlack <dmatlack@google.com>
Message-Id: <20220119230739.2234394-3-dmatlack@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 1346bbb6b4189bc355417ef4d021011ac7e8d239)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
diff --cc arch/x86/kvm/mmu/mmu.c
index 74910234d306,443c1b35fc7a..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -1227,9 -1228,8 +1227,14 @@@ static bool spte_write_protect(u64 *spt
  	return mmu_spte_update(sptep, spte);
  }
  
++<<<<<<< HEAD
 +static bool __rmap_write_protect(struct kvm *kvm,
 +				 struct kvm_rmap_head *rmap_head,
 +				 bool pt_protect)
++=======
+ static bool rmap_write_protect(struct kvm_rmap_head *rmap_head,
+ 			       bool pt_protect)
++>>>>>>> 1346bbb6b418 (KVM: x86/mmu: Rename __rmap_write_protect() to rmap_write_protect())
  {
  	u64 *sptep;
  	struct rmap_iterator iter;
@@@ -1302,10 -1302,14 +1307,16 @@@ static void kvm_mmu_write_protect_pt_ma
  	if (is_tdp_mmu_enabled(kvm))
  		kvm_tdp_mmu_clear_dirty_pt_masked(kvm, slot,
  				slot->base_gfn + gfn_offset, mask, true);
 -
 -	if (!kvm_memslots_have_rmaps(kvm))
 -		return;
 -
  	while (mask) {
++<<<<<<< HEAD
 +		rmap_head = __gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),
 +					  PG_LEVEL_4K, slot);
 +		__rmap_write_protect(kvm, rmap_head, false);
++=======
+ 		rmap_head = gfn_to_rmap(slot->base_gfn + gfn_offset + __ffs(mask),
+ 					PG_LEVEL_4K, slot);
+ 		rmap_write_protect(rmap_head, false);
++>>>>>>> 1346bbb6b418 (KVM: x86/mmu: Rename __rmap_write_protect() to rmap_write_protect())
  
  		/* clear the first set bit */
  		mask &= mask - 1;
@@@ -1397,9 -1405,11 +1408,17 @@@ bool kvm_mmu_slot_gfn_write_protect(str
  	int i;
  	bool write_protected = false;
  
++<<<<<<< HEAD
 +	for (i = min_level; i <= KVM_MAX_HUGEPAGE_LEVEL; ++i) {
 +		rmap_head = __gfn_to_rmap(gfn, i, slot);
 +		write_protected |= __rmap_write_protect(kvm, rmap_head, true);
++=======
+ 	if (kvm_memslots_have_rmaps(kvm)) {
+ 		for (i = min_level; i <= KVM_MAX_HUGEPAGE_LEVEL; ++i) {
+ 			rmap_head = gfn_to_rmap(gfn, i, slot);
+ 			write_protected |= rmap_write_protect(rmap_head, true);
+ 		}
++>>>>>>> 1346bbb6b418 (KVM: x86/mmu: Rename __rmap_write_protect() to rmap_write_protect())
  	}
  
  	if (is_tdp_mmu_enabled(kvm))
@@@ -5725,9 -5796,9 +5744,13 @@@ void kvm_zap_gfn_range(struct kvm *kvm
  
  static bool slot_rmap_write_protect(struct kvm *kvm,
  				    struct kvm_rmap_head *rmap_head,
 -				    const struct kvm_memory_slot *slot)
 +				    struct kvm_memory_slot *slot)
  {
++<<<<<<< HEAD
 +	return __rmap_write_protect(kvm, rmap_head, false);
++=======
+ 	return rmap_write_protect(rmap_head, false);
++>>>>>>> 1346bbb6b418 (KVM: x86/mmu: Rename __rmap_write_protect() to rmap_write_protect())
  }
  
  void kvm_mmu_slot_remove_write_access(struct kvm *kvm,
* Unmerged path arch/x86/kvm/mmu/mmu.c
