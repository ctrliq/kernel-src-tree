KVM: SVM: Rename AVIC helpers to use "avic" prefix instead of "svm"

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit db6e7adf8de9b3b99a9856acb73870cc3a70e3ca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/db6e7adf.failed

Use "avic" instead of "svm" for SVM's all of APICv hooks and make a few
additional funciton name tweaks so that the AVIC functions conform to
their associated kvm_x86_ops hooks.

No functional change intended.

	Signed-off-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20220128005208.4008533-19-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit db6e7adf8de9b3b99a9856acb73870cc3a70e3ca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/avic.c
#	arch/x86/kvm/svm/svm.h
diff --cc arch/x86/kvm/svm/avic.c
index a77f6cee3cf0,abd0e664bf22..000000000000
--- a/arch/x86/kvm/svm/avic.c
+++ b/arch/x86/kvm/svm/avic.c
@@@ -667,51 -668,7 +667,55 @@@ void avic_load_eoi_exitmap(struct kvm_v
  	return;
  }
  
++<<<<<<< HEAD
 +int svm_deliver_avic_intr(struct kvm_vcpu *vcpu, int vec)
 +{
 +	if (!vcpu->arch.apicv_active)
 +		return -1;
 +
 +	/*
 +	 * Pairs with the smp_mb_*() after setting vcpu->guest_mode in
 +	 * vcpu_enter_guest() to ensure the write to the vIRR is ordered before
 +	 * the read of guest_mode, which guarantees that either VMRUN will see
 +	 * and process the new vIRR entry, or that the below code will signal
 +	 * the doorbell if the vCPU is already running in the guest.
 +	 */
 +	smp_mb__after_atomic();
 +
 +	/*
 +	 * Signal the doorbell to tell hardware to inject the IRQ if the vCPU
 +	 * is in the guest.  If the vCPU is not in the guest, hardware will
 +	 * automatically process AVIC interrupts at VMRUN.
 +	 */
 +	if (vcpu->mode == IN_GUEST_MODE) {
 +		int cpu = READ_ONCE(vcpu->cpu);
 +
 +		/*
 +		 * Note, the vCPU could get migrated to a different pCPU at any
 +		 * point, which could result in signalling the wrong/previous
 +		 * pCPU.  But if that happens the vCPU is guaranteed to do a
 +		 * VMRUN (after being migrated) and thus will process pending
 +		 * interrupts, i.e. a doorbell is not needed (and the spurious
 +		 * one is harmless).
 +		 */
 +		if (cpu != get_cpu())
 +			wrmsrl(SVM_AVIC_DOORBELL, kvm_cpu_get_apicid(cpu));
 +		put_cpu();
 +	} else {
 +		/*
 +		 * Wake the vCPU if it was blocking.  KVM will then detect the
 +		 * pending IRQ when checking if the vCPU has a wake event.
 +		 */
 +		kvm_vcpu_wake_up(vcpu);
 +	}
 +
 +	return 0;
 +}
 +
 +bool svm_dy_apicv_has_pending_interrupt(struct kvm_vcpu *vcpu)
++=======
+ bool avic_dy_apicv_has_pending_interrupt(struct kvm_vcpu *vcpu)
++>>>>>>> db6e7adf8de9 (KVM: SVM: Rename AVIC helpers to use "avic" prefix instead of "svm")
  {
  	return false;
  }
diff --cc arch/x86/kvm/svm/svm.h
index b72dd1b3a3c6,c1f0cc4a9369..000000000000
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@@ -585,19 -577,19 +585,35 @@@ int avic_unaccelerated_access_intercept
  int avic_init_vcpu(struct vcpu_svm *svm);
  void avic_vcpu_load(struct kvm_vcpu *vcpu, int cpu);
  void avic_vcpu_put(struct kvm_vcpu *vcpu);
++<<<<<<< HEAD
 +void avic_post_state_restore(struct kvm_vcpu *vcpu);
 +void svm_set_virtual_apic_mode(struct kvm_vcpu *vcpu);
 +void svm_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu);
 +bool svm_check_apicv_inhibit_reasons(ulong bit);
 +void svm_load_eoi_exitmap(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap);
 +void svm_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr);
 +void svm_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr);
 +int svm_deliver_avic_intr(struct kvm_vcpu *vcpu, int vec);
 +bool svm_dy_apicv_has_pending_interrupt(struct kvm_vcpu *vcpu);
 +int svm_update_pi_irte(struct kvm *kvm, unsigned int host_irq,
 +		       uint32_t guest_irq, bool set);
 +void svm_vcpu_blocking(struct kvm_vcpu *vcpu);
 +void svm_vcpu_unblocking(struct kvm_vcpu *vcpu);
++=======
+ void avic_apicv_post_state_restore(struct kvm_vcpu *vcpu);
+ void avic_set_virtual_apic_mode(struct kvm_vcpu *vcpu);
+ void avic_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu);
+ bool avic_check_apicv_inhibit_reasons(ulong bit);
+ void avic_load_eoi_exitmap(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap);
+ void avic_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr);
+ void avic_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr);
+ bool avic_dy_apicv_has_pending_interrupt(struct kvm_vcpu *vcpu);
+ int avic_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
+ 			uint32_t guest_irq, bool set);
+ void avic_vcpu_blocking(struct kvm_vcpu *vcpu);
+ void avic_vcpu_unblocking(struct kvm_vcpu *vcpu);
+ void avic_ring_doorbell(struct kvm_vcpu *vcpu);
++>>>>>>> db6e7adf8de9 (KVM: SVM: Rename AVIC helpers to use "avic" prefix instead of "svm")
  
  /* sev.c */
  
* Unmerged path arch/x86/kvm/svm/avic.c
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 3765ba922ed5..fd3a1c12c7e1 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -4520,13 +4520,13 @@ static struct kvm_x86_ops svm_x86_ops __initdata = {
 	.enable_nmi_window = svm_enable_nmi_window,
 	.enable_irq_window = svm_enable_irq_window,
 	.update_cr8_intercept = svm_update_cr8_intercept,
-	.set_virtual_apic_mode = svm_set_virtual_apic_mode,
-	.refresh_apicv_exec_ctrl = svm_refresh_apicv_exec_ctrl,
-	.check_apicv_inhibit_reasons = svm_check_apicv_inhibit_reasons,
-	.load_eoi_exitmap = svm_load_eoi_exitmap,
-	.hwapic_irr_update = svm_hwapic_irr_update,
-	.hwapic_isr_update = svm_hwapic_isr_update,
-	.apicv_post_state_restore = avic_post_state_restore,
+	.set_virtual_apic_mode = avic_set_virtual_apic_mode,
+	.refresh_apicv_exec_ctrl = avic_refresh_apicv_exec_ctrl,
+	.check_apicv_inhibit_reasons = avic_check_apicv_inhibit_reasons,
+	.load_eoi_exitmap = avic_load_eoi_exitmap,
+	.hwapic_irr_update = avic_hwapic_irr_update,
+	.hwapic_isr_update = avic_hwapic_isr_update,
+	.apicv_post_state_restore = avic_apicv_post_state_restore,
 
 	.set_tss_addr = svm_set_tss_addr,
 	.set_identity_map_addr = svm_set_identity_map_addr,
@@ -4556,8 +4556,8 @@ static struct kvm_x86_ops svm_x86_ops __initdata = {
 	.nested_ops = &svm_nested_ops,
 
 	.deliver_interrupt = svm_deliver_interrupt,
-	.dy_apicv_has_pending_interrupt = svm_dy_apicv_has_pending_interrupt,
-	.pi_update_irte = svm_update_pi_irte,
+	.dy_apicv_has_pending_interrupt = avic_dy_apicv_has_pending_interrupt,
+	.pi_update_irte = avic_pi_update_irte,
 	.setup_mce = svm_setup_mce,
 
 	.smi_allowed = svm_smi_allowed,
* Unmerged path arch/x86/kvm/svm/svm.h
