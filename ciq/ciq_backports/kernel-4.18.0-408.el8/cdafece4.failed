KVM: x86: Invoke kvm_vcpu_block() directly for non-HALTED wait states

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit cdafece4b964a27b2d3d76bf5725b49415bbaaea
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/cdafece4.failed

Call kvm_vcpu_block() directly for all wait states except HALTED so that
kvm_vcpu_halt() is no longer a misnomer on x86.

Functionally, this means KVM will never attempt halt-polling or adjust
vcpu->halt_poll_ns for INIT_RECEIVED (a.k.a. Wait-For-SIPI (WFS)) or
AP_RESET_HOLD; UNINITIALIZED is handled in kvm_arch_vcpu_ioctl_run(),
and x86 doesn't use any other "wait" states.

As mentioned above, the motivation of this is purely so that "halt" isn't
overloaded on x86, e.g. in KVM's stats.  Skipping halt-polling for WFS
(and RESET_HOLD) has no meaningful effect on guest performance as there
are typically single-digit numbers of INIT-SIPI sequences per AP vCPU,
per boot, versus thousands of HLTs just to boot to console.

	Reviewed-by: David Matlack <dmatlack@google.com>
	Signed-off-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20211009021236.4122790-19-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit cdafece4b964a27b2d3d76bf5725b49415bbaaea)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index c4415c448661,50450ebe709f..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -10127,7 -10006,10 +10127,14 @@@ static inline int vcpu_block(struct kv
  	if (!kvm_arch_vcpu_runnable(vcpu) &&
  	    (!kvm_x86_ops.pre_block || static_call(kvm_x86_pre_block)(vcpu) == 0)) {
  		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
++<<<<<<< HEAD
 +		kvm_vcpu_block(vcpu);
++=======
+ 		if (vcpu->arch.mp_state == KVM_MP_STATE_HALTED)
+ 			kvm_vcpu_halt(vcpu);
+ 		else
+ 			kvm_vcpu_block(vcpu);
++>>>>>>> cdafece4b964 (KVM: x86: Invoke kvm_vcpu_block() directly for non-HALTED wait states)
  		vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
  
  		if (kvm_x86_ops.post_block)
* Unmerged path arch/x86/kvm/x86.c
