KVM: x86: Check for rmaps allocation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Nikunj A Dadhania <nikunj@amd.com>
commit fffb5323780786c81ba005f8b8603d4a558aad28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/fffb5323.failed

With TDP MMU being the default now, access to mmu_rmaps_stat debugfs
file causes following oops:

BUG: kernel NULL pointer dereference, address: 0000000000000000
PGD 0 P4D 0
Oops: 0000 [#1] PREEMPT SMP NOPTI
CPU: 7 PID: 3185 Comm: cat Not tainted 5.16.0-rc4+ #204
RIP: 0010:pte_list_count+0x6/0x40
 Call Trace:
  <TASK>
  ? kvm_mmu_rmaps_stat_show+0x15e/0x320
  seq_read_iter+0x126/0x4b0
  ? aa_file_perm+0x124/0x490
  seq_read+0xf5/0x140
  full_proxy_read+0x5c/0x80
  vfs_read+0x9f/0x1a0
  ksys_read+0x67/0xe0
  __x64_sys_read+0x19/0x20
  do_syscall_64+0x3b/0xc0
  entry_SYSCALL_64_after_hwframe+0x44/0xae
 RIP: 0033:0x7fca6fc13912

Return early when rmaps are not present.

	Reported-by: Vasant Hegde <vasant.hegde@amd.com>
	Tested-by: Vasant Hegde <vasant.hegde@amd.com>
	Signed-off-by: Nikunj A Dadhania <nikunj@amd.com>
	Reviewed-by: Peter Xu <peterx@redhat.com>
	Reviewed-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20220105040337.4234-1-nikunj@amd.com>
	Cc: stable@vger.kernel.org
Fixes: 3bcd0662d66f ("KVM: X86: Introduce mmu_rmaps_stat per-vm debugfs file")
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit fffb5323780786c81ba005f8b8603d4a558aad28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/debugfs.c
diff --cc arch/x86/kvm/debugfs.c
index 95a98413dc32,f33c804a922a..000000000000
--- a/arch/x86/kvm/debugfs.c
+++ b/arch/x86/kvm/debugfs.c
@@@ -73,3 -75,115 +73,118 @@@ void kvm_arch_create_vcpu_debugfs(struc
  				    &vcpu_tsc_scaling_frac_fops);
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * This covers statistics <1024 (11=log(1024)+1), which should be enough to
+  * cover RMAP_RECYCLE_THRESHOLD.
+  */
+ #define  RMAP_LOG_SIZE  11
+ 
+ static const char *kvm_lpage_str[KVM_NR_PAGE_SIZES] = { "4K", "2M", "1G" };
+ 
+ static int kvm_mmu_rmaps_stat_show(struct seq_file *m, void *v)
+ {
+ 	struct kvm_rmap_head *rmap;
+ 	struct kvm *kvm = m->private;
+ 	struct kvm_memory_slot *slot;
+ 	struct kvm_memslots *slots;
+ 	unsigned int lpage_size, index;
+ 	/* Still small enough to be on the stack */
+ 	unsigned int *log[KVM_NR_PAGE_SIZES], *cur;
+ 	int i, j, k, l, ret;
+ 
+ 	if (!kvm_memslots_have_rmaps(kvm))
+ 		return 0;
+ 
+ 	ret = -ENOMEM;
+ 	memset(log, 0, sizeof(log));
+ 	for (i = 0; i < KVM_NR_PAGE_SIZES; i++) {
+ 		log[i] = kcalloc(RMAP_LOG_SIZE, sizeof(unsigned int), GFP_KERNEL);
+ 		if (!log[i])
+ 			goto out;
+ 	}
+ 
+ 	mutex_lock(&kvm->slots_lock);
+ 	write_lock(&kvm->mmu_lock);
+ 
+ 	for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {
+ 		slots = __kvm_memslots(kvm, i);
+ 		for (j = 0; j < slots->used_slots; j++) {
+ 			slot = &slots->memslots[j];
+ 			for (k = 0; k < KVM_NR_PAGE_SIZES; k++) {
+ 				rmap = slot->arch.rmap[k];
+ 				lpage_size = kvm_mmu_slot_lpages(slot, k + 1);
+ 				cur = log[k];
+ 				for (l = 0; l < lpage_size; l++) {
+ 					index = ffs(pte_list_count(&rmap[l]));
+ 					if (WARN_ON_ONCE(index >= RMAP_LOG_SIZE))
+ 						index = RMAP_LOG_SIZE - 1;
+ 					cur[index]++;
+ 				}
+ 			}
+ 		}
+ 	}
+ 
+ 	write_unlock(&kvm->mmu_lock);
+ 	mutex_unlock(&kvm->slots_lock);
+ 
+ 	/* index=0 counts no rmap; index=1 counts 1 rmap */
+ 	seq_printf(m, "Rmap_Count:\t0\t1\t");
+ 	for (i = 2; i < RMAP_LOG_SIZE; i++) {
+ 		j = 1 << (i - 1);
+ 		k = (1 << i) - 1;
+ 		seq_printf(m, "%d-%d\t", j, k);
+ 	}
+ 	seq_printf(m, "\n");
+ 
+ 	for (i = 0; i < KVM_NR_PAGE_SIZES; i++) {
+ 		seq_printf(m, "Level=%s:\t", kvm_lpage_str[i]);
+ 		cur = log[i];
+ 		for (j = 0; j < RMAP_LOG_SIZE; j++)
+ 			seq_printf(m, "%d\t", cur[j]);
+ 		seq_printf(m, "\n");
+ 	}
+ 
+ 	ret = 0;
+ out:
+ 	for (i = 0; i < KVM_NR_PAGE_SIZES; i++)
+ 		kfree(log[i]);
+ 
+ 	return ret;
+ }
+ 
+ static int kvm_mmu_rmaps_stat_open(struct inode *inode, struct file *file)
+ {
+ 	struct kvm *kvm = inode->i_private;
+ 
+ 	if (!kvm_get_kvm_safe(kvm))
+ 		return -ENOENT;
+ 
+ 	return single_open(file, kvm_mmu_rmaps_stat_show, kvm);
+ }
+ 
+ static int kvm_mmu_rmaps_stat_release(struct inode *inode, struct file *file)
+ {
+ 	struct kvm *kvm = inode->i_private;
+ 
+ 	kvm_put_kvm(kvm);
+ 
+ 	return single_release(inode, file);
+ }
+ 
+ static const struct file_operations mmu_rmaps_stat_fops = {
+ 	.open		= kvm_mmu_rmaps_stat_open,
+ 	.read		= seq_read,
+ 	.llseek		= seq_lseek,
+ 	.release	= kvm_mmu_rmaps_stat_release,
+ };
+ 
+ int kvm_arch_create_vm_debugfs(struct kvm *kvm)
+ {
+ 	debugfs_create_file("mmu_rmaps_stat", 0644, kvm->debugfs_dentry, kvm,
+ 			    &mmu_rmaps_stat_fops);
+ 	return 0;
+ }
++>>>>>>> fffb53237807 (KVM: x86: Check for rmaps allocation)
* Unmerged path arch/x86/kvm/debugfs.c
