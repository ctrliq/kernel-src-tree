KVM: x86: hyper-v: Fix the maximum number of sparse banks for XMM fast TLB flush hypercalls

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit 7321f47eada53a395fb3086d49297eebb19e8e58
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/7321f47e.failed

When TLB flush hypercalls (HVCALL_FLUSH_VIRTUAL_ADDRESS_{LIST,SPACE}_EX are
issued in 'XMM fast' mode, the maximum number of allowed sparse_banks is
not 'HV_HYPERCALL_MAX_XMM_REGISTERS - 1' (5) but twice as many (10) as each
XMM register is 128 bit long and can hold two 64 bit long banks.

	Cc: stable@vger.kernel.org # 5.14.x
Fixes: 5974565bc26d ("KVM: x86: kvm_hv_flush_tlb use inputs from XMM registers")
	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Message-Id: <20220222154642.684285-4-vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 7321f47eada53a395fb3086d49297eebb19e8e58)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/hyperv.c
diff --cc arch/x86/kvm/hyperv.c
index 2ec52ff76a36,8f07b13c9f15..000000000000
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@@ -1836,32 -1812,31 +1836,51 @@@ static u64 kvm_hv_flush_tlb(struct kvm_
  		all_cpus = flush_ex.hv_vp_set.format !=
  			HV_GENERIC_SET_SPARSE_4K;
  
 -		sparse_banks_len = bitmap_weight((unsigned long *)&valid_bank_mask, 64);
 +		if (hc->var_cnt != bitmap_weight((unsigned long *)&valid_bank_mask, 64))
 +			return HV_STATUS_INVALID_HYPERCALL_INPUT;
 +
 +		if (all_cpus)
 +			goto do_flush;
  
 -		if (!sparse_banks_len && !all_cpus)
 +		if (!hc->var_cnt)
  			goto ret_success;
  
++<<<<<<< HEAD
 +		if (hc->fast) {
 +			if (hc->var_cnt > HV_HYPERCALL_MAX_XMM_REGISTERS - 1)
 +				return HV_STATUS_INVALID_HYPERCALL_INPUT;
 +			for (i = 0; i < hc->var_cnt; i += 2) {
 +				sparse_banks[i] = sse128_lo(hc->xmm[i / 2 + 1]);
 +				sparse_banks[i + 1] = sse128_hi(hc->xmm[i / 2 + 1]);
++=======
+ 		if (!all_cpus) {
+ 			if (hc->fast) {
+ 				/* XMM0 is already consumed, each XMM holds two sparse banks. */
+ 				if (sparse_banks_len > 2 * (HV_HYPERCALL_MAX_XMM_REGISTERS - 1))
+ 					return HV_STATUS_INVALID_HYPERCALL_INPUT;
+ 				for (i = 0; i < sparse_banks_len; i += 2) {
+ 					sparse_banks[i] = sse128_lo(hc->xmm[i / 2 + 1]);
+ 					sparse_banks[i + 1] = sse128_hi(hc->xmm[i / 2 + 1]);
+ 				}
+ 			} else {
+ 				gpa = hc->ingpa + offsetof(struct hv_tlb_flush_ex,
+ 							   hv_vp_set.bank_contents);
+ 				if (unlikely(kvm_read_guest(kvm, gpa, sparse_banks,
+ 							    sparse_banks_len *
+ 							    sizeof(sparse_banks[0]))))
+ 					return HV_STATUS_INVALID_HYPERCALL_INPUT;
++>>>>>>> 7321f47eada5 (KVM: x86: hyper-v: Fix the maximum number of sparse banks for XMM fast TLB flush hypercalls)
  			}
 +			goto do_flush;
  		}
 +
 +		if (kvm_get_sparse_vp_set(kvm, hc, sparse_banks,
 +					  offsetof(struct hv_tlb_flush_ex,
 +						   hv_vp_set.bank_contents)))
 +			return HV_STATUS_INVALID_HYPERCALL_INPUT;
  	}
  
 +do_flush:
  	/*
  	 * vcpu->arch.cr3 may not be up-to-date for running vCPUs so we can't
  	 * analyze it here, flush TLB regardless of the specified address space.
* Unmerged path arch/x86/kvm/hyperv.c
