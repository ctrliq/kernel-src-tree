KVM: VMX: Handle PI descriptor updates during vcpu_put/load

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit d76fb40637fc0e84b27bf431cd72cf8fe3f813ef
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/d76fb406.failed

Move the posted interrupt pre/post_block logic into vcpu_put/load
respectively, using the kvm_vcpu_is_blocking() to determining whether or
not the wakeup handler needs to be set (and unset).  This avoids updating
the PI descriptor if halt-polling is successful, reduces the number of
touchpoints for updating the descriptor, and eliminates the confusing
behavior of intentionally leaving a "stale" PI.NDST when a blocking vCPU
is scheduled back in after preemption.

The downside is that KVM will do the PID update twice if the vCPU is
preempted after prepare_to_rcuwait() but before schedule(), but that's a
rare case (and non-existent on !PREEMPT kernels).

The notable wart is the need to send a self-IPI on the wakeup vector if
an outstanding notification is pending after configuring the wakeup
vector.  Ideally, KVM would just do a kvm_vcpu_wake_up() in this case,
but the scheduler doesn't support waking a task from its preemption
notifier callback, i.e. while the task is right in the middle of
being scheduled out.

Note, setting the wakeup vector before halt-polling is not necessary:
once the pending IRQ will be recorded in the PIR, kvm_vcpu_has_events()
will detect this (via kvm_cpu_get_interrupt(), kvm_apic_get_interrupt(),
apic_has_interrupt_for_ppr() and finally vmx_sync_pir_to_irr()) and
terminate the polling.

	Signed-off-by: Sean Christopherson <seanjc@google.com>
	Reviewed-by: Maxim Levitsky <mlevitsk@redhat.com>
Message-Id: <20211208015236.1616697-5-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit d76fb40637fc0e84b27bf431cd72cf8fe3f813ef)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/posted_intr.c
diff --cc arch/x86/kvm/vmx/posted_intr.c
index 359222f558f9,63e2399f353a..000000000000
--- a/arch/x86/kvm/vmx/posted_intr.c
+++ b/arch/x86/kvm/vmx/posted_intr.c
@@@ -60,10 -98,21 +72,26 @@@ void vmx_vcpu_pi_load(struct kvm_vcpu *
  	do {
  		old.control = new.control = READ_ONCE(pi_desc->control);
  
+ 		/*
+ 		 * Clear SN (as above) and refresh the destination APIC ID to
+ 		 * handle task migration (@cpu != vcpu->cpu).
+ 		 */
  		new.ndst = dest;
  		new.sn = 0;
++<<<<<<< HEAD
 +	} while (cmpxchg64(&pi_desc->control, old.control,
 +			   new.control) != old.control);
++=======
+ 
+ 		/*
+ 		 * Restore the notification vector; in the blocking case, the
+ 		 * descriptor was modified on "put" to use the wakeup vector.
+ 		 */
+ 		new.nv = POSTED_INTR_VECTOR;
+ 	} while (pi_try_set_control(pi_desc, old.control, new.control));
++>>>>>>> d76fb40637fc (KVM: VMX: Handle PI descriptor updates during vcpu_put/load)
+ 
+ 	local_irq_restore(flags);
  
  after_clear_sn:
  
@@@ -86,126 -135,63 +114,176 @@@ static bool vmx_can_use_vtd_pi(struct k
  		irq_remapping_cap(IRQ_POSTING_CAP);
  }
  
++<<<<<<< HEAD
 +void vmx_vcpu_pi_put(struct kvm_vcpu *vcpu)
 +{
 +	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
 +
 +	if (!vmx_can_use_vtd_pi(vcpu->kvm))
 +		return;
 +
 +	/* Set SN when the vCPU is preempted */
 +	if (vcpu->preempted)
 +		pi_set_sn(pi_desc);
 +}
 +
 +static void __pi_post_block(struct kvm_vcpu *vcpu)
 +{
 +	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
 +	struct pi_desc old, new;
 +	unsigned int dest;
 +
 +	dest = cpu_physical_id(vcpu->cpu);
 +	if (!x2apic_mode)
 +		dest = (dest << 8) & 0xFF00;
 +
 +	do {
 +		old.control = new.control = READ_ONCE(pi_desc->control);
 +		WARN(old.nv != POSTED_INTR_WAKEUP_VECTOR,
 +		     "Wakeup handler not enabled while the VCPU is blocked\n");
 +
 +		new.ndst = dest;
 +
 +		/* set 'NV' to 'notification vector' */
 +		new.nv = POSTED_INTR_VECTOR;
 +	} while (cmpxchg64(&pi_desc->control, old.control,
 +			   new.control) != old.control);
 +
 +	if (!WARN_ON_ONCE(vcpu->pre_pcpu == -1)) {
 +		raw_spin_lock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->pre_pcpu));
 +		list_del(&vcpu->blocked_vcpu_list);
 +		raw_spin_unlock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->pre_pcpu));
 +		vcpu->pre_pcpu = -1;
 +	}
 +}
 +
 +/*
 + * This routine does the following things for vCPU which is going
 + * to be blocked if VT-d PI is enabled.
 + * - Store the vCPU to the wakeup list, so when interrupts happen
 + *   we can find the right vCPU to wake up.
 + * - Change the Posted-interrupt descriptor as below:
 + *      'NDST' <-- vcpu->pre_pcpu
 + *      'NV' <-- POSTED_INTR_WAKEUP_VECTOR
 + * - If 'ON' is set during this process, which means at least one
 + *   interrupt is posted for this vCPU, we cannot block it, in
 + *   this case, return 1, otherwise, return 0.
 + *
++=======
+ /*
+  * Put the vCPU on this pCPU's list of vCPUs that needs to be awakened and set
+  * WAKEUP as the notification vector in the PI descriptor.
++>>>>>>> d76fb40637fc (KVM: VMX: Handle PI descriptor updates during vcpu_put/load)
   */
- int pi_pre_block(struct kvm_vcpu *vcpu)
+ static void pi_enable_wakeup_handler(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	unsigned int dest;
 +	struct pi_desc old, new;
 +	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
 +
 +	if (!vmx_can_use_vtd_pi(vcpu->kvm) ||
 +	    vmx_interrupt_blocked(vcpu))
 +		return 0;
 +
 +	WARN_ON(irqs_disabled());
 +	local_irq_disable();
 +	if (!WARN_ON_ONCE(vcpu->pre_pcpu != -1)) {
 +		vcpu->pre_pcpu = vcpu->cpu;
 +		raw_spin_lock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->pre_pcpu));
 +		list_add_tail(&vcpu->blocked_vcpu_list,
 +			      &per_cpu(blocked_vcpu_on_cpu,
 +				       vcpu->pre_pcpu));
 +		raw_spin_unlock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->pre_pcpu));
 +	}
++=======
+ 	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
+ 	struct pi_desc old, new;
+ 	unsigned long flags;
+ 
+ 	local_irq_save(flags);
+ 
+ 	raw_spin_lock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->cpu));
+ 	list_add_tail(&vcpu->blocked_vcpu_list,
+ 		      &per_cpu(blocked_vcpu_on_cpu, vcpu->cpu));
+ 	raw_spin_unlock(&per_cpu(blocked_vcpu_on_cpu_lock, vcpu->cpu));
+ 
+ 	WARN(pi_desc->sn, "PI descriptor SN field set before blocking");
++>>>>>>> d76fb40637fc (KVM: VMX: Handle PI descriptor updates during vcpu_put/load)
  
  	do {
  		old.control = new.control = READ_ONCE(pi_desc->control);
  
 +		WARN((pi_desc->sn == 1),
 +		     "Warning: SN field of posted-interrupts "
 +		     "is set before blocking\n");
 +
 +		/*
 +		 * Since vCPU can be preempted during this process,
 +		 * vcpu->cpu could be different with pre_pcpu, we
 +		 * need to set pre_pcpu as the destination of wakeup
 +		 * notification event, then we can find the right vCPU
 +		 * to wakeup in wakeup handler if interrupts happen
 +		 * when the vCPU is in blocked state.
 +		 */
 +		dest = cpu_physical_id(vcpu->pre_pcpu);
 +
 +		if (x2apic_mode)
 +			new.ndst = dest;
 +		else
 +			new.ndst = (dest << 8) & 0xFF00;
 +
  		/* set 'NV' to 'wakeup vector' */
  		new.nv = POSTED_INTR_WAKEUP_VECTOR;
 -	} while (pi_try_set_control(pi_desc, old.control, new.control));
 +	} while (cmpxchg64(&pi_desc->control, old.control,
 +			   new.control) != old.control);
  
- 	/* We should not block the vCPU if an interrupt is posted for it.  */
- 	if (pi_test_on(pi_desc))
- 		__pi_post_block(vcpu);
+ 	/*
+ 	 * Send a wakeup IPI to this CPU if an interrupt may have been posted
+ 	 * before the notification vector was updated, in which case the IRQ
+ 	 * will arrive on the non-wakeup vector.  An IPI is needed as calling
+ 	 * try_to_wake_up() from ->sched_out() isn't allowed (IRQs are not
+ 	 * enabled until it is safe to call try_to_wake_up() on the task being
+ 	 * scheduled out).
+ 	 */
+ 	if (pi_test_on(&new))
+ 		apic->send_IPI_self(POSTED_INTR_WAKEUP_VECTOR);
  
++<<<<<<< HEAD
 +	local_irq_enable();
 +	return (vcpu->pre_pcpu == -1);
++=======
+ 	local_irq_restore(flags);
++>>>>>>> d76fb40637fc (KVM: VMX: Handle PI descriptor updates during vcpu_put/load)
  }
  
- void pi_post_block(struct kvm_vcpu *vcpu)
+ void vmx_vcpu_pi_put(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	if (vcpu->pre_pcpu == -1)
 +		return;
 +
 +	WARN_ON(irqs_disabled());
 +	local_irq_disable();
 +	__pi_post_block(vcpu);
 +	local_irq_enable();
++=======
+ 	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
+ 
+ 	if (!vmx_can_use_vtd_pi(vcpu->kvm))
+ 		return;
+ 
+ 	if (kvm_vcpu_is_blocking(vcpu) && !vmx_interrupt_blocked(vcpu))
+ 		pi_enable_wakeup_handler(vcpu);
+ 
+ 	/*
+ 	 * Set SN when the vCPU is preempted.  Note, the vCPU can both be seen
+ 	 * as blocking and preempted, e.g. if it's preempted between setting
+ 	 * its wait state and manually scheduling out.
+ 	 */
+ 	if (vcpu->preempted)
+ 		pi_set_sn(pi_desc);
++>>>>>>> d76fb40637fc (KVM: VMX: Handle PI descriptor updates during vcpu_put/load)
  }
  
  /*
* Unmerged path arch/x86/kvm/vmx/posted_intr.c
diff --git a/arch/x86/kvm/vmx/posted_intr.h b/arch/x86/kvm/vmx/posted_intr.h
index 36ae035f14aa..eb14e76b84ef 100644
--- a/arch/x86/kvm/vmx/posted_intr.h
+++ b/arch/x86/kvm/vmx/posted_intr.h
@@ -40,6 +40,12 @@ static inline bool pi_test_and_clear_on(struct pi_desc *pi_desc)
 			(unsigned long *)&pi_desc->control);
 }
 
+static inline bool pi_test_and_clear_sn(struct pi_desc *pi_desc)
+{
+	return test_and_clear_bit(POSTED_INTR_SN,
+			(unsigned long *)&pi_desc->control);
+}
+
 static inline bool pi_test_and_set_pir(int vector, struct pi_desc *pi_desc)
 {
 	return test_and_set_bit(vector, (unsigned long *)pi_desc->pir);
@@ -88,8 +94,6 @@ static inline bool pi_test_sn(struct pi_desc *pi_desc)
 
 void vmx_vcpu_pi_load(struct kvm_vcpu *vcpu, int cpu);
 void vmx_vcpu_pi_put(struct kvm_vcpu *vcpu);
-int pi_pre_block(struct kvm_vcpu *vcpu);
-void pi_post_block(struct kvm_vcpu *vcpu);
 void pi_wakeup_handler(void);
 void __init pi_init_cpu(int cpu);
 bool pi_has_pending_interrupt(struct kvm_vcpu *vcpu);
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index fa7a11f6f244..36375eafca13 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -7567,9 +7567,6 @@ void vmx_update_cpu_dirty_logging(struct kvm_vcpu *vcpu)
 
 static int vmx_pre_block(struct kvm_vcpu *vcpu)
 {
-	if (pi_pre_block(vcpu))
-		return 1;
-
 	if (kvm_lapic_hv_timer_in_use(vcpu))
 		kvm_lapic_switch_to_sw_timer(vcpu);
 
@@ -7580,8 +7577,6 @@ static void vmx_post_block(struct kvm_vcpu *vcpu)
 {
 	if (kvm_x86_ops.set_hv_timer)
 		kvm_lapic_switch_to_hv_timer(vcpu);
-
-	pi_post_block(vcpu);
 }
 
 static void vmx_setup_mce(struct kvm_vcpu *vcpu)
