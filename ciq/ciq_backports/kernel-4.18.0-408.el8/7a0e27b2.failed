mm: remove vmalloc_exec

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 7a0e27b2a0ce2735e27e21ebc8b777550fe0ed81
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/7a0e27b2.failed

Merge vmalloc_exec into its only caller.  Note that for !CONFIG_MMU
__vmalloc_node_range maps to __vmalloc, which directly clears the
__GFP_HIGHMEM added by the vmalloc_exec stub anyway.

Link: http://lkml.kernel.org/r/20200618064307.32739-4-hch@lst.de
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: David Hildenbrand <david@redhat.com>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Dexuan Cui <decui@microsoft.com>
	Cc: Jessica Yu <jeyu@kernel.org>
	Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
	Cc: Wei Liu <wei.liu@kernel.org>
	Cc: Will Deacon <will@kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 7a0e27b2a0ce2735e27e21ebc8b777550fe0ed81)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/vmalloc.h
#	mm/nommu.c
#	mm/vmalloc.c
diff --cc include/linux/vmalloc.h
index 4cb3acd097c5,0221f852a7e1..000000000000
--- a/include/linux/vmalloc.h
+++ b/include/linux/vmalloc.h
@@@ -98,11 -106,9 +98,14 @@@ extern void *vzalloc(unsigned long size
  extern void *vmalloc_user(unsigned long size);
  extern void *vmalloc_node(unsigned long size, int node);
  extern void *vzalloc_node(unsigned long size, int node);
++<<<<<<< HEAD
 +extern void *vmalloc_user_node_flags(unsigned long size, int node, gfp_t flags);
 +extern void *vmalloc_exec(unsigned long size);
++=======
++>>>>>>> 7a0e27b2a0ce (mm: remove vmalloc_exec)
  extern void *vmalloc_32(unsigned long size);
  extern void *vmalloc_32_user(unsigned long size);
 -extern void *__vmalloc(unsigned long size, gfp_t gfp_mask);
 +extern void *__vmalloc(unsigned long size, gfp_t gfp_mask, pgprot_t prot);
  extern void *__vmalloc_node_range(unsigned long size, unsigned long align,
  			unsigned long start, unsigned long end, gfp_t gfp_mask,
  			pgprot_t prot, unsigned long vm_flags, int node,
diff --cc mm/nommu.c
index b04bb3c4c5ef,f32a69095d50..000000000000
--- a/mm/nommu.c
+++ b/mm/nommu.c
@@@ -287,28 -290,7 +287,31 @@@ void *vzalloc_node(unsigned long size, 
  }
  EXPORT_SYMBOL(vzalloc_node);
  
 +#ifndef PAGE_KERNEL_EXEC
 +# define PAGE_KERNEL_EXEC PAGE_KERNEL
 +#endif
 +
  /**
++<<<<<<< HEAD
 + *	vmalloc_exec  -  allocate virtually contiguous, executable memory
 + *	@size:		allocation size
 + *
 + *	Kernel-internal function to allocate enough pages to cover @size
 + *	the page level allocator and map them into contiguous and
 + *	executable kernel virtual space.
 + *
 + *	For tight control over page level allocator and protection flags
 + *	use __vmalloc() instead.
 + */
 +
 +void *vmalloc_exec(unsigned long size)
 +{
 +	return __vmalloc(size, GFP_KERNEL | __GFP_HIGHMEM, PAGE_KERNEL_EXEC);
 +}
 +
 +/**
++=======
++>>>>>>> 7a0e27b2a0ce (mm: remove vmalloc_exec)
   * vmalloc_32  -  allocate virtually contiguous memory (32bit addressable)
   *	@size:		allocation size
   *
diff --cc mm/vmalloc.c
index 673ddeda3cba,5a2b55c8dd9a..000000000000
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@@ -2709,50 -2695,6 +2709,53 @@@ void *vzalloc_node(unsigned long size, 
  }
  EXPORT_SYMBOL(vzalloc_node);
  
++<<<<<<< HEAD
 +/**
 + * vmalloc_user_node_flags - allocate memory for userspace on a specific node
 + * @size: allocation size
 + * @node: numa node
 + * @flags: flags for the page level allocator
 + *
 + * The resulting memory area is zeroed so it can be mapped to userspace
 + * without leaking data.
 + *
 + * Return: pointer to the allocated memory or %NULL on error
 + */
 +void *vmalloc_user_node_flags(unsigned long size, int node, gfp_t flags)
 +{
 +	return __vmalloc_node_range(size, SHMLBA,  VMALLOC_START, VMALLOC_END,
 +				    flags | __GFP_ZERO, PAGE_KERNEL,
 +				    VM_USERMAP, node,
 +				    __builtin_return_address(0));
 +}
 +EXPORT_SYMBOL(vmalloc_user_node_flags);
 +
 +#ifndef PAGE_KERNEL_EXEC
 +# define PAGE_KERNEL_EXEC PAGE_KERNEL
 +#endif
 +
 +/**
 + * vmalloc_exec - allocate virtually contiguous, executable memory
 + * @size:	  allocation size
 + *
 + * Kernel-internal function to allocate enough pages to cover @size
 + * the page level allocator and map them into contiguous and
 + * executable kernel virtual space.
 + *
 + * For tight control over page level allocator and protection flags
 + * use __vmalloc() instead.
 + *
 + * Return: pointer to the allocated memory or %NULL on error
 + */
 +void *vmalloc_exec(unsigned long size)
 +{
 +	return __vmalloc_node_range(size, 1, VMALLOC_START, VMALLOC_END,
 +			GFP_KERNEL, PAGE_KERNEL_EXEC, VM_FLUSH_RESET_PERMS,
 +			NUMA_NO_NODE, __builtin_return_address(0));
 +}
 +
++=======
++>>>>>>> 7a0e27b2a0ce (mm: remove vmalloc_exec)
  #if defined(CONFIG_64BIT) && defined(CONFIG_ZONE_DMA32)
  #define GFP_VMALLOC32 (GFP_DMA32 | GFP_KERNEL)
  #elif defined(CONFIG_64BIT) && defined(CONFIG_ZONE_DMA)
* Unmerged path include/linux/vmalloc.h
diff --git a/kernel/module.c b/kernel/module.c
index e07ea2b09d06..e87184ee17cb 100644
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -2750,7 +2750,9 @@ static void dynamic_debug_remove(struct module *mod, struct _ddebug *debug)
 
 void * __weak module_alloc(unsigned long size)
 {
-	return vmalloc_exec(size);
+	return __vmalloc_node_range(size, 1, VMALLOC_START, VMALLOC_END,
+			GFP_KERNEL, PAGE_KERNEL_EXEC, VM_FLUSH_RESET_PERMS,
+			NUMA_NO_NODE, __func__);
 }
 
 bool __weak module_exit_section(const char *name)
* Unmerged path mm/nommu.c
* Unmerged path mm/vmalloc.c
