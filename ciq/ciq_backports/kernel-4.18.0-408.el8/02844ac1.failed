KVM: x86/mmu: Consolidate comments about {Host,MMU}-writable

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author David Matlack <dmatlack@google.com>
commit 02844ac1eb3413c53cb05a59b36980b59b690244
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/02844ac1.failed

Consolidate the large comment above DEFAULT_SPTE_HOST_WRITABLE with the
large comment above is_writable_pte() into one comment. This comment
explains the different reasons why an SPTE may be non-writable and KVM
keeps track of that with the {Host,MMU}-writable bits.

No functional change intended.

	Signed-off-by: David Matlack <dmatlack@google.com>
Message-Id: <20220125230723.1701061-1-dmatlack@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 02844ac1eb3413c53cb05a59b36980b59b690244)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
#	arch/x86/kvm/mmu/spte.h
diff --cc arch/x86/kvm/mmu/mmu.c
index b66e2b4a1ec3,f45ddae39b2c..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -5731,28 -5802,47 +5729,52 @@@ static bool slot_rmap_write_protect(str
  }
  
  void kvm_mmu_slot_remove_write_access(struct kvm *kvm,
 -				      const struct kvm_memory_slot *memslot,
 +				      struct kvm_memory_slot *memslot,
  				      int start_level)
  {
 -	bool flush = false;
 -
 -	if (kvm_memslots_have_rmaps(kvm)) {
 -		write_lock(&kvm->mmu_lock);
 -		flush = slot_handle_level(kvm, memslot, slot_rmap_write_protect,
 -					  start_level, KVM_MAX_HUGEPAGE_LEVEL,
 -					  false);
 -		write_unlock(&kvm->mmu_lock);
 -	}
 +	bool flush;
  
 -	if (is_tdp_mmu_enabled(kvm)) {
 -		read_lock(&kvm->mmu_lock);
 +	write_lock(&kvm->mmu_lock);
 +	flush = slot_handle_level(kvm, memslot, slot_rmap_write_protect,
 +				start_level, KVM_MAX_HUGEPAGE_LEVEL, false);
 +	if (is_tdp_mmu_enabled(kvm))
  		flush |= kvm_tdp_mmu_wrprot_slot(kvm, memslot, start_level);
 -		read_unlock(&kvm->mmu_lock);
 -	}
 +	write_unlock(&kvm->mmu_lock);
  
  	/*
++<<<<<<< HEAD
 +	 * We can flush all the TLBs out of the mmu lock without TLB
 +	 * corruption since we just change the spte from writable to
 +	 * readonly so that we only need to care the case of changing
 +	 * spte from present to present (changing the spte from present
 +	 * to nonpresent will flush all the TLBs immediately), in other
 +	 * words, the only case we care is mmu_spte_update() where we
 +	 * have checked Host-writable | MMU-writable instead of
 +	 * PT_WRITABLE_MASK, that means it does not depend on PT_WRITABLE_MASK
 +	 * anymore.
++=======
+ 	 * Flush TLBs if any SPTEs had to be write-protected to ensure that
+ 	 * guest writes are reflected in the dirty bitmap before the memslot
+ 	 * update completes, i.e. before enabling dirty logging is visible to
+ 	 * userspace.
+ 	 *
+ 	 * Perform the TLB flush outside the mmu_lock to reduce the amount of
+ 	 * time the lock is held. However, this does mean that another CPU can
+ 	 * now grab mmu_lock and encounter a write-protected SPTE while CPUs
+ 	 * still have a writable mapping for the associated GFN in their TLB.
+ 	 *
+ 	 * This is safe but requires KVM to be careful when making decisions
+ 	 * based on the write-protection status of an SPTE. Specifically, KVM
+ 	 * also write-protects SPTEs to monitor changes to guest page tables
+ 	 * during shadow paging, and must guarantee no CPUs can write to those
+ 	 * page before the lock is dropped. As mentioned in the previous
+ 	 * paragraph, a write-protected SPTE is no guarantee that CPU cannot
+ 	 * perform writes. So to determine if a TLB flush is truly required, KVM
+ 	 * will clear a separate software-only bit (MMU-writable) and skip the
+ 	 * flush if-and-only-if this bit was already clear.
+ 	 *
+ 	 * See is_writable_pte() for more details.
++>>>>>>> 02844ac1eb34 (KVM: x86/mmu: Consolidate comments about {Host,MMU}-writable)
  	 */
  	if (flush)
  		kvm_arch_flush_remote_tlbs_memslot(kvm, memslot);
diff --cc arch/x86/kvm/mmu/spte.h
index c12a635ff808,08f471d8e409..000000000000
--- a/arch/x86/kvm/mmu/spte.h
+++ b/arch/x86/kvm/mmu/spte.h
@@@ -75,28 -75,8 +75,33 @@@ static_assert(SPTE_TDP_AD_ENABLED_MASK 
  static_assert(!(SPTE_TDP_AD_MASK & SHADOW_ACC_TRACK_SAVED_MASK));
  
  /*
++<<<<<<< HEAD
 + * *_SPTE_HOST_WRITEABLE (aka Host-writable) indicates whether the host permits
 + * writes to the guest page mapped by the SPTE. This bit is cleared on SPTEs
 + * that map guest pages in read-only memslots and read-only VMAs.
 + *
 + * Invariants:
 + *  - If Host-writable is clear, PT_WRITABLE_MASK must be clear.
 + *
 + *
 + * *_SPTE_MMU_WRITEABLE (aka MMU-writable) indicates whether the shadow MMU
 + * allows writes to the guest page mapped by the SPTE. This bit is cleared when
 + * the guest page mapped by the SPTE contains a page table that is being
 + * monitored for shadow paging. In this case the SPTE can only be made writable
 + * by unsyncing the shadow page under the mmu_lock.
 + *
 + * Invariants:
 + *  - If MMU-writable is clear, PT_WRITABLE_MASK must be clear.
 + *  - If MMU-writable is set, Host-writable must be set.
 + *
 + * If MMU-writable is set, PT_WRITABLE_MASK is normally set but can be cleared
 + * to track writes for dirty logging. For such SPTEs, KVM will locklessly set
 + * PT_WRITABLE_MASK upon the next write from the guest and record the write in
 + * the dirty log (see fast_page_fault()).
++=======
+  * {DEFAULT,EPT}_SPTE_{HOST,MMU}_WRITABLE are used to keep track of why a given
+  * SPTE is write-protected. See is_writable_pte() for details.
++>>>>>>> 02844ac1eb34 (KVM: x86/mmu: Consolidate comments about {Host,MMU}-writable)
   */
  
  /* Bits 9 and 10 are ignored by all non-EPT PTEs. */
* Unmerged path arch/x86/kvm/mmu/mmu.c
* Unmerged path arch/x86/kvm/mmu/spte.h
