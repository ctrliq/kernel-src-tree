dmaengine: idxd: move dsa_drv support to compatible mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Dave Jiang <dave.jiang@intel.com>
commit 6e7f3ee97bbe2c7d7a53b7dbd7a08a579e03c8c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/6e7f3ee9.failed

The original architecture of /sys/bus/dsa invented a scheme whereby
a single entry in the list of bus drivers, /sys/bus/drivers/dsa,
handled all device types and internally routed them to different
different drivers. Those internal drivers were invisible to
userspace.

With the idxd driver transitioned to a proper bus device-driver model,
the legacy behavior needs to be preserved due to it being exposed to
user space via sysfs. Create a compat driver to provide the legacy
behavior for /sys/bus/dsa/drivers/dsa. This should satisfy user
tool accel-config v3.2 or ealier where this behavior is expected.
If the distro has a newer accel-config then the legacy mode does
not need to be enabled.

When the compat driver binds the device (i.e. dsa0) to the dsa driver,
it will be bound to the new idxd_drv. The wq device (i.e. wq0.0) will
be bound to either the dmaengine_drv or the user_drv. The dsa_drv
becomes a routing mechansim for the new drivers. It will not support
additional external drivers that are implemented later.

	Reviewed-by: Dan Williams <dan.j.williams@intel.com>
	Signed-off-by: Dave Jiang <dave.jiang@intel.com>
Link: https://lore.kernel.org/r/162637468705.744545.4399080971745974435.stgit@djiang5-desk3.ch.intel.com
	Signed-off-by: Vinod Koul <vkoul@kernel.org>
(cherry picked from commit 6e7f3ee97bbe2c7d7a53b7dbd7a08a579e03c8c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/dma/idxd/Makefile
#	drivers/dma/idxd/cdev.c
#	drivers/dma/idxd/device.c
#	drivers/dma/idxd/dma.c
#	drivers/dma/idxd/init.c
#	drivers/dma/idxd/sysfs.c
diff --cc drivers/dma/idxd/Makefile
index 6d11558756f8,a1e9f2b3a37c..000000000000
--- a/drivers/dma/idxd/Makefile
+++ b/drivers/dma/idxd/Makefile
@@@ -2,3 -4,9 +2,12 @@@ obj-$(CONFIG_INTEL_IDXD) += idxd.
  idxd-y := init.o irq.o device.o sysfs.o submit.o dma.o cdev.o
  
  idxd-$(CONFIG_INTEL_IDXD_PERFMON) += perfmon.o
++<<<<<<< HEAD
++=======
+ 
+ obj-$(CONFIG_INTEL_IDXD_BUS) += idxd_bus.o
+ idxd_bus-y := bus.o
+ 
+ obj-$(CONFIG_INTEL_IDXD_COMPAT) += idxd_compat.o
+ idxd_compat-y := compat.o
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
diff --cc drivers/dma/idxd/cdev.c
index e9def577c697,f6a4603517ba..000000000000
--- a/drivers/dma/idxd/cdev.c
+++ b/drivers/dma/idxd/cdev.c
@@@ -299,10 -300,64 +299,67 @@@ void idxd_wq_del_cdev(struct idxd_wq *w
  
  	idxd_cdev = wq->idxd_cdev;
  	wq->idxd_cdev = NULL;
 -	cdev_device_del(&idxd_cdev->cdev, cdev_dev(idxd_cdev));
 -	put_device(cdev_dev(idxd_cdev));
 +	cdev_device_del(&idxd_cdev->cdev, &idxd_cdev->dev);
 +	put_device(&idxd_cdev->dev);
  }
  
++<<<<<<< HEAD
++=======
+ static int idxd_user_drv_probe(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 	struct idxd_device *idxd = wq->idxd;
+ 	int rc;
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED)
+ 		return -ENXIO;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	wq->type = IDXD_WQT_USER;
+ 	rc = __drv_enable_wq(wq);
+ 	if (rc < 0)
+ 		goto err;
+ 
+ 	rc = idxd_wq_add_cdev(wq);
+ 	if (rc < 0)
+ 		goto err_cdev;
+ 
+ 	mutex_unlock(&wq->wq_lock);
+ 	return 0;
+ 
+ err_cdev:
+ 	__drv_disable_wq(wq);
+ err:
+ 	wq->type = IDXD_WQT_NONE;
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ static void idxd_user_drv_remove(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	idxd_wq_del_cdev(wq);
+ 	__drv_disable_wq(wq);
+ 	wq->type = IDXD_WQT_NONE;
+ 	mutex_unlock(&wq->wq_lock);
+ }
+ 
+ static enum idxd_dev_type dev_types[] = {
+ 	IDXD_DEV_WQ,
+ 	IDXD_DEV_NONE,
+ };
+ 
+ struct idxd_device_driver idxd_user_drv = {
+ 	.probe = idxd_user_drv_probe,
+ 	.remove = idxd_user_drv_remove,
+ 	.name = "user",
+ 	.type = dev_types,
+ };
+ EXPORT_SYMBOL_GPL(idxd_user_drv);
+ 
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
  int idxd_cdev_register(void)
  {
  	int rc, i;
diff --cc drivers/dma/idxd/device.c
index 4a2af9799239,99350ac9a292..000000000000
--- a/drivers/dma/idxd/device.c
+++ b/drivers/dma/idxd/device.c
@@@ -1129,3 -1129,193 +1129,196 @@@ int idxd_device_load_config(struct idxd
  
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ 
+ int __drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 	unsigned long flags;
+ 	int rc = -ENXIO;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED)
+ 		goto err;
+ 
+ 	if (wq->state != IDXD_WQ_DISABLED) {
+ 		dev_dbg(dev, "wq %d already enabled.\n", wq->id);
+ 		rc = -EBUSY;
+ 		goto err;
+ 	}
+ 
+ 	if (!wq->group) {
+ 		dev_dbg(dev, "wq %d not attached to group.\n", wq->id);
+ 		goto err;
+ 	}
+ 
+ 	if (strlen(wq->name) == 0) {
+ 		dev_dbg(dev, "wq %d name not set.\n", wq->id);
+ 		goto err;
+ 	}
+ 
+ 	/* Shared WQ checks */
+ 	if (wq_shared(wq)) {
+ 		if (!device_swq_supported(idxd)) {
+ 			dev_dbg(dev, "PASID not enabled and shared wq.\n");
+ 			goto err;
+ 		}
+ 		/*
+ 		 * Shared wq with the threshold set to 0 means the user
+ 		 * did not set the threshold or transitioned from a
+ 		 * dedicated wq but did not set threshold. A value
+ 		 * of 0 would effectively disable the shared wq. The
+ 		 * driver does not allow a value of 0 to be set for
+ 		 * threshold via sysfs.
+ 		 */
+ 		if (wq->threshold == 0) {
+ 			dev_dbg(dev, "Shared wq and threshold 0.\n");
+ 			goto err;
+ 		}
+ 	}
+ 
+ 	rc = 0;
+ 	spin_lock_irqsave(&idxd->dev_lock, flags);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		rc = idxd_device_config(idxd);
+ 	spin_unlock_irqrestore(&idxd->dev_lock, flags);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Writing wq %d config failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_enable(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq %d enabling failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_map_portal(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq %d portal mapping failed: %d\n", wq->id, rc);
+ 		goto err_map_portal;
+ 	}
+ 
+ 	wq->client_count = 0;
+ 	return 0;
+ 
+ err_map_portal:
+ 	rc = idxd_wq_disable(wq, false);
+ 	if (rc < 0)
+ 		dev_dbg(dev, "wq %s disable failed\n", dev_name(wq_confdev(wq)));
+ err:
+ 	return rc;
+ }
+ 
+ int drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	int rc;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	rc = __drv_enable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ void __drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (idxd_wq_refcount(wq))
+ 		dev_warn(dev, "Clients has claim on wq %d: %d\n",
+ 			 wq->id, idxd_wq_refcount(wq));
+ 
+ 	idxd_wq_unmap_portal(wq);
+ 
+ 	idxd_wq_drain(wq);
+ 	idxd_wq_reset(wq);
+ 
+ 	wq->client_count = 0;
+ }
+ 
+ void drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	mutex_lock(&wq->wq_lock);
+ 	__drv_disable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ }
+ 
+ int idxd_device_drv_probe(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_device *idxd = idxd_dev_to_idxd(idxd_dev);
+ 	unsigned long flags;
+ 	int rc = 0;
+ 
+ 	/*
+ 	 * Device should be in disabled state for the idxd_drv to load. If it's in
+ 	 * enabled state, then the device was altered outside of driver's control.
+ 	 * If the state is in halted state, then we don't want to proceed.
+ 	 */
+ 	if (idxd->state != IDXD_DEV_DISABLED)
+ 		return -ENXIO;
+ 
+ 	/* Device configuration */
+ 	spin_lock_irqsave(&idxd->dev_lock, flags);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		rc = idxd_device_config(idxd);
+ 	spin_unlock_irqrestore(&idxd->dev_lock, flags);
+ 	if (rc < 0)
+ 		return -ENXIO;
+ 
+ 	/* Start device */
+ 	rc = idxd_device_enable(idxd);
+ 	if (rc < 0)
+ 		return rc;
+ 
+ 	/* Setup DMA device without channels */
+ 	rc = idxd_register_dma_device(idxd);
+ 	if (rc < 0) {
+ 		idxd_device_disable(idxd);
+ 		return rc;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ void idxd_device_drv_remove(struct idxd_dev *idxd_dev)
+ {
+ 	struct device *dev = &idxd_dev->conf_dev;
+ 	struct idxd_device *idxd = idxd_dev_to_idxd(idxd_dev);
+ 	int i;
+ 
+ 	for (i = 0; i < idxd->max_wqs; i++) {
+ 		struct idxd_wq *wq = idxd->wqs[i];
+ 		struct device *wq_dev = wq_confdev(wq);
+ 
+ 		if (wq->state == IDXD_WQ_DISABLED)
+ 			continue;
+ 		dev_warn(dev, "Active wq %d on disable %s.\n", i, dev_name(wq_dev));
+ 		device_release_driver(wq_dev);
+ 	}
+ 
+ 	idxd_unregister_dma_device(idxd);
+ 	idxd_device_disable(idxd);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		idxd_device_reset(idxd);
+ }
+ 
+ static enum idxd_dev_type dev_types[] = {
+ 	IDXD_DEV_DSA,
+ 	IDXD_DEV_IAX,
+ 	IDXD_DEV_NONE,
+ };
+ 
+ struct idxd_device_driver idxd_drv = {
+ 	.type = dev_types,
+ 	.probe = idxd_device_drv_probe,
+ 	.remove = idxd_device_drv_remove,
+ 	.name = "idxd",
+ };
+ EXPORT_SYMBOL_GPL(idxd_drv);
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
diff --cc drivers/dma/idxd/dma.c
index 77439b645044,2fd7ec29a08f..000000000000
--- a/drivers/dma/idxd/dma.c
+++ b/drivers/dma/idxd/dma.c
@@@ -260,5 -260,83 +260,86 @@@ void idxd_unregister_dma_channel(struc
  	list_del(&chan->device_node);
  	kfree(wq->idxd_chan);
  	wq->idxd_chan = NULL;
 -	put_device(wq_confdev(wq));
 +	put_device(&wq->conf_dev);
  }
++<<<<<<< HEAD
++=======
+ 
+ static int idxd_dmaengine_drv_probe(struct idxd_dev *idxd_dev)
+ {
+ 	struct device *dev = &idxd_dev->conf_dev;
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 	struct idxd_device *idxd = wq->idxd;
+ 	int rc;
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED)
+ 		return -ENXIO;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	wq->type = IDXD_WQT_KERNEL;
+ 	rc = __drv_enable_wq(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Enable wq %d failed: %d\n", wq->id, rc);
+ 		rc = -ENXIO;
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_alloc_resources(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "WQ resource alloc failed\n");
+ 		goto err_res_alloc;
+ 	}
+ 
+ 	rc = idxd_wq_init_percpu_ref(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "percpu_ref setup failed\n");
+ 		goto err_ref;
+ 	}
+ 
+ 	rc = idxd_register_dma_channel(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Failed to register dma channel\n");
+ 		goto err_dma;
+ 	}
+ 
+ 	mutex_unlock(&wq->wq_lock);
+ 	return 0;
+ 
+ err_dma:
+ 	idxd_wq_quiesce(wq);
+ err_ref:
+ 	idxd_wq_free_resources(wq);
+ err_res_alloc:
+ 	__drv_disable_wq(wq);
+ err:
+ 	wq->type = IDXD_WQT_NONE;
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ static void idxd_dmaengine_drv_remove(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	idxd_wq_quiesce(wq);
+ 	idxd_unregister_dma_channel(wq);
+ 	__drv_disable_wq(wq);
+ 	idxd_wq_free_resources(wq);
+ 	wq->type = IDXD_WQT_NONE;
+ 	mutex_unlock(&wq->wq_lock);
+ }
+ 
+ static enum idxd_dev_type dev_types[] = {
+ 	IDXD_DEV_WQ,
+ 	IDXD_DEV_NONE,
+ };
+ 
+ struct idxd_device_driver idxd_dmaengine_drv = {
+ 	.probe = idxd_dmaengine_drv_probe,
+ 	.remove = idxd_dmaengine_drv_remove,
+ 	.name = "dmaengine",
+ 	.type = dev_types,
+ };
+ EXPORT_SYMBOL_GPL(idxd_dmaengine_drv);
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
diff --cc drivers/dma/idxd/init.c
index 20eae71edab4,8db56f98059f..000000000000
--- a/drivers/dma/idxd/init.c
+++ b/drivers/dma/idxd/init.c
@@@ -824,6 -841,14 +824,17 @@@ static int __init idxd_init_module(void
  	if (err < 0)
  		goto err_idxd_driver_register;
  
++<<<<<<< HEAD
++=======
+ 	err = idxd_driver_register(&idxd_dmaengine_drv);
+ 	if (err < 0)
+ 		goto err_idxd_dmaengine_driver_register;
+ 
+ 	err = idxd_driver_register(&idxd_user_drv);
+ 	if (err < 0)
+ 		goto err_idxd_user_driver_register;
+ 
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
  	err = idxd_cdev_register();
  	if (err)
  		goto err_cdev_register;
@@@ -837,19 -862,23 +848,33 @@@
  err_pci_register:
  	idxd_cdev_remove();
  err_cdev_register:
++<<<<<<< HEAD
 +	idxd_unregister_driver();
++=======
+ 	idxd_driver_unregister(&idxd_user_drv);
+ err_idxd_user_driver_register:
+ 	idxd_driver_unregister(&idxd_dmaengine_drv);
+ err_idxd_dmaengine_driver_register:
+ 	idxd_driver_unregister(&idxd_drv);
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
  err_idxd_driver_register:
 +	idxd_unregister_bus_type();
  	return err;
  }
  module_init(idxd_init_module);
  
  static void __exit idxd_exit_module(void)
  {
++<<<<<<< HEAD
 +	idxd_unregister_driver();
++=======
+ 	idxd_driver_unregister(&idxd_user_drv);
+ 	idxd_driver_unregister(&idxd_dmaengine_drv);
+ 	idxd_driver_unregister(&idxd_drv);
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
  	pci_unregister_driver(&idxd_pci_driver);
  	idxd_cdev_remove();
 +	idxd_unregister_bus_type();
  	perfmon_exit();
  }
  module_exit(idxd_exit_module);
diff --cc drivers/dma/idxd/sysfs.c
index e25f04f3917e,b883e9f16e7f..000000000000
--- a/drivers/dma/idxd/sysfs.c
+++ b/drivers/dma/idxd/sysfs.c
@@@ -16,296 -16,6 +16,299 @@@ static char *idxd_wq_type_names[] = 
  	[IDXD_WQT_USER]		= "user",
  };
  
++<<<<<<< HEAD
 +static int idxd_config_bus_match(struct device *dev,
 +				 struct device_driver *drv)
 +{
 +	int matched = 0;
 +
 +	if (is_idxd_dev(dev)) {
 +		matched = 1;
 +	} else if (is_idxd_wq_dev(dev)) {
 +		struct idxd_wq *wq = confdev_to_wq(dev);
 +
 +		if (wq->state != IDXD_WQ_DISABLED) {
 +			dev_dbg(dev, "%s not disabled\n", dev_name(dev));
 +			return 0;
 +		}
 +		matched = 1;
 +	}
 +
 +	if (matched)
 +		dev_dbg(dev, "%s matched\n", dev_name(dev));
 +
 +	return matched;
 +}
 +
 +static int enable_wq(struct idxd_wq *wq)
 +{
 +	struct idxd_device *idxd = wq->idxd;
 +	struct device *dev = &idxd->pdev->dev;
 +	unsigned long flags;
 +	int rc;
 +
 +	mutex_lock(&wq->wq_lock);
 +
 +	if (idxd->state != IDXD_DEV_ENABLED) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "Enabling while device not enabled.\n");
 +		return -EPERM;
 +	}
 +
 +	if (wq->state != IDXD_WQ_DISABLED) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "WQ %d already enabled.\n", wq->id);
 +		return -EBUSY;
 +	}
 +
 +	if (!wq->group) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "WQ not attached to group.\n");
 +		return -EINVAL;
 +	}
 +
 +	if (strlen(wq->name) == 0) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "WQ name not set.\n");
 +		return -EINVAL;
 +	}
 +
 +	/* Shared WQ checks */
 +	if (wq_shared(wq)) {
 +		if (!device_swq_supported(idxd)) {
 +			dev_warn(dev, "PASID not enabled and shared WQ.\n");
 +			mutex_unlock(&wq->wq_lock);
 +			return -ENXIO;
 +		}
 +		/*
 +		 * Shared wq with the threshold set to 0 means the user
 +		 * did not set the threshold or transitioned from a
 +		 * dedicated wq but did not set threshold. A value
 +		 * of 0 would effectively disable the shared wq. The
 +		 * driver does not allow a value of 0 to be set for
 +		 * threshold via sysfs.
 +		 */
 +		if (wq->threshold == 0) {
 +			dev_warn(dev, "Shared WQ and threshold 0.\n");
 +			mutex_unlock(&wq->wq_lock);
 +			return -EINVAL;
 +		}
 +	}
 +
 +	rc = idxd_wq_alloc_resources(wq);
 +	if (rc < 0) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "WQ resource alloc failed\n");
 +		return rc;
 +	}
 +
 +	spin_lock_irqsave(&idxd->dev_lock, flags);
 +	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
 +		rc = idxd_device_config(idxd);
 +	spin_unlock_irqrestore(&idxd->dev_lock, flags);
 +	if (rc < 0) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "Writing WQ %d config failed: %d\n", wq->id, rc);
 +		return rc;
 +	}
 +
 +	rc = idxd_wq_enable(wq);
 +	if (rc < 0) {
 +		mutex_unlock(&wq->wq_lock);
 +		dev_warn(dev, "WQ %d enabling failed: %d\n", wq->id, rc);
 +		return rc;
 +	}
 +
 +	rc = idxd_wq_map_portal(wq);
 +	if (rc < 0) {
 +		dev_warn(dev, "wq portal mapping failed: %d\n", rc);
 +		rc = idxd_wq_disable(wq, false);
 +		if (rc < 0)
 +			dev_warn(dev, "IDXD wq disable failed\n");
 +		mutex_unlock(&wq->wq_lock);
 +		return rc;
 +	}
 +
 +	wq->client_count = 0;
 +
 +	if (wq->type == IDXD_WQT_KERNEL) {
 +		rc = idxd_wq_init_percpu_ref(wq);
 +		if (rc < 0) {
 +			dev_dbg(dev, "percpu_ref setup failed\n");
 +			mutex_unlock(&wq->wq_lock);
 +			return rc;
 +		}
 +	}
 +
 +	if (is_idxd_wq_dmaengine(wq)) {
 +		rc = idxd_register_dma_channel(wq);
 +		if (rc < 0) {
 +			dev_dbg(dev, "DMA channel register failed\n");
 +			mutex_unlock(&wq->wq_lock);
 +			return rc;
 +		}
 +	} else if (is_idxd_wq_cdev(wq)) {
 +		rc = idxd_wq_add_cdev(wq);
 +		if (rc < 0) {
 +			dev_dbg(dev, "Cdev creation failed\n");
 +			mutex_unlock(&wq->wq_lock);
 +			return rc;
 +		}
 +	}
 +
 +	mutex_unlock(&wq->wq_lock);
 +	dev_info(dev, "wq %s enabled\n", dev_name(&wq->conf_dev));
 +
 +	return 0;
 +}
 +
 +static int idxd_config_bus_probe(struct device *dev)
 +{
 +	int rc = 0;
 +	unsigned long flags;
 +
 +	dev_dbg(dev, "%s called\n", __func__);
 +
 +	if (is_idxd_dev(dev)) {
 +		struct idxd_device *idxd = confdev_to_idxd(dev);
 +
 +		if (!try_module_get(THIS_MODULE))
 +			return -ENXIO;
 +
 +		/* Perform IDXD configuration and enabling */
 +		spin_lock_irqsave(&idxd->dev_lock, flags);
 +		if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
 +			rc = idxd_device_config(idxd);
 +		spin_unlock_irqrestore(&idxd->dev_lock, flags);
 +		if (rc < 0) {
 +			module_put(THIS_MODULE);
 +			dev_warn(dev, "Device config failed: %d\n", rc);
 +			return rc;
 +		}
 +
 +		/* start device */
 +		rc = idxd_device_enable(idxd);
 +		if (rc < 0) {
 +			module_put(THIS_MODULE);
 +			dev_warn(dev, "Device enable failed: %d\n", rc);
 +			return rc;
 +		}
 +
 +		dev_info(dev, "Device %s enabled\n", dev_name(dev));
 +
 +		rc = idxd_register_dma_device(idxd);
 +		if (rc < 0) {
 +			module_put(THIS_MODULE);
 +			dev_dbg(dev, "Failed to register dmaengine device\n");
 +			return rc;
 +		}
 +		return 0;
 +	} else if (is_idxd_wq_dev(dev)) {
 +		struct idxd_wq *wq = confdev_to_wq(dev);
 +
 +		return enable_wq(wq);
 +	}
 +
 +	return -ENODEV;
 +}
 +
 +static void disable_wq(struct idxd_wq *wq)
 +{
 +	struct idxd_device *idxd = wq->idxd;
 +	struct device *dev = &idxd->pdev->dev;
 +
 +	mutex_lock(&wq->wq_lock);
 +	dev_dbg(dev, "%s removing WQ %s\n", __func__, dev_name(&wq->conf_dev));
 +	if (wq->state == IDXD_WQ_DISABLED) {
 +		mutex_unlock(&wq->wq_lock);
 +		return;
 +	}
 +
 +	if (wq->type == IDXD_WQT_KERNEL)
 +		idxd_wq_quiesce(wq);
 +
 +	if (is_idxd_wq_dmaengine(wq))
 +		idxd_unregister_dma_channel(wq);
 +	else if (is_idxd_wq_cdev(wq))
 +		idxd_wq_del_cdev(wq);
 +
 +	if (idxd_wq_refcount(wq))
 +		dev_warn(dev, "Clients has claim on wq %d: %d\n",
 +			 wq->id, idxd_wq_refcount(wq));
 +
 +	idxd_wq_unmap_portal(wq);
 +
 +	idxd_wq_drain(wq);
 +	idxd_wq_reset(wq);
 +
 +	idxd_wq_free_resources(wq);
 +	wq->client_count = 0;
 +	mutex_unlock(&wq->wq_lock);
 +
 +	dev_info(dev, "wq %s disabled\n", dev_name(&wq->conf_dev));
 +}
 +
 +static int idxd_config_bus_remove(struct device *dev)
 +{
 +	dev_dbg(dev, "%s called for %s\n", __func__, dev_name(dev));
 +
 +	/* disable workqueue here */
 +	if (is_idxd_wq_dev(dev)) {
 +		struct idxd_wq *wq = confdev_to_wq(dev);
 +
 +		disable_wq(wq);
 +	} else if (is_idxd_dev(dev)) {
 +		struct idxd_device *idxd = confdev_to_idxd(dev);
 +		int i;
 +
 +		dev_dbg(dev, "%s removing dev %s\n", __func__,
 +			dev_name(&idxd->conf_dev));
 +		for (i = 0; i < idxd->max_wqs; i++) {
 +			struct idxd_wq *wq = idxd->wqs[i];
 +
 +			if (wq->state == IDXD_WQ_DISABLED)
 +				continue;
 +			dev_warn(dev, "Active wq %d on disable %s.\n", i,
 +				 dev_name(&idxd->conf_dev));
 +			device_release_driver(&wq->conf_dev);
 +		}
 +
 +		idxd_unregister_dma_device(idxd);
 +		idxd_device_disable(idxd);
 +		if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
 +			idxd_device_reset(idxd);
 +		module_put(THIS_MODULE);
 +
 +		dev_info(dev, "Device %s disabled\n", dev_name(dev));
 +	}
 +
 +	return 0;
 +}
 +
 +struct bus_type dsa_bus_type = {
 +	.name = "dsa",
 +	.match = idxd_config_bus_match,
 +	.probe = idxd_config_bus_probe,
 +	.remove = idxd_config_bus_remove,
 +};
 +
 +static struct idxd_device_driver dsa_drv = {
 +	.name = "dsa",
 +};
 +
 +/* IDXD generic driver setup */
 +int idxd_register_driver(void)
 +{
 +	return idxd_driver_register(&dsa_drv);
 +}
 +
 +void idxd_unregister_driver(void)
 +{
 +	idxd_driver_unregister(&dsa_drv);
 +}
 +
++=======
++>>>>>>> 6e7f3ee97bbe (dmaengine: idxd: move dsa_drv support to compatible mode)
  /* IDXD engine attributes */
  static ssize_t engine_group_id_show(struct device *dev,
  				    struct device_attribute *attr, char *buf)
diff --git a/drivers/dma/Kconfig b/drivers/dma/Kconfig
index f70e6a229c06..4e1424576265 100644
--- a/drivers/dma/Kconfig
+++ b/drivers/dma/Kconfig
@@ -277,6 +277,23 @@ config INTEL_IDXD
 
 	  If unsure, say N.
 
+config INTEL_IDXD_COMPAT
+	bool "Legacy behavior for idxd driver"
+	depends on PCI && X86_64
+	select INTEL_IDXD_BUS
+	help
+	  Compatible driver to support old /sys/bus/dsa/drivers/dsa behavior.
+	  The old behavior performed driver bind/unbind for device and wq
+	  devices all under the dsa driver. The compat driver will emulate
+	  the legacy behavior in order to allow existing support apps (i.e.
+	  accel-config) to continue function. It is expected that accel-config
+	  v3.2 and earlier will need the compat mode. A distro with later
+	  accel-config version can disable this compat config.
+
+	  Say Y if you have old applications that require such behavior.
+
+	  If unsure, say N.
+
 # Config symbol that collects all the dependencies that's necessary to
 # support shared virtual memory for the devices supported by idxd.
 config INTEL_IDXD_SVM
* Unmerged path drivers/dma/idxd/Makefile
* Unmerged path drivers/dma/idxd/cdev.c
diff --git a/drivers/dma/idxd/compat.c b/drivers/dma/idxd/compat.c
new file mode 100644
index 000000000000..d67746ee0c1a
--- /dev/null
+++ b/drivers/dma/idxd/compat.c
@@ -0,0 +1,114 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright(c) 2021 Intel Corporation. All rights rsvd. */
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/device/bus.h>
+#include "idxd.h"
+
+extern int device_driver_attach(struct device_driver *drv, struct device *dev);
+extern void device_driver_detach(struct device *dev);
+
+#define DRIVER_ATTR_IGNORE_LOCKDEP(_name, _mode, _show, _store)	\
+	struct driver_attribute driver_attr_##_name =		\
+	__ATTR_IGNORE_LOCKDEP(_name, _mode, _show, _store)
+
+static ssize_t unbind_store(struct device_driver *drv, const char *buf, size_t count)
+{
+	struct bus_type *bus = drv->bus;
+	struct device *dev;
+	int rc = -ENODEV;
+
+	dev = bus_find_device_by_name(bus, NULL, buf);
+	if (dev && dev->driver) {
+		device_driver_detach(dev);
+		rc = count;
+	}
+
+	return rc;
+}
+static DRIVER_ATTR_IGNORE_LOCKDEP(unbind, 0200, NULL, unbind_store);
+
+static ssize_t bind_store(struct device_driver *drv, const char *buf, size_t count)
+{
+	struct bus_type *bus = drv->bus;
+	struct device *dev;
+	struct device_driver *alt_drv;
+	int rc = -ENODEV;
+	struct idxd_dev *idxd_dev;
+
+	dev = bus_find_device_by_name(bus, NULL, buf);
+	if (!dev || dev->driver || drv != &dsa_drv.drv)
+		return -ENODEV;
+
+	idxd_dev = confdev_to_idxd_dev(dev);
+	if (is_idxd_dev(idxd_dev)) {
+		alt_drv = driver_find("idxd", bus);
+		if (!alt_drv)
+			return -ENODEV;
+	} else if (is_idxd_wq_dev(idxd_dev)) {
+		struct idxd_wq *wq = confdev_to_wq(dev);
+
+		if (is_idxd_wq_kernel(wq)) {
+			alt_drv = driver_find("dmaengine", bus);
+			if (!alt_drv)
+				return -ENODEV;
+		} else if (is_idxd_wq_user(wq)) {
+			alt_drv = driver_find("user", bus);
+			if (!alt_drv)
+				return -ENODEV;
+		} else {
+			return -ENODEV;
+		}
+	}
+
+	rc = device_driver_attach(alt_drv, dev);
+	if (rc < 0)
+		return rc;
+
+	return count;
+}
+static DRIVER_ATTR_IGNORE_LOCKDEP(bind, 0200, NULL, bind_store);
+
+static struct attribute *dsa_drv_compat_attrs[] = {
+	&driver_attr_bind.attr,
+	&driver_attr_unbind.attr,
+	NULL,
+};
+
+static const struct attribute_group dsa_drv_compat_attr_group = {
+	.attrs = dsa_drv_compat_attrs,
+};
+
+static const struct attribute_group *dsa_drv_compat_groups[] = {
+	&dsa_drv_compat_attr_group,
+	NULL,
+};
+
+static int idxd_dsa_drv_probe(struct idxd_dev *idxd_dev)
+{
+	return -ENODEV;
+}
+
+static void idxd_dsa_drv_remove(struct idxd_dev *idxd_dev)
+{
+}
+
+static enum idxd_dev_type dev_types[] = {
+	IDXD_DEV_NONE,
+};
+
+struct idxd_device_driver dsa_drv = {
+	.name = "dsa",
+	.probe = idxd_dsa_drv_probe,
+	.remove = idxd_dsa_drv_remove,
+	.type = dev_types,
+	.drv = {
+		.suppress_bind_attrs = true,
+		.groups = dsa_drv_compat_groups,
+	},
+};
+
+module_idxd_driver(dsa_drv);
+MODULE_IMPORT_NS(IDXD);
* Unmerged path drivers/dma/idxd/device.c
* Unmerged path drivers/dma/idxd/dma.c
diff --git a/drivers/dma/idxd/idxd.h b/drivers/dma/idxd/idxd.h
index 813e19b4ecc8..db634520ed73 100644
--- a/drivers/dma/idxd/idxd.h
+++ b/drivers/dma/idxd/idxd.h
@@ -334,11 +334,16 @@ static inline bool is_idxd_wq_dmaengine(struct idxd_wq *wq)
 	return false;
 }
 
-static inline bool is_idxd_wq_cdev(struct idxd_wq *wq)
+static inline bool is_idxd_wq_user(struct idxd_wq *wq)
 {
 	return wq->type == IDXD_WQT_USER;
 }
 
+static inline bool is_idxd_wq_kernel(struct idxd_wq *wq)
+{
+	return wq->type == IDXD_WQT_KERNEL;
+}
+
 static inline bool wq_dedicated(struct idxd_wq *wq)
 {
 	return test_bit(WQ_FLAG_DEDICATED, &wq->flags);
@@ -402,6 +407,9 @@ int __must_check __idxd_driver_register(struct idxd_device_driver *idxd_drv,
 
 void idxd_driver_unregister(struct idxd_device_driver *idxd_drv);
 
+#define module_idxd_driver(__idxd_driver) \
+	module_driver(__idxd_driver, idxd_driver_register, idxd_driver_unregister)
+
 int idxd_register_bus_type(void);
 void idxd_unregister_bus_type(void);
 int idxd_register_devices(struct idxd_device *idxd);
* Unmerged path drivers/dma/idxd/init.c
* Unmerged path drivers/dma/idxd/sysfs.c
