Revert "KVM: x86/mmu: Allow zap gfn range to operate under the mmu read lock"

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit 5a324c24b638d0f3194e1dc8f0cebd28a0745238
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/5a324c24.failed

This together with the next patch will fix a future race between
kvm_zap_gfn_range and the page fault handler, which will happen
when AVIC memslot is going to be only partially disabled.

The performance impact is minimal since kvm_zap_gfn_range is only
called by users, update_mtrr() and kvm_post_set_cr0().

Both only use it if the guest has non-coherent DMA, in order to
honor the guest's UC memtype.

MTRR and CD setup only happens at boot, and generally in an area
where the page tables should be small (for CD) or should not
include the affected GFNs at all (for MTRRs).

This is based on a patch suggested by Sean Christopherson:
https://lkml.org/lkml/2021/7/22/1025

	Signed-off-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: Maxim Levitsky <mlevitsk@redhat.com>
Message-Id: <20210810205251.424103-2-mlevitsk@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 5a324c24b638d0f3194e1dc8f0cebd28a0745238)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
#	arch/x86/kvm/mmu/tdp_mmu.c
diff --cc arch/x86/kvm/mmu/mmu.c
index 4c612c0dc324,9a7199679f62..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -5694,21 -5683,27 +5694,35 @@@ void kvm_zap_gfn_range(struct kvm *kvm
  	bool flush = false;
  
  	write_lock(&kvm->mmu_lock);
++<<<<<<< HEAD
 +	for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {
 +		slots = __kvm_memslots(kvm, i);
 +		kvm_for_each_memslot(memslot, slots) {
 +			gfn_t start, end;
++=======
+ 
+ 	if (kvm_memslots_have_rmaps(kvm)) {
+ 		for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++) {
+ 			slots = __kvm_memslots(kvm, i);
+ 			kvm_for_each_memslot(memslot, slots) {
+ 				gfn_t start, end;
++>>>>>>> 5a324c24b638 (Revert "KVM: x86/mmu: Allow zap gfn range to operate under the mmu read lock")
  
 -				start = max(gfn_start, memslot->base_gfn);
 -				end = min(gfn_end, memslot->base_gfn + memslot->npages);
 -				if (start >= end)
 -					continue;
 +			start = max(gfn_start, memslot->base_gfn);
 +			end = min(gfn_end, memslot->base_gfn + memslot->npages);
 +			if (start >= end)
 +				continue;
  
 -				flush = slot_handle_level_range(kvm,
 -						(const struct kvm_memory_slot *) memslot,
 -						kvm_zap_rmapp, PG_LEVEL_4K,
 -						KVM_MAX_HUGEPAGE_LEVEL, start,
 -						end - 1, true, flush);
 -			}
 +			flush = slot_handle_level_range(kvm, memslot, kvm_zap_rmapp,
 +							PG_LEVEL_4K,
 +							KVM_MAX_HUGEPAGE_LEVEL,
 +							start, end - 1, true, flush);
  		}
++<<<<<<< HEAD
++=======
+ 		if (flush)
+ 			kvm_flush_remote_tlbs_with_address(kvm, gfn_start, gfn_end);
++>>>>>>> 5a324c24b638 (Revert "KVM: x86/mmu: Allow zap gfn range to operate under the mmu read lock")
  	}
  
  	if (is_tdp_mmu_enabled(kvm)) {
diff --cc arch/x86/kvm/mmu/tdp_mmu.c
index 506d3bdb9486,fb1b2dc7a6d1..000000000000
--- a/arch/x86/kvm/mmu/tdp_mmu.c
+++ b/arch/x86/kvm/mmu/tdp_mmu.c
@@@ -741,8 -824,9 +741,14 @@@ bool __kvm_tdp_mmu_zap_gfn_range(struc
  {
  	struct kvm_mmu_page *root;
  
++<<<<<<< HEAD
 +	for_each_tdp_mmu_root_yield_safe(kvm, root, as_id)
 +		flush = zap_gfn_range(kvm, root, start, end, can_yield, flush);
++=======
+ 	for_each_tdp_mmu_root_yield_safe(kvm, root, as_id, false)
+ 		flush = zap_gfn_range(kvm, root, start, end, can_yield, flush,
+ 				      false);
++>>>>>>> 5a324c24b638 (Revert "KVM: x86/mmu: Allow zap gfn range to operate under the mmu read lock")
  
  	return flush;
  }
@@@ -754,7 -837,7 +760,11 @@@ void kvm_tdp_mmu_zap_all(struct kvm *kv
  	int i;
  
  	for (i = 0; i < KVM_ADDRESS_SPACE_NUM; i++)
++<<<<<<< HEAD
 +		flush = kvm_tdp_mmu_zap_gfn_range(kvm, i, 0, max_gfn, flush);
++=======
+ 		flush = kvm_tdp_mmu_zap_gfn_range(kvm, i, 0, -1ull, flush);
++>>>>>>> 5a324c24b638 (Revert "KVM: x86/mmu: Allow zap gfn range to operate under the mmu read lock")
  
  	if (flush)
  		kvm_flush_remote_tlbs(kvm);
* Unmerged path arch/x86/kvm/mmu/mmu.c
* Unmerged path arch/x86/kvm/mmu/tdp_mmu.c
