KVM: selftests: Fill per-vCPU struct during "perf_test" VM creation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit cf1d59300ab27af6a2e96b4882fe3d9a72b32b15
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/cf1d5930.failed

Fill the per-vCPU args when creating the perf_test VM instead of having
the caller do so.  This helps ensure that any adjustments to the number
of pages (and thus vcpu_memory_bytes) are reflected in the per-VM args.
Automatically filling the per-vCPU args will also allow a future patch
to do the sync to the guest during creation.

	Signed-off-by: Sean Christopherson <seanjc@google.com>
[Updated access_tracking_perf_test as well.]
	Signed-off-by: David Matlack <dmatlack@google.com>
	Reviewed-by: Ben Gardon <bgardon@google.com>
Message-Id: <20211111000310.1435032-12-dmatlack@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit cf1d59300ab27af6a2e96b4882fe3d9a72b32b15)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/testing/selftests/kvm/demand_paging_test.c
#	tools/testing/selftests/kvm/lib/perf_test_util.c
diff --cc tools/testing/selftests/kvm/demand_paging_test.c
index 52bd44288de9,0fee44f5e5ae..000000000000
--- a/tools/testing/selftests/kvm/demand_paging_test.c
+++ b/tools/testing/selftests/kvm/demand_paging_test.c
@@@ -271,10 -307,7 +271,14 @@@ static void run_test(enum vm_guest_mod
  	vcpu_threads = malloc(nr_vcpus * sizeof(*vcpu_threads));
  	TEST_ASSERT(vcpu_threads, "Memory allocation failed");
  
++<<<<<<< HEAD
 +	perf_test_setup_vcpus(vm, nr_vcpus, guest_percpu_mem_size,
 +			      p->partition_vcpu_memory_access);
 +
 +	if (p->use_uffd) {
++=======
+ 	if (p->uffd_mode) {
++>>>>>>> cf1d59300ab2 (KVM: selftests: Fill per-vCPU struct during "perf_test" VM creation)
  		uffd_handler_threads =
  			malloc(nr_vcpus * sizeof(*uffd_handler_threads));
  		TEST_ASSERT(uffd_handler_threads, "Memory allocation failed");
diff --cc tools/testing/selftests/kvm/lib/perf_test_util.c
index 0ef80dbdc116,13c8bc22f4e1..000000000000
--- a/tools/testing/selftests/kvm/lib/perf_test_util.c
+++ b/tools/testing/selftests/kvm/lib/perf_test_util.c
@@@ -49,12 -48,48 +49,46 @@@ static void guest_code(uint32_t vcpu_id
  	}
  }
  
+ void perf_test_setup_vcpus(struct kvm_vm *vm, int vcpus,
+ 			   uint64_t vcpu_memory_bytes,
+ 			   bool partition_vcpu_memory_access)
+ {
+ 	struct perf_test_args *pta = &perf_test_args;
+ 	struct perf_test_vcpu_args *vcpu_args;
+ 	int vcpu_id;
+ 
+ 	for (vcpu_id = 0; vcpu_id < vcpus; vcpu_id++) {
+ 		vcpu_args = &pta->vcpu_args[vcpu_id];
+ 
+ 		vcpu_args->vcpu_id = vcpu_id;
+ 		if (partition_vcpu_memory_access) {
+ 			vcpu_args->gva = guest_test_virt_mem +
+ 					 (vcpu_id * vcpu_memory_bytes);
+ 			vcpu_args->pages = vcpu_memory_bytes /
+ 					   pta->guest_page_size;
+ 			vcpu_args->gpa = pta->gpa + (vcpu_id * vcpu_memory_bytes);
+ 		} else {
+ 			vcpu_args->gva = guest_test_virt_mem;
+ 			vcpu_args->pages = (vcpus * vcpu_memory_bytes) /
+ 					   pta->guest_page_size;
+ 			vcpu_args->gpa = pta->gpa;
+ 		}
+ 
+ 		vcpu_args_set(vm, vcpu_id, 1, vcpu_id);
+ 
+ 		pr_debug("Added VCPU %d with test mem gpa [%lx, %lx)\n",
+ 			 vcpu_id, vcpu_args->gpa, vcpu_args->gpa +
+ 			 (vcpu_args->pages * pta->guest_page_size));
+ 	}
+ }
+ 
  struct kvm_vm *perf_test_create_vm(enum vm_guest_mode mode, int vcpus,
  				   uint64_t vcpu_memory_bytes, int slots,
- 				   enum vm_mem_backing_src_type backing_src)
+ 				   enum vm_mem_backing_src_type backing_src,
+ 				   bool partition_vcpu_memory_access)
  {
 -	struct perf_test_args *pta = &perf_test_args;
  	struct kvm_vm *vm;
  	uint64_t guest_num_pages;
 -	uint64_t backing_src_pagesz = get_backing_src_pagesz(backing_src);
  	int i;
  
  	pr_info("Testing guest mode: %s\n", vm_guest_mode_string(mode));
@@@ -111,8 -151,10 +145,10 @@@
  	}
  
  	/* Do mapping for the demand paging memory slot */
 -	virt_map(vm, guest_test_virt_mem, pta->gpa, guest_num_pages);
 +	virt_map(vm, guest_test_virt_mem, guest_test_phys_mem, guest_num_pages);
  
+ 	perf_test_setup_vcpus(vm, vcpus, vcpu_memory_bytes, partition_vcpu_memory_access);
+ 
  	ucall_init(vm, NULL);
  
  	return vm;
@@@ -123,37 -165,3 +159,40 @@@ void perf_test_destroy_vm(struct kvm_v
  	ucall_uninit(vm);
  	kvm_vm_free(vm);
  }
++<<<<<<< HEAD
 +
 +void perf_test_setup_vcpus(struct kvm_vm *vm, int vcpus,
 +			   uint64_t vcpu_memory_bytes,
 +			   bool partition_vcpu_memory_access)
 +{
 +	vm_paddr_t vcpu_gpa;
 +	struct perf_test_vcpu_args *vcpu_args;
 +	int vcpu_id;
 +
 +	for (vcpu_id = 0; vcpu_id < vcpus; vcpu_id++) {
 +		vcpu_args = &perf_test_args.vcpu_args[vcpu_id];
 +
 +		vcpu_args->vcpu_id = vcpu_id;
 +		if (partition_vcpu_memory_access) {
 +			vcpu_args->gva = guest_test_virt_mem +
 +					 (vcpu_id * vcpu_memory_bytes);
 +			vcpu_args->pages = vcpu_memory_bytes /
 +					   perf_test_args.guest_page_size;
 +			vcpu_gpa = guest_test_phys_mem +
 +				   (vcpu_id * vcpu_memory_bytes);
 +		} else {
 +			vcpu_args->gva = guest_test_virt_mem;
 +			vcpu_args->pages = (vcpus * vcpu_memory_bytes) /
 +					   perf_test_args.guest_page_size;
 +			vcpu_gpa = guest_test_phys_mem;
 +		}
 +
 +		vcpu_args_set(vm, vcpu_id, 1, vcpu_id);
 +
 +		pr_debug("Added VCPU %d with test mem gpa [%lx, %lx)\n",
 +			 vcpu_id, vcpu_gpa, vcpu_gpa +
 +			 (vcpu_args->pages * perf_test_args.guest_page_size));
 +	}
 +}
++=======
++>>>>>>> cf1d59300ab2 (KVM: selftests: Fill per-vCPU struct during "perf_test" VM creation)
diff --git a/tools/testing/selftests/kvm/access_tracking_perf_test.c b/tools/testing/selftests/kvm/access_tracking_perf_test.c
index 8964fe69d998..64077b3c88d0 100644
--- a/tools/testing/selftests/kvm/access_tracking_perf_test.c
+++ b/tools/testing/selftests/kvm/access_tracking_perf_test.c
@@ -330,10 +330,7 @@ static void run_test(enum vm_guest_mode mode, void *arg)
 	int vcpus = params->vcpus;
 
 	vm = perf_test_create_vm(mode, vcpus, params->vcpu_memory_bytes, 1,
-				 params->backing_src);
-
-	perf_test_setup_vcpus(vm, vcpus, params->vcpu_memory_bytes,
-			      !overlap_memory_access);
+				 params->backing_src, !overlap_memory_access);
 
 	vcpu_threads = create_vcpu_threads(vcpus);
 
* Unmerged path tools/testing/selftests/kvm/demand_paging_test.c
diff --git a/tools/testing/selftests/kvm/dirty_log_perf_test.c b/tools/testing/selftests/kvm/dirty_log_perf_test.c
index 7ffab5bd5ce5..62f9cc2a3146 100644
--- a/tools/testing/selftests/kvm/dirty_log_perf_test.c
+++ b/tools/testing/selftests/kvm/dirty_log_perf_test.c
@@ -186,7 +186,8 @@ static void run_test(enum vm_guest_mode mode, void *arg)
 	struct timespec clear_dirty_log_total = (struct timespec){0};
 
 	vm = perf_test_create_vm(mode, nr_vcpus, guest_percpu_mem_size,
-				 p->slots, p->backing_src);
+				 p->slots, p->backing_src,
+				 p->partition_vcpu_memory_access);
 
 	perf_test_args.wr_fract = p->wr_fract;
 
@@ -206,9 +207,6 @@ static void run_test(enum vm_guest_mode mode, void *arg)
 	vcpu_threads = malloc(nr_vcpus * sizeof(*vcpu_threads));
 	TEST_ASSERT(vcpu_threads, "Memory allocation failed");
 
-	perf_test_setup_vcpus(vm, nr_vcpus, guest_percpu_mem_size,
-			      p->partition_vcpu_memory_access);
-
 	sync_global_to_guest(vm, perf_test_args);
 
 	/* Start the iterations */
diff --git a/tools/testing/selftests/kvm/include/perf_test_util.h b/tools/testing/selftests/kvm/include/perf_test_util.h
index df9f1a3a3ffb..8a046167f4ce 100644
--- a/tools/testing/selftests/kvm/include/perf_test_util.h
+++ b/tools/testing/selftests/kvm/include/perf_test_util.h
@@ -45,10 +45,8 @@ extern uint64_t guest_test_phys_mem;
 
 struct kvm_vm *perf_test_create_vm(enum vm_guest_mode mode, int vcpus,
 				   uint64_t vcpu_memory_bytes, int slots,
-				   enum vm_mem_backing_src_type backing_src);
+				   enum vm_mem_backing_src_type backing_src,
+				   bool partition_vcpu_memory_access);
 void perf_test_destroy_vm(struct kvm_vm *vm);
-void perf_test_setup_vcpus(struct kvm_vm *vm, int vcpus,
-			   uint64_t vcpu_memory_bytes,
-			   bool partition_vcpu_memory_access);
 
 #endif /* SELFTEST_KVM_PERF_TEST_UTIL_H */
* Unmerged path tools/testing/selftests/kvm/lib/perf_test_util.c
diff --git a/tools/testing/selftests/kvm/memslot_modification_stress_test.c b/tools/testing/selftests/kvm/memslot_modification_stress_test.c
index 4cfcafea9f5a..71e932076f24 100644
--- a/tools/testing/selftests/kvm/memslot_modification_stress_test.c
+++ b/tools/testing/selftests/kvm/memslot_modification_stress_test.c
@@ -105,16 +105,14 @@ static void run_test(enum vm_guest_mode mode, void *arg)
 	int vcpu_id;
 
 	vm = perf_test_create_vm(mode, nr_vcpus, guest_percpu_mem_size, 1,
-				 VM_MEM_SRC_ANONYMOUS);
+				 VM_MEM_SRC_ANONYMOUS,
+				 p->partition_vcpu_memory_access);
 
 	perf_test_args.wr_fract = 1;
 
 	vcpu_threads = malloc(nr_vcpus * sizeof(*vcpu_threads));
 	TEST_ASSERT(vcpu_threads, "Memory allocation failed");
 
-	perf_test_setup_vcpus(vm, nr_vcpus, guest_percpu_mem_size,
-			      p->partition_vcpu_memory_access);
-
 	/* Export the shared variables to the guest */
 	sync_global_to_guest(vm, perf_test_args);
 
