x86/sev: Replace occurrences of sev_es_active() with cc_platform_has()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Tom Lendacky <thomas.lendacky@amd.com>
commit 6283f2effbd62a71a7c29062f8093c335ff3ea89
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/6283f2ef.failed

Replace uses of sev_es_active() with the more generic cc_platform_has()
using CC_ATTR_GUEST_STATE_ENCRYPT. If future support is added for other
memory encyrption techonologies, the use of CC_ATTR_GUEST_STATE_ENCRYPT
can be updated, as required.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20210928191009.32551-8-bp@alien8.de
(cherry picked from commit 6283f2effbd62a71a7c29062f8093c335ff3ea89)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mem_encrypt.h
#	arch/x86/kernel/sev.c
#	arch/x86/mm/mem_encrypt.c
#	arch/x86/realmode/init.c
diff --cc arch/x86/include/asm/mem_encrypt.h
index fd679b0543a3,da14ede311aa..000000000000
--- a/arch/x86/include/asm/mem_encrypt.h
+++ b/arch/x86/include/asm/mem_encrypt.h
@@@ -47,16 -45,14 +47,19 @@@ void __init sme_enable(struct boot_para
  int __init early_set_memory_decrypted(unsigned long vaddr, unsigned long size);
  int __init early_set_memory_encrypted(unsigned long vaddr, unsigned long size);
  
 -void __init mem_encrypt_free_decrypted_mem(void);
 -
  /* Architecture __weak replacement functions */
  void __init mem_encrypt_init(void);
 +void __init mem_encrypt_free_decrypted_mem(void);
  
  void __init sev_es_init_vc_handling(void);
++<<<<<<< HEAD
 +bool sme_active(void);
 +bool sev_active(void);
 +bool sev_es_active(void);
++=======
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  
 -#define __bss_decrypted __section(".bss..decrypted")
 +#define __bss_decrypted __attribute__((__section__(".bss..decrypted")))
  
  #else	/* !CONFIG_AMD_MEM_ENCRYPT */
  
@@@ -77,9 -73,6 +80,12 @@@ static inline void __init sme_encrypt_k
  static inline void __init sme_enable(struct boot_params *bp) { }
  
  static inline void sev_es_init_vc_handling(void) { }
++<<<<<<< HEAD
 +static inline bool sme_active(void) { return false; }
 +static inline bool sev_active(void) { return false; }
 +static inline bool sev_es_active(void) { return false; }
++=======
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  
  static inline int __init
  early_set_memory_decrypted(unsigned long vaddr, unsigned long size) { return 0; }
diff --cc arch/x86/kernel/sev.c
index f9d5320b6d45,53a6837d354b..000000000000
--- a/arch/x86/kernel/sev.c
+++ b/arch/x86/kernel/sev.c
@@@ -11,8 -11,7 +11,12 @@@
  
  #include <linux/sched/debug.h>	/* For show_regs() */
  #include <linux/percpu-defs.h>
++<<<<<<< HEAD
 +#include <linux/mem_encrypt.h>
 +#include <linux/lockdep.h>
++=======
+ #include <linux/cc_platform.h>
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  #include <linux/printk.h>
  #include <linux/mm_types.h>
  #include <linux/set_memory.h>
@@@ -748,9 -772,9 +752,9 @@@ void __init sev_es_init_vc_handling(voi
  {
  	int cpu;
  
 -	BUILD_BUG_ON(offsetof(struct sev_es_runtime_data, ghcb_page) % PAGE_SIZE);
 +	/* BUILD_BUG_ON(offsetof(struct sev_es_runtime_data, ghcb_page) % PAGE_SIZE); */
  
- 	if (!sev_es_active())
+ 	if (!cc_platform_has(CC_ATTR_GUEST_STATE_ENCRYPT))
  		return;
  
  	if (!sev_es_check_cpu_features())
diff --cc arch/x86/mm/mem_encrypt.c
index d16a12ec26d9,2d04c39bea1d..000000000000
--- a/arch/x86/mm/mem_encrypt.c
+++ b/arch/x86/mm/mem_encrypt.c
@@@ -362,36 -361,6 +362,39 @@@ int __init early_set_memory_encrypted(u
  	return early_set_memory_enc_dec(vaddr, size, true);
  }
  
++<<<<<<< HEAD
 +/*
 + * SME and SEV are very similar but they are not the same, so there are
 + * times that the kernel will need to distinguish between SME and SEV. The
 + * sme_active() and sev_active() functions are used for this.  When a
 + * distinction isn't needed, the mem_encrypt_active() function can be used.
 + *
 + * The trampoline code is a good example for this requirement.  Before
 + * paging is activated, SME will access all memory as decrypted, but SEV
 + * will access all memory as encrypted.  So, when APs are being brought
 + * up under SME the trampoline area cannot be encrypted, whereas under SEV
 + * the trampoline area must be encrypted.
 + */
 +bool sev_active(void)
 +{
 +	return sev_status & MSR_AMD64_SEV_ENABLED;
 +}
 +EXPORT_SYMBOL(sme_active);
 +
 +bool sme_active(void)
 +{
 +	return sme_me_mask && !sev_active();
 +}
 +EXPORT_SYMBOL_GPL(sev_active);
 +
 +/* Needs to be called from non-instrumentable code */
 +bool noinstr sev_es_active(void)
 +{
 +	return sev_status & MSR_AMD64_SEV_ES_ENABLED;
 +}
 +
++=======
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  /* Override for DMA direct allocation check - ARCH_HAS_FORCE_DMA_UNENCRYPTED */
  bool force_dma_unencrypted(struct device *dev)
  {
@@@ -480,7 -449,8 +483,12 @@@ void __init mem_encrypt_init(void
  	 * With SEV, we need to unroll the rep string I/O instructions,
  	 * but SEV-ES supports them through the #VC handler.
  	 */
++<<<<<<< HEAD
 +	if (sev_active() && !sev_es_active())
++=======
+ 	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT) &&
+ 	    !cc_platform_has(CC_ATTR_GUEST_STATE_ENCRYPT))
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  		static_branch_enable(&sev_enable_key);
  
  	print_mem_encrypt_feature_info();
diff --cc arch/x86/realmode/init.c
index d1bb2ffcfb07,4a3da7592b99..000000000000
--- a/arch/x86/realmode/init.c
+++ b/arch/x86/realmode/init.c
@@@ -2,10 -2,10 +2,15 @@@
  #include <linux/io.h>
  #include <linux/slab.h>
  #include <linux/memblock.h>
++<<<<<<< HEAD
 +#include <linux/mem_encrypt.h>
++=======
+ #include <linux/cc_platform.h>
+ #include <linux/pgtable.h>
++>>>>>>> 6283f2effbd6 (x86/sev: Replace occurrences of sev_es_active() with cc_platform_has())
  
  #include <asm/set_memory.h>
 +#include <asm/pgtable.h>
  #include <asm/realmode.h>
  #include <asm/tlbflush.h>
  #include <asm/crash.h>
@@@ -44,10 -44,10 +49,10 @@@ void __init reserve_real_mode(void
  static void sme_sev_setup_real_mode(struct trampoline_header *th)
  {
  #ifdef CONFIG_AMD_MEM_ENCRYPT
 -	if (cc_platform_has(CC_ATTR_HOST_MEM_ENCRYPT))
 +	if (sme_active())
  		th->flags |= TH_FLAGS_SME_ACTIVE;
  
- 	if (sev_es_active()) {
+ 	if (cc_platform_has(CC_ATTR_GUEST_STATE_ENCRYPT)) {
  		/*
  		 * Skip the call to verify_cpu() in secondary_startup_64 as it
  		 * will cause #VC exceptions when the AP can't handle them yet.
* Unmerged path arch/x86/include/asm/mem_encrypt.h
* Unmerged path arch/x86/kernel/sev.c
* Unmerged path arch/x86/mm/mem_encrypt.c
* Unmerged path arch/x86/realmode/init.c
