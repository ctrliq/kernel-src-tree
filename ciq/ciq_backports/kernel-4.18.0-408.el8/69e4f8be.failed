dmaengine: idxd: move wq_disable() to device.c

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Dave Jiang <dave.jiang@intel.com>
commit 69e4f8be596d897679e44e86a323629537c02975
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/69e4f8be.failed

Move the wq_disable() function to device.c in preparation of setting up the
idxd internal sub-driver framework. No logic changes.

	Reviewed-by: Dan Williams <dan.j.williams@intel.com>
	Signed-off-by: Dave Jiang <dave.jiang@intel.com>
Link: https://lore.kernel.org/r/162637461775.744545.9644048686618957886.stgit@djiang5-desk3.ch.intel.com
	Signed-off-by: Vinod Koul <vkoul@kernel.org>
(cherry picked from commit 69e4f8be596d897679e44e86a323629537c02975)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/dma/idxd/device.c
#	drivers/dma/idxd/idxd.h
#	drivers/dma/idxd/sysfs.c
diff --cc drivers/dma/idxd/device.c
index 4a2af9799239,8d8e249931a9..000000000000
--- a/drivers/dma/idxd/device.c
+++ b/drivers/dma/idxd/device.c
@@@ -1129,3 -1129,164 +1129,167 @@@ int idxd_device_load_config(struct idxd
  
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ 
+ static int __drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 	unsigned long flags;
+ 	int rc = -ENXIO;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED)
+ 		goto err;
+ 
+ 	if (wq->state != IDXD_WQ_DISABLED) {
+ 		dev_dbg(dev, "wq %d already enabled.\n", wq->id);
+ 		rc = -EBUSY;
+ 		goto err;
+ 	}
+ 
+ 	if (!wq->group) {
+ 		dev_dbg(dev, "wq %d not attached to group.\n", wq->id);
+ 		goto err;
+ 	}
+ 
+ 	if (strlen(wq->name) == 0) {
+ 		dev_dbg(dev, "wq %d name not set.\n", wq->id);
+ 		goto err;
+ 	}
+ 
+ 	/* Shared WQ checks */
+ 	if (wq_shared(wq)) {
+ 		if (!device_swq_supported(idxd)) {
+ 			dev_dbg(dev, "PASID not enabled and shared wq.\n");
+ 			goto err;
+ 		}
+ 		/*
+ 		 * Shared wq with the threshold set to 0 means the user
+ 		 * did not set the threshold or transitioned from a
+ 		 * dedicated wq but did not set threshold. A value
+ 		 * of 0 would effectively disable the shared wq. The
+ 		 * driver does not allow a value of 0 to be set for
+ 		 * threshold via sysfs.
+ 		 */
+ 		if (wq->threshold == 0) {
+ 			dev_dbg(dev, "Shared wq and threshold 0.\n");
+ 			goto err;
+ 		}
+ 	}
+ 
+ 	rc = idxd_wq_alloc_resources(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq resource alloc failed\n");
+ 		goto err;
+ 	}
+ 
+ 	spin_lock_irqsave(&idxd->dev_lock, flags);
+ 	if (test_bit(IDXD_FLAG_CONFIGURABLE, &idxd->flags))
+ 		rc = idxd_device_config(idxd);
+ 	spin_unlock_irqrestore(&idxd->dev_lock, flags);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Writing wq %d config failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_enable(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq %d enabling failed: %d\n", wq->id, rc);
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_map_portal(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "wq %d portal mapping failed: %d\n", wq->id, rc);
+ 		goto err_map_portal;
+ 	}
+ 
+ 	wq->client_count = 0;
+ 
+ 	if (wq->type == IDXD_WQT_KERNEL) {
+ 		rc = idxd_wq_init_percpu_ref(wq);
+ 		if (rc < 0) {
+ 			dev_dbg(dev, "wq %d percpu_ref setup failed\n", wq->id);
+ 			goto err_cpu_ref;
+ 		}
+ 	}
+ 
+ 	if (is_idxd_wq_dmaengine(wq)) {
+ 		rc = idxd_register_dma_channel(wq);
+ 		if (rc < 0) {
+ 			dev_dbg(dev, "wq %d DMA channel register failed\n", wq->id);
+ 			goto err_client;
+ 		}
+ 	} else if (is_idxd_wq_cdev(wq)) {
+ 		rc = idxd_wq_add_cdev(wq);
+ 		if (rc < 0) {
+ 			dev_dbg(dev, "wq %d cdev creation failed\n", wq->id);
+ 			goto err_client;
+ 		}
+ 	}
+ 
+ 	dev_info(dev, "wq %s enabled\n", dev_name(wq_confdev(wq)));
+ 	return 0;
+ 
+ err_client:
+ 	idxd_wq_quiesce(wq);
+ err_cpu_ref:
+ 	idxd_wq_unmap_portal(wq);
+ err_map_portal:
+ 	rc = idxd_wq_disable(wq, false);
+ 	if (rc < 0)
+ 		dev_dbg(dev, "wq %s disable failed\n", dev_name(wq_confdev(wq)));
+ err:
+ 	return rc;
+ }
+ 
+ int drv_enable_wq(struct idxd_wq *wq)
+ {
+ 	int rc;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	rc = __drv_enable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ static void __drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	struct idxd_device *idxd = wq->idxd;
+ 	struct device *dev = &idxd->pdev->dev;
+ 
+ 	lockdep_assert_held(&wq->wq_lock);
+ 
+ 	if (wq->type == IDXD_WQT_KERNEL)
+ 		idxd_wq_quiesce(wq);
+ 
+ 	if (is_idxd_wq_dmaengine(wq))
+ 		idxd_unregister_dma_channel(wq);
+ 	else if (is_idxd_wq_cdev(wq))
+ 		idxd_wq_del_cdev(wq);
+ 
+ 	if (idxd_wq_refcount(wq))
+ 		dev_warn(dev, "Clients has claim on wq %d: %d\n",
+ 			 wq->id, idxd_wq_refcount(wq));
+ 
+ 	idxd_wq_unmap_portal(wq);
+ 
+ 	idxd_wq_drain(wq);
+ 	idxd_wq_reset(wq);
+ 
+ 	idxd_wq_free_resources(wq);
+ 	wq->client_count = 0;
+ 
+ 	dev_info(dev, "wq %s disabled\n", dev_name(wq_confdev(wq)));
+ }
+ 
+ void drv_disable_wq(struct idxd_wq *wq)
+ {
+ 	mutex_lock(&wq->wq_lock);
+ 	__drv_disable_wq(wq);
+ 	mutex_unlock(&wq->wq_lock);
+ }
++>>>>>>> 69e4f8be596d (dmaengine: idxd: move wq_disable() to device.c)
diff --cc drivers/dma/idxd/idxd.h
index 69b07f16a011,e96ddbfc4569..000000000000
--- a/drivers/dma/idxd/idxd.h
+++ b/drivers/dma/idxd/idxd.h
@@@ -423,6 -495,8 +423,11 @@@ void idxd_mask_msix_vector(struct idxd_
  void idxd_unmask_msix_vector(struct idxd_device *idxd, int vec_id);
  
  /* device control */
++<<<<<<< HEAD
++=======
+ int drv_enable_wq(struct idxd_wq *wq);
+ void drv_disable_wq(struct idxd_wq *wq);
++>>>>>>> 69e4f8be596d (dmaengine: idxd: move wq_disable() to device.c)
  int idxd_device_init_reset(struct idxd_device *idxd);
  int idxd_device_enable(struct idxd_device *idxd);
  int idxd_device_disable(struct idxd_device *idxd);
diff --cc drivers/dma/idxd/sysfs.c
index f11da39c1159,9967fad58a01..000000000000
--- a/drivers/dma/idxd/sysfs.c
+++ b/drivers/dma/idxd/sysfs.c
@@@ -211,42 -89,6 +211,45 @@@ static int idxd_config_bus_probe(struc
  	return -ENODEV;
  }
  
++<<<<<<< HEAD
 +static void disable_wq(struct idxd_wq *wq)
 +{
 +	struct idxd_device *idxd = wq->idxd;
 +	struct device *dev = &idxd->pdev->dev;
 +
 +	mutex_lock(&wq->wq_lock);
 +	dev_dbg(dev, "%s removing WQ %s\n", __func__, dev_name(&wq->conf_dev));
 +	if (wq->state == IDXD_WQ_DISABLED) {
 +		mutex_unlock(&wq->wq_lock);
 +		return;
 +	}
 +
 +	if (wq->type == IDXD_WQT_KERNEL)
 +		idxd_wq_quiesce(wq);
 +
 +	if (is_idxd_wq_dmaengine(wq))
 +		idxd_unregister_dma_channel(wq);
 +	else if (is_idxd_wq_cdev(wq))
 +		idxd_wq_del_cdev(wq);
 +
 +	if (idxd_wq_refcount(wq))
 +		dev_warn(dev, "Clients has claim on wq %d: %d\n",
 +			 wq->id, idxd_wq_refcount(wq));
 +
 +	idxd_wq_unmap_portal(wq);
 +
 +	idxd_wq_drain(wq);
 +	idxd_wq_reset(wq);
 +
 +	idxd_wq_free_resources(wq);
 +	wq->client_count = 0;
 +	mutex_unlock(&wq->wq_lock);
 +
 +	dev_info(dev, "wq %s disabled\n", dev_name(&wq->conf_dev));
 +}
 +
++=======
++>>>>>>> 69e4f8be596d (dmaengine: idxd: move wq_disable() to device.c)
  static int idxd_config_bus_remove(struct device *dev)
  {
  	dev_dbg(dev, "%s called for %s\n", __func__, dev_name(dev));
* Unmerged path drivers/dma/idxd/device.c
* Unmerged path drivers/dma/idxd/idxd.h
* Unmerged path drivers/dma/idxd/sysfs.c
