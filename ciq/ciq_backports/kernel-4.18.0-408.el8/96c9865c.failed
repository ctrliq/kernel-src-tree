dm: rename split functions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Mike Snitzer <snitzer@redhat.com>
commit 96c9865cb6dd068a74f844e1c14114b7e676f727
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/96c9865c.failed

Rename __split_and_process_bio to dm_split_and_process_bio.
Rename __split_and_process_non_flush to __split_and_process_bio.

Also fix a stale comment and whitespace.

	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Mikulas Patocka <mpatocka@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 96c9865cb6dd068a74f844e1c14114b7e676f727)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm.c
diff --cc drivers/md/dm.c
index 495368816d3f,7d1bf59c4663..000000000000
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@@ -1609,11 -1414,10 +1609,16 @@@ static void init_clone_info(struct clon
  /*
   * Entry point to split a bio into clones and submit them to the targets.
   */
++<<<<<<< HEAD
 +static blk_qc_t __split_and_process_bio(struct mapped_device *md,
 +					struct dm_table *map, struct bio *bio)
++=======
+ static void dm_split_and_process_bio(struct mapped_device *md,
+ 				     struct dm_table *map, struct bio *bio)
++>>>>>>> 96c9865cb6dd (dm: rename split functions)
  {
  	struct clone_info ci;
 +	blk_qc_t ret = BLK_QC_T_NONE;
  	int error = 0;
  
  	init_clone_info(&ci, md, map, bio);
@@@ -1628,15 -1432,15 +1633,20 @@@
  	} else {
  		ci.bio = bio;
  		ci.sector_count = bio_sectors(bio);
- 		error = __split_and_process_non_flush(&ci);
+ 		error = __split_and_process_bio(&ci);
  		if (ci.sector_count && !error) {
  			/*
 -			 * Remainder must be passed to submit_bio_noacct()
 +			 * Remainder must be passed to generic_make_request()
  			 * so that it gets handled *after* bios already submitted
  			 * have been completely processed.
  			 * We take a clone of the original to store in
++<<<<<<< HEAD
 +			 * ci.io->orig_bio to be used by end_io_acct() and
 +			 * for dec_pending to use for completion handling.
++=======
+ 			 * ci.io->orig_bio to be used by dm_end_io_acct() and for
+ 			 * dm_io_dec_pending() to use for completion handling.
++>>>>>>> 96c9865cb6dd (dm: rename split functions)
  			 */
  			struct bio *b = bio_split(bio, bio_sectors(bio) - ci.sector_count,
  						  GFP_NOIO, &md->queue->bio_split);
@@@ -1685,37 -1487,11 +1695,41 @@@ static blk_qc_t dm_make_request(struct 
  	 * otherwise associated queue_limits won't be imposed.
  	 */
  	if (is_abnormal_io(bio))
 -		blk_queue_split(&bio);
 +		blk_queue_split(md->queue, &bio);
  
++<<<<<<< HEAD
 +	ret = __split_and_process_bio(md, map, bio);
++=======
+ 	dm_split_and_process_bio(md, map, bio);
++>>>>>>> 96c9865cb6dd (dm: rename split functions)
  out:
  	dm_put_live_table(md, srcu_idx);
 +	return ret;
 +}
 +
 +static int dm_any_congested(void *congested_data, int bdi_bits)
 +{
 +	int r = bdi_bits;
 +	struct mapped_device *md = congested_data;
 +	struct dm_table *map;
 +
 +	if (!test_bit(DMF_BLOCK_IO_FOR_SUSPEND, &md->flags)) {
 +		if (dm_request_based(md)) {
 +			/*
 +			 * With request-based DM we only need to check the
 +			 * top-level queue for congestion.
 +			 */
 +			struct backing_dev_info *bdi = md->queue->backing_dev_info;
 +			r = bdi->wb.congested->state & bdi_bits;
 +		} else {
 +			map = dm_get_live_table_fast(md);
 +			if (map)
 +				r = dm_table_any_congested(map, bdi_bits);
 +			dm_put_live_table_fast(md);
 +		}
 +	}
 +
 +	return r;
  }
  
  /*-----------------------------------------------------------------
@@@ -2537,11 -2310,11 +2551,19 @@@ static int __dm_suspend(struct mapped_d
  	/*
  	 * Here we must make sure that no processes are submitting requests
  	 * to target drivers i.e. no one may be executing
++<<<<<<< HEAD
 +	 * __split_and_process_bio from dm_make_request.
 +	 *
 +	 * To get all processes out of __split_and_process_bio in dm_make_request,
 +	 * we take the write lock. To prevent any process from reentering
 +	 * __split_and_process_bio from dm_make_request and quiesce the thread
++=======
+ 	 * dm_split_and_process_bio from dm_submit_bio.
+ 	 *
+ 	 * To get all processes out of dm_split_and_process_bio in dm_submit_bio,
+ 	 * we take the write lock. To prevent any process from reentering
+ 	 * dm_split_and_process_bio from dm_submit_bio and quiesce the thread
++>>>>>>> 96c9865cb6dd (dm: rename split functions)
  	 * (dm_wq_work), we set DMF_BLOCK_IO_FOR_SUSPEND and call
  	 * flush_workqueue(md->wq).
  	 */
* Unmerged path drivers/md/dm.c
