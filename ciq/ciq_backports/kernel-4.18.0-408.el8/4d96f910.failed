x86/sev: Replace occurrences of sev_active() with cc_platform_has()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Tom Lendacky <thomas.lendacky@amd.com>
commit 4d96f9109109be93618050a50cabb8df7c931ba7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/4d96f910.failed

Replace uses of sev_active() with the more generic cc_platform_has()
using CC_ATTR_GUEST_MEM_ENCRYPT. If future support is added for other
memory encryption technologies, the use of CC_ATTR_GUEST_MEM_ENCRYPT
can be updated, as required.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20210928191009.32551-7-bp@alien8.de
(cherry picked from commit 4d96f9109109be93618050a50cabb8df7c931ba7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mem_encrypt.h
#	arch/x86/mm/mem_encrypt.c
diff --cc arch/x86/include/asm/mem_encrypt.h
index fd679b0543a3,a5a58ccd1ee3..000000000000
--- a/arch/x86/include/asm/mem_encrypt.h
+++ b/arch/x86/include/asm/mem_encrypt.h
@@@ -47,16 -45,15 +47,19 @@@ void __init sme_enable(struct boot_para
  int __init early_set_memory_decrypted(unsigned long vaddr, unsigned long size);
  int __init early_set_memory_encrypted(unsigned long vaddr, unsigned long size);
  
 -void __init mem_encrypt_free_decrypted_mem(void);
 -
  /* Architecture __weak replacement functions */
  void __init mem_encrypt_init(void);
 +void __init mem_encrypt_free_decrypted_mem(void);
  
  void __init sev_es_init_vc_handling(void);
++<<<<<<< HEAD
 +bool sme_active(void);
 +bool sev_active(void);
++=======
++>>>>>>> 4d96f9109109 (x86/sev: Replace occurrences of sev_active() with cc_platform_has())
  bool sev_es_active(void);
  
 -#define __bss_decrypted __section(".bss..decrypted")
 +#define __bss_decrypted __attribute__((__section__(".bss..decrypted")))
  
  #else	/* !CONFIG_AMD_MEM_ENCRYPT */
  
@@@ -77,8 -74,6 +80,11 @@@ static inline void __init sme_encrypt_k
  static inline void __init sme_enable(struct boot_params *bp) { }
  
  static inline void sev_es_init_vc_handling(void) { }
++<<<<<<< HEAD
 +static inline bool sme_active(void) { return false; }
 +static inline bool sev_active(void) { return false; }
++=======
++>>>>>>> 4d96f9109109 (x86/sev: Replace occurrences of sev_active() with cc_platform_has())
  static inline bool sev_es_active(void) { return false; }
  
  static inline int __init
diff --cc arch/x86/mm/mem_encrypt.c
index d16a12ec26d9,932007a6913b..000000000000
--- a/arch/x86/mm/mem_encrypt.c
+++ b/arch/x86/mm/mem_encrypt.c
@@@ -374,17 -373,6 +374,20 @@@ int __init early_set_memory_encrypted(u
   * up under SME the trampoline area cannot be encrypted, whereas under SEV
   * the trampoline area must be encrypted.
   */
++<<<<<<< HEAD
 +bool sev_active(void)
 +{
 +	return sev_status & MSR_AMD64_SEV_ENABLED;
 +}
 +EXPORT_SYMBOL(sme_active);
 +
 +bool sme_active(void)
 +{
 +	return sme_me_mask && !sev_active();
 +}
 +EXPORT_SYMBOL_GPL(sev_active);
++=======
++>>>>>>> 4d96f9109109 (x86/sev: Replace occurrences of sev_active() with cc_platform_has())
  
  /* Needs to be called from non-instrumentable code */
  bool noinstr sev_es_active(void)
@@@ -486,3 -474,8 +489,11 @@@ void __init mem_encrypt_init(void
  	print_mem_encrypt_feature_info();
  }
  
++<<<<<<< HEAD
++=======
+ int arch_has_restricted_virtio_memory_access(void)
+ {
+ 	return cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT);
+ }
+ EXPORT_SYMBOL_GPL(arch_has_restricted_virtio_memory_access);
++>>>>>>> 4d96f9109109 (x86/sev: Replace occurrences of sev_active() with cc_platform_has())
* Unmerged path arch/x86/include/asm/mem_encrypt.h
diff --git a/arch/x86/kernel/crash_dump_64.c b/arch/x86/kernel/crash_dump_64.c
index b398885c31ff..7d74a47433f2 100644
--- a/arch/x86/kernel/crash_dump_64.c
+++ b/arch/x86/kernel/crash_dump_64.c
@@ -10,6 +10,7 @@
 #include <linux/crash_dump.h>
 #include <linux/uaccess.h>
 #include <linux/io.h>
+#include <linux/cc_platform.h>
 
 static ssize_t __copy_oldmem_page(unsigned long pfn, char *buf, size_t csize,
 				  unsigned long offset, int userbuf,
@@ -73,5 +74,6 @@ ssize_t copy_oldmem_page_encrypted(unsigned long pfn, char *buf, size_t csize,
 
 ssize_t elfcorehdr_read(char *buf, size_t count, u64 *ppos)
 {
-	return read_from_oldmem(buf, count, ppos, 0, sev_active());
+	return read_from_oldmem(buf, count, ppos, 0,
+				cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT));
 }
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index 15c68597108b..ae6426fd59d9 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -39,6 +39,7 @@
 #include <linux/nmi.h>
 #include <linux/swait.h>
 #include <linux/syscore_ops.h>
+#include <linux/cc_platform.h>
 #include <asm/timer.h>
 #include <asm/cpu.h>
 #include <asm/traps.h>
@@ -428,7 +429,7 @@ static void __init sev_map_percpu_data(void)
 {
 	int cpu;
 
-	if (!sev_active())
+	if (!cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 		return;
 
 	for_each_possible_cpu(cpu) {
diff --git a/arch/x86/kernel/kvmclock.c b/arch/x86/kernel/kvmclock.c
index f7b0f58b457e..dca1c6fe9d77 100644
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@ -16,9 +16,9 @@
 #include <linux/mm.h>
 #include <linux/slab.h>
 #include <linux/set_memory.h>
+#include <linux/cc_platform.h>
 
 #include <asm/hypervisor.h>
-#include <asm/mem_encrypt.h>
 #include <asm/x86_init.h>
 #include <asm/kvmclock.h>
 
@@ -223,7 +223,7 @@ static void __init kvmclock_init_mem(void)
 	 * hvclock is shared between the guest and the hypervisor, must
 	 * be mapped decrypted.
 	 */
-	if (sev_active()) {
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT)) {
 		r = set_memory_decrypted((unsigned long) hvclock_mem,
 					 1UL << order);
 		if (r) {
diff --git a/arch/x86/kernel/machine_kexec_64.c b/arch/x86/kernel/machine_kexec_64.c
index 19a506dce5e6..e33c167710aa 100644
--- a/arch/x86/kernel/machine_kexec_64.c
+++ b/arch/x86/kernel/machine_kexec_64.c
@@ -169,7 +169,7 @@ static int init_transition_pgtable(struct kimage *image, pgd_t *pgd)
 	}
 	pte = pte_offset_kernel(pmd, vaddr);
 
-	if (sev_active())
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 		prot = PAGE_KERNEL_EXEC;
 
 	set_pte(pte, pfn_pte(paddr >> PAGE_SHIFT, prot));
@@ -209,7 +209,7 @@ static int init_pgtable(struct kimage *image, unsigned long start_pgtable)
 	level4p = (pgd_t *)__va(start_pgtable);
 	clear_page(level4p);
 
-	if (sev_active()) {
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT)) {
 		info.page_flag   |= _PAGE_ENC;
 		info.kernpg_flag |= _PAGE_ENC;
 	}
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 0ab1b5b9b96a..e2bc2ab5b439 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -25,6 +25,7 @@
 #include <linux/pagemap.h>
 #include <linux/swap.h>
 #include <linux/rwsem.h>
+#include <linux/cc_platform.h>
 
 #include <asm/apic.h>
 #include <asm/perf_event.h>
@@ -459,7 +460,7 @@ static int has_svm(void)
 		return 0;
 	}
 
-	if (sev_active()) {
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT)) {
 		pr_info("KVM is unsupported when running as an SEV guest\n");
 		return 0;
 	}
diff --git a/arch/x86/mm/ioremap.c b/arch/x86/mm/ioremap.c
index 6c1b63b0fd16..db30be26c61f 100644
--- a/arch/x86/mm/ioremap.c
+++ b/arch/x86/mm/ioremap.c
@@ -91,7 +91,7 @@ static unsigned int __ioremap_check_ram(struct resource *res)
  */
 static unsigned int __ioremap_check_encrypted(struct resource *res)
 {
-	if (!sev_active())
+	if (!cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 		return 0;
 
 	switch (res->desc) {
@@ -111,7 +111,7 @@ static unsigned int __ioremap_check_encrypted(struct resource *res)
  */
 static void __ioremap_check_other(resource_size_t addr, struct ioremap_desc *desc)
 {
-	if (!sev_active())
+	if (!cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 		return;
 
 	if (!IS_ENABLED(CONFIG_EFI))
@@ -566,7 +566,7 @@ static bool memremap_should_map_decrypted(resource_size_t phys_addr,
 	case E820_TYPE_NVS:
 	case E820_TYPE_UNUSABLE:
 		/* For SEV, these areas are encrypted */
-		if (sev_active())
+		if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 			break;
 		/* Fallthrough */
 
* Unmerged path arch/x86/mm/mem_encrypt.c
diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c
index 198f41d744ef..09c2559c0206 100644
--- a/arch/x86/platform/efi/efi_64.c
+++ b/arch/x86/platform/efi/efi_64.c
@@ -33,7 +33,7 @@
 #include <linux/reboot.h>
 #include <linux/slab.h>
 #include <linux/ucs2_string.h>
-#include <linux/mem_encrypt.h>
+#include <linux/cc_platform.h>
 #include <linux/sched/task.h>
 
 #include <asm/setup.h>
@@ -278,7 +278,8 @@ static void __init __map_region(efi_memory_desc_t *md, u64 va)
 	if (!(md->attribute & EFI_MEMORY_WB))
 		flags |= _PAGE_PCD;
 
-	if (sev_active() && md->type != EFI_MEMORY_MAPPED_IO)
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT) &&
+	    md->type != EFI_MEMORY_MAPPED_IO)
 		flags |= _PAGE_ENC;
 
 	pfn = md->phys_addr >> PAGE_SHIFT;
@@ -384,7 +385,7 @@ static int __init efi_update_mem_attr(struct mm_struct *mm, efi_memory_desc_t *m
 	if (!(md->attribute & EFI_MEMORY_RO))
 		pf |= _PAGE_RW;
 
-	if (sev_active())
+	if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 		pf |= _PAGE_ENC;
 
 	return efi_update_mappings(md, pf);
@@ -432,7 +433,7 @@ void __init efi_runtime_update_mappings(void)
 			(md->type != EFI_RUNTIME_SERVICES_CODE))
 			pf |= _PAGE_RW;
 
-		if (sev_active())
+		if (cc_platform_has(CC_ATTR_GUEST_MEM_ENCRYPT))
 			pf |= _PAGE_ENC;
 
 		efi_update_mappings(md, pf);
