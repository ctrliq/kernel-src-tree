KVM: x86/mmu: WARN on any attempt to atomically update REMOVED SPTE

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit 396fd74d61343aaa4c30a7eb67132b7ef5762744
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/396fd74d.failed

Disallow calling tdp_mmu_set_spte_atomic() with a REMOVED "old" SPTE.
This solves a conundrum introduced by commit 3255530ab191 ("KVM: x86/mmu:
Automatically update iter->old_spte if cmpxchg fails"); if the helper
doesn't update old_spte in the REMOVED case, then theoretically the
caller could get stuck in an infinite loop as it will fail indefinitely
on the REMOVED SPTE.  E.g. until recently, clear_dirty_gfn_range() didn't
check for a present SPTE and would have spun until getting rescheduled.

In practice, only the page fault path should "create" a new SPTE, all
other paths should only operate on existing, a.k.a. shadow present,
SPTEs.  Now that the page fault path pre-checks for a REMOVED SPTE in all
cases, require all other paths to indirectly pre-check by verifying the
target SPTE is a shadow-present SPTE.

Note, this does not guarantee the actual SPTE isn't REMOVED, nor is that
scenario disallowed.  The invariant is only that the caller mustn't
invoke tdp_mmu_set_spte_atomic() if the SPTE was REMOVED when last
observed by the caller.

	Cc: David Matlack <dmatlack@google.com>
	Signed-off-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20220226001546.360188-25-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 396fd74d61343aaa4c30a7eb67132b7ef5762744)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/tdp_mmu.c
diff --cc arch/x86/kvm/mmu/tdp_mmu.c
index 97bb57fe39ca,af60922906ef..000000000000
--- a/arch/x86/kvm/mmu/tdp_mmu.c
+++ b/arch/x86/kvm/mmu/tdp_mmu.c
@@@ -507,25 -599,30 +507,41 @@@ static void handle_changed_spte(struct 
   * @kvm: kvm instance
   * @iter: a tdp_iter instance currently on the SPTE that should be set
   * @new_spte: The value the SPTE should be set to
 - * Return:
 - * * 0      - If the SPTE was set.
 - * * -EBUSY - If the SPTE cannot be set. In this case this function will have
 - *            no side-effects other than setting iter->old_spte to the last
 - *            known value of the spte.
 + * Returns: true if the SPTE was set, false if it was not. If false is returned,
 + *	    this function will have no side-effects.
   */
 -static inline int tdp_mmu_set_spte_atomic(struct kvm *kvm,
 -					  struct tdp_iter *iter,
 -					  u64 new_spte)
 +static inline bool tdp_mmu_set_spte_atomic(struct kvm *kvm,
 +					   struct tdp_iter *iter,
 +					   u64 new_spte)
  {
++<<<<<<< HEAD
 +	WARN_ON_ONCE(iter->yielded);
++=======
+ 	u64 *sptep = rcu_dereference(iter->sptep);
+ 	u64 old_spte;
+ 
+ 	/*
+ 	 * The caller is responsible for ensuring the old SPTE is not a REMOVED
+ 	 * SPTE.  KVM should never attempt to zap or manipulate a REMOVED SPTE,
+ 	 * and pre-checking before inserting a new SPTE is advantageous as it
+ 	 * avoids unnecessary work.
+ 	 */
+ 	WARN_ON_ONCE(iter->yielded || is_removed_spte(iter->old_spte));
++>>>>>>> 396fd74d6134 (KVM: x86/mmu: WARN on any attempt to atomically update REMOVED SPTE)
  
  	lockdep_assert_held_read(&kvm->mmu_lock);
  
  	/*
++<<<<<<< HEAD
 +	 * Do not change removed SPTEs. Only the thread that froze the SPTE
 +	 * may modify it.
 +	 */
 +	if (is_removed_spte(iter->old_spte))
 +		return false;
 +
 +	/*
++=======
++>>>>>>> 396fd74d6134 (KVM: x86/mmu: WARN on any attempt to atomically update REMOVED SPTE)
  	 * Note, fast_pf_fix_direct_spte() can also modify TDP MMU SPTEs and
  	 * does not hold the mmu_lock.
  	 */
* Unmerged path arch/x86/kvm/mmu/tdp_mmu.c
