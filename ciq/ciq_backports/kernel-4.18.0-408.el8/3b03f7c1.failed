dm: simplify dm_start_io_acct

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Mike Snitzer <snitzer@kernel.org>
commit 3b03f7c1242c754f0c474b37eec7d79107b9f375
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/3b03f7c1.failed

Pull common DM_IO_ACCOUNTED check out to beginning of dm_start_io_acct.
Also, use dm_tio_is_normal (and move it to dm-core.h).

	Signed-off-by: Mike Snitzer <snitzer@kernel.org>
(cherry picked from commit 3b03f7c1242c754f0c474b37eec7d79107b9f375)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-core.h
#	drivers/md/dm.c
diff --cc drivers/md/dm-core.h
index a9c78c74b3c7,db069fa9cee5..000000000000
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@@ -207,6 -220,30 +207,33 @@@ struct dm_target_io 
  };
  
  /*
++<<<<<<< HEAD
++=======
+  * dm_target_io flags
+  */
+ enum {
+ 	DM_TIO_INSIDE_DM_IO,
+ 	DM_TIO_IS_DUPLICATE_BIO
+ };
+ 
+ static inline bool dm_tio_flagged(struct dm_target_io *tio, unsigned int bit)
+ {
+ 	return (tio->flags & (1U << bit)) != 0;
+ }
+ 
+ static inline void dm_tio_set_flag(struct dm_target_io *tio, unsigned int bit)
+ {
+ 	tio->flags |= (1U << bit);
+ }
+ 
+ static inline bool dm_tio_is_normal(struct dm_target_io *tio)
+ {
+ 	return (dm_tio_flagged(tio, DM_TIO_INSIDE_DM_IO) &&
+ 		!dm_tio_flagged(tio, DM_TIO_IS_DUPLICATE_BIO));
+ }
+ 
+ /*
++>>>>>>> 3b03f7c1242c (dm: simplify dm_start_io_acct)
   * One of these is allocated per original bio.
   * It contains the first clone used for that original.
   */
diff --cc drivers/md/dm.c
index e7cb1b8972bd,e6b6fe03dbcf..000000000000
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@@ -584,15 -526,39 +584,44 @@@ static void dm_io_acct(bool end, struc
  		bio->bi_iter.bi_size = bi_size;
  }
  
 -static void __dm_start_io_acct(struct dm_io *io, struct bio *bio)
 +static void start_io_acct(struct dm_io *io)
  {
 -	dm_io_acct(false, io->md, bio, io->start_time, &io->stats_aux);
 +	dm_io_acct(false, io->md, io->orig_bio, io->start_time, &io->stats_aux);
  }
  
 -static void dm_start_io_acct(struct dm_io *io, struct bio *clone)
 +static void end_io_acct(struct mapped_device *md, struct bio *bio,
 +			unsigned long start_time, struct dm_stats_aux *stats_aux)
  {
++<<<<<<< HEAD
 +	dm_io_acct(true, md, bio, start_time, stats_aux);
++=======
+ 	/* Must account IO to DM device in terms of orig_bio */
+ 	struct bio *bio = io->orig_bio;
+ 
+ 	/*
+ 	 * Ensure IO accounting is only ever started once.
+ 	 */
+ 	if (dm_io_flagged(io, DM_IO_ACCOUNTED))
+ 		return;
+ 
+ 	/* Expect no possibility for race unless DM_TIO_IS_DUPLICATE_BIO. */
+ 	if (!clone || likely(dm_tio_is_normal(clone_to_tio(clone)))) {
+ 		dm_io_set_flag(io, DM_IO_ACCOUNTED);
+ 	} else {
+ 		unsigned long flags;
+ 		/* Can afford locking given DM_TIO_IS_DUPLICATE_BIO */
+ 		spin_lock_irqsave(&io->lock, flags);
+ 		dm_io_set_flag(io, DM_IO_ACCOUNTED);
+ 		spin_unlock_irqrestore(&io->lock, flags);
+ 	}
+ 
+ 	__dm_start_io_acct(io, bio);
+ }
+ 
+ static void dm_end_io_acct(struct dm_io *io, struct bio *bio)
+ {
+ 	dm_io_acct(true, io->md, bio, io->start_time, &io->stats_aux);
++>>>>>>> 3b03f7c1242c (dm: simplify dm_start_io_acct)
  }
  
  static struct dm_io *alloc_io(struct mapped_device *md, struct bio *bio)
@@@ -866,6 -845,82 +895,85 @@@ static int __noflush_suspending(struct 
  	return test_bit(DMF_NOFLUSH_SUSPENDING, &md->flags);
  }
  
++<<<<<<< HEAD
++=======
+ static void dm_io_complete(struct dm_io *io)
+ {
+ 	blk_status_t io_error;
+ 	struct mapped_device *md = io->md;
+ 	struct bio *bio = io->orig_bio;
+ 
+ 	if (io->status == BLK_STS_DM_REQUEUE) {
+ 		unsigned long flags;
+ 		/*
+ 		 * Target requested pushing back the I/O.
+ 		 */
+ 		spin_lock_irqsave(&md->deferred_lock, flags);
+ 		if (__noflush_suspending(md) &&
+ 		    !WARN_ON_ONCE(dm_is_zone_write(md, bio))) {
+ 			/* NOTE early return due to BLK_STS_DM_REQUEUE below */
+ 			bio_list_add_head(&md->deferred, bio);
+ 		} else {
+ 			/*
+ 			 * noflush suspend was interrupted or this is
+ 			 * a write to a zoned target.
+ 			 */
+ 			io->status = BLK_STS_IOERR;
+ 		}
+ 		spin_unlock_irqrestore(&md->deferred_lock, flags);
+ 	}
+ 
+ 	io_error = io->status;
+ 	if (dm_io_flagged(io, DM_IO_ACCOUNTED))
+ 		dm_end_io_acct(io, bio);
+ 	else if (!io_error) {
+ 		/*
+ 		 * Must handle target that DM_MAPIO_SUBMITTED only to
+ 		 * then bio_endio() rather than dm_submit_bio_remap()
+ 		 */
+ 		__dm_start_io_acct(io, bio);
+ 		dm_end_io_acct(io, bio);
+ 	}
+ 	free_io(io);
+ 	smp_wmb();
+ 	this_cpu_dec(*md->pending_io);
+ 
+ 	/* nudge anyone waiting on suspend queue */
+ 	if (unlikely(wq_has_sleeper(&md->wait)))
+ 		wake_up(&md->wait);
+ 
+ 	if (io_error == BLK_STS_DM_REQUEUE || io_error == BLK_STS_AGAIN) {
+ 		if (bio->bi_opf & REQ_POLLED) {
+ 			/*
+ 			 * Upper layer won't help us poll split bio (io->orig_bio
+ 			 * may only reflect a subset of the pre-split original)
+ 			 * so clear REQ_POLLED in case of requeue.
+ 			 */
+ 			bio_clear_polled(bio);
+ 			if (io_error == BLK_STS_AGAIN) {
+ 				/* io_uring doesn't handle BLK_STS_AGAIN (yet) */
+ 				queue_io(md, bio);
+ 			}
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (bio_is_flush_with_data(bio)) {
+ 		/*
+ 		 * Preflush done for flush with data, reissue
+ 		 * without REQ_PREFLUSH.
+ 		 */
+ 		bio->bi_opf &= ~REQ_PREFLUSH;
+ 		queue_io(md, bio);
+ 	} else {
+ 		/* done with normal IO or empty flush */
+ 		if (io_error)
+ 			bio->bi_status = io_error;
+ 		bio_endio(bio);
+ 	}
+ }
+ 
++>>>>>>> 3b03f7c1242c (dm: simplify dm_start_io_acct)
  /*
   * Decrements the number of outstanding ios that a bio has been
   * cloned into, completing the original io if necc.
* Unmerged path drivers/md/dm-core.h
* Unmerged path drivers/md/dm.c
