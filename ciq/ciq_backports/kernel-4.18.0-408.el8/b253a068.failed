tcp: ensure to use the most recently sent skb when filling the rate sample

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Pengcheng Yang <yangpc@wangsu.com>
commit b253a0680ceadc5d7b4acca7aa2d870326cad8ad
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/b253a068.failed

If an ACK (s)acks multiple skbs, we favor the information
from the most recently sent skb by choosing the skb with
the highest prior_delivered count. But in the interval
between receiving ACKs, we send multiple skbs with the same
prior_delivered, because the tp->delivered only changes
when we receive an ACK.

We used RACK's solution, copying tcp_rack_sent_after() as
tcp_skb_sent_after() helper to determine "which packet was
sent last?". Later, we will use tcp_skb_sent_after() instead
in RACK.

Fixes: b9f64820fb22 ("tcp: track data delivery rate for a TCP connection")
	Signed-off-by: Pengcheng Yang <yangpc@wangsu.com>
	Cc: Paolo Abeni <pabeni@redhat.com>
	Acked-by: Neal Cardwell <ncardwell@google.com>
	Tested-by: Neal Cardwell <ncardwell@google.com>
	Reviewed-by: Eric Dumazet <edumazet@google.com>
Link: https://lore.kernel.org/r/1650422081-22153-1-git-send-email-yangpc@wangsu.com
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit b253a0680ceadc5d7b4acca7aa2d870326cad8ad)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/tcp_rate.c
diff --cc net/ipv4/tcp_rate.c
index e917abbd9834,9a8e014d9b5b..000000000000
--- a/net/ipv4/tcp_rate.c
+++ b/net/ipv4/tcp_rate.c
@@@ -83,8 -87,11 +85,15 @@@ void tcp_rate_skb_delivered(struct soc
  	if (!scb->tx.delivered_mstamp)
  		return;
  
+ 	tx_tstamp = tcp_skb_timestamp_us(skb);
  	if (!rs->prior_delivered ||
++<<<<<<< HEAD
 +	    after(scb->tx.delivered, rs->prior_delivered)) {
++=======
+ 	    tcp_skb_sent_after(tx_tstamp, tp->first_tx_mstamp,
+ 			       scb->end_seq, rs->last_end_seq)) {
+ 		rs->prior_delivered_ce  = scb->tx.delivered_ce;
++>>>>>>> b253a0680cea (tcp: ensure to use the most recently sent skb when filling the rate sample)
  		rs->prior_delivered  = scb->tx.delivered;
  		rs->prior_mstamp     = scb->tx.delivered_mstamp;
  		rs->is_app_limited   = scb->tx.is_app_limited;
diff --git a/include/net/tcp.h b/include/net/tcp.h
index 02171d34f0f6..d7b7462069b5 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -1038,6 +1038,7 @@ struct rate_sample {
 	int  losses;		/* number of packets marked lost upon ACK */
 	u32  acked_sacked;	/* number of packets newly (S)ACKed upon ACK */
 	u32  prior_in_flight;	/* in flight before this ACK */
+	u32  last_end_seq;	/* end_seq of most recently ACKed packet */
 	bool is_app_limited;	/* is sample from packet with bubble in pipe? */
 	bool is_retrans;	/* is sample from retransmission? */
 	bool is_ack_delayed;	/* is this (likely) a delayed ACK? */
@@ -1148,6 +1149,11 @@ void tcp_rate_gen(struct sock *sk, u32 delivered, u32 lost,
 		  bool is_sack_reneg, struct rate_sample *rs);
 void tcp_rate_check_app_limited(struct sock *sk);
 
+static inline bool tcp_skb_sent_after(u64 t1, u64 t2, u32 seq1, u32 seq2)
+{
+	return t1 > t2 || (t1 == t2 && after(seq1, seq2));
+}
+
 /* These functions determine how the current flow behaves in respect of SACK
  * handling. SACK is negotiated with the peer, and therefore it can vary
  * between different flows.
* Unmerged path net/ipv4/tcp_rate.c
