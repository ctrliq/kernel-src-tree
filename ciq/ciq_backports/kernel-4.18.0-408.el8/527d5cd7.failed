KVM: x86/mmu: Zap only obsolete roots if a root shadow page is zapped

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit 527d5cd7eece9f9f5e9c5b6692cd6814a46df6fe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/527d5cd7.failed

Zap only obsolete roots when responding to zapping a single root shadow
page.  Because KVM keeps root_count elevated when stuffing a previous
root into its PGD cache, shadowing a 64-bit guest means that zapping any
root causes all vCPUs to reload all roots, even if their current root is
not affected by the zap.

For many kernels, zapping a single root is a frequent operation, e.g. in
Linux it happens whenever an mm is dropped, e.g. process exits, etc...

	Signed-off-by: Sean Christopherson <seanjc@google.com>
	Reviewed-by: Ben Gardon <bgardon@google.com>
Message-Id: <20220225182248.3812651-5-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 527d5cd7eece9f9f5e9c5b6692cd6814a46df6fe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
diff --cc arch/x86/kvm/mmu/mmu.c
index 501d35b7ab20,825996408465..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -3931,6 -3932,34 +3937,37 @@@ out_retry
  	return true;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Returns true if the page fault is stale and needs to be retried, i.e. if the
+  * root was invalidated by a memslot update or a relevant mmu_notifier fired.
+  */
+ static bool is_page_fault_stale(struct kvm_vcpu *vcpu,
+ 				struct kvm_page_fault *fault, int mmu_seq)
+ {
+ 	struct kvm_mmu_page *sp = to_shadow_page(vcpu->arch.mmu->root.hpa);
+ 
+ 	/* Special roots, e.g. pae_root, are not backed by shadow pages. */
+ 	if (sp && is_obsolete_sp(vcpu->kvm, sp))
+ 		return true;
+ 
+ 	/*
+ 	 * Roots without an associated shadow page are considered invalid if
+ 	 * there is a pending request to free obsolete roots.  The request is
+ 	 * only a hint that the current root _may_ be obsolete and needs to be
+ 	 * reloaded, e.g. if the guest frees a PGD that KVM is tracking as a
+ 	 * previous root, then __kvm_mmu_prepare_zap_page() signals all vCPUs
+ 	 * to reload even if no vCPU is actively using the root.
+ 	 */
+ 	if (!sp && kvm_test_request(KVM_REQ_MMU_FREE_OBSOLETE_ROOTS, vcpu))
+ 		return true;
+ 
+ 	return fault->slot &&
+ 	       mmu_notifier_retry_hva(vcpu->kvm, mmu_seq, fault->hva);
+ }
+ 
++>>>>>>> 527d5cd7eece (KVM: x86/mmu: Zap only obsolete roots if a root shadow page is zapped)
  static int direct_page_fault(struct kvm_vcpu *vcpu, struct kvm_page_fault *fault)
  {
  	bool is_tdp_mmu_fault = is_tdp_mmu(vcpu->arch.mmu);
@@@ -5045,12 -5082,60 +5082,57 @@@ out
  
  void kvm_mmu_unload(struct kvm_vcpu *vcpu)
  {
 -	struct kvm *kvm = vcpu->kvm;
 -
 -	kvm_mmu_free_roots(kvm, &vcpu->arch.root_mmu, KVM_MMU_ROOTS_ALL);
 -	WARN_ON(VALID_PAGE(vcpu->arch.root_mmu.root.hpa));
 -	kvm_mmu_free_roots(kvm, &vcpu->arch.guest_mmu, KVM_MMU_ROOTS_ALL);
 -	WARN_ON(VALID_PAGE(vcpu->arch.guest_mmu.root.hpa));
 -	vcpu_clear_mmio_info(vcpu, MMIO_GVA_ANY);
 +	kvm_mmu_free_roots(vcpu, &vcpu->arch.root_mmu, KVM_MMU_ROOTS_ALL);
 +	WARN_ON(VALID_PAGE(vcpu->arch.root_mmu.root_hpa));
 +	kvm_mmu_free_roots(vcpu, &vcpu->arch.guest_mmu, KVM_MMU_ROOTS_ALL);
 +	WARN_ON(VALID_PAGE(vcpu->arch.guest_mmu.root_hpa));
  }
  
+ static bool is_obsolete_root(struct kvm *kvm, hpa_t root_hpa)
+ {
+ 	struct kvm_mmu_page *sp;
+ 
+ 	if (!VALID_PAGE(root_hpa))
+ 		return false;
+ 
+ 	/*
+ 	 * When freeing obsolete roots, treat roots as obsolete if they don't
+ 	 * have an associated shadow page.  This does mean KVM will get false
+ 	 * positives and free roots that don't strictly need to be freed, but
+ 	 * such false positives are relatively rare:
+ 	 *
+ 	 *  (a) only PAE paging and nested NPT has roots without shadow pages
+ 	 *  (b) remote reloads due to a memslot update obsoletes _all_ roots
+ 	 *  (c) KVM doesn't track previous roots for PAE paging, and the guest
+ 	 *      is unlikely to zap an in-use PGD.
+ 	 */
+ 	sp = to_shadow_page(root_hpa);
+ 	return !sp || is_obsolete_sp(kvm, sp);
+ }
+ 
+ static void __kvm_mmu_free_obsolete_roots(struct kvm *kvm, struct kvm_mmu *mmu)
+ {
+ 	unsigned long roots_to_free = 0;
+ 	int i;
+ 
+ 	if (is_obsolete_root(kvm, mmu->root.hpa))
+ 		roots_to_free |= KVM_MMU_ROOT_CURRENT;
+ 
+ 	for (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {
+ 		if (is_obsolete_root(kvm, mmu->root.hpa))
+ 			roots_to_free |= KVM_MMU_ROOT_PREVIOUS(i);
+ 	}
+ 
+ 	if (roots_to_free)
+ 		kvm_mmu_free_roots(kvm, mmu, roots_to_free);
+ }
+ 
+ void kvm_mmu_free_obsolete_roots(struct kvm_vcpu *vcpu)
+ {
+ 	__kvm_mmu_free_obsolete_roots(vcpu->kvm, &vcpu->arch.root_mmu);
+ 	__kvm_mmu_free_obsolete_roots(vcpu->kvm, &vcpu->arch.guest_mmu);
+ }
+ 
  static bool need_remote_flush(u64 old, u64 new)
  {
  	if (!is_shadow_present_pte(old))
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 96ecf6f2c1a5..eb3f04eaae01 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -95,6 +95,8 @@
 #define KVM_REQ_MSR_FILTER_CHANGED	KVM_ARCH_REQ(29)
 #define KVM_REQ_UPDATE_CPU_DIRTY_LOGGING \
 	KVM_ARCH_REQ_FLAGS(30, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+#define KVM_REQ_MMU_FREE_OBSOLETE_ROOTS \
+	KVM_ARCH_REQ_FLAGS(31, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
 
 #define CR0_RESERVED_BITS                                               \
 	(~(unsigned long)(X86_CR0_PE | X86_CR0_MP | X86_CR0_EM | X86_CR0_TS \
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index c605a3c2b84d..144bfc709948 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -80,6 +80,7 @@ int kvm_handle_page_fault(struct kvm_vcpu *vcpu, u64 error_code,
 
 int kvm_mmu_load(struct kvm_vcpu *vcpu);
 void kvm_mmu_unload(struct kvm_vcpu *vcpu);
+void kvm_mmu_free_obsolete_roots(struct kvm_vcpu *vcpu);
 void kvm_mmu_sync_roots(struct kvm_vcpu *vcpu);
 void kvm_mmu_sync_prev_roots(struct kvm_vcpu *vcpu);
 
* Unmerged path arch/x86/kvm/mmu/mmu.c
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index cb917ed70ca0..5e41719013b4 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -9848,8 +9848,8 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 				goto out;
 			}
 		}
-		if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
-			kvm_mmu_unload(vcpu);
+		if (kvm_check_request(KVM_REQ_MMU_FREE_OBSOLETE_ROOTS, vcpu))
+			kvm_mmu_free_obsolete_roots(vcpu);
 		if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))
 			__kvm_migrate_timers(vcpu);
 		if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
