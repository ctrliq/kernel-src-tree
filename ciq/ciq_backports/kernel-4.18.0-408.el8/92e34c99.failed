KVM: selftests: Use perf util's per-vCPU GPA/pages in demand paging test

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Sean Christopherson <seanjc@google.com>
commit 92e34c9974f55519bc0c3386221aadf387162ea6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/92e34c99.failed

Grab the per-vCPU GPA and number of pages from perf_util in the demand
paging test instead of duplicating perf_util's calculations.

Note, this may or may not result in a functional change.  It's not clear
that the test's calculations are guaranteed to yield the same value as
perf_util, e.g. if guest_percpu_mem_size != vcpu_args->pages.

	Signed-off-by: Sean Christopherson <seanjc@google.com>
	Reviewed-by: Ben Gardon <bgardon@google.com>
	Signed-off-by: David Matlack <dmatlack@google.com>
Message-Id: <20211111000310.1435032-8-dmatlack@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 92e34c9974f55519bc0c3386221aadf387162ea6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/testing/selftests/kvm/demand_paging_test.c
diff --cc tools/testing/selftests/kvm/demand_paging_test.c
index 52bd44288de9,3c729a0a1ab1..000000000000
--- a/tools/testing/selftests/kvm/demand_paging_test.c
+++ b/tools/testing/selftests/kvm/demand_paging_test.c
@@@ -286,24 -322,15 +286,24 @@@ static void run_test(enum vm_guest_mod
  		TEST_ASSERT(pipefds, "Unable to allocate memory for pipefd");
  
  		for (vcpu_id = 0; vcpu_id < nr_vcpus; vcpu_id++) {
- 			vm_paddr_t vcpu_gpa;
+ 			struct perf_test_vcpu_args *vcpu_args;
  			void *vcpu_hva;
++<<<<<<< HEAD
 +			uint64_t vcpu_mem_size;
++=======
+ 			void *vcpu_alias;
++>>>>>>> 92e34c9974f5 (KVM: selftests: Use perf util's per-vCPU GPA/pages in demand paging test)
  
+ 			vcpu_args = &perf_test_args.vcpu_args[vcpu_id];
  
- 			if (p->partition_vcpu_memory_access) {
- 				vcpu_gpa = guest_test_phys_mem +
- 					   (vcpu_id * guest_percpu_mem_size);
- 				vcpu_mem_size = guest_percpu_mem_size;
- 			} else {
- 				vcpu_gpa = guest_test_phys_mem;
- 				vcpu_mem_size = guest_percpu_mem_size * nr_vcpus;
- 			}
- 			PER_VCPU_DEBUG("Added VCPU %d with test mem gpa [%lx, %lx)\n",
- 				       vcpu_id, vcpu_gpa, vcpu_gpa + vcpu_mem_size);
- 
++<<<<<<< HEAD
 +			/* Cache the HVA pointer of the region */
 +			vcpu_hva = addr_gpa2hva(vm, vcpu_gpa);
++=======
+ 			/* Cache the host addresses of the region */
+ 			vcpu_hva = addr_gpa2hva(vm, vcpu_args->gpa);
+ 			vcpu_alias = addr_gpa2alias(vm, vcpu_args->gpa);
++>>>>>>> 92e34c9974f5 (KVM: selftests: Use perf util's per-vCPU GPA/pages in demand paging test)
  
  			/*
  			 * Set up user fault fd to handle demand paging
@@@ -314,9 -341,10 +314,16 @@@
  			TEST_ASSERT(!r, "Failed to set up pipefd");
  
  			setup_demand_paging(vm, &uffd_handler_threads[vcpu_id],
++<<<<<<< HEAD
 +					    pipefds[vcpu_id * 2], p->uffd_delay,
 +					    &uffd_args[vcpu_id], vcpu_hva,
 +					    vcpu_mem_size);
++=======
+ 					    pipefds[vcpu_id * 2], p->uffd_mode,
+ 					    p->uffd_delay, &uffd_args[vcpu_id],
+ 					    vcpu_hva, vcpu_alias,
+ 					    vcpu_args->pages * perf_test_args.guest_page_size);
++>>>>>>> 92e34c9974f5 (KVM: selftests: Use perf util's per-vCPU GPA/pages in demand paging test)
  		}
  	}
  
* Unmerged path tools/testing/selftests/kvm/demand_paging_test.c
