dmaengine: idxd: create locked version of idxd_quiesce() call

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Dave Jiang <dave.jiang@intel.com>
commit bd5970a0d01f8e45af9b2e2cf1d245b84ea757ba
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/bd5970a0.failed

Add a locked version of idxd_quiesce() call so that the quiesce can be
called with a lock in situations where the lock is not held by the caller.

In the driver probe/remove path, the lock is already held, so the raw
version can be called w/o locking.

	Reviewed-by: Kevin Tian <kevin.tian@intel.com>
	Signed-off-by: Dave Jiang <dave.jiang@intel.com>
Link: https://lore.kernel.org/r/163528418980.3925689.5841907054957931211.stgit@djiang5-desk3.ch.intel.com
	Signed-off-by: Vinod Koul <vkoul@kernel.org>
(cherry picked from commit bd5970a0d01f8e45af9b2e2cf1d245b84ea757ba)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/dma/idxd/dma.c
diff --cc drivers/dma/idxd/dma.c
index 77439b645044,375dbae18583..000000000000
--- a/drivers/dma/idxd/dma.c
+++ b/drivers/dma/idxd/dma.c
@@@ -260,5 -268,88 +260,91 @@@ void idxd_unregister_dma_channel(struc
  	list_del(&chan->device_node);
  	kfree(wq->idxd_chan);
  	wq->idxd_chan = NULL;
 -	put_device(wq_confdev(wq));
 +	put_device(&wq->conf_dev);
  }
++<<<<<<< HEAD
++=======
+ 
+ static int idxd_dmaengine_drv_probe(struct idxd_dev *idxd_dev)
+ {
+ 	struct device *dev = &idxd_dev->conf_dev;
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 	struct idxd_device *idxd = wq->idxd;
+ 	int rc;
+ 
+ 	if (idxd->state != IDXD_DEV_ENABLED)
+ 		return -ENXIO;
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	wq->type = IDXD_WQT_KERNEL;
+ 	rc = __drv_enable_wq(wq);
+ 	if (rc < 0) {
+ 		dev_dbg(dev, "Enable wq %d failed: %d\n", wq->id, rc);
+ 		rc = -ENXIO;
+ 		goto err;
+ 	}
+ 
+ 	rc = idxd_wq_alloc_resources(wq);
+ 	if (rc < 0) {
+ 		idxd->cmd_status = IDXD_SCMD_WQ_RES_ALLOC_ERR;
+ 		dev_dbg(dev, "WQ resource alloc failed\n");
+ 		goto err_res_alloc;
+ 	}
+ 
+ 	rc = idxd_wq_init_percpu_ref(wq);
+ 	if (rc < 0) {
+ 		idxd->cmd_status = IDXD_SCMD_PERCPU_ERR;
+ 		dev_dbg(dev, "percpu_ref setup failed\n");
+ 		goto err_ref;
+ 	}
+ 
+ 	rc = idxd_register_dma_channel(wq);
+ 	if (rc < 0) {
+ 		idxd->cmd_status = IDXD_SCMD_DMA_CHAN_ERR;
+ 		dev_dbg(dev, "Failed to register dma channel\n");
+ 		goto err_dma;
+ 	}
+ 
+ 	idxd->cmd_status = 0;
+ 	mutex_unlock(&wq->wq_lock);
+ 	return 0;
+ 
+ err_dma:
+ 	__idxd_wq_quiesce(wq);
+ 	percpu_ref_exit(&wq->wq_active);
+ err_ref:
+ 	idxd_wq_free_resources(wq);
+ err_res_alloc:
+ 	__drv_disable_wq(wq);
+ err:
+ 	wq->type = IDXD_WQT_NONE;
+ 	mutex_unlock(&wq->wq_lock);
+ 	return rc;
+ }
+ 
+ static void idxd_dmaengine_drv_remove(struct idxd_dev *idxd_dev)
+ {
+ 	struct idxd_wq *wq = idxd_dev_to_wq(idxd_dev);
+ 
+ 	mutex_lock(&wq->wq_lock);
+ 	__idxd_wq_quiesce(wq);
+ 	idxd_unregister_dma_channel(wq);
+ 	idxd_wq_free_resources(wq);
+ 	__drv_disable_wq(wq);
+ 	percpu_ref_exit(&wq->wq_active);
+ 	mutex_unlock(&wq->wq_lock);
+ }
+ 
+ static enum idxd_dev_type dev_types[] = {
+ 	IDXD_DEV_WQ,
+ 	IDXD_DEV_NONE,
+ };
+ 
+ struct idxd_device_driver idxd_dmaengine_drv = {
+ 	.probe = idxd_dmaengine_drv_probe,
+ 	.remove = idxd_dmaengine_drv_remove,
+ 	.name = "dmaengine",
+ 	.type = dev_types,
+ };
+ EXPORT_SYMBOL_GPL(idxd_dmaengine_drv);
++>>>>>>> bd5970a0d01f (dmaengine: idxd: create locked version of idxd_quiesce() call)
diff --git a/drivers/dma/idxd/device.c b/drivers/dma/idxd/device.c
index eadb0129f3b6..d628759269a0 100644
--- a/drivers/dma/idxd/device.c
+++ b/drivers/dma/idxd/device.c
@@ -413,13 +413,21 @@ int idxd_wq_init_percpu_ref(struct idxd_wq *wq)
 	return 0;
 }
 
-void idxd_wq_quiesce(struct idxd_wq *wq)
+void __idxd_wq_quiesce(struct idxd_wq *wq)
 {
+	lockdep_assert_held(&wq->wq_lock);
 	percpu_ref_kill(&wq->wq_active);
 	wait_for_completion(&wq->wq_dead);
 	percpu_ref_exit(&wq->wq_active);
 }
 
+void idxd_wq_quiesce(struct idxd_wq *wq)
+{
+	mutex_lock(&wq->wq_lock);
+	__idxd_wq_quiesce(wq);
+	mutex_unlock(&wq->wq_lock);
+}
+
 /* Device control bits */
 static inline bool idxd_is_enabled(struct idxd_device *idxd)
 {
* Unmerged path drivers/dma/idxd/dma.c
diff --git a/drivers/dma/idxd/idxd.h b/drivers/dma/idxd/idxd.h
index 03dc70e1f4d4..33dc0bbf8b13 100644
--- a/drivers/dma/idxd/idxd.h
+++ b/drivers/dma/idxd/idxd.h
@@ -466,6 +466,7 @@ int idxd_wq_map_portal(struct idxd_wq *wq);
 void idxd_wq_unmap_portal(struct idxd_wq *wq);
 int idxd_wq_set_pasid(struct idxd_wq *wq, int pasid);
 int idxd_wq_disable_pasid(struct idxd_wq *wq);
+void __idxd_wq_quiesce(struct idxd_wq *wq);
 void idxd_wq_quiesce(struct idxd_wq *wq);
 int idxd_wq_init_percpu_ref(struct idxd_wq *wq);
 
