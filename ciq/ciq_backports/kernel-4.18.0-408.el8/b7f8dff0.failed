dm: simplify dm_sumbit_bio_remap interface

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-408.el8
commit-author Mike Snitzer <snitzer@redhat.com>
commit b7f8dff09827c96032c34a945ee7757e394b5952
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-408.el8/b7f8dff0.failed

Remove the from_wq argument from dm_sumbit_bio_remap(). Eliminates the
need for dm_sumbit_bio_remap() callers to know whether they are
calling for a workqueue or from the original dm_submit_bio().

Add map_task to dm_io struct, record the map_task in alloc_io and
clear it after all target ->map() calls have completed. Update
dm_sumbit_bio_remap to check if 'current' matches io->map_task rather
than rely on passed 'from_rq' argument.

This change really simplifies the chore of porting each DM target to
using dm_sumbit_bio_remap() because there is no longer the risk of
programming error by not completely knowing all the different contexts
a particular method that calls dm_sumbit_bio_remap() might be used in.

	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit b7f8dff09827c96032c34a945ee7757e394b5952)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-core.h
#	drivers/md/dm-crypt.c
#	drivers/md/dm-delay.c
#	drivers/md/dm-thin.c
#	drivers/md/dm.c
#	include/linux/device-mapper.h
diff --cc drivers/md/dm-core.h
index a9c78c74b3c7,8d3d11887343..000000000000
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@@ -217,7 -232,12 +217,13 @@@ struct dm_io 
  	struct mapped_device *md;
  	struct bio *orig_bio;
  	blk_status_t status;
 -	bool start_io_acct:1;
 -	int was_accounted;
  	unsigned long start_time;
++<<<<<<< HEAD
++=======
+ 	void *data;
+ 	struct hlist_node node;
+ 	struct task_struct *map_task;
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  	spinlock_t endio_lock;
  	struct dm_stats_aux stats_aux;
  	/* last member of dm_target_io is 'struct bio' */
diff --cc drivers/md/dm-crypt.c
index 44280ae22276,a1730cc8ae27..000000000000
--- a/drivers/md/dm-crypt.c
+++ b/drivers/md/dm-crypt.c
@@@ -1857,7 -1857,7 +1857,11 @@@ static int kcryptd_io_read(struct dm_cr
  		return 1;
  	}
  
++<<<<<<< HEAD
 +	generic_make_request(clone);
++=======
+ 	dm_submit_bio_remap(io->base_bio, clone);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  	return 0;
  }
  
@@@ -1883,7 -1883,7 +1887,11 @@@ static void kcryptd_io_write(struct dm_
  {
  	struct bio *clone = io->ctx.bio_out;
  
++<<<<<<< HEAD
 +	generic_make_request(clone);
++=======
+ 	dm_submit_bio_remap(io->base_bio, clone);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  }
  
  #define crypt_io_from_node(node) rb_entry((node), struct dm_crypt_io, rb_node)
@@@ -1962,7 -1962,7 +1970,11 @@@ static void kcryptd_crypt_write_io_subm
  
  	if ((likely(!async) && test_bit(DM_CRYPT_NO_OFFLOAD, &cc->flags)) ||
  	    test_bit(DM_CRYPT_NO_WRITE_WORKQUEUE, &cc->flags)) {
++<<<<<<< HEAD
 +		generic_make_request(clone);
++=======
+ 		dm_submit_bio_remap(io->base_bio, clone);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  		return;
  	}
  
diff --cc drivers/md/dm-delay.c
index f496213f8b67,9a51bf51a859..000000000000
--- a/drivers/md/dm-delay.c
+++ b/drivers/md/dm-delay.c
@@@ -72,7 -72,7 +72,11 @@@ static void flush_bios(struct bio *bio
  	while (bio) {
  		n = bio->bi_next;
  		bio->bi_next = NULL;
++<<<<<<< HEAD
 +		generic_make_request(bio);
++=======
+ 		dm_submit_bio_remap(bio, NULL);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  		bio = n;
  	}
  }
diff --cc drivers/md/dm-thin.c
index 9eaeb33e8975,4d25d0e27031..000000000000
--- a/drivers/md/dm-thin.c
+++ b/drivers/md/dm-thin.c
@@@ -758,7 -755,7 +758,11 @@@ static void issue(struct thin_c *tc, st
  	struct pool *pool = tc->pool;
  
  	if (!bio_triggers_commit(tc, bio)) {
++<<<<<<< HEAD
 +		generic_make_request(bio);
++=======
+ 		dm_submit_bio_remap(bio, NULL);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  		return;
  	}
  
@@@ -2394,7 -2383,7 +2398,11 @@@ static void process_deferred_bios(struc
  		if (bio->bi_opf & REQ_PREFLUSH)
  			bio_endio(bio);
  		else
++<<<<<<< HEAD
 +			generic_make_request(bio);
++=======
+ 			dm_submit_bio_remap(bio, NULL);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  	}
  }
  
diff --cc drivers/md/dm.c
index e7cb1b8972bd,c470f54f9193..000000000000
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@@ -614,8 -572,9 +614,9 @@@ static struct dm_io *alloc_io(struct ma
  	io->status = 0;
  	atomic_set(&io->io_count, 1);
  	this_cpu_inc(*md->pending_io);
 -	io->orig_bio = NULL;
 +	io->orig_bio = bio;
  	io->md = md;
+ 	io->map_task = current;
  	spin_lock_init(&io->endio_lock);
  
  	io->start_time = jiffies;
@@@ -1252,6 -1180,56 +1253,59 @@@ void dm_accept_partial_bio(struct bio *
  }
  EXPORT_SYMBOL_GPL(dm_accept_partial_bio);
  
++<<<<<<< HEAD
++=======
+ static inline void __dm_submit_bio_remap(struct bio *clone,
+ 					 dev_t dev, sector_t old_sector)
+ {
+ 	trace_block_bio_remap(clone, dev, old_sector);
+ 	submit_bio_noacct(clone);
+ }
+ 
+ /*
+  * @clone: clone bio that DM core passed to target's .map function
+  * @tgt_clone: clone of @clone bio that target needs submitted
+  *
+  * Targets should use this interface to submit bios they take
+  * ownership of when returning DM_MAPIO_SUBMITTED.
+  *
+  * Target should also enable ti->accounts_remapped_io
+  */
+ void dm_submit_bio_remap(struct bio *clone, struct bio *tgt_clone)
+ {
+ 	struct dm_target_io *tio = clone_to_tio(clone);
+ 	struct dm_io *io = tio->io;
+ 
+ 	WARN_ON_ONCE(!tio->ti->accounts_remapped_io);
+ 
+ 	/* establish bio that will get submitted */
+ 	if (!tgt_clone)
+ 		tgt_clone = clone;
+ 
+ 	/*
+ 	 * Account io->origin_bio to DM dev on behalf of target
+ 	 * that took ownership of IO with DM_MAPIO_SUBMITTED.
+ 	 */
+ 	if (io->map_task == current) {
+ 		/* Still in target's map function */
+ 		io->start_io_acct = true;
+ 	} else {
+ 		/*
+ 		 * Called by another thread, managed by DM target,
+ 		 * wait for dm_split_and_process_bio() to store
+ 		 * io->orig_bio
+ 		 */
+ 		while (unlikely(!smp_load_acquire(&io->orig_bio)))
+ 			msleep(1);
+ 		dm_start_io_acct(io, clone);
+ 	}
+ 
+ 	__dm_submit_bio_remap(tgt_clone, disk_devt(io->md->disk),
+ 			      tio->old_sector);
+ }
+ EXPORT_SYMBOL_GPL(dm_submit_bio_remap);
+ 
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  static noinline void __set_swap_bios_limit(struct mapped_device *md, int latch)
  {
  	mutex_lock(&md->swap_bios_lock);
@@@ -1620,43 -1563,49 +1674,81 @@@ static blk_qc_t __split_and_process_bio
  	if (bio->bi_opf & REQ_PREFLUSH) {
  		error = __send_empty_flush(&ci);
  		/* dm_io_dec_pending submits any data associated with flush */
 -		goto out;
 +	} else if (op_is_zone_mgmt(bio_op(bio))) {
 +		ci.bio = bio;
 +		ci.sector_count = 0;
 +		error = __split_and_process_non_flush(&ci);
 +	} else {
 +		ci.bio = bio;
 +		ci.sector_count = bio_sectors(bio);
 +		error = __split_and_process_non_flush(&ci);
 +		if (ci.sector_count && !error) {
 +			/*
 +			 * Remainder must be passed to generic_make_request()
 +			 * so that it gets handled *after* bios already submitted
 +			 * have been completely processed.
 +			 * We take a clone of the original to store in
 +			 * ci.io->orig_bio to be used by end_io_acct() and
 +			 * for dec_pending to use for completion handling.
 +			 */
 +			struct bio *b = bio_split(bio, bio_sectors(bio) - ci.sector_count,
 +						  GFP_NOIO, &md->queue->bio_split);
 +			ci.io->orig_bio = b;
 +
 +			bio_chain(b, bio);
 +			trace_block_split(md->queue, b, bio->bi_iter.bi_sector);
 +			ret = generic_make_request(bio);
 +		}
  	}
 +	start_io_acct(ci.io);
  
++<<<<<<< HEAD
 +	/* drop the extra reference count */
 +	dm_io_dec_pending(ci.io, errno_to_blk_status(error));
 +	return ret;
++=======
+ 	error = __split_and_process_bio(&ci);
+ 	ci.io->map_task = NULL;
+ 	if (error || !ci.sector_count)
+ 		goto out;
+ 
+ 	/*
+ 	 * Remainder must be passed to submit_bio_noacct() so it gets handled
+ 	 * *after* bios already submitted have been completely processed.
+ 	 * We take a clone of the original to store in ci.io->orig_bio to be
+ 	 * used by dm_end_io_acct() and for dm_io_dec_pending() to use for
+ 	 * completion handling.
+ 	 */
+ 	orig_bio = bio_split(bio, bio_sectors(bio) - ci.sector_count,
+ 			     GFP_NOIO, &md->queue->bio_split);
+ 	bio_chain(orig_bio, bio);
+ 	trace_block_split(orig_bio, bio->bi_iter.bi_sector);
+ 	submit_bio_noacct(bio);
+ out:
+ 	if (!orig_bio)
+ 		orig_bio = bio;
+ 	smp_store_release(&ci.io->orig_bio, orig_bio);
+ 	if (ci.io->start_io_acct)
+ 		dm_start_io_acct(ci.io, NULL);
+ 
+ 	/*
+ 	 * Drop the extra reference count for non-POLLED bio, and hold one
+ 	 * reference for POLLED bio, which will be released in dm_poll_bio
+ 	 *
+ 	 * Add every dm_io instance into the hlist_head which is stored in
+ 	 * bio->bi_private, so that dm_poll_bio can poll them all.
+ 	 */
+ 	if (error || !ci.submit_as_polled)
+ 		dm_io_dec_pending(ci.io, errno_to_blk_status(error));
+ 	else
+ 		dm_queue_poll_io(bio, ci.io);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  }
  
 -static void dm_submit_bio(struct bio *bio)
 +static blk_qc_t dm_make_request(struct request_queue *q, struct bio *bio)
  {
 -	struct mapped_device *md = bio->bi_bdev->bd_disk->private_data;
 +	struct mapped_device *md = q->queuedata;
 +	blk_qc_t ret = BLK_QC_T_NONE;
  	int srcu_idx;
  	struct dm_table *map;
  
diff --cc include/linux/device-mapper.h
index 8546b303c08e,901ec191250c..000000000000
--- a/include/linux/device-mapper.h
+++ b/include/linux/device-mapper.h
@@@ -469,6 -471,7 +469,10 @@@ int dm_suspended(struct dm_target *ti)
  int dm_post_suspending(struct dm_target *ti);
  int dm_noflush_suspending(struct dm_target *ti);
  void dm_accept_partial_bio(struct bio *bio, unsigned n_sectors);
++<<<<<<< HEAD
++=======
+ void dm_submit_bio_remap(struct bio *clone, struct bio *tgt_clone);
++>>>>>>> b7f8dff09827 (dm: simplify dm_sumbit_bio_remap interface)
  union map_info *dm_get_rq_mapinfo(struct request *rq);
  
  #ifdef CONFIG_BLK_DEV_ZONED
* Unmerged path drivers/md/dm-core.h
* Unmerged path drivers/md/dm-crypt.c
* Unmerged path drivers/md/dm-delay.c
* Unmerged path drivers/md/dm-thin.c
* Unmerged path drivers/md/dm.c
* Unmerged path include/linux/device-mapper.h
