net/mlx5e: Consider tunnel type for encap contexts

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Eli Britstein <elibr@mellanox.com>
commit 7f1a546e322287ae948e0f5eb8d12b7b638d93a6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/7f1a546e.failed

The driver allocates an encap context based on the tunnel properties,
and reuse that context for all flows using the same tunnel properties.
Commit df2ef3bff193 ("net/mlx5e: Add GRE protocol offloading")
introduced another tunnel protocol other than the single VXLAN
previously supported. A flow that uses a tunnel with the same tunnel
properties but with a different tunnel type (GRE vs VXLAN for example)
would mistakenly reuse the previous alocated context, causing the
traffic to be sent with the wrong encapsulation. Fix that by
considering the tunnel type for encap contexts.

Fixes: df2ef3bff193 ("net/mlx5e: Add GRE protocol offloading")
	Signed-off-by: Eli Britstein <elibr@mellanox.com>
	Reviewed-by: Roi Dayan <roid@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 7f1a546e322287ae948e0f5eb8d12b7b638d93a6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 0898ea0b9f0c,d75dc44eb2ff..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -2113,56 -2384,24 +2113,63 @@@ static int parse_tc_nic_actions(struct 
  	return 0;
  }
  
- static inline int cmp_encap_info(struct ip_tunnel_key *a,
- 				 struct ip_tunnel_key *b)
+ struct encap_key {
+ 	struct ip_tunnel_key *ip_tun_key;
+ 	int tunnel_type;
+ };
+ 
+ static inline int cmp_encap_info(struct encap_key *a,
+ 				 struct encap_key *b)
  {
- 	return memcmp(a, b, sizeof(*a));
+ 	return memcmp(a->ip_tun_key, b->ip_tun_key, sizeof(*a->ip_tun_key)) ||
+ 	       a->tunnel_type != b->tunnel_type;
  }
  
- static inline int hash_encap_info(struct ip_tunnel_key *key)
+ static inline int hash_encap_info(struct encap_key *key)
  {
- 	return jhash(key, sizeof(*key), 0);
+ 	return jhash(key->ip_tun_key, sizeof(*key->ip_tun_key),
+ 		     key->tunnel_type);
  }
  
 +static int mlx5e_route_lookup_ipv4(struct mlx5e_priv *priv,
 +				   struct net_device *mirred_dev,
 +				   struct net_device **out_dev,
 +				   struct flowi4 *fl4,
 +				   struct neighbour **out_n,
 +				   u8 *out_ttl)
 +{
 +	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +	struct mlx5e_rep_priv *uplink_rpriv;
 +	struct rtable *rt;
 +	struct neighbour *n = NULL;
 +
 +#if IS_ENABLED(CONFIG_INET)
 +	int ret;
 +
 +	rt = ip_route_output_key(dev_net(mirred_dev), fl4);
 +	ret = PTR_ERR_OR_ZERO(rt);
 +	if (ret)
 +		return ret;
 +#else
 +	return -EOPNOTSUPP;
 +#endif
 +	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 +	/* if the egress device isn't on the same HW e-switch, we use the uplink */
 +	if (!switchdev_port_same_parent_id(priv->netdev, rt->dst.dev))
 +		*out_dev = uplink_rpriv->netdev;
 +	else
 +		*out_dev = rt->dst.dev;
 +
 +	if (!(*out_ttl))
 +		*out_ttl = ip4_dst_hoplimit(&rt->dst);
 +	n = dst_neigh_lookup(&rt->dst, &fl4->daddr);
 +	ip_rt_put(rt);
 +	if (!n)
 +		return -ENOMEM;
 +
 +	*out_n = n;
 +	return 0;
 +}
  
  static bool is_merged_eswitch_dev(struct mlx5e_priv *priv,
  				  struct net_device *peer_netdev)
@@@ -2177,384 -2416,34 +2184,398 @@@
  		same_hw_devs(priv, peer_priv));
  }
  
 +static int mlx5e_route_lookup_ipv6(struct mlx5e_priv *priv,
 +				   struct net_device *mirred_dev,
 +				   struct net_device **out_dev,
 +				   struct flowi6 *fl6,
 +				   struct neighbour **out_n,
 +				   u8 *out_ttl)
 +{
 +	struct neighbour *n = NULL;
 +	struct dst_entry *dst;
 +
 +#if IS_ENABLED(CONFIG_INET) && IS_ENABLED(CONFIG_IPV6)
 +	struct mlx5e_rep_priv *uplink_rpriv;
 +	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +	int ret;
 +
 +	ret = ipv6_stub->ipv6_dst_lookup(dev_net(mirred_dev), NULL, &dst,
 +					 fl6);
 +	if (ret < 0)
 +		return ret;
 +
 +	if (!(*out_ttl))
 +		*out_ttl = ip6_dst_hoplimit(dst);
 +
 +	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 +	/* if the egress device isn't on the same HW e-switch, we use the uplink */
 +	if (!switchdev_port_same_parent_id(priv->netdev, dst->dev))
 +		*out_dev = uplink_rpriv->netdev;
 +	else
 +		*out_dev = dst->dev;
 +#else
 +	return -EOPNOTSUPP;
 +#endif
 +
 +	n = dst_neigh_lookup(dst, &fl6->daddr);
 +	dst_release(dst);
 +	if (!n)
 +		return -ENOMEM;
 +
 +	*out_n = n;
 +	return 0;
 +}
 +
 +static void gen_vxlan_header_ipv4(struct net_device *out_dev,
 +				  char buf[], int encap_size,
 +				  unsigned char h_dest[ETH_ALEN],
 +				  u8 tos, u8 ttl,
 +				  __be32 daddr,
 +				  __be32 saddr,
 +				  __be16 udp_dst_port,
 +				  __be32 vx_vni)
 +{
 +	struct ethhdr *eth = (struct ethhdr *)buf;
 +	struct iphdr  *ip = (struct iphdr *)((char *)eth + sizeof(struct ethhdr));
 +	struct udphdr *udp = (struct udphdr *)((char *)ip + sizeof(struct iphdr));
 +	struct vxlanhdr *vxh = (struct vxlanhdr *)((char *)udp + sizeof(struct udphdr));
 +
 +	memset(buf, 0, encap_size);
 +
 +	ether_addr_copy(eth->h_dest, h_dest);
 +	ether_addr_copy(eth->h_source, out_dev->dev_addr);
 +	eth->h_proto = htons(ETH_P_IP);
 +
 +	ip->daddr = daddr;
 +	ip->saddr = saddr;
 +
 +	ip->tos = tos;
 +	ip->ttl = ttl;
 +	ip->protocol = IPPROTO_UDP;
 +	ip->version = 0x4;
 +	ip->ihl = 0x5;
 +
 +	udp->dest = udp_dst_port;
 +	vxh->vx_flags = VXLAN_HF_VNI;
 +	vxh->vx_vni = vxlan_vni_field(vx_vni);
 +}
 +
 +static void gen_vxlan_header_ipv6(struct net_device *out_dev,
 +				  char buf[], int encap_size,
 +				  unsigned char h_dest[ETH_ALEN],
 +				  u8 tos, u8 ttl,
 +				  struct in6_addr *daddr,
 +				  struct in6_addr *saddr,
 +				  __be16 udp_dst_port,
 +				  __be32 vx_vni)
 +{
 +	struct ethhdr *eth = (struct ethhdr *)buf;
 +	struct ipv6hdr *ip6h = (struct ipv6hdr *)((char *)eth + sizeof(struct ethhdr));
 +	struct udphdr *udp = (struct udphdr *)((char *)ip6h + sizeof(struct ipv6hdr));
 +	struct vxlanhdr *vxh = (struct vxlanhdr *)((char *)udp + sizeof(struct udphdr));
 +
 +	memset(buf, 0, encap_size);
 +
 +	ether_addr_copy(eth->h_dest, h_dest);
 +	ether_addr_copy(eth->h_source, out_dev->dev_addr);
 +	eth->h_proto = htons(ETH_P_IPV6);
 +
 +	ip6_flow_hdr(ip6h, tos, 0);
 +	/* the HW fills up ipv6 payload len */
 +	ip6h->nexthdr     = IPPROTO_UDP;
 +	ip6h->hop_limit   = ttl;
 +	ip6h->daddr	  = *daddr;
 +	ip6h->saddr	  = *saddr;
 +
 +	udp->dest = udp_dst_port;
 +	vxh->vx_flags = VXLAN_HF_VNI;
 +	vxh->vx_vni = vxlan_vni_field(vx_vni);
 +}
 +
 +static int mlx5e_create_encap_header_ipv4(struct mlx5e_priv *priv,
 +					  struct net_device *mirred_dev,
 +					  struct mlx5e_encap_entry *e)
 +{
 +	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
 +	int ipv4_encap_size = ETH_HLEN + sizeof(struct iphdr) + VXLAN_HLEN;
 +	struct ip_tunnel_key *tun_key = &e->tun_info.key;
 +	struct net_device *out_dev;
 +	struct neighbour *n = NULL;
 +	struct flowi4 fl4 = {};
 +	u8 nud_state, tos, ttl;
 +	char *encap_header;
 +	int err;
 +
 +	if (max_encap_size < ipv4_encap_size) {
 +		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
 +			       ipv4_encap_size, max_encap_size);
 +		return -EOPNOTSUPP;
 +	}
 +
 +	encap_header = kzalloc(ipv4_encap_size, GFP_KERNEL);
 +	if (!encap_header)
 +		return -ENOMEM;
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_REFORMAT_TYPE_L2_TO_VXLAN:
 +		fl4.flowi4_proto = IPPROTO_UDP;
 +		fl4.fl4_dport = tun_key->tp_dst;
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto free_encap;
 +	}
 +
 +	tos = tun_key->tos;
 +	ttl = tun_key->ttl;
 +
 +	fl4.flowi4_tos = tun_key->tos;
 +	fl4.daddr = tun_key->u.ipv4.dst;
 +	fl4.saddr = tun_key->u.ipv4.src;
 +
 +	err = mlx5e_route_lookup_ipv4(priv, mirred_dev, &out_dev,
 +				      &fl4, &n, &ttl);
 +	if (err)
 +		goto free_encap;
 +
 +	/* used by mlx5e_detach_encap to lookup a neigh hash table
 +	 * entry in the neigh hash table when a user deletes a rule
 +	 */
 +	e->m_neigh.dev = n->dev;
 +	e->m_neigh.family = n->ops->family;
 +	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
 +	e->out_dev = out_dev;
 +
 +	/* It's importent to add the neigh to the hash table before checking
 +	 * the neigh validity state. So if we'll get a notification, in case the
 +	 * neigh changes it's validity state, we would find the relevant neigh
 +	 * in the hash.
 +	 */
 +	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
 +	if (err)
 +		goto free_encap;
 +
 +	read_lock_bh(&n->lock);
 +	nud_state = n->nud_state;
 +	ether_addr_copy(e->h_dest, n->ha);
 +	read_unlock_bh(&n->lock);
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_REFORMAT_TYPE_L2_TO_VXLAN:
 +		gen_vxlan_header_ipv4(out_dev, encap_header,
 +				      ipv4_encap_size, e->h_dest, tos, ttl,
 +				      fl4.daddr,
 +				      fl4.saddr, tun_key->tp_dst,
 +				      tunnel_id_to_key32(tun_key->tun_id));
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto destroy_neigh_entry;
 +	}
 +	e->encap_size = ipv4_encap_size;
 +	e->encap_header = encap_header;
 +
 +	if (!(nud_state & NUD_VALID)) {
 +		neigh_event_send(n, NULL);
 +		err = -EAGAIN;
 +		goto out;
 +	}
 +
 +	err = mlx5_packet_reformat_alloc(priv->mdev, e->tunnel_type,
 +					 ipv4_encap_size, encap_header,
 +					 MLX5_FLOW_NAMESPACE_FDB,
 +					 &e->encap_id);
 +	if (err)
 +		goto destroy_neigh_entry;
 +
 +	e->flags |= MLX5_ENCAP_ENTRY_VALID;
 +	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
 +	neigh_release(n);
 +	return err;
 +
 +destroy_neigh_entry:
 +	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
 +free_encap:
 +	kfree(encap_header);
 +out:
 +	if (n)
 +		neigh_release(n);
 +	return err;
 +}
 +
 +static int mlx5e_create_encap_header_ipv6(struct mlx5e_priv *priv,
 +					  struct net_device *mirred_dev,
 +					  struct mlx5e_encap_entry *e)
 +{
 +	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
 +	int ipv6_encap_size = ETH_HLEN + sizeof(struct ipv6hdr) + VXLAN_HLEN;
 +	struct ip_tunnel_key *tun_key = &e->tun_info.key;
 +	struct net_device *out_dev;
 +	struct neighbour *n = NULL;
 +	struct flowi6 fl6 = {};
 +	u8 nud_state, tos, ttl;
 +	char *encap_header;
 +	int err;
 +
 +	if (max_encap_size < ipv6_encap_size) {
 +		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
 +			       ipv6_encap_size, max_encap_size);
 +		return -EOPNOTSUPP;
 +	}
 +
 +	encap_header = kzalloc(ipv6_encap_size, GFP_KERNEL);
 +	if (!encap_header)
 +		return -ENOMEM;
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_REFORMAT_TYPE_L2_TO_VXLAN:
 +		fl6.flowi6_proto = IPPROTO_UDP;
 +		fl6.fl6_dport = tun_key->tp_dst;
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto free_encap;
 +	}
 +
 +	tos = tun_key->tos;
 +	ttl = tun_key->ttl;
 +
 +	fl6.flowlabel = ip6_make_flowinfo(RT_TOS(tun_key->tos), tun_key->label);
 +	fl6.daddr = tun_key->u.ipv6.dst;
 +	fl6.saddr = tun_key->u.ipv6.src;
 +
 +	err = mlx5e_route_lookup_ipv6(priv, mirred_dev, &out_dev,
 +				      &fl6, &n, &ttl);
 +	if (err)
 +		goto free_encap;
 +
 +	/* used by mlx5e_detach_encap to lookup a neigh hash table
 +	 * entry in the neigh hash table when a user deletes a rule
 +	 */
 +	e->m_neigh.dev = n->dev;
 +	e->m_neigh.family = n->ops->family;
 +	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
 +	e->out_dev = out_dev;
 +
 +	/* It's importent to add the neigh to the hash table before checking
 +	 * the neigh validity state. So if we'll get a notification, in case the
 +	 * neigh changes it's validity state, we would find the relevant neigh
 +	 * in the hash.
 +	 */
 +	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
 +	if (err)
 +		goto free_encap;
 +
 +	read_lock_bh(&n->lock);
 +	nud_state = n->nud_state;
 +	ether_addr_copy(e->h_dest, n->ha);
 +	read_unlock_bh(&n->lock);
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_REFORMAT_TYPE_L2_TO_VXLAN:
 +		gen_vxlan_header_ipv6(out_dev, encap_header,
 +				      ipv6_encap_size, e->h_dest, tos, ttl,
 +				      &fl6.daddr,
 +				      &fl6.saddr, tun_key->tp_dst,
 +				      tunnel_id_to_key32(tun_key->tun_id));
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto destroy_neigh_entry;
 +	}
 +
 +	e->encap_size = ipv6_encap_size;
 +	e->encap_header = encap_header;
 +
 +	if (!(nud_state & NUD_VALID)) {
 +		neigh_event_send(n, NULL);
 +		err = -EAGAIN;
 +		goto out;
 +	}
 +
 +	err = mlx5_packet_reformat_alloc(priv->mdev, e->tunnel_type,
 +					 ipv6_encap_size, encap_header,
 +					 MLX5_FLOW_NAMESPACE_FDB,
 +					 &e->encap_id);
 +	if (err)
 +		goto destroy_neigh_entry;
 +
 +	e->flags |= MLX5_ENCAP_ENTRY_VALID;
 +	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
 +	neigh_release(n);
 +	return err;
 +
 +destroy_neigh_entry:
 +	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
 +free_encap:
 +	kfree(encap_header);
 +out:
 +	if (n)
 +		neigh_release(n);
 +	return err;
 +}
 +
 +bool mlx5e_tc_tun_device_to_offload(struct mlx5e_priv *priv,
 +				    struct net_device *netdev)
 +{
 +	if (netif_is_vxlan(netdev) &&
 +	    MLX5_CAP_ESW(priv->mdev, vxlan_encap_decap))
 +		return true;
  
 +	return false;
 +}
  
  static int mlx5e_attach_encap(struct mlx5e_priv *priv,
 -			      struct mlx5e_tc_flow *flow,
 +			      struct ip_tunnel_info *tun_info,
  			      struct net_device *mirred_dev,
 -			      int out_index,
 -			      struct netlink_ext_ack *extack,
  			      struct net_device **encap_dev,
 -			      bool *encap_valid)
 +			      struct mlx5e_tc_flow *flow)
  {
  	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +	unsigned short family = ip_tunnel_info_af(tun_info);
  	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
++<<<<<<< HEAD
 +	struct ip_tunnel_key *key = &tun_info->key;
++=======
+ 	struct mlx5e_tc_flow_parse_attr *parse_attr;
+ 	struct ip_tunnel_info *tun_info;
+ 	struct encap_key key, e_key;
++>>>>>>> 7f1a546e3222 (net/mlx5e: Consider tunnel type for encap contexts)
  	struct mlx5e_encap_entry *e;
 -	unsigned short family;
 +	int tunnel_type, err = 0;
  	uintptr_t hash_key;
  	bool found = false;
 -	int err = 0;
  
++<<<<<<< HEAD
 +	/* udp dst port must be set */
 +	if (!memchr_inv(&key->tp_dst, 0, sizeof(key->tp_dst)))
 +		goto vxlan_encap_offload_err;
 +
 +	/* setting udp src port isn't supported */
 +	if (memchr_inv(&key->tp_src, 0, sizeof(key->tp_src))) {
 +vxlan_encap_offload_err:
 +		netdev_warn(priv->netdev,
 +			    "must set udp dst port and not set udp src port\n");
 +		return -EOPNOTSUPP;
 +	}
 +
 +	if (mlx5_vxlan_lookup_port(priv->mdev->vxlan, be16_to_cpu(key->tp_dst)) &&
 +	    MLX5_CAP_ESW(priv->mdev, vxlan_encap_decap)) {
 +		tunnel_type = MLX5_REFORMAT_TYPE_L2_TO_VXLAN;
 +	} else {
 +		netdev_warn(priv->netdev,
 +			    "%d isn't an offloaded vxlan udp dport\n", be16_to_cpu(key->tp_dst));
 +		return -EOPNOTSUPP;
 +	}
++=======
+ 	parse_attr = attr->parse_attr;
+ 	tun_info = &parse_attr->tun_info[out_index];
+ 	family = ip_tunnel_info_af(tun_info);
+ 	key.ip_tun_key = &tun_info->key;
+ 	key.tunnel_type = mlx5e_tc_tun_get_type(mirred_dev);
++>>>>>>> 7f1a546e3222 (net/mlx5e: Consider tunnel type for encap contexts)
  
- 	hash_key = hash_encap_info(key);
+ 	hash_key = hash_encap_info(&key);
  
  	hash_for_each_possible_rcu(esw->offloads.encap_tbl, e,
  				   encap_hlist, hash_key) {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
