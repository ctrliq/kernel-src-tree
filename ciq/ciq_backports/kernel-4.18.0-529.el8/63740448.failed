mptcp: fix accept vs worker race

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-529.el8
commit-author Paolo Abeni <pabeni@redhat.com>
commit 63740448a32eb662e05894425b47bcc5814136f4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-529.el8/63740448.failed

The mptcp worker and mptcp_accept() can race, as reported by Christoph:

refcount_t: addition on 0; use-after-free.
WARNING: CPU: 1 PID: 14351 at lib/refcount.c:25 refcount_warn_saturate+0x105/0x1b0 lib/refcount.c:25
Modules linked in:
CPU: 1 PID: 14351 Comm: syz-executor.2 Not tainted 6.3.0-rc1-gde5e8fd0123c #11
Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-2.el7 04/01/2014
RIP: 0010:refcount_warn_saturate+0x105/0x1b0 lib/refcount.c:25
Code: 02 31 ff 89 de e8 1b f0 a7 ff 84 db 0f 85 6e ff ff ff e8 3e f5 a7 ff 48 c7 c7 d8 c7 34 83 c6 05 6d 2d 0f 02 01 e8 cb 3d 90 ff <0f> 0b e9 4f ff ff ff e8 1f f5 a7 ff 0f b6 1d 54 2d 0f 02 31 ff 89
RSP: 0018:ffffc90000a47bf8 EFLAGS: 00010282
RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
RDX: ffff88802eae98c0 RSI: ffffffff81097d4f RDI: 0000000000000001
RBP: ffff88802e712180 R08: 0000000000000001 R09: 0000000000000000
R10: 0000000000000001 R11: ffff88802eaea148 R12: ffff88802e712100
R13: ffff88802e712a88 R14: ffff888005cb93a8 R15: ffff88802e712a88
FS:  0000000000000000(0000) GS:ffff88803ed00000(0000) knlGS:0000000000000000
CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 00007f277fd89120 CR3: 0000000035486002 CR4: 0000000000370ee0
DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
Call Trace:
 <TASK>
 __refcount_add include/linux/refcount.h:199 [inline]
 __refcount_inc include/linux/refcount.h:250 [inline]
 refcount_inc include/linux/refcount.h:267 [inline]
 sock_hold include/net/sock.h:775 [inline]
 __mptcp_close+0x4c6/0x4d0 net/mptcp/protocol.c:3051
 mptcp_close+0x24/0xe0 net/mptcp/protocol.c:3072
 inet_release+0x56/0xa0 net/ipv4/af_inet.c:429
 __sock_release+0x51/0xf0 net/socket.c:653
 sock_close+0x18/0x20 net/socket.c:1395
 __fput+0x113/0x430 fs/file_table.c:321
 task_work_run+0x96/0x100 kernel/task_work.c:179
 exit_task_work include/linux/task_work.h:38 [inline]
 do_exit+0x4fc/0x10c0 kernel/exit.c:869
 do_group_exit+0x51/0xf0 kernel/exit.c:1019
 get_signal+0x12b0/0x1390 kernel/signal.c:2859
 arch_do_signal_or_restart+0x25/0x260 arch/x86/kernel/signal.c:306
 exit_to_user_mode_loop kernel/entry/common.c:168 [inline]
 exit_to_user_mode_prepare+0x131/0x1a0 kernel/entry/common.c:203
 __syscall_exit_to_user_mode_work kernel/entry/common.c:285 [inline]
 syscall_exit_to_user_mode+0x19/0x40 kernel/entry/common.c:296
 do_syscall_64+0x46/0x90 arch/x86/entry/common.c:86
 entry_SYSCALL_64_after_hwframe+0x72/0xdc
RIP: 0033:0x7fec4b4926a9
Code: Unable to access opcode bytes at 0x7fec4b49267f.
RSP: 002b:00007fec49f9dd78 EFLAGS: 00000246 ORIG_RAX: 00000000000000ca
RAX: fffffffffffffe00 RBX: 00000000006bc058 RCX: 00007fec4b4926a9
RDX: 0000000000000000 RSI: 0000000000000080 RDI: 00000000006bc058
RBP: 00000000006bc050 R08: 00000000007df998 R09: 00000000007df998
R10: 0000000000000000 R11: 0000000000000246 R12: 00000000006bc05c
R13: fffffffffffffea8 R14: 000000000000000b R15: 000000000001fe40
 </TASK>

The root cause is that the worker can force fallback to TCP the first
mptcp subflow, actually deleting the unaccepted msk socket.

We can explicitly prevent the race delaying the unaccepted msk deletion
at listener shutdown time. In case the closed subflow is later accepted,
just drop the mptcp context and let the user-space deal with the
paired mptcp socket.

Fixes: b6985b9b8295 ("mptcp: use the workqueue to destroy unaccepted sockets")
	Cc: stable@vger.kernel.org
	Reported-by: Christoph Paasch <cpaasch@apple.com>
Link: https://github.com/multipath-tcp/mptcp_net-next/issues/375
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Reviewed-by: Matthieu Baerts <matthieu.baerts@tessares.net>
	Tested-by: Christoph Paasch <cpaasch@apple.com>
	Signed-off-by: Matthieu Baerts <matthieu.baerts@tessares.net>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 63740448a32eb662e05894425b47bcc5814136f4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/mptcp/protocol.c
#	net/mptcp/protocol.h
#	net/mptcp/subflow.c
diff --cc net/mptcp/protocol.c
index 06fc28bcb1ca,b998e9df53ce..000000000000
--- a/net/mptcp/protocol.c
+++ b/net/mptcp/protocol.c
@@@ -2237,12 -2311,34 +2237,35 @@@ bool __mptcp_retransmit_pending_data(st
   * parent socket.
   */
  static void __mptcp_close_ssk(struct sock *sk, struct sock *ssk,
 -			      struct mptcp_subflow_context *subflow,
 -			      unsigned int flags)
 +			      struct mptcp_subflow_context *subflow)
  {
  	struct mptcp_sock *msk = mptcp_sk(sk);
++<<<<<<< HEAD
 +	bool need_push;
++=======
+ 	bool dispose_it, need_push = false;
+ 
+ 	/* If the first subflow moved to a close state before accept, e.g. due
+ 	 * to an incoming reset, mptcp either:
+ 	 * - if either the subflow or the msk are dead, destroy the context
+ 	 *   (the subflow socket is deleted by inet_child_forget) and the msk
+ 	 * - otherwise do nothing at the moment and take action at accept and/or
+ 	 *   listener shutdown - user-space must be able to accept() the closed
+ 	 *   socket.
+ 	 */
+ 	if (msk->in_accept_queue && msk->first == ssk) {
+ 		if (!sock_flag(sk, SOCK_DEAD) && !sock_flag(ssk, SOCK_DEAD))
+ 			return;
+ 
+ 		/* ensure later check in mptcp_worker() will dispose the msk */
+ 		sock_set_flag(sk, SOCK_DEAD);
+ 		lock_sock_nested(ssk, SINGLE_DEPTH_NESTING);
+ 		mptcp_subflow_drop_ctx(ssk);
+ 		goto out_release;
+ 	}
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  
 -	dispose_it = !msk->subflow || ssk != msk->subflow->sk;
 -	if (dispose_it)
 -		list_del(&subflow->node);
 +	list_del(&subflow->node);
  
  	lock_sock_nested(ssk, SINGLE_DEPTH_NESTING);
  
@@@ -2321,11 -2437,12 +2346,17 @@@ static void __mptcp_close_subflow(struc
  		if (!skb_queue_empty_lockless(&ssk->sk_receive_queue))
  			continue;
  
++<<<<<<< HEAD
 +		mptcp_close_ssk((struct sock *)msk, ssk, subflow);
 +	}
++=======
+ 		mptcp_close_ssk(sk, ssk, subflow);
+ 	}
+ 
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  }
  
- static bool mptcp_check_close_timeout(const struct sock *sk)
+ static bool mptcp_should_close(const struct sock *sk)
  {
  	s32 delta = tcp_jiffies32 - inet_csk(sk)->icsk_mtup.probe_timestamp;
  	struct mptcp_subflow_context *subflow;
@@@ -2462,16 -2654,17 +2493,28 @@@ static void mptcp_worker(struct work_st
  	 * closed, but we need the msk around to reply to incoming DATA_FIN,
  	 * even if it is orphaned and in FIN_WAIT2 state
  	 */
++<<<<<<< HEAD
 +	if (sock_flag(sk, SOCK_DEAD) &&
 +	    (mptcp_check_close_timeout(sk) || sk->sk_state == TCP_CLOSE)) {
 +		inet_sk_state_store(sk, TCP_CLOSE);
 +		__mptcp_destroy_sock(sk);
 +		goto unlock;
++=======
+ 	if (sock_flag(sk, SOCK_DEAD)) {
+ 		if (mptcp_should_close(sk)) {
+ 			inet_sk_state_store(sk, TCP_CLOSE);
+ 			mptcp_do_fastclose(sk);
+ 		}
+ 		if (sk->sk_state == TCP_CLOSE) {
+ 			__mptcp_destroy_sock(sk);
+ 			goto unlock;
+ 		}
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  	}
  
 +	if (test_and_clear_bit(MPTCP_WORK_CLOSE_SUBFLOW, &msk->flags))
 +		__mptcp_close_subflow(msk);
 +
  	if (test_and_clear_bit(MPTCP_WORK_RTX, &msk->flags))
  		__mptcp_retrans(sk);
  
@@@ -2695,6 -2901,32 +2738,35 @@@ static void __mptcp_destroy_sock(struc
  	sock_put(sk);
  }
  
++<<<<<<< HEAD
++=======
+ void __mptcp_unaccepted_force_close(struct sock *sk)
+ {
+ 	sock_set_flag(sk, SOCK_DEAD);
+ 	inet_sk_state_store(sk, TCP_CLOSE);
+ 	mptcp_do_fastclose(sk);
+ 	__mptcp_destroy_sock(sk);
+ }
+ 
+ static __poll_t mptcp_check_readable(struct mptcp_sock *msk)
+ {
+ 	/* Concurrent splices from sk_receive_queue into receive_queue will
+ 	 * always show at least one non-empty queue when checked in this order.
+ 	 */
+ 	if (skb_queue_empty_lockless(&((struct sock *)msk)->sk_receive_queue) &&
+ 	    skb_queue_empty_lockless(&msk->receive_queue))
+ 		return 0;
+ 
+ 	return EPOLLIN | EPOLLRDNORM;
+ }
+ 
+ static void mptcp_listen_inuse_dec(struct sock *sk)
+ {
+ 	if (inet_sk_state_load(sk) == TCP_LISTEN)
+ 		sock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);
+ }
+ 
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  bool __mptcp_close(struct sock *sk, long timeout)
  {
  	struct mptcp_subflow_context *subflow;
diff --cc net/mptcp/protocol.h
index e985de3f0f58,d6469b6ab38e..000000000000
--- a/net/mptcp/protocol.h
+++ b/net/mptcp/protocol.h
@@@ -557,6 -634,11 +557,14 @@@ void mptcp_sock_graft(struct sock *sk, 
  struct socket *__mptcp_nmpc_socket(const struct mptcp_sock *msk);
  bool __mptcp_close(struct sock *sk, long timeout);
  void mptcp_cancel_work(struct sock *sk);
++<<<<<<< HEAD
++=======
+ void __mptcp_unaccepted_force_close(struct sock *sk);
+ void mptcp_set_owner_r(struct sk_buff *skb, struct sock *sk);
+ 
+ bool mptcp_addresses_equal(const struct mptcp_addr_info *a,
+ 			   const struct mptcp_addr_info *b, bool use_port);
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  
  /* called with sk socket lock held */
  int __mptcp_subflow_connect(struct sock *sk, const struct mptcp_addr_info *loc,
diff --cc net/mptcp/subflow.c
index 7d8558c6c894,281c1cc8dc8d..000000000000
--- a/net/mptcp/subflow.c
+++ b/net/mptcp/subflow.c
@@@ -1529,6 -1848,7 +1534,10 @@@ void mptcp_subflow_queue_clean(struct s
  		if (msk->dl_next || msk == head)
  			continue;
  
++<<<<<<< HEAD
++=======
+ 		sock_hold(sk);
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  		msk->dl_next = head;
  		head = msk;
  	}
@@@ -1542,34 -1862,30 +1551,42 @@@
  	release_sock(listener_ssk);
  
  	for (msk = head; msk; msk = next) {
++<<<<<<< HEAD
 +		struct sock *sk = (struct sock *)msk;
 +		bool do_cancel_work;
++=======
+ 		sk = (struct sock *)msk;
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  
 +		sock_hold(sk);
  		lock_sock_nested(sk, SINGLE_DEPTH_NESTING);
  		next = msk->dl_next;
 +		msk->first = NULL;
  		msk->dl_next = NULL;
  
++<<<<<<< HEAD
 +		do_cancel_work = __mptcp_close(sk, 0);
++=======
+ 		__mptcp_unaccepted_force_close(sk);
++>>>>>>> 63740448a32e (mptcp: fix accept vs worker race)
  		release_sock(sk);
 -
 -		/* lockdep will report a false positive ABBA deadlock
 -		 * between cancel_work_sync and the listener socket.
 -		 * The involved locks belong to different sockets WRT
 -		 * the existing AB chain.
 -		 * Using a per socket key is problematic as key
 -		 * deregistration requires process context and must be
 -		 * performed at socket disposal time, in atomic
 -		 * context.
 -		 * Just tell lockdep to consider the listener socket
 -		 * released here.
 -		 */
 -		mutex_release(&listener_sk->sk_lock.dep_map, _RET_IP_);
 -		mptcp_cancel_work(sk);
 -		mutex_acquire(&listener_sk->sk_lock.dep_map, 0, 0, _RET_IP_);
 -
 +		if (do_cancel_work) {
 +			/* lockdep will report a false positive ABBA deadlock
 +			 * between cancel_work_sync and the listener socket.
 +			 * The involved locks belong to different sockets WRT
 +			 * the existing AB chain.
 +			 * Using a per socket key is problematic as key
 +			 * deregistration requires process context and must be
 +			 * performed at socket disposal time, in atomic
 +			 * context.
 +			 * Just tell lockdep to consider the listener socket
 +			 * released here.
 +			 */
 +			mutex_release(&listener_sk->sk_lock.dep_map, _RET_IP_);
 +			mptcp_cancel_work(sk);
 +			mutex_acquire(&listener_sk->sk_lock.dep_map,
 +				      SINGLE_DEPTH_NESTING, 0, _RET_IP_);
 +		}
  		sock_put(sk);
  	}
  
* Unmerged path net/mptcp/protocol.c
* Unmerged path net/mptcp/protocol.h
* Unmerged path net/mptcp/subflow.c
