x86/mce/therm_throt: Mark throttle_active_work() as __maybe_unused

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-553.22.1.el8_10
commit-author Arnd Bergmann <arnd@arndb.de>
commit db1ae0314f47e88ae06679270adf17ffa245afd4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-553.22.1.el8_10/db1ae031.failed

throttle_active_work() is only called if CONFIG_SYSFS is set, otherwise
we get a harmless warning:

  arch/x86/kernel/cpu/mce/therm_throt.c:238:13: error: 'throttle_active_work' \
	  defined but not used [-Werror=unused-function]

Mark the function as __maybe_unused to avoid the warning.

Fixes: f6656208f04e ("x86/mce/therm_throt: Optimize notifications of thermal throttle")
	Signed-off-by: Arnd Bergmann <arnd@arndb.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
	Cc: bberg@redhat.com
	Cc: ckellner@redhat.com
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: hdegoede@redhat.com
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: linux-edac <linux-edac@vger.kernel.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: x86-ml <x86@kernel.org>
Link: https://lkml.kernel.org/r/20191210203925.3119091-1-arnd@arndb.de
(cherry picked from commit db1ae0314f47e88ae06679270adf17ffa245afd4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/thermal/intel/therm_throt.c
diff --cc drivers/thermal/intel/therm_throt.c
index dd55d96efeff,8963493a1e9e..000000000000
--- a/drivers/thermal/intel/therm_throt.c
+++ b/drivers/thermal/intel/therm_throt.c
@@@ -134,6 -192,112 +134,115 @@@ static const struct attribute_group the
  #define CORE_LEVEL	0
  #define PACKAGE_LEVEL	1
  
++<<<<<<< HEAD:drivers/thermal/intel/therm_throt.c
++=======
+ #define THERM_THROT_POLL_INTERVAL	HZ
+ #define THERM_STATUS_PROCHOT_LOG	BIT(1)
+ 
+ #define THERM_STATUS_CLEAR_CORE_MASK (BIT(1) | BIT(3) | BIT(5) | BIT(7) | BIT(9) | BIT(11) | BIT(13) | BIT(15))
+ #define THERM_STATUS_CLEAR_PKG_MASK  (BIT(1) | BIT(3) | BIT(5) | BIT(7) | BIT(9) | BIT(11))
+ 
+ static void clear_therm_status_log(int level)
+ {
+ 	int msr;
+ 	u64 mask, msr_val;
+ 
+ 	if (level == CORE_LEVEL) {
+ 		msr  = MSR_IA32_THERM_STATUS;
+ 		mask = THERM_STATUS_CLEAR_CORE_MASK;
+ 	} else {
+ 		msr  = MSR_IA32_PACKAGE_THERM_STATUS;
+ 		mask = THERM_STATUS_CLEAR_PKG_MASK;
+ 	}
+ 
+ 	rdmsrl(msr, msr_val);
+ 	msr_val &= mask;
+ 	wrmsrl(msr, msr_val & ~THERM_STATUS_PROCHOT_LOG);
+ }
+ 
+ static void get_therm_status(int level, bool *proc_hot, u8 *temp)
+ {
+ 	int msr;
+ 	u64 msr_val;
+ 
+ 	if (level == CORE_LEVEL)
+ 		msr = MSR_IA32_THERM_STATUS;
+ 	else
+ 		msr = MSR_IA32_PACKAGE_THERM_STATUS;
+ 
+ 	rdmsrl(msr, msr_val);
+ 	if (msr_val & THERM_STATUS_PROCHOT_LOG)
+ 		*proc_hot = true;
+ 	else
+ 		*proc_hot = false;
+ 
+ 	*temp = (msr_val >> 16) & 0x7F;
+ }
+ 
+ static void __maybe_unused throttle_active_work(struct work_struct *work)
+ {
+ 	struct _thermal_state *state = container_of(to_delayed_work(work),
+ 						struct _thermal_state, therm_work);
+ 	unsigned int i, avg, this_cpu = smp_processor_id();
+ 	u64 now = get_jiffies_64();
+ 	bool hot;
+ 	u8 temp;
+ 
+ 	get_therm_status(state->level, &hot, &temp);
+ 	/* temperature value is offset from the max so lesser means hotter */
+ 	if (!hot && temp > state->baseline_temp) {
+ 		if (state->rate_control_active)
+ 			pr_info("CPU%d: %s temperature/speed normal (total events = %lu)\n",
+ 				this_cpu,
+ 				state->level == CORE_LEVEL ? "Core" : "Package",
+ 				state->count);
+ 
+ 		state->rate_control_active = false;
+ 		return;
+ 	}
+ 
+ 	if (time_before64(now, state->next_check) &&
+ 			  state->rate_control_active)
+ 		goto re_arm;
+ 
+ 	state->next_check = now + CHECK_INTERVAL;
+ 
+ 	if (state->count != state->last_count) {
+ 		/* There was one new thermal interrupt */
+ 		state->last_count = state->count;
+ 		state->average = 0;
+ 		state->sample_count = 0;
+ 		state->sample_index = 0;
+ 	}
+ 
+ 	state->temp_samples[state->sample_index] = temp;
+ 	state->sample_count++;
+ 	state->sample_index = (state->sample_index + 1) % ARRAY_SIZE(state->temp_samples);
+ 	if (state->sample_count < ARRAY_SIZE(state->temp_samples))
+ 		goto re_arm;
+ 
+ 	avg = 0;
+ 	for (i = 0; i < ARRAY_SIZE(state->temp_samples); ++i)
+ 		avg += state->temp_samples[i];
+ 
+ 	avg /= ARRAY_SIZE(state->temp_samples);
+ 
+ 	if (state->average > avg) {
+ 		pr_warn("CPU%d: %s temperature is above threshold, cpu clock is throttled (total events = %lu)\n",
+ 			this_cpu,
+ 			state->level == CORE_LEVEL ? "Core" : "Package",
+ 			state->count);
+ 		state->rate_control_active = true;
+ 	}
+ 
+ 	state->average = avg;
+ 
+ re_arm:
+ 	clear_therm_status_log(state->level);
+ 	schedule_delayed_work_on(this_cpu, &state->therm_work, THERM_THROT_POLL_INTERVAL);
+ }
+ 
++>>>>>>> db1ae0314f47 (x86/mce/therm_throt: Mark throttle_active_work() as __maybe_unused):arch/x86/kernel/cpu/mce/therm_throt.c
  /***
   * therm_throt_process - Process thermal throttling event from interrupt
   * @curr: Whether the condition is current or not (boolean), since the
* Unmerged path drivers/thermal/intel/therm_throt.c
