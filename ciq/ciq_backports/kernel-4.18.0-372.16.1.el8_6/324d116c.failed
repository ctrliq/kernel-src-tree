gfs2: Align read and write chunks to the page cache

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-372.16.1.el8_6
commit-author Andreas Gruenbacher <agruenba@redhat.com>
commit 324d116c5a5c8204dc00e63f725a3c5ed09afb53
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-372.16.1.el8_6/324d116c.failed

Align the chunks that reads and writes are carried out in to the page
cache rather than the user buffers.  This will be more efficient in
general, especially for allocating writes.  Optimizing the case that the
user buffer is gfs2 backed isn't very useful; we only need to make sure
we won't deadlock.

	Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
(cherry picked from commit 324d116c5a5c8204dc00e63f725a3c5ed09afb53)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/gfs2/file.c
diff --cc fs/gfs2/file.c
index 37f4489b53a0,11c46407d4a8..000000000000
--- a/fs/gfs2/file.c
+++ b/fs/gfs2/file.c
@@@ -764,7 -770,8 +764,12 @@@ static int gfs2_fsync(struct file *file
  	return ret ? ret : ret1;
  }
  
++<<<<<<< HEAD
 +static inline bool should_fault_in_pages(ssize_t ret, struct iov_iter *i,
++=======
+ static inline bool should_fault_in_pages(struct iov_iter *i,
+ 					 struct kiocb *iocb,
++>>>>>>> 324d116c5a5c (gfs2: Align read and write chunks to the page cache)
  					 size_t *prev_count,
  					 size_t *window_size)
  {
@@@ -810,12 -831,37 +813,28 @@@ static ssize_t gfs2_file_direct_read(st
  	ret = gfs2_glock_nq(gh);
  	if (ret)
  		goto out_uninit;
 -retry_under_glock:
 -	pagefault_disable();
 -	to->nofault = true;
 -	ret = iomap_dio_rw(iocb, to, &gfs2_iomap_ops, NULL,
 -			   IOMAP_DIO_PARTIAL, read);
 -	to->nofault = false;
 -	pagefault_enable();
 -	if (ret <= 0 && ret != -EFAULT)
 -		goto out_unlock;
 -	if (ret > 0)
 -		read = ret;
  
++<<<<<<< HEAD
 +	ret = iomap_dio_rw(iocb, to, &gfs2_iomap_ops, NULL, 0);
 +	gfs2_glock_dq(gh);
++=======
+ 	if (should_fault_in_pages(to, iocb, &prev_count, &window_size)) {
+ 		gfs2_holder_allow_demote(gh);
+ 		window_size -= fault_in_iov_iter_writeable(to, window_size);
+ 		gfs2_holder_disallow_demote(gh);
+ 		if (window_size) {
+ 			if (gfs2_holder_queued(gh))
+ 				goto retry_under_glock;
+ 			goto retry;
+ 		}
+ 	}
+ out_unlock:
+ 	if (gfs2_holder_queued(gh))
+ 		gfs2_glock_dq(gh);
++>>>>>>> 324d116c5a5c (gfs2: Align read and write chunks to the page cache)
  out_uninit:
  	gfs2_holder_uninit(gh);
 -	if (ret < 0)
 -		return ret;
 -	return read;
 +	return ret;
  }
  
  static ssize_t gfs2_file_direct_write(struct kiocb *iocb, struct iov_iter *from,
@@@ -840,19 -896,43 +859,48 @@@
  	ret = gfs2_glock_nq(gh);
  	if (ret)
  		goto out_uninit;
 +
  	/* Silently fall back to buffered I/O when writing beyond EOF */
 -	if (iocb->ki_pos + iov_iter_count(from) > i_size_read(&ip->i_inode))
 -		goto out_unlock;
 -retry_under_glock:
 +	if (offset + len > i_size_read(&ip->i_inode))
 +		goto out;
  
++<<<<<<< HEAD
 +	ret = iomap_dio_rw(iocb, from, &gfs2_iomap_ops, NULL, 0);
 +	if (ret == -ENOTBLK)
 +		ret = 0;
 +out:
 +	gfs2_glock_dq(gh);
++=======
+ 	from->nofault = true;
+ 	ret = iomap_dio_rw(iocb, from, &gfs2_iomap_ops, NULL,
+ 			   IOMAP_DIO_PARTIAL, written);
+ 	from->nofault = false;
+ 	if (ret <= 0) {
+ 		if (ret == -ENOTBLK)
+ 			ret = 0;
+ 		if (ret != -EFAULT)
+ 			goto out_unlock;
+ 	}
+ 	if (ret > 0)
+ 		written = ret;
+ 
+ 	if (should_fault_in_pages(from, iocb, &prev_count, &window_size)) {
+ 		gfs2_holder_allow_demote(gh);
+ 		window_size -= fault_in_iov_iter_readable(from, window_size);
+ 		gfs2_holder_disallow_demote(gh);
+ 		if (window_size) {
+ 			if (gfs2_holder_queued(gh))
+ 				goto retry_under_glock;
+ 			goto retry;
+ 		}
+ 	}
+ out_unlock:
+ 	if (gfs2_holder_queued(gh))
+ 		gfs2_glock_dq(gh);
++>>>>>>> 324d116c5a5c (gfs2: Align read and write chunks to the page cache)
  out_uninit:
  	gfs2_holder_uninit(gh);
 -	if (ret < 0)
 -		return ret;
 -	return written;
 +	return ret;
  }
  
  static ssize_t gfs2_file_read_iter(struct kiocb *iocb, struct iov_iter *to)
@@@ -898,24 -978,22 +946,28 @@@ retry_under_glock
  	pagefault_disable();
  	ret = generic_file_read_iter(iocb, to);
  	pagefault_enable();
 -	if (ret <= 0 && ret != -EFAULT)
 -		goto out_unlock;
  	if (ret > 0)
 -		read += ret;
 +		written += ret;
 +
 +	if (should_fault_in_pages(ret, to, &prev_count, &window_size)) {
 +		size_t leftover;
  
++<<<<<<< HEAD
++=======
+ 	if (should_fault_in_pages(to, iocb, &prev_count, &window_size)) {
++>>>>>>> 324d116c5a5c (gfs2: Align read and write chunks to the page cache)
  		gfs2_holder_allow_demote(&gh);
 -		window_size -= fault_in_iov_iter_writeable(to, window_size);
 +		leftover = fault_in_iov_iter_writeable(to, window_size);
  		gfs2_holder_disallow_demote(&gh);
 -		if (window_size) {
 -			if (gfs2_holder_queued(&gh))
 -				goto retry_under_glock;
 -			goto retry;
 +		if (leftover != window_size) {
 +			if (!gfs2_holder_queued(&gh)) {
 +				if (written)
 +					goto out_uninit;
 +				goto retry;
 +			}
 +			goto retry_under_glock;
  		}
  	}
 -out_unlock:
  	if (gfs2_holder_queued(&gh))
  		gfs2_glock_dq(&gh);
  out_uninit:
@@@ -978,21 -1056,19 +1030,26 @@@ retry_under_glock
  	if (inode == sdp->sd_rindex)
  		gfs2_glock_dq_uninit(statfs_gh);
  
 -	if (ret <= 0 && ret != -EFAULT)
 -		goto out_unlock;
 +	from->count = orig_count - read;
 +	if (should_fault_in_pages(ret, from, &prev_count, &window_size)) {
 +		size_t leftover;
  
++<<<<<<< HEAD
++=======
+ 	from->count = orig_count - written;
+ 	if (should_fault_in_pages(from, iocb, &prev_count, &window_size)) {
++>>>>>>> 324d116c5a5c (gfs2: Align read and write chunks to the page cache)
  		gfs2_holder_allow_demote(gh);
 -		window_size -= fault_in_iov_iter_readable(from, window_size);
 +		leftover = fault_in_iov_iter_readable(from, window_size);
  		gfs2_holder_disallow_demote(gh);
 -		if (window_size) {
 -			from->count = min(from->count, window_size);
 -			if (gfs2_holder_queued(gh))
 -				goto retry_under_glock;
 -			goto retry;
 +		if (leftover != window_size) {
 +			from->count = min(from->count, window_size - leftover);
 +			if (!gfs2_holder_queued(gh)) {
 +				if (read)
 +					goto out_uninit;
 +				goto retry;
 +			}
 +			goto retry_under_glock;
  		}
  	}
  out_unlock:
* Unmerged path fs/gfs2/file.c
