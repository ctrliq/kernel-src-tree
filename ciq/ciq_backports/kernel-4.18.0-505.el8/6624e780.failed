ice: split ice_vsi_setup into smaller functions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-505.el8
commit-author Michal Swiatkowski <michal.swiatkowski@linux.intel.com>
commit 6624e780a577fc59678853be7959a153558e11b1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-505.el8/6624e780.failed

Main goal is to reuse the same functions in VSI config and rebuild
paths.
To do this split ice_vsi_setup into smaller pieces and reuse it during
rebuild.

ice_vsi_alloc() should only alloc memory, not set the default values
for VSI.
Move setting defaults to separate function. This will allow config of
already allocated VSI, for example in reload path.

The path is mostly moving code around without introducing new
functionality. Functions ice_vsi_cfg() and ice_vsi_decfg() were
added, but they are using code that already exist.

Use flag to pass information about VSI initialization during rebuild
instead of using boolean value.

Co-developed-by: Jacob Keller <jacob.e.keller@intel.com>
	Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
	Signed-off-by: Michal Swiatkowski <michal.swiatkowski@linux.intel.com>
	Tested-by: Gurucharan G <gurucharanx.g@intel.com> (A Contingent worker at Intel)
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit 6624e780a577fc59678853be7959a153558e11b1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_lib.c
diff --cc drivers/net/ethernet/intel/ice/ice_lib.c
index 5a7867ad1ffd,f9690c0fe5da..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_lib.c
@@@ -348,7 -348,107 +348,111 @@@ static void ice_vsi_free_arrays(struct 
  }
  
  /**
++<<<<<<< HEAD
 + * ice_vsi_clear - clean up and deallocate the provided VSI
++=======
+  * ice_vsi_free_stats - Free the ring statistics structures
+  * @vsi: VSI pointer
+  */
+ static void ice_vsi_free_stats(struct ice_vsi *vsi)
+ {
+ 	struct ice_vsi_stats *vsi_stat;
+ 	struct ice_pf *pf = vsi->back;
+ 	int i;
+ 
+ 	if (vsi->type == ICE_VSI_CHNL)
+ 		return;
+ 	if (!pf->vsi_stats)
+ 		return;
+ 
+ 	vsi_stat = pf->vsi_stats[vsi->idx];
+ 	if (!vsi_stat)
+ 		return;
+ 
+ 	ice_for_each_alloc_txq(vsi, i) {
+ 		if (vsi_stat->tx_ring_stats[i]) {
+ 			kfree_rcu(vsi_stat->tx_ring_stats[i], rcu);
+ 			WRITE_ONCE(vsi_stat->tx_ring_stats[i], NULL);
+ 		}
+ 	}
+ 
+ 	ice_for_each_alloc_rxq(vsi, i) {
+ 		if (vsi_stat->rx_ring_stats[i]) {
+ 			kfree_rcu(vsi_stat->rx_ring_stats[i], rcu);
+ 			WRITE_ONCE(vsi_stat->rx_ring_stats[i], NULL);
+ 		}
+ 	}
+ 
+ 	kfree(vsi_stat->tx_ring_stats);
+ 	kfree(vsi_stat->rx_ring_stats);
+ 	kfree(vsi_stat);
+ 	pf->vsi_stats[vsi->idx] = NULL;
+ }
+ 
+ /**
+  * ice_vsi_alloc_ring_stats - Allocates Tx and Rx ring stats for the VSI
+  * @vsi: VSI which is having stats allocated
+  */
+ static int ice_vsi_alloc_ring_stats(struct ice_vsi *vsi)
+ {
+ 	struct ice_ring_stats **tx_ring_stats;
+ 	struct ice_ring_stats **rx_ring_stats;
+ 	struct ice_vsi_stats *vsi_stats;
+ 	struct ice_pf *pf = vsi->back;
+ 	u16 i;
+ 
+ 	vsi_stats = pf->vsi_stats[vsi->idx];
+ 	tx_ring_stats = vsi_stats->tx_ring_stats;
+ 	rx_ring_stats = vsi_stats->rx_ring_stats;
+ 
+ 	/* Allocate Tx ring stats */
+ 	ice_for_each_alloc_txq(vsi, i) {
+ 		struct ice_ring_stats *ring_stats;
+ 		struct ice_tx_ring *ring;
+ 
+ 		ring = vsi->tx_rings[i];
+ 		ring_stats = tx_ring_stats[i];
+ 
+ 		if (!ring_stats) {
+ 			ring_stats = kzalloc(sizeof(*ring_stats), GFP_KERNEL);
+ 			if (!ring_stats)
+ 				goto err_out;
+ 
+ 			WRITE_ONCE(tx_ring_stats[i], ring_stats);
+ 		}
+ 
+ 		ring->ring_stats = ring_stats;
+ 	}
+ 
+ 	/* Allocate Rx ring stats */
+ 	ice_for_each_alloc_rxq(vsi, i) {
+ 		struct ice_ring_stats *ring_stats;
+ 		struct ice_rx_ring *ring;
+ 
+ 		ring = vsi->rx_rings[i];
+ 		ring_stats = rx_ring_stats[i];
+ 
+ 		if (!ring_stats) {
+ 			ring_stats = kzalloc(sizeof(*ring_stats), GFP_KERNEL);
+ 			if (!ring_stats)
+ 				goto err_out;
+ 
+ 			WRITE_ONCE(rx_ring_stats[i], ring_stats);
+ 		}
+ 
+ 		ring->ring_stats = ring_stats;
+ 	}
+ 
+ 	return 0;
+ 
+ err_out:
+ 	ice_vsi_free_stats(vsi);
+ 	return -ENOMEM;
+ }
+ 
+ /**
+  * ice_vsi_free - clean up and deallocate the provided VSI
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
   * @vsi: pointer to VSI being cleared
   *
   * This deallocates the VSI's queue resources, removes it from the PF's
@@@ -448,8 -549,103 +553,106 @@@ static irqreturn_t ice_eswitch_msix_cle
  }
  
  /**
++<<<<<<< HEAD
++=======
+  * ice_vsi_alloc_stat_arrays - Allocate statistics arrays
+  * @vsi: VSI pointer
+  */
+ static int ice_vsi_alloc_stat_arrays(struct ice_vsi *vsi)
+ {
+ 	struct ice_vsi_stats *vsi_stat;
+ 	struct ice_pf *pf = vsi->back;
+ 
+ 	if (vsi->type == ICE_VSI_CHNL)
+ 		return 0;
+ 	if (!pf->vsi_stats)
+ 		return -ENOENT;
+ 
+ 	if (pf->vsi_stats[vsi->idx])
+ 	/* realloc will happen in rebuild path */
+ 		return 0;
+ 
+ 	vsi_stat = kzalloc(sizeof(*vsi_stat), GFP_KERNEL);
+ 	if (!vsi_stat)
+ 		return -ENOMEM;
+ 
+ 	vsi_stat->tx_ring_stats =
+ 		kcalloc(vsi->alloc_txq, sizeof(*vsi_stat->tx_ring_stats),
+ 			GFP_KERNEL);
+ 	if (!vsi_stat->tx_ring_stats)
+ 		goto err_alloc_tx;
+ 
+ 	vsi_stat->rx_ring_stats =
+ 		kcalloc(vsi->alloc_rxq, sizeof(*vsi_stat->rx_ring_stats),
+ 			GFP_KERNEL);
+ 	if (!vsi_stat->rx_ring_stats)
+ 		goto err_alloc_rx;
+ 
+ 	pf->vsi_stats[vsi->idx] = vsi_stat;
+ 
+ 	return 0;
+ 
+ err_alloc_rx:
+ 	kfree(vsi_stat->rx_ring_stats);
+ err_alloc_tx:
+ 	kfree(vsi_stat->tx_ring_stats);
+ 	kfree(vsi_stat);
+ 	pf->vsi_stats[vsi->idx] = NULL;
+ 	return -ENOMEM;
+ }
+ 
+ /**
+  * ice_vsi_alloc_def - set default values for already allocated VSI
+  * @vsi: ptr to VSI
+  * @vf: VF for ICE_VSI_VF and ICE_VSI_CTRL
+  * @ch: ptr to channel
+  */
+ static int
+ ice_vsi_alloc_def(struct ice_vsi *vsi, struct ice_vf *vf,
+ 		  struct ice_channel *ch)
+ {
+ 	if (vsi->type != ICE_VSI_CHNL) {
+ 		ice_vsi_set_num_qs(vsi, vf);
+ 		if (ice_vsi_alloc_arrays(vsi))
+ 			return -ENOMEM;
+ 	}
+ 
+ 	switch (vsi->type) {
+ 	case ICE_VSI_SWITCHDEV_CTRL:
+ 		/* Setup eswitch MSIX irq handler for VSI */
+ 		vsi->irq_handler = ice_eswitch_msix_clean_rings;
+ 		break;
+ 	case ICE_VSI_PF:
+ 		/* Setup default MSIX irq handler for VSI */
+ 		vsi->irq_handler = ice_msix_clean_rings;
+ 		break;
+ 	case ICE_VSI_CTRL:
+ 		/* Setup ctrl VSI MSIX irq handler */
+ 		vsi->irq_handler = ice_msix_clean_ctrl_vsi;
+ 		break;
+ 	case ICE_VSI_CHNL:
+ 		if (!ch)
+ 			return -EINVAL;
+ 
+ 		vsi->num_rxq = ch->num_rxq;
+ 		vsi->num_txq = ch->num_txq;
+ 		vsi->next_base_q = ch->base_q;
+ 		break;
+ 	case ICE_VSI_VF:
+ 		break;
+ 	default:
+ 		ice_vsi_free_arrays(vsi);
+ 		return -EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /**
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
   * ice_vsi_alloc - Allocates the next available struct VSI in the PF
   * @pf: board private structure
+  * @pi: pointer to the port_info instance
   * @vsi_type: type of VSI
   * @ch: ptr to channel
   * @vf: VF for ICE_VSI_VF and ICE_VSI_CTRL
@@@ -560,11 -707,7 +714,15 @@@ ice_vsi_alloc(struct ice_pf *pf, struc
  
  	if (vsi->type == ICE_VSI_CTRL && vf)
  		vf->ctrl_vsi_idx = vsi->idx;
++<<<<<<< HEAD
 +	goto unlock_pf;
  
 +err_rings:
 +	devm_kfree(dev, vsi);
 +	vsi = NULL;
++=======
++
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  unlock_pf:
  	mutex_unlock(&pf->sw_mutex);
  	return vsi;
@@@ -2517,34 -2675,65 +2690,85 @@@ static int ice_vsi_cfg_tc_lan(struct ic
  {
  	u16 max_txqs[ICE_MAX_TRAFFIC_CLASS] = { 0 };
  	struct device *dev = ice_pf_to_dev(pf);
- 	struct ice_vsi *vsi;
  	int ret, i;
  
++<<<<<<< HEAD
 +	if (vsi_type == ICE_VSI_CHNL)
 +		vsi = ice_vsi_alloc(pf, vsi_type, ch, NULL);
 +	else if (vsi_type == ICE_VSI_VF || vsi_type == ICE_VSI_CTRL)
 +		vsi = ice_vsi_alloc(pf, vsi_type, NULL, vf);
 +	else
 +		vsi = ice_vsi_alloc(pf, vsi_type, NULL, NULL);
++=======
+ 	/* configure VSI nodes based on number of queues and TC's */
+ 	ice_for_each_traffic_class(i) {
+ 		if (!(vsi->tc_cfg.ena_tc & BIT(i)))
+ 			continue;
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  
- 	if (!vsi) {
- 		dev_err(dev, "could not allocate VSI\n");
- 		return NULL;
+ 		if (vsi->type == ICE_VSI_CHNL) {
+ 			if (!vsi->alloc_txq && vsi->num_txq)
+ 				max_txqs[i] = vsi->num_txq;
+ 			else
+ 				max_txqs[i] = pf->num_lan_tx;
+ 		} else {
+ 			max_txqs[i] = vsi->alloc_txq;
+ 		}
  	}
  
- 	vsi->port_info = pi;
+ 	dev_dbg(dev, "vsi->tc_cfg.ena_tc = %d\n", vsi->tc_cfg.ena_tc);
+ 	ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx, vsi->tc_cfg.ena_tc,
+ 			      max_txqs);
+ 	if (ret) {
+ 		dev_err(dev, "VSI %d failed lan queue config, error %d\n",
+ 			vsi->vsi_num, ret);
+ 		return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * ice_vsi_cfg_def - configure default VSI based on the type
+  * @vsi: pointer to VSI
+  * @vf: pointer to VF to which this VSI connects. This field is used primarily
+  *      for the ICE_VSI_VF type. Other VSI types should pass NULL.
+  * @ch: ptr to channel
+  */
+ static int
+ ice_vsi_cfg_def(struct ice_vsi *vsi, struct ice_vf *vf, struct ice_channel *ch)
+ {
+ 	struct device *dev = ice_pf_to_dev(vsi->back);
+ 	struct ice_pf *pf = vsi->back;
+ 	int ret;
+ 
  	vsi->vsw = pf->first_sw;
 +	if (vsi->type == ICE_VSI_PF)
 +		vsi->ethtype = ETH_P_PAUSE;
  
+ 	ret = ice_vsi_alloc_def(vsi, vf, ch);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/* allocate memory for Tx/Rx ring stat pointers */
+ 	if (ice_vsi_alloc_stat_arrays(vsi))
+ 		goto unroll_vsi_alloc;
+ 
  	ice_alloc_fd_res(vsi);
  
++<<<<<<< HEAD
 +	if (vsi_type != ICE_VSI_CHNL) {
 +		if (ice_vsi_get_qs(vsi)) {
 +			dev_err(dev, "Failed to allocate queues. vsi->idx = %d\n",
 +				vsi->idx);
 +			goto unroll_vsi_alloc;
 +		}
++=======
+ 	if (ice_vsi_get_qs(vsi)) {
+ 		dev_err(dev, "Failed to allocate queues. vsi->idx = %d\n",
+ 			vsi->idx);
+ 		goto unroll_vsi_alloc_stat;
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  	}
  
  	/* set RSS capabilities */
@@@ -2580,7 -2769,19 +2804,15 @@@
  		if (ret)
  			goto unroll_vector_base;
  
 -		ret = ice_vsi_alloc_ring_stats(vsi);
 -		if (ret)
 -			goto unroll_vector_base;
 -
  		ice_vsi_map_rings_to_vectors(vsi);
+ 		if (ice_is_xdp_ena_vsi(vsi)) {
+ 			ret = ice_vsi_determine_xdp_res(vsi);
+ 			if (ret)
+ 				goto unroll_vector_base;
+ 			ret = ice_prepare_xdp_rings(vsi, vsi->xdp_prog);
+ 			if (ret)
+ 				goto unroll_vector_base;
+ 		}
  
  		/* ICE_VSI_CTRL does not need RSS so skip RSS processing */
  		if (vsi->type != ICE_VSI_CTRL)
@@@ -2679,22 -2995,13 +3018,30 @@@ ice_vsi_setup(struct ice_pf *pf, struc
  
  	if (!vsi->agg_node)
  		ice_set_agg_vsi(vsi);
+ 
  	return vsi;
  
++<<<<<<< HEAD
 +unroll_clear_rings:
 +	ice_vsi_clear_rings(vsi);
 +unroll_vector_base:
 +	/* reclaim SW interrupts back to the common pool */
 +	ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
 +	pf->num_avail_sw_msix += vsi->num_q_vectors;
 +unroll_alloc_q_vector:
 +	ice_vsi_free_q_vectors(vsi);
 +unroll_vsi_init:
 +	ice_vsi_delete(vsi);
 +unroll_get_qs:
 +	ice_vsi_put_qs(vsi);
 +unroll_vsi_alloc:
 +	ice_vsi_clear(vsi);
++=======
+ err_vsi_cfg:
+ 	if (vsi_type == ICE_VSI_VF)
+ 		ice_enable_lag(pf->lag);
+ 	ice_vsi_free(vsi);
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  
  	return NULL;
  }
@@@ -3018,47 -3296,8 +3336,51 @@@ int ice_vsi_release(struct ice_vsi *vsi
  	if (test_bit(ICE_FLAG_RSS_ENA, pf->flags))
  		ice_rss_clean(vsi);
  
 +	/* Disable VSI and free resources */
 +	if (vsi->type != ICE_VSI_LB)
 +		ice_vsi_dis_irq(vsi);
  	ice_vsi_close(vsi);
++<<<<<<< HEAD
 +
 +	/* SR-IOV determines needed MSIX resources all at once instead of per
 +	 * VSI since when VFs are spawned we know how many VFs there are and how
 +	 * many interrupts each VF needs. SR-IOV MSIX resources are also
 +	 * cleared in the same manner.
 +	 */
 +	if (vsi->type == ICE_VSI_CTRL && vsi->vf) {
 +		ice_free_vf_ctrl_res(pf, vsi);
 +	} else if (vsi->type != ICE_VSI_VF) {
 +		/* reclaim SW interrupts back to the common pool */
 +		ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
 +		pf->num_avail_sw_msix += vsi->num_q_vectors;
 +	}
 +
 +	if (!ice_is_safe_mode(pf)) {
 +		if (vsi->type == ICE_VSI_PF) {
 +			ice_fltr_remove_eth(vsi, ETH_P_PAUSE, ICE_FLTR_TX,
 +					    ICE_DROP_PACKET);
 +			ice_cfg_sw_lldp(vsi, true, false);
 +			/* The Rx rule will only exist to remove if the LLDP FW
 +			 * engine is currently stopped
 +			 */
 +			if (!test_bit(ICE_FLAG_FW_LLDP_AGENT, pf->flags))
 +				ice_cfg_sw_lldp(vsi, false, false);
 +		}
 +	}
 +
 +	if (ice_is_vsi_dflt_vsi(vsi))
 +		ice_clear_dflt_vsi(vsi);
 +	ice_fltr_remove_all(vsi);
 +	ice_rm_vsi_lan_cfg(vsi->port_info, vsi->idx);
 +	err = ice_rm_vsi_rdma_cfg(vsi->port_info, vsi->idx);
 +	if (err)
 +		dev_err(ice_pf_to_dev(vsi->back), "Failed to remove RDMA scheduler config for VSI %u, err %d\n",
 +			vsi->vsi_num, err);
 +	ice_vsi_delete(vsi);
 +	ice_vsi_free_q_vectors(vsi);
++=======
+ 	ice_vsi_decfg(vsi);
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  
  	if (vsi->netdev) {
  		if (test_bit(ICE_VSI_NETDEV_REGISTERED, vsi->state)) {
@@@ -3072,16 -3311,6 +3394,19 @@@
  		}
  	}
  
++<<<<<<< HEAD
 +	if (vsi->type == ICE_VSI_PF)
 +		ice_devlink_destroy_pf_port(pf);
 +
 +	if (vsi->type == ICE_VSI_VF &&
 +	    vsi->agg_node && vsi->agg_node->valid)
 +		vsi->agg_node->num_vsis--;
 +	ice_vsi_clear_rings(vsi);
 +
 +	ice_vsi_put_qs(vsi);
 +
++=======
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  	/* retain SW VSI data structure since it is needed to unregister and
  	 * free VSI netdev when PF is not in reset recovery pending state,\
  	 * for ex: during rmmod.
@@@ -3213,14 -3483,12 +3538,16 @@@ ice_vsi_rebuild_set_coalesce(struct ice
   *
   * Returns 0 on success and negative value on failure
   */
- int ice_vsi_rebuild(struct ice_vsi *vsi, bool init_vsi)
+ int ice_vsi_rebuild(struct ice_vsi *vsi, int init_vsi)
  {
- 	u16 max_txqs[ICE_MAX_TRAFFIC_CLASS] = { 0 };
  	struct ice_coalesce_stored *coalesce;
++<<<<<<< HEAD
++=======
+ 	int ret, prev_txq, prev_rxq;
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  	int prev_num_q_vectors = 0;
- 	enum ice_vsi_type vtype;
  	struct ice_pf *pf;
 +	int ret, i;
  
  	if (!vsi)
  		return -EINVAL;
@@@ -3239,176 -3504,36 +3563,198 @@@
  
  	prev_num_q_vectors = ice_vsi_rebuild_get_coalesce(vsi, coalesce);
  
++<<<<<<< HEAD
 +	ice_rm_vsi_lan_cfg(vsi->port_info, vsi->idx);
 +	ret = ice_rm_vsi_rdma_cfg(vsi->port_info, vsi->idx);
 +	if (ret)
 +		dev_err(ice_pf_to_dev(vsi->back), "Failed to remove RDMA scheduler config for VSI %u, err %d\n",
 +			vsi->vsi_num, ret);
 +	ice_vsi_free_q_vectors(vsi);
 +
 +	/* SR-IOV determines needed MSIX resources all at once instead of per
 +	 * VSI since when VFs are spawned we know how many VFs there are and how
 +	 * many interrupts each VF needs. SR-IOV MSIX resources are also
 +	 * cleared in the same manner.
 +	 */
 +	if (vtype != ICE_VSI_VF) {
 +		/* reclaim SW interrupts back to the common pool */
 +		ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
 +		pf->num_avail_sw_msix += vsi->num_q_vectors;
 +		vsi->base_vector = 0;
 +	}
 +
 +	if (ice_is_xdp_ena_vsi(vsi))
 +		/* return value check can be skipped here, it always returns
 +		 * 0 if reset is in progress
 +		 */
 +		ice_destroy_xdp_rings(vsi);
 +	ice_vsi_put_qs(vsi);
 +	ice_vsi_clear_rings(vsi);
 +	ice_vsi_free_arrays(vsi);
 +	if (vtype == ICE_VSI_VF)
 +		ice_vsi_set_num_qs(vsi, vsi->vf);
 +	else
 +		ice_vsi_set_num_qs(vsi, NULL);
 +
 +	ret = ice_vsi_alloc_arrays(vsi);
 +	if (ret < 0)
 +		goto err_vsi;
 +
 +	ice_vsi_get_qs(vsi);
 +
 +	ice_alloc_fd_res(vsi);
 +	ice_vsi_set_tc_cfg(vsi);
 +
 +	/* Initialize VSI struct elements and create VSI in FW */
 +	ret = ice_vsi_init(vsi, init_vsi);
 +	if (ret < 0)
 +		goto err_vsi;
 +
 +	switch (vtype) {
 +	case ICE_VSI_CTRL:
 +	case ICE_VSI_SWITCHDEV_CTRL:
 +	case ICE_VSI_PF:
 +		ret = ice_vsi_alloc_q_vectors(vsi);
 +		if (ret)
 +			goto err_rings;
 +
 +		ret = ice_vsi_setup_vector_base(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_set_q_vectors_reg_idx(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_alloc_rings(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ice_vsi_map_rings_to_vectors(vsi);
 +
 +		vsi->stat_offsets_loaded = false;
 +		if (ice_is_xdp_ena_vsi(vsi)) {
 +			ret = ice_vsi_determine_xdp_res(vsi);
 +			if (ret)
 +				goto err_vectors;
 +			ret = ice_prepare_xdp_rings(vsi, vsi->xdp_prog);
 +			if (ret)
 +				goto err_vectors;
 +		}
 +		/* ICE_VSI_CTRL does not need RSS so skip RSS processing */
 +		if (vtype != ICE_VSI_CTRL)
 +			/* Do not exit if configuring RSS had an issue, at
 +			 * least receive traffic on first queue. Hence no
 +			 * need to capture return value
 +			 */
 +			if (test_bit(ICE_FLAG_RSS_ENA, pf->flags))
 +				ice_vsi_cfg_rss_lut_key(vsi);
 +
 +		/* disable or enable CRC stripping */
 +		if (vsi->netdev)
 +			ice_vsi_cfg_crc_strip(vsi, !!(vsi->netdev->features &
 +					      NETIF_F_RXFCS));
 +
 +		break;
 +	case ICE_VSI_VF:
 +		ret = ice_vsi_alloc_q_vectors(vsi);
 +		if (ret)
 +			goto err_rings;
 +
 +		ret = ice_vsi_set_q_vectors_reg_idx(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_alloc_rings(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		vsi->stat_offsets_loaded = false;
 +		break;
 +	case ICE_VSI_CHNL:
 +		if (test_bit(ICE_FLAG_RSS_ENA, pf->flags)) {
 +			ice_vsi_cfg_rss_lut_key(vsi);
 +			ice_vsi_set_rss_flow_fld(vsi);
 +		}
 +		break;
 +	default:
 +		break;
 +	}
 +
 +	/* configure VSI nodes based on number of queues and TC's */
 +	for (i = 0; i < vsi->tc_cfg.numtc; i++) {
 +		/* configure VSI nodes based on number of queues and TC's.
 +		 * ADQ creates VSIs for each TC/Channel but doesn't
 +		 * allocate queues instead it reconfigures the PF queues
 +		 * as per the TC command. So max_txqs should point to the
 +		 * PF Tx queues.
 +		 */
 +		if (vtype == ICE_VSI_CHNL)
 +			max_txqs[i] = pf->num_lan_tx;
 +		else
 +			max_txqs[i] = vsi->alloc_txq;
 +
 +		if (ice_is_xdp_ena_vsi(vsi))
 +			max_txqs[i] += vsi->num_xdp_txq;
 +	}
 +
 +	if (test_bit(ICE_FLAG_TC_MQPRIO, pf->flags))
 +		/* If MQPRIO is set, means channel code path, hence for main
 +		 * VSI's, use TC as 1
 +		 */
 +		ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx, 1, max_txqs);
 +	else
 +		ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx,
 +				      vsi->tc_cfg.ena_tc, max_txqs);
++=======
+ 	prev_txq = vsi->num_txq;
+ 	prev_rxq = vsi->num_rxq;
  
+ 	ice_vsi_decfg(vsi);
+ 	ret = ice_vsi_cfg_def(vsi, vsi->vf, vsi->ch);
+ 	if (ret)
+ 		goto err_vsi_cfg;
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
+ 
+ 	ret = ice_vsi_cfg_tc_lan(pf, vsi);
  	if (ret) {
- 		dev_err(ice_pf_to_dev(pf), "VSI %d failed lan queue config, error %d\n",
- 			vsi->vsi_num, ret);
- 		if (init_vsi) {
+ 		if (init_vsi & ICE_VSI_FLAG_INIT) {
  			ret = -EIO;
- 			goto err_vectors;
+ 			goto err_vsi_cfg_tc_lan;
  		} else {
 -			kfree(coalesce);
  			return ice_schedule_reset(pf, ICE_RESET_PFR);
  		}
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	if (ice_vsi_realloc_stat_arrays(vsi, prev_txq, prev_rxq))
+ 		goto err_vsi_cfg_tc_lan;
+ 
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  	ice_vsi_rebuild_set_coalesce(vsi, coalesce, prev_num_q_vectors);
  	kfree(coalesce);
  
  	return 0;
  
++<<<<<<< HEAD
 +err_vectors:
 +	ice_vsi_free_q_vectors(vsi);
 +err_rings:
 +	if (vsi->netdev) {
 +		vsi->current_netdev_flags = 0;
 +		unregister_netdev(vsi->netdev);
 +		free_netdev(vsi->netdev);
 +		vsi->netdev = NULL;
 +	}
 +err_vsi:
 +	ice_vsi_clear(vsi);
 +	set_bit(ICE_RESET_FAILED, pf->state);
++=======
+ err_vsi_cfg_tc_lan:
+ 	ice_vsi_decfg(vsi);
+ err_vsi_cfg:
++>>>>>>> 6624e780a577 (ice: split ice_vsi_setup into smaller functions)
  	kfree(coalesce);
  	return ret;
  }
* Unmerged path drivers/net/ethernet/intel/ice/ice_lib.c
diff --git a/drivers/net/ethernet/intel/ice/ice_lib.h b/drivers/net/ethernet/intel/ice/ice_lib.h
index dcdf69a693e9..4fa7f3cc587f 100644
--- a/drivers/net/ethernet/intel/ice/ice_lib.h
+++ b/drivers/net/ethernet/intel/ice/ice_lib.h
@@ -61,8 +61,11 @@ int ice_vsi_release(struct ice_vsi *vsi);
 
 void ice_vsi_close(struct ice_vsi *vsi);
 
+int ice_vsi_cfg(struct ice_vsi *vsi, struct ice_vf *vf,
+		struct ice_channel *ch);
 int ice_ena_vsi(struct ice_vsi *vsi, bool locked);
 
+void ice_vsi_decfg(struct ice_vsi *vsi);
 void ice_dis_vsi(struct ice_vsi *vsi, bool locked);
 
 int ice_free_res(struct ice_res_tracker *res, u16 index, u16 id);
@@ -70,7 +73,9 @@ int ice_free_res(struct ice_res_tracker *res, u16 index, u16 id);
 int
 ice_get_res(struct ice_pf *pf, struct ice_res_tracker *res, u16 needed, u16 id);
 
-int ice_vsi_rebuild(struct ice_vsi *vsi, bool init_vsi);
+#define ICE_VSI_FLAG_INIT	BIT(0)
+#define ICE_VSI_FLAG_NO_INIT	0
+int ice_vsi_rebuild(struct ice_vsi *vsi, int init_vsi);
 
 bool ice_is_reset_in_progress(unsigned long *state);
 int ice_wait_for_reset(struct ice_pf *pf, unsigned long timeout);
diff --git a/drivers/net/ethernet/intel/ice/ice_main.c b/drivers/net/ethernet/intel/ice/ice_main.c
index 4662285d8d28..0d8906bcc181 100644
--- a/drivers/net/ethernet/intel/ice/ice_main.c
+++ b/drivers/net/ethernet/intel/ice/ice_main.c
@@ -4250,13 +4250,13 @@ int ice_vsi_recfg_qs(struct ice_vsi *vsi, int new_rx, int new_tx, bool locked)
 
 	/* set for the next time the netdev is started */
 	if (!netif_running(vsi->netdev)) {
-		ice_vsi_rebuild(vsi, false);
+		ice_vsi_rebuild(vsi, ICE_VSI_FLAG_NO_INIT);
 		dev_dbg(ice_pf_to_dev(pf), "Link is down, queue count change happens when link is brought up\n");
 		goto done;
 	}
 
 	ice_vsi_close(vsi);
-	ice_vsi_rebuild(vsi, false);
+	ice_vsi_rebuild(vsi, ICE_VSI_FLAG_NO_INIT);
 	ice_pf_dcb_recfg(pf, locked);
 	ice_vsi_open(vsi);
 done:
@@ -7059,7 +7059,7 @@ static int ice_vsi_rebuild_by_type(struct ice_pf *pf, enum ice_vsi_type type)
 			continue;
 
 		/* rebuild the VSI */
-		err = ice_vsi_rebuild(vsi, true);
+		err = ice_vsi_rebuild(vsi, ICE_VSI_FLAG_INIT);
 		if (err) {
 			dev_err(dev, "rebuild VSI failed, err %d, VSI index %d, type %s\n",
 				err, vsi->idx, ice_vsi_type_str(type));
@@ -8468,7 +8468,7 @@ static int ice_rebuild_channels(struct ice_pf *pf)
 		type = vsi->type;
 
 		/* rebuild ADQ VSI */
-		err = ice_vsi_rebuild(vsi, true);
+		err = ice_vsi_rebuild(vsi, ICE_VSI_FLAG_INIT);
 		if (err) {
 			dev_err(dev, "VSI (type:%s) at index %d rebuild failed, err %d\n",
 				ice_vsi_type_str(type), vsi->idx, err);
@@ -8694,14 +8694,14 @@ static int ice_setup_tc_mqprio_qdisc(struct net_device *netdev, void *type_data)
 	cur_rxq = vsi->num_rxq;
 
 	/* proceed with rebuild main VSI using correct number of queues */
-	ret = ice_vsi_rebuild(vsi, false);
+	ret = ice_vsi_rebuild(vsi, ICE_VSI_FLAG_NO_INIT);
 	if (ret) {
 		/* fallback to current number of queues */
 		dev_info(dev, "Rebuild failed with new queues, try with current number of queues\n");
 		vsi->req_txq = cur_txq;
 		vsi->req_rxq = cur_rxq;
 		clear_bit(ICE_RESET_FAILED, pf->state);
-		if (ice_vsi_rebuild(vsi, false)) {
+		if (ice_vsi_rebuild(vsi, ICE_VSI_FLAG_NO_INIT)) {
 			dev_err(dev, "Rebuild of main VSI failed again\n");
 			return ret;
 		}
diff --git a/drivers/net/ethernet/intel/ice/ice_vf_lib.c b/drivers/net/ethernet/intel/ice/ice_vf_lib.c
index 375eb6493f0f..c3b406df269f 100644
--- a/drivers/net/ethernet/intel/ice/ice_vf_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_vf_lib.c
@@ -256,7 +256,7 @@ static int ice_vf_rebuild_vsi(struct ice_vf *vf)
 	if (WARN_ON(!vsi))
 		return -EINVAL;
 
-	if (ice_vsi_rebuild(vsi, true)) {
+	if (ice_vsi_rebuild(vsi, ICE_VSI_FLAG_INIT)) {
 		dev_err(ice_pf_to_dev(pf), "failed to rebuild VF %d VSI\n",
 			vf->vf_id);
 		return -EIO;
