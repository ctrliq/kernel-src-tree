ice: refactor VSI setup to use parameter structure

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-505.el8
commit-author Jacob Keller <jacob.e.keller@intel.com>
commit 5e509ab237f175a0985e9ca7d696fbdc62434e56
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-505.el8/5e509ab2.failed

The ice_vsi_setup function, ice_vsi_alloc, and ice_vsi_cfg functions have
grown a large number of parameters. These parameters are used to initialize
a new VSI, as well as re-configure an existing VSI

Any time we want to add a new parameter to this function chain, even if it
will usually be unset, we have to change many call sites due to changing
the function signature.

A future change is going to refactor ice_vsi_alloc and ice_vsi_cfg to move
the VSI configuration and initialization all into ice_vsi_cfg.

Before this, refactor the VSI setup flow to use a new ice_vsi_cfg_params
structure. This will contain the configuration (mainly pointers) used to
initialize a VSI.

Pass this from ice_vsi_setup into the related functions such as
ice_vsi_alloc, ice_vsi_cfg, and ice_vsi_cfg_def.

Introduce a helper, ice_vsi_to_params to convert an existing VSI to the
parameters used to initialize it. This will aid in the flows where we
rebuild an existing VSI.

Since we also pass the ICE_VSI_FLAG_INIT to more functions which do not
need (or cannot yet have) the VSI parameters, lets make this clear by
renaming the function parameter to vsi_flags and using a u32 instead of a
signed integer. The name vsi_flags also makes it clear that we may extend
the flags in the future.

This change will make it easier to refactor the setup flow in the future,
and will reduce the complexity required to add a new parameter for
configuration in the future.

	Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
	Tested-by: Gurucharan G <gurucharanx.g@intel.com> (A Contingent worker at Intel)
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
(cherry picked from commit 5e509ab237f175a0985e9ca7d696fbdc62434e56)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_lib.c
#	drivers/net/ethernet/intel/ice/ice_lib.h
#	drivers/net/ethernet/intel/ice/ice_main.c
diff --cc drivers/net/ethernet/intel/ice/ice_lib.c
index dc99c12b0643,90592a231bcb..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_lib.c
@@@ -450,9 -547,99 +450,13 @@@ static irqreturn_t ice_eswitch_msix_cle
  /**
   * ice_vsi_alloc - Allocates the next available struct VSI in the PF
   * @pf: board private structure
++<<<<<<< HEAD
 + * @vsi_type: type of VSI
 + * @ch: ptr to channel
 + * @vf: VF for ICE_VSI_VF and ICE_VSI_CTRL
++=======
+  * @params: parameters to use when allocating the new VSI
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
   *
   * The VF pointer is used for ICE_VSI_VF and ICE_VSI_CTRL. For ICE_VSI_CTRL,
   * it may be NULL in the case there is no association with a VF. For
@@@ -461,8 -648,7 +465,12 @@@
   * returns a pointer to a VSI on success, NULL on failure.
   */
  static struct ice_vsi *
++<<<<<<< HEAD
 +ice_vsi_alloc(struct ice_pf *pf, enum ice_vsi_type vsi_type,
 +	      struct ice_channel *ch, struct ice_vf *vf)
++=======
+ ice_vsi_alloc(struct ice_pf *pf, struct ice_vsi_cfg_params *params)
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  {
  	struct device *dev = ice_pf_to_dev(pf);
  	struct ice_vsi *vsi = NULL;
@@@ -486,85 -672,31 +494,102 @@@
  	if (!vsi)
  		goto unlock_pf;
  
- 	vsi->type = vsi_type;
+ 	vsi->type = params->type;
  	vsi->back = pf;
++<<<<<<< HEAD
++=======
+ 	vsi->port_info = params->pi;
+ 	/* For VSIs which don't have a connected VF, this will be NULL */
+ 	vsi->vf = params->vf;
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  	set_bit(ICE_VSI_DOWN, vsi->state);
  
 -	/* fill slot and make note of the index */
 -	vsi->idx = pf->next_vsi;
 -	pf->vsi[pf->next_vsi] = vsi;
 +	if (vsi_type == ICE_VSI_VF)
 +		ice_vsi_set_num_qs(vsi, vf);
 +	else if (vsi_type != ICE_VSI_CHNL)
 +		ice_vsi_set_num_qs(vsi, NULL);
  
 -	/* prepare pf->next_vsi for next use */
 -	pf->next_vsi = ice_get_free_slot(pf->vsi, pf->num_alloc_vsi,
 -					 pf->next_vsi);
 +	switch (vsi->type) {
 +	case ICE_VSI_SWITCHDEV_CTRL:
 +		if (ice_vsi_alloc_arrays(vsi))
 +			goto err_rings;
  
++<<<<<<< HEAD
 +		/* Setup eswitch MSIX irq handler for VSI */
 +		vsi->irq_handler = ice_eswitch_msix_clean_rings;
 +		break;
 +	case ICE_VSI_PF:
 +		if (ice_vsi_alloc_arrays(vsi))
 +			goto err_rings;
 +
 +		/* Setup default MSIX irq handler for VSI */
 +		vsi->irq_handler = ice_msix_clean_rings;
 +		break;
 +	case ICE_VSI_CTRL:
 +		if (ice_vsi_alloc_arrays(vsi))
 +			goto err_rings;
 +
 +		/* Setup ctrl VSI MSIX irq handler */
 +		vsi->irq_handler = ice_msix_clean_ctrl_vsi;
 +
 +		/* For the PF control VSI this is NULL, for the VF control VSI
 +		 * this will be the first VF to allocate it.
 +		 */
 +		vsi->vf = vf;
 +		break;
 +	case ICE_VSI_VF:
 +		if (ice_vsi_alloc_arrays(vsi))
 +			goto err_rings;
 +		vsi->vf = vf;
 +		break;
 +	case ICE_VSI_CHNL:
 +		if (!ch)
 +			goto err_rings;
 +		vsi->num_rxq = ch->num_rxq;
 +		vsi->num_txq = ch->num_txq;
 +		vsi->next_base_q = ch->base_q;
 +		break;
 +	case ICE_VSI_LB:
 +		if (ice_vsi_alloc_arrays(vsi))
 +			goto err_rings;
 +		break;
 +	default:
 +		dev_warn(dev, "Unknown VSI type %d\n", vsi->type);
 +		goto unlock_pf;
++=======
+ 	if (vsi->type == ICE_VSI_CTRL) {
+ 		if (vsi->vf) {
+ 			WARN_ON(vsi->vf->ctrl_vsi_idx != ICE_NO_VSI);
+ 			vsi->vf->ctrl_vsi_idx = vsi->idx;
+ 		} else {
+ 			WARN_ON(pf->ctrl_vsi_idx != ICE_NO_VSI);
+ 			pf->ctrl_vsi_idx = vsi->idx;
+ 		}
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
 +	}
 +
 +	if (vsi->type == ICE_VSI_CTRL && !vf) {
 +		/* Use the last VSI slot as the index for PF control VSI */
 +		vsi->idx = pf->num_alloc_vsi - 1;
 +		pf->ctrl_vsi_idx = vsi->idx;
 +		pf->vsi[vsi->idx] = vsi;
 +	} else {
 +		/* fill slot and make note of the index */
 +		vsi->idx = pf->next_vsi;
 +		pf->vsi[pf->next_vsi] = vsi;
 +
 +		/* prepare pf->next_vsi for next use */
 +		pf->next_vsi = ice_get_free_slot(pf->vsi, pf->num_alloc_vsi,
 +						 pf->next_vsi);
  	}
  
 +	if (vsi->type == ICE_VSI_CTRL && vf)
 +		vf->ctrl_vsi_idx = vsi->idx;
 +	goto unlock_pf;
 +
 +err_rings:
 +	devm_kfree(dev, vsi);
 +	vsi = NULL;
  unlock_pf:
  	mutex_unlock(&pf->sw_mutex);
  	return vsi;
@@@ -1129,12 -1261,15 +1154,23 @@@ ice_chnl_vsi_setup_q_map(struct ice_vs
  /**
   * ice_vsi_init - Create and initialize a VSI
   * @vsi: the VSI being configured
++<<<<<<< HEAD
 + * @init_vsi: is this call creating a VSI
++=======
+  * @vsi_flags: VSI configuration flags
+  *
+  * Set ICE_FLAG_VSI_INIT to initialize a new VSI context, clear it to
+  * reconfigure an existing context.
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
   *
   * This initializes a VSI context depending on the VSI type to be added and
   * passes it down to the add_vsi aq command to create a new VSI.
   */
++<<<<<<< HEAD
 +static int ice_vsi_init(struct ice_vsi *vsi, bool init_vsi)
++=======
+ static int ice_vsi_init(struct ice_vsi *vsi, u32 vsi_flags)
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  {
  	struct ice_pf *pf = vsi->back;
  	struct ice_hw *hw = &pf->hw;
@@@ -1196,7 -1331,7 +1232,11 @@@
  		/* if updating VSI context, make sure to set valid_section:
  		 * to indicate which section of VSI context being updated
  		 */
++<<<<<<< HEAD
 +		if (!init_vsi)
++=======
+ 		if (!(vsi_flags & ICE_VSI_FLAG_INIT))
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  			ctxt->info.valid_sections |=
  				cpu_to_le16(ICE_AQ_VSI_PROP_Q_OPT_VALID);
  	}
@@@ -1209,7 -1344,8 +1249,12 @@@
  		if (ret)
  			goto out;
  
++<<<<<<< HEAD
 +		if (!init_vsi) /* means VSI being updated */
++=======
+ 		if (!(vsi_flags & ICE_VSI_FLAG_INIT))
+ 			/* means VSI being updated */
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  			/* must to indicate which section of VSI context are
  			 * being modified
  			 */
@@@ -1224,7 -1360,7 +1269,11 @@@
  			cpu_to_le16(ICE_AQ_VSI_PROP_SECURITY_VALID);
  	}
  
++<<<<<<< HEAD
 +	if (init_vsi) {
++=======
+ 	if (vsi_flags & ICE_VSI_FLAG_INIT) {
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  		ret = ice_add_vsi(hw, vsi->idx, ctxt, NULL);
  		if (ret) {
  			dev_err(dev, "Add VSI failed, err %d\n", ret);
@@@ -2517,25 -2667,56 +2566,61 @@@ ice_vsi_setup(struct ice_pf *pf, struc
  {
  	u16 max_txqs[ICE_MAX_TRAFFIC_CLASS] = { 0 };
  	struct device *dev = ice_pf_to_dev(pf);
 +	struct ice_vsi *vsi;
  	int ret, i;
  
 -	/* configure VSI nodes based on number of queues and TC's */
 -	ice_for_each_traffic_class(i) {
 -		if (!(vsi->tc_cfg.ena_tc & BIT(i)))
 -			continue;
 +	if (vsi_type == ICE_VSI_CHNL)
 +		vsi = ice_vsi_alloc(pf, vsi_type, ch, NULL);
 +	else if (vsi_type == ICE_VSI_VF || vsi_type == ICE_VSI_CTRL)
 +		vsi = ice_vsi_alloc(pf, vsi_type, NULL, vf);
 +	else
 +		vsi = ice_vsi_alloc(pf, vsi_type, NULL, NULL);
  
 -		if (vsi->type == ICE_VSI_CHNL) {
 -			if (!vsi->alloc_txq && vsi->num_txq)
 -				max_txqs[i] = vsi->num_txq;
 -			else
 -				max_txqs[i] = pf->num_lan_tx;
 -		} else {
 -			max_txqs[i] = vsi->alloc_txq;
 -		}
 +	if (!vsi) {
 +		dev_err(dev, "could not allocate VSI\n");
 +		return NULL;
  	}
  
++<<<<<<< HEAD
 +	vsi->port_info = pi;
 +	vsi->vsw = pf->first_sw;
 +	if (vsi->type == ICE_VSI_PF)
 +		vsi->ethtype = ETH_P_PAUSE;
++=======
+ 	dev_dbg(dev, "vsi->tc_cfg.ena_tc = %d\n", vsi->tc_cfg.ena_tc);
+ 	ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx, vsi->tc_cfg.ena_tc,
+ 			      max_txqs);
+ 	if (ret) {
+ 		dev_err(dev, "VSI %d failed lan queue config, error %d\n",
+ 			vsi->vsi_num, ret);
+ 		return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * ice_vsi_cfg_def - configure default VSI based on the type
+  * @vsi: pointer to VSI
+  * @params: the parameters to configure this VSI with
+  */
+ static int
+ ice_vsi_cfg_def(struct ice_vsi *vsi, struct ice_vsi_cfg_params *params)
+ {
+ 	struct device *dev = ice_pf_to_dev(vsi->back);
+ 	struct ice_pf *pf = vsi->back;
+ 	int ret;
+ 
+ 	vsi->vsw = pf->first_sw;
+ 
+ 	ret = ice_vsi_alloc_def(vsi, params->ch);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/* allocate memory for Tx/Rx ring stat pointers */
+ 	if (ice_vsi_alloc_stat_arrays(vsi))
+ 		goto unroll_vsi_alloc;
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  
  	ice_alloc_fd_res(vsi);
  
@@@ -2554,7 -2733,7 +2639,11 @@@
  	ice_vsi_set_tc_cfg(vsi);
  
  	/* create the VSI */
++<<<<<<< HEAD
 +	ret = ice_vsi_init(vsi, true);
++=======
+ 	ret = ice_vsi_init(vsi, params->flags);
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  	if (ret)
  		goto unroll_get_qs;
  
@@@ -2637,29 -2836,135 +2726,153 @@@
  		goto unroll_vsi_init;
  	}
  
 -	return 0;
 +	/* configure VSI nodes based on number of queues and TC's */
 +	ice_for_each_traffic_class(i) {
 +		if (!(vsi->tc_cfg.ena_tc & BIT(i)))
 +			continue;
  
++<<<<<<< HEAD
 +		if (vsi->type == ICE_VSI_CHNL) {
 +			if (!vsi->alloc_txq && vsi->num_txq)
 +				max_txqs[i] = vsi->num_txq;
 +			else
 +				max_txqs[i] = pf->num_lan_tx;
 +		} else {
 +			max_txqs[i] = vsi->alloc_txq;
 +		}
++=======
+ unroll_vector_base:
+ 	/* reclaim SW interrupts back to the common pool */
+ 	ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
+ 	pf->num_avail_sw_msix += vsi->num_q_vectors;
+ unroll_alloc_q_vector:
+ 	ice_vsi_free_q_vectors(vsi);
+ unroll_vsi_init:
+ 	ice_vsi_delete_from_hw(vsi);
+ unroll_get_qs:
+ 	ice_vsi_put_qs(vsi);
+ unroll_vsi_alloc_stat:
+ 	ice_vsi_free_stats(vsi);
+ unroll_vsi_alloc:
+ 	ice_vsi_free_arrays(vsi);
+ 	return ret;
+ }
+ 
+ /**
+  * ice_vsi_cfg - configure VSI and tc on it
+  * @vsi: pointer to VSI
+  * @params: parameters used to configure this VSI
+  */
+ int ice_vsi_cfg(struct ice_vsi *vsi, struct ice_vsi_cfg_params *params)
+ {
+ 	int ret;
+ 
+ 	ret = ice_vsi_cfg_def(vsi, params);
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = ice_vsi_cfg_tc_lan(vsi->back, vsi);
+ 	if (ret)
+ 		ice_vsi_decfg(vsi);
+ 
+ 	return ret;
+ }
+ 
+ /**
+  * ice_vsi_decfg - remove all VSI configuration
+  * @vsi: pointer to VSI
+  */
+ void ice_vsi_decfg(struct ice_vsi *vsi)
+ {
+ 	struct ice_pf *pf = vsi->back;
+ 	int err;
+ 
+ 	/* The Rx rule will only exist to remove if the LLDP FW
+ 	 * engine is currently stopped
+ 	 */
+ 	if (!ice_is_safe_mode(pf) && vsi->type == ICE_VSI_PF &&
+ 	    !test_bit(ICE_FLAG_FW_LLDP_AGENT, pf->flags))
+ 		ice_cfg_sw_lldp(vsi, false, false);
+ 
+ 	ice_fltr_remove_all(vsi);
+ 	ice_rm_vsi_lan_cfg(vsi->port_info, vsi->idx);
+ 	err = ice_rm_vsi_rdma_cfg(vsi->port_info, vsi->idx);
+ 	if (err)
+ 		dev_err(ice_pf_to_dev(pf), "Failed to remove RDMA scheduler config for VSI %u, err %d\n",
+ 			vsi->vsi_num, err);
+ 
+ 	if (ice_is_xdp_ena_vsi(vsi))
+ 		/* return value check can be skipped here, it always returns
+ 		 * 0 if reset is in progress
+ 		 */
+ 		ice_destroy_xdp_rings(vsi);
+ 
+ 	ice_vsi_clear_rings(vsi);
+ 	ice_vsi_free_q_vectors(vsi);
+ 	ice_vsi_put_qs(vsi);
+ 	ice_vsi_free_arrays(vsi);
+ 
+ 	/* SR-IOV determines needed MSIX resources all at once instead of per
+ 	 * VSI since when VFs are spawned we know how many VFs there are and how
+ 	 * many interrupts each VF needs. SR-IOV MSIX resources are also
+ 	 * cleared in the same manner.
+ 	 */
+ 	if (vsi->type == ICE_VSI_CTRL && vsi->vf) {
+ 		ice_free_vf_ctrl_res(pf, vsi);
+ 	} else if (vsi->type != ICE_VSI_VF) {
+ 		/* reclaim SW interrupts back to the common pool */
+ 		ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
+ 		pf->num_avail_sw_msix += vsi->num_q_vectors;
+ 		vsi->base_vector = 0;
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  	}
  
 -	if (vsi->type == ICE_VSI_VF &&
 -	    vsi->agg_node && vsi->agg_node->valid)
 -		vsi->agg_node->num_vsis--;
 -	if (vsi->agg_node) {
 -		vsi->agg_node->valid = false;
 -		vsi->agg_node->agg_id = 0;
 +	dev_dbg(dev, "vsi->tc_cfg.ena_tc = %d\n", vsi->tc_cfg.ena_tc);
 +	ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx, vsi->tc_cfg.ena_tc,
 +			      max_txqs);
 +	if (ret) {
 +		dev_err(dev, "VSI %d failed lan queue config, error %d\n",
 +			vsi->vsi_num, ret);
 +		goto unroll_clear_rings;
  	}
++<<<<<<< HEAD
++=======
+ }
+ 
+ /**
+  * ice_vsi_setup - Set up a VSI by a given type
+  * @pf: board private structure
+  * @params: parameters to use when creating the VSI
+  *
+  * This allocates the sw VSI structure and its queue resources.
+  *
+  * Returns pointer to the successfully allocated and configured VSI sw struct on
+  * success, NULL on failure.
+  */
+ struct ice_vsi *
+ ice_vsi_setup(struct ice_pf *pf, struct ice_vsi_cfg_params *params)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 	struct ice_vsi *vsi;
+ 	int ret;
+ 
+ 	/* ice_vsi_setup can only initialize a new VSI, and we must have
+ 	 * a port_info structure for it.
+ 	 */
+ 	if (WARN_ON(!(params->flags & ICE_VSI_FLAG_INIT)) ||
+ 	    WARN_ON(!params->pi))
+ 		return NULL;
+ 
+ 	vsi = ice_vsi_alloc(pf, params);
+ 	if (!vsi) {
+ 		dev_err(dev, "could not allocate VSI\n");
+ 		return NULL;
+ 	}
+ 
+ 	ret = ice_vsi_cfg(vsi, params);
+ 	if (ret)
+ 		goto err_vsi_cfg;
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  
  	/* Add switch rule to drop all Tx Flow Control Frames, of look up
  	 * type ETHERTYPE from VSIs, and restrict malicious VF from sending
@@@ -2679,22 -2983,13 +2892,29 @@@
  
  	if (!vsi->agg_node)
  		ice_set_agg_vsi(vsi);
 -
  	return vsi;
  
++<<<<<<< HEAD
 +unroll_clear_rings:
 +	ice_vsi_clear_rings(vsi);
 +unroll_vector_base:
 +	/* reclaim SW interrupts back to the common pool */
 +	ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
 +	pf->num_avail_sw_msix += vsi->num_q_vectors;
 +unroll_alloc_q_vector:
 +	ice_vsi_free_q_vectors(vsi);
 +unroll_vsi_init:
 +	ice_vsi_delete(vsi);
 +unroll_get_qs:
 +	ice_vsi_put_qs(vsi);
 +unroll_vsi_alloc:
 +	ice_vsi_clear(vsi);
++=======
+ err_vsi_cfg:
+ 	if (params->type == ICE_VSI_VF)
+ 		ice_enable_lag(pf->lag);
+ 	ice_vsi_free(vsi);
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  
  	return NULL;
  }
@@@ -3209,29 -3426,72 +3429,45 @@@ ice_vsi_rebuild_set_coalesce(struct ice
  /**
   * ice_vsi_rebuild - Rebuild VSI after reset
   * @vsi: VSI to be rebuild
++<<<<<<< HEAD
 + * @init_vsi: is this an initialization or a reconfigure of the VSI
 + *
 + * Returns 0 on success and negative value on failure
 + */
 +int ice_vsi_rebuild(struct ice_vsi *vsi, bool init_vsi)
 +{
 +	u16 max_txqs[ICE_MAX_TRAFFIC_CLASS] = { 0 };
++=======
+  * @vsi_flags: flags used for VSI rebuild flow
+  *
+  * Set vsi_flags to ICE_VSI_FLAG_INIT to initialize a new VSI, or
+  * ICE_VSI_FLAG_NO_INIT to rebuild an existing VSI in hardware.
+  *
+  * Returns 0 on success and negative value on failure
+  */
+ int ice_vsi_rebuild(struct ice_vsi *vsi, u32 vsi_flags)
+ {
+ 	struct ice_vsi_cfg_params params = {};
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  	struct ice_coalesce_stored *coalesce;
 -	int ret, prev_txq, prev_rxq;
  	int prev_num_q_vectors = 0;
 +	enum ice_vsi_type vtype;
  	struct ice_pf *pf;
 +	int ret, i;
  
  	if (!vsi)
  		return -EINVAL;
  
+ 	params = ice_vsi_to_params(vsi);
+ 	params.flags = vsi_flags;
+ 
  	pf = vsi->back;
 -	if (WARN_ON(vsi->type == ICE_VSI_VF && !vsi->vf))
 +	vtype = vsi->type;
 +	if (WARN_ON(vtype == ICE_VSI_VF && !vsi->vf))
  		return -EINVAL;
  
 +	ice_vsi_init_vlan_ops(vsi);
 +
  	coalesce = kcalloc(vsi->num_q_vectors,
  			   sizeof(struct ice_coalesce_stored), GFP_KERNEL);
  	if (!coalesce)
@@@ -3239,156 -3499,21 +3475,168 @@@
  
  	prev_num_q_vectors = ice_vsi_rebuild_get_coalesce(vsi, coalesce);
  
++<<<<<<< HEAD
 +	ice_rm_vsi_lan_cfg(vsi->port_info, vsi->idx);
 +	ret = ice_rm_vsi_rdma_cfg(vsi->port_info, vsi->idx);
++=======
+ 	prev_txq = vsi->num_txq;
+ 	prev_rxq = vsi->num_rxq;
+ 
+ 	ice_vsi_decfg(vsi);
+ 	ret = ice_vsi_cfg_def(vsi, &params);
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  	if (ret)
 -		goto err_vsi_cfg;
 +		dev_err(ice_pf_to_dev(vsi->back), "Failed to remove RDMA scheduler config for VSI %u, err %d\n",
 +			vsi->vsi_num, ret);
 +	ice_vsi_free_q_vectors(vsi);
 +
 +	/* SR-IOV determines needed MSIX resources all at once instead of per
 +	 * VSI since when VFs are spawned we know how many VFs there are and how
 +	 * many interrupts each VF needs. SR-IOV MSIX resources are also
 +	 * cleared in the same manner.
 +	 */
 +	if (vtype != ICE_VSI_VF) {
 +		/* reclaim SW interrupts back to the common pool */
 +		ice_free_res(pf->irq_tracker, vsi->base_vector, vsi->idx);
 +		pf->num_avail_sw_msix += vsi->num_q_vectors;
 +		vsi->base_vector = 0;
 +	}
 +
 +	if (ice_is_xdp_ena_vsi(vsi))
 +		/* return value check can be skipped here, it always returns
 +		 * 0 if reset is in progress
 +		 */
 +		ice_destroy_xdp_rings(vsi);
 +	ice_vsi_put_qs(vsi);
 +	ice_vsi_clear_rings(vsi);
 +	ice_vsi_free_arrays(vsi);
 +	if (vtype == ICE_VSI_VF)
 +		ice_vsi_set_num_qs(vsi, vsi->vf);
 +	else
 +		ice_vsi_set_num_qs(vsi, NULL);
 +
 +	ret = ice_vsi_alloc_arrays(vsi);
 +	if (ret < 0)
 +		goto err_vsi;
 +
 +	ice_vsi_get_qs(vsi);
 +
 +	ice_alloc_fd_res(vsi);
 +	ice_vsi_set_tc_cfg(vsi);
 +
 +	/* Initialize VSI struct elements and create VSI in FW */
 +	ret = ice_vsi_init(vsi, init_vsi);
 +	if (ret < 0)
 +		goto err_vsi;
 +
 +	switch (vtype) {
 +	case ICE_VSI_CTRL:
 +	case ICE_VSI_SWITCHDEV_CTRL:
 +	case ICE_VSI_PF:
 +		ret = ice_vsi_alloc_q_vectors(vsi);
 +		if (ret)
 +			goto err_rings;
 +
 +		ret = ice_vsi_setup_vector_base(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_set_q_vectors_reg_idx(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_alloc_rings(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ice_vsi_map_rings_to_vectors(vsi);
 +
 +		vsi->stat_offsets_loaded = false;
 +		if (ice_is_xdp_ena_vsi(vsi)) {
 +			ret = ice_vsi_determine_xdp_res(vsi);
 +			if (ret)
 +				goto err_vectors;
 +			ret = ice_prepare_xdp_rings(vsi, vsi->xdp_prog);
 +			if (ret)
 +				goto err_vectors;
 +		}
 +		/* ICE_VSI_CTRL does not need RSS so skip RSS processing */
 +		if (vtype != ICE_VSI_CTRL)
 +			/* Do not exit if configuring RSS had an issue, at
 +			 * least receive traffic on first queue. Hence no
 +			 * need to capture return value
 +			 */
 +			if (test_bit(ICE_FLAG_RSS_ENA, pf->flags))
 +				ice_vsi_cfg_rss_lut_key(vsi);
 +
 +		/* disable or enable CRC stripping */
 +		if (vsi->netdev)
 +			ice_vsi_cfg_crc_strip(vsi, !!(vsi->netdev->features &
 +					      NETIF_F_RXFCS));
 +
 +		break;
 +	case ICE_VSI_VF:
 +		ret = ice_vsi_alloc_q_vectors(vsi);
 +		if (ret)
 +			goto err_rings;
 +
 +		ret = ice_vsi_set_q_vectors_reg_idx(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		ret = ice_vsi_alloc_rings(vsi);
 +		if (ret)
 +			goto err_vectors;
 +
 +		vsi->stat_offsets_loaded = false;
 +		break;
 +	case ICE_VSI_CHNL:
 +		if (test_bit(ICE_FLAG_RSS_ENA, pf->flags)) {
 +			ice_vsi_cfg_rss_lut_key(vsi);
 +			ice_vsi_set_rss_flow_fld(vsi);
 +		}
 +		break;
 +	default:
 +		break;
 +	}
 +
 +	/* configure VSI nodes based on number of queues and TC's */
 +	for (i = 0; i < vsi->tc_cfg.numtc; i++) {
 +		/* configure VSI nodes based on number of queues and TC's.
 +		 * ADQ creates VSIs for each TC/Channel but doesn't
 +		 * allocate queues instead it reconfigures the PF queues
 +		 * as per the TC command. So max_txqs should point to the
 +		 * PF Tx queues.
 +		 */
 +		if (vtype == ICE_VSI_CHNL)
 +			max_txqs[i] = pf->num_lan_tx;
 +		else
 +			max_txqs[i] = vsi->alloc_txq;
 +
 +		if (ice_is_xdp_ena_vsi(vsi))
 +			max_txqs[i] += vsi->num_xdp_txq;
 +	}
 +
 +	if (test_bit(ICE_FLAG_TC_MQPRIO, pf->flags))
 +		/* If MQPRIO is set, means channel code path, hence for main
 +		 * VSI's, use TC as 1
 +		 */
 +		ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx, 1, max_txqs);
 +	else
 +		ret = ice_cfg_vsi_lan(vsi->port_info, vsi->idx,
 +				      vsi->tc_cfg.ena_tc, max_txqs);
  
 -	ret = ice_vsi_cfg_tc_lan(pf, vsi);
  	if (ret) {
++<<<<<<< HEAD
 +		dev_err(ice_pf_to_dev(pf), "VSI %d failed lan queue config, error %d\n",
 +			vsi->vsi_num, ret);
 +		if (init_vsi) {
++=======
+ 		if (vsi_flags & ICE_VSI_FLAG_INIT) {
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  			ret = -EIO;
 -			goto err_vsi_cfg_tc_lan;
 +			goto err_vectors;
  		} else {
 -			kfree(coalesce);
  			return ice_schedule_reset(pf, ICE_RESET_PFR);
  		}
  	}
diff --cc drivers/net/ethernet/intel/ice/ice_lib.h
index dcdf69a693e9,75221478f2dc..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_lib.h
+++ b/drivers/net/ethernet/intel/ice/ice_lib.h
@@@ -70,7 -109,8 +109,12 @@@ int ice_free_res(struct ice_res_tracke
  int
  ice_get_res(struct ice_pf *pf, struct ice_res_tracker *res, u16 needed, u16 id);
  
++<<<<<<< HEAD
 +int ice_vsi_rebuild(struct ice_vsi *vsi, bool init_vsi);
++=======
+ int ice_vsi_rebuild(struct ice_vsi *vsi, u32 vsi_flags);
+ int ice_vsi_cfg(struct ice_vsi *vsi, struct ice_vsi_cfg_params *params);
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  
  bool ice_is_reset_in_progress(unsigned long *state);
  int ice_wait_for_reset(struct ice_pf *pf, unsigned long timeout);
diff --cc drivers/net/ethernet/intel/ice/ice_main.c
index 4662285d8d28,e7ea63adfebb..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_main.c
+++ b/drivers/net/ethernet/intel/ice/ice_main.c
@@@ -4654,6 -4641,450 +4679,453 @@@ err_devlink_create
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ static void ice_deinit_eth(struct ice_pf *pf)
+ {
+ 	struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
+ 	if (!vsi)
+ 		return;
+ 
+ 	ice_vsi_close(vsi);
+ 	ice_unregister_netdev(vsi);
+ 	ice_devlink_destroy_pf_port(pf);
+ 	ice_tc_indir_block_unregister(vsi);
+ 	ice_decfg_netdev(vsi);
+ }
+ 
+ static int ice_init_dev(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 	struct ice_hw *hw = &pf->hw;
+ 	int err;
+ 
+ 	err = ice_init_hw(hw);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_hw failed: %d\n", err);
+ 		return err;
+ 	}
+ 
+ 	ice_init_feature_support(pf);
+ 
+ 	ice_request_fw(pf);
+ 
+ 	/* if ice_request_fw fails, ICE_FLAG_ADV_FEATURES bit won't be
+ 	 * set in pf->state, which will cause ice_is_safe_mode to return
+ 	 * true
+ 	 */
+ 	if (ice_is_safe_mode(pf)) {
+ 		/* we already got function/device capabilities but these don't
+ 		 * reflect what the driver needs to do in safe mode. Instead of
+ 		 * adding conditional logic everywhere to ignore these
+ 		 * device/function capabilities, override them.
+ 		 */
+ 		ice_set_safe_mode_caps(hw);
+ 	}
+ 
+ 	err = ice_init_pf(pf);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_pf failed: %d\n", err);
+ 		goto err_init_pf;
+ 	}
+ 
+ 	pf->hw.udp_tunnel_nic.set_port = ice_udp_tunnel_set_port;
+ 	pf->hw.udp_tunnel_nic.unset_port = ice_udp_tunnel_unset_port;
+ 	pf->hw.udp_tunnel_nic.flags = UDP_TUNNEL_NIC_INFO_MAY_SLEEP;
+ 	pf->hw.udp_tunnel_nic.shared = &pf->hw.udp_tunnel_shared;
+ 	if (pf->hw.tnl.valid_count[TNL_VXLAN]) {
+ 		pf->hw.udp_tunnel_nic.tables[0].n_entries =
+ 			pf->hw.tnl.valid_count[TNL_VXLAN];
+ 		pf->hw.udp_tunnel_nic.tables[0].tunnel_types =
+ 			UDP_TUNNEL_TYPE_VXLAN;
+ 	}
+ 	if (pf->hw.tnl.valid_count[TNL_GENEVE]) {
+ 		pf->hw.udp_tunnel_nic.tables[1].n_entries =
+ 			pf->hw.tnl.valid_count[TNL_GENEVE];
+ 		pf->hw.udp_tunnel_nic.tables[1].tunnel_types =
+ 			UDP_TUNNEL_TYPE_GENEVE;
+ 	}
+ 
+ 	err = ice_init_interrupt_scheme(pf);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_interrupt_scheme failed: %d\n", err);
+ 		err = -EIO;
+ 		goto err_init_interrupt_scheme;
+ 	}
+ 
+ 	/* In case of MSIX we are going to setup the misc vector right here
+ 	 * to handle admin queue events etc. In case of legacy and MSI
+ 	 * the misc functionality and queue processing is combined in
+ 	 * the same vector and that gets setup at open.
+ 	 */
+ 	err = ice_req_irq_msix_misc(pf);
+ 	if (err) {
+ 		dev_err(dev, "setup of misc vector failed: %d\n", err);
+ 		goto err_req_irq_msix_misc;
+ 	}
+ 
+ 	return 0;
+ 
+ err_req_irq_msix_misc:
+ 	ice_clear_interrupt_scheme(pf);
+ err_init_interrupt_scheme:
+ 	ice_deinit_pf(pf);
+ err_init_pf:
+ 	ice_deinit_hw(hw);
+ 	return err;
+ }
+ 
+ static void ice_deinit_dev(struct ice_pf *pf)
+ {
+ 	ice_free_irq_msix_misc(pf);
+ 	ice_clear_interrupt_scheme(pf);
+ 	ice_deinit_pf(pf);
+ 	ice_deinit_hw(&pf->hw);
+ }
+ 
+ static void ice_init_features(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 
+ 	if (ice_is_safe_mode(pf))
+ 		return;
+ 
+ 	/* initialize DDP driven features */
+ 	if (test_bit(ICE_FLAG_PTP_SUPPORTED, pf->flags))
+ 		ice_ptp_init(pf);
+ 
+ 	if (ice_is_feature_supported(pf, ICE_F_GNSS))
+ 		ice_gnss_init(pf);
+ 
+ 	/* Note: Flow director init failure is non-fatal to load */
+ 	if (ice_init_fdir(pf))
+ 		dev_err(dev, "could not initialize flow director\n");
+ 
+ 	/* Note: DCB init failure is non-fatal to load */
+ 	if (ice_init_pf_dcb(pf, false)) {
+ 		clear_bit(ICE_FLAG_DCB_CAPABLE, pf->flags);
+ 		clear_bit(ICE_FLAG_DCB_ENA, pf->flags);
+ 	} else {
+ 		ice_cfg_lldp_mib_change(&pf->hw, true);
+ 	}
+ 
+ 	if (ice_init_lag(pf))
+ 		dev_warn(dev, "Failed to init link aggregation support\n");
+ }
+ 
+ static void ice_deinit_features(struct ice_pf *pf)
+ {
+ 	ice_deinit_lag(pf);
+ 	if (test_bit(ICE_FLAG_DCB_CAPABLE, pf->flags))
+ 		ice_cfg_lldp_mib_change(&pf->hw, false);
+ 	ice_deinit_fdir(pf);
+ 	if (ice_is_feature_supported(pf, ICE_F_GNSS))
+ 		ice_gnss_exit(pf);
+ 	if (test_bit(ICE_FLAG_PTP_SUPPORTED, pf->flags))
+ 		ice_ptp_release(pf);
+ }
+ 
+ static void ice_init_wakeup(struct ice_pf *pf)
+ {
+ 	/* Save wakeup reason register for later use */
+ 	pf->wakeup_reason = rd32(&pf->hw, PFPM_WUS);
+ 
+ 	/* check for a power management event */
+ 	ice_print_wake_reason(pf);
+ 
+ 	/* clear wake status, all bits */
+ 	wr32(&pf->hw, PFPM_WUS, U32_MAX);
+ 
+ 	/* Disable WoL at init, wait for user to enable */
+ 	device_set_wakeup_enable(ice_pf_to_dev(pf), false);
+ }
+ 
+ static int ice_init_link(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 	int err;
+ 
+ 	err = ice_init_link_events(pf->hw.port_info);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_link_events failed: %d\n", err);
+ 		return err;
+ 	}
+ 
+ 	/* not a fatal error if this fails */
+ 	err = ice_init_nvm_phy_type(pf->hw.port_info);
+ 	if (err)
+ 		dev_err(dev, "ice_init_nvm_phy_type failed: %d\n", err);
+ 
+ 	/* not a fatal error if this fails */
+ 	err = ice_update_link_info(pf->hw.port_info);
+ 	if (err)
+ 		dev_err(dev, "ice_update_link_info failed: %d\n", err);
+ 
+ 	ice_init_link_dflt_override(pf->hw.port_info);
+ 
+ 	ice_check_link_cfg_err(pf,
+ 			       pf->hw.port_info->phy.link_info.link_cfg_err);
+ 
+ 	/* if media available, initialize PHY settings */
+ 	if (pf->hw.port_info->phy.link_info.link_info &
+ 	    ICE_AQ_MEDIA_AVAILABLE) {
+ 		/* not a fatal error if this fails */
+ 		err = ice_init_phy_user_cfg(pf->hw.port_info);
+ 		if (err)
+ 			dev_err(dev, "ice_init_phy_user_cfg failed: %d\n", err);
+ 
+ 		if (!test_bit(ICE_FLAG_LINK_DOWN_ON_CLOSE_ENA, pf->flags)) {
+ 			struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
+ 			if (vsi)
+ 				ice_configure_phy(vsi);
+ 		}
+ 	} else {
+ 		set_bit(ICE_FLAG_NO_MEDIA, pf->flags);
+ 	}
+ 
+ 	return err;
+ }
+ 
+ static int ice_init_pf_sw(struct ice_pf *pf)
+ {
+ 	bool dvm = ice_is_dvm_ena(&pf->hw);
+ 	struct ice_vsi *vsi;
+ 	int err;
+ 
+ 	/* create switch struct for the switch element created by FW on boot */
+ 	pf->first_sw = kzalloc(sizeof(*pf->first_sw), GFP_KERNEL);
+ 	if (!pf->first_sw)
+ 		return -ENOMEM;
+ 
+ 	if (pf->hw.evb_veb)
+ 		pf->first_sw->bridge_mode = BRIDGE_MODE_VEB;
+ 	else
+ 		pf->first_sw->bridge_mode = BRIDGE_MODE_VEPA;
+ 
+ 	pf->first_sw->pf = pf;
+ 
+ 	/* record the sw_id available for later use */
+ 	pf->first_sw->sw_id = pf->hw.port_info->sw_id;
+ 
+ 	err = ice_aq_set_port_params(pf->hw.port_info, dvm, NULL);
+ 	if (err)
+ 		goto err_aq_set_port_params;
+ 
+ 	vsi = ice_pf_vsi_setup(pf, pf->hw.port_info);
+ 	if (!vsi) {
+ 		err = -ENOMEM;
+ 		goto err_pf_vsi_setup;
+ 	}
+ 
+ 	return 0;
+ 
+ err_pf_vsi_setup:
+ err_aq_set_port_params:
+ 	kfree(pf->first_sw);
+ 	return err;
+ }
+ 
+ static void ice_deinit_pf_sw(struct ice_pf *pf)
+ {
+ 	struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
+ 	if (!vsi)
+ 		return;
+ 
+ 	ice_vsi_release(vsi);
+ 	kfree(pf->first_sw);
+ }
+ 
+ static int ice_alloc_vsis(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 
+ 	pf->num_alloc_vsi = pf->hw.func_caps.guar_num_vsi;
+ 	if (!pf->num_alloc_vsi)
+ 		return -EIO;
+ 
+ 	if (pf->num_alloc_vsi > UDP_TUNNEL_NIC_MAX_SHARING_DEVICES) {
+ 		dev_warn(dev,
+ 			 "limiting the VSI count due to UDP tunnel limitation %d > %d\n",
+ 			 pf->num_alloc_vsi, UDP_TUNNEL_NIC_MAX_SHARING_DEVICES);
+ 		pf->num_alloc_vsi = UDP_TUNNEL_NIC_MAX_SHARING_DEVICES;
+ 	}
+ 
+ 	pf->vsi = devm_kcalloc(dev, pf->num_alloc_vsi, sizeof(*pf->vsi),
+ 			       GFP_KERNEL);
+ 	if (!pf->vsi)
+ 		return -ENOMEM;
+ 
+ 	pf->vsi_stats = devm_kcalloc(dev, pf->num_alloc_vsi,
+ 				     sizeof(*pf->vsi_stats), GFP_KERNEL);
+ 	if (!pf->vsi_stats) {
+ 		devm_kfree(dev, pf->vsi);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void ice_dealloc_vsis(struct ice_pf *pf)
+ {
+ 	devm_kfree(ice_pf_to_dev(pf), pf->vsi_stats);
+ 	pf->vsi_stats = NULL;
+ 
+ 	pf->num_alloc_vsi = 0;
+ 	devm_kfree(ice_pf_to_dev(pf), pf->vsi);
+ 	pf->vsi = NULL;
+ }
+ 
+ static int ice_init_devlink(struct ice_pf *pf)
+ {
+ 	int err;
+ 
+ 	err = ice_devlink_register_params(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	ice_devlink_init_regions(pf);
+ 	ice_devlink_register(pf);
+ 
+ 	return 0;
+ }
+ 
+ static void ice_deinit_devlink(struct ice_pf *pf)
+ {
+ 	ice_devlink_unregister(pf);
+ 	ice_devlink_destroy_regions(pf);
+ 	ice_devlink_unregister_params(pf);
+ }
+ 
+ static int ice_init(struct ice_pf *pf)
+ {
+ 	int err;
+ 
+ 	err = ice_init_dev(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	err = ice_alloc_vsis(pf);
+ 	if (err)
+ 		goto err_alloc_vsis;
+ 
+ 	err = ice_init_pf_sw(pf);
+ 	if (err)
+ 		goto err_init_pf_sw;
+ 
+ 	ice_init_wakeup(pf);
+ 
+ 	err = ice_init_link(pf);
+ 	if (err)
+ 		goto err_init_link;
+ 
+ 	err = ice_send_version(pf);
+ 	if (err)
+ 		goto err_init_link;
+ 
+ 	ice_verify_cacheline_size(pf);
+ 
+ 	if (ice_is_safe_mode(pf))
+ 		ice_set_safe_mode_vlan_cfg(pf);
+ 	else
+ 		/* print PCI link speed and width */
+ 		pcie_print_link_status(pf->pdev);
+ 
+ 	/* ready to go, so clear down state bit */
+ 	clear_bit(ICE_DOWN, pf->state);
+ 	clear_bit(ICE_SERVICE_DIS, pf->state);
+ 
+ 	/* since everything is good, start the service timer */
+ 	mod_timer(&pf->serv_tmr, round_jiffies(jiffies + pf->serv_tmr_period));
+ 
+ 	return 0;
+ 
+ err_init_link:
+ 	ice_deinit_pf_sw(pf);
+ err_init_pf_sw:
+ 	ice_dealloc_vsis(pf);
+ err_alloc_vsis:
+ 	ice_deinit_dev(pf);
+ 	return err;
+ }
+ 
+ static void ice_deinit(struct ice_pf *pf)
+ {
+ 	set_bit(ICE_SERVICE_DIS, pf->state);
+ 	set_bit(ICE_DOWN, pf->state);
+ 
+ 	ice_deinit_pf_sw(pf);
+ 	ice_dealloc_vsis(pf);
+ 	ice_deinit_dev(pf);
+ }
+ 
+ /**
+  * ice_load - load pf by init hw and starting VSI
+  * @pf: pointer to the pf instance
+  */
+ int ice_load(struct ice_pf *pf)
+ {
+ 	struct ice_vsi_cfg_params params = {};
+ 	struct ice_vsi *vsi;
+ 	int err;
+ 
+ 	err = ice_reset(&pf->hw, ICE_RESET_PFR);
+ 	if (err)
+ 		return err;
+ 
+ 	err = ice_init_dev(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	vsi = ice_get_main_vsi(pf);
+ 
+ 	params = ice_vsi_to_params(vsi);
+ 	params.flags = ICE_VSI_FLAG_INIT;
+ 
+ 	err = ice_vsi_cfg(vsi, &params);
+ 	if (err)
+ 		goto err_vsi_cfg;
+ 
+ 	err = ice_start_eth(ice_get_main_vsi(pf));
+ 	if (err)
+ 		goto err_start_eth;
+ 
+ 	err = ice_init_rdma(pf);
+ 	if (err)
+ 		goto err_init_rdma;
+ 
+ 	ice_init_features(pf);
+ 	ice_service_task_restart(pf);
+ 
+ 	clear_bit(ICE_DOWN, pf->state);
+ 
+ 	return 0;
+ 
+ err_init_rdma:
+ 	ice_vsi_close(ice_get_main_vsi(pf));
+ err_start_eth:
+ 	ice_vsi_decfg(ice_get_main_vsi(pf));
+ err_vsi_cfg:
+ 	ice_deinit_dev(pf);
+ 	return err;
+ }
+ 
+ /**
+  * ice_unload - unload pf by stopping VSI and deinit hw
+  * @pf: pointer to the pf instance
+  */
+ void ice_unload(struct ice_pf *pf)
+ {
+ 	ice_deinit_features(pf);
+ 	ice_deinit_rdma(pf);
+ 	ice_vsi_close(ice_get_main_vsi(pf));
+ 	ice_vsi_decfg(ice_get_main_vsi(pf));
+ 	ice_deinit_dev(pf);
+ }
+ 
++>>>>>>> 5e509ab237f1 (ice: refactor VSI setup to use parameter structure)
  /**
   * ice_probe - Device initialization routine
   * @pdev: PCI device information struct
diff --git a/drivers/net/ethernet/intel/ice/ice_eswitch.c b/drivers/net/ethernet/intel/ice/ice_eswitch.c
index f9f15acae90a..b86d173a20af 100644
--- a/drivers/net/ethernet/intel/ice/ice_eswitch.c
+++ b/drivers/net/ethernet/intel/ice/ice_eswitch.c
@@ -425,7 +425,13 @@ static void ice_eswitch_release_env(struct ice_pf *pf)
 static struct ice_vsi *
 ice_eswitch_vsi_setup(struct ice_pf *pf, struct ice_port_info *pi)
 {
-	return ice_vsi_setup(pf, pi, ICE_VSI_SWITCHDEV_CTRL, NULL, NULL);
+	struct ice_vsi_cfg_params params = {};
+
+	params.type = ICE_VSI_SWITCHDEV_CTRL;
+	params.pi = pi;
+	params.flags = ICE_VSI_FLAG_INIT;
+
+	return ice_vsi_setup(pf, &params);
 }
 
 /**
* Unmerged path drivers/net/ethernet/intel/ice/ice_lib.c
* Unmerged path drivers/net/ethernet/intel/ice/ice_lib.h
* Unmerged path drivers/net/ethernet/intel/ice/ice_main.c
diff --git a/drivers/net/ethernet/intel/ice/ice_sriov.c b/drivers/net/ethernet/intel/ice/ice_sriov.c
index a50439f5e24e..2adccf3d4ae3 100644
--- a/drivers/net/ethernet/intel/ice/ice_sriov.c
+++ b/drivers/net/ethernet/intel/ice/ice_sriov.c
@@ -248,11 +248,16 @@ void ice_free_vfs(struct ice_pf *pf)
  */
 static struct ice_vsi *ice_vf_vsi_setup(struct ice_vf *vf)
 {
-	struct ice_port_info *pi = ice_vf_get_port_info(vf);
+	struct ice_vsi_cfg_params params = {};
 	struct ice_pf *pf = vf->pf;
 	struct ice_vsi *vsi;
 
-	vsi = ice_vsi_setup(pf, pi, ICE_VSI_VF, vf, NULL);
+	params.type = ICE_VSI_VF;
+	params.pi = ice_vf_get_port_info(vf);
+	params.vf = vf;
+	params.flags = ICE_VSI_FLAG_INIT;
+
+	vsi = ice_vsi_setup(pf, &params);
 
 	if (!vsi) {
 		dev_err(ice_pf_to_dev(pf), "Failed to create VF VSI\n");
diff --git a/drivers/net/ethernet/intel/ice/ice_vf_lib.c b/drivers/net/ethernet/intel/ice/ice_vf_lib.c
index 375eb6493f0f..0618093a6c70 100644
--- a/drivers/net/ethernet/intel/ice/ice_vf_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_vf_lib.c
@@ -1115,11 +1115,16 @@ void ice_vf_ctrl_vsi_release(struct ice_vf *vf)
  */
 struct ice_vsi *ice_vf_ctrl_vsi_setup(struct ice_vf *vf)
 {
-	struct ice_port_info *pi = ice_vf_get_port_info(vf);
+	struct ice_vsi_cfg_params params = {};
 	struct ice_pf *pf = vf->pf;
 	struct ice_vsi *vsi;
 
-	vsi = ice_vsi_setup(pf, pi, ICE_VSI_CTRL, vf, NULL);
+	params.type = ICE_VSI_CTRL;
+	params.pi = ice_vf_get_port_info(vf);
+	params.vf = vf;
+	params.flags = ICE_VSI_FLAG_INIT;
+
+	vsi = ice_vsi_setup(pf, &params);
 	if (!vsi) {
 		dev_err(ice_pf_to_dev(pf), "Failed to create VF control VSI\n");
 		ice_vf_ctrl_invalidate_vsi(vf);
