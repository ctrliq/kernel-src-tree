ice: Fix ice module unload

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-505.el8
commit-author Jakub Buchocki <jakubx.buchocki@intel.com>
commit 24b454bc354ab7b1aa918a4fe3d7696516f592d4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-505.el8/24b454bc.failed

Clearing the interrupt scheme before PFR reset,
during the removal routine, could cause the hardware
errors and possibly lead to system reboot, as the PF
reset can cause the interrupt to be generated.

Place the call for PFR reset inside ice_deinit_dev(),
wait until reset and all pending transactions are done,
then call ice_clear_interrupt_scheme().

This introduces a PFR reset to multiple error paths.

Additionally, remove the call for the reset from
ice_load() - it will be a part of ice_unload() now.

Error example:
[   75.229328] ice 0000:ca:00.1: Failed to read Tx Scheduler Tree - User Selection data from flash
[   77.571315] {1}[Hardware Error]: Hardware error from APEI Generic Hardware Error Source: 1
[   77.571418] {1}[Hardware Error]: event severity: recoverable
[   77.571459] {1}[Hardware Error]:  Error 0, type: recoverable
[   77.571500] {1}[Hardware Error]:   section_type: PCIe error
[   77.571540] {1}[Hardware Error]:   port_type: 4, root port
[   77.571580] {1}[Hardware Error]:   version: 3.0
[   77.571615] {1}[Hardware Error]:   command: 0x0547, status: 0x4010
[   77.571661] {1}[Hardware Error]:   device_id: 0000:c9:02.0
[   77.571703] {1}[Hardware Error]:   slot: 25
[   77.571736] {1}[Hardware Error]:   secondary_bus: 0xca
[   77.571773] {1}[Hardware Error]:   vendor_id: 0x8086, device_id: 0x347a
[   77.571821] {1}[Hardware Error]:   class_code: 060400
[   77.571858] {1}[Hardware Error]:   bridge: secondary_status: 0x2800, control: 0x0013
[   77.572490] pcieport 0000:c9:02.0: AER: aer_status: 0x00200000, aer_mask: 0x00100020
[   77.572870] pcieport 0000:c9:02.0:    [21] ACSViol                (First)
[   77.573222] pcieport 0000:c9:02.0: AER: aer_layer=Transaction Layer, aer_agent=Receiver ID
[   77.573554] pcieport 0000:c9:02.0: AER: aer_uncor_severity: 0x00463010
[   77.691273] {2}[Hardware Error]: Hardware error from APEI Generic Hardware Error Source: 1
[   77.691738] {2}[Hardware Error]: event severity: recoverable
[   77.691971] {2}[Hardware Error]:  Error 0, type: recoverable
[   77.692192] {2}[Hardware Error]:   section_type: PCIe error
[   77.692403] {2}[Hardware Error]:   port_type: 4, root port
[   77.692616] {2}[Hardware Error]:   version: 3.0
[   77.692825] {2}[Hardware Error]:   command: 0x0547, status: 0x4010
[   77.693032] {2}[Hardware Error]:   device_id: 0000:c9:02.0
[   77.693238] {2}[Hardware Error]:   slot: 25
[   77.693440] {2}[Hardware Error]:   secondary_bus: 0xca
[   77.693641] {2}[Hardware Error]:   vendor_id: 0x8086, device_id: 0x347a
[   77.693853] {2}[Hardware Error]:   class_code: 060400
[   77.694054] {2}[Hardware Error]:   bridge: secondary_status: 0x0800, control: 0x0013
[   77.719115] pci 0000:ca:00.1: AER: can't recover (no error_detected callback)
[   77.719140] pcieport 0000:c9:02.0: AER: device recovery failed
[   77.719216] pcieport 0000:c9:02.0: AER: aer_status: 0x00200000, aer_mask: 0x00100020
[   77.719390] pcieport 0000:c9:02.0:    [21] ACSViol                (First)
[   77.719557] pcieport 0000:c9:02.0: AER: aer_layer=Transaction Layer, aer_agent=Receiver ID
[   77.719723] pcieport 0000:c9:02.0: AER: aer_uncor_severity: 0x00463010

Fixes: 5b246e533d01 ("ice: split probe into smaller functions")
	Signed-off-by: Jakub Buchocki <jakubx.buchocki@intel.com>
	Reviewed-by: Przemek Kitszel <przemyslaw.kitszel@intel.com>
	Tested-by: Pucha Himasekhar Reddy <himasekharx.reddy.pucha@intel.com> (A Contingent worker at Intel)
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
	Reviewed-by: Simon Horman <simon.horman@corigine.com>
Link: https://lore.kernel.org/r/20230612171421.21570-1-anthony.l.nguyen@intel.com
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 24b454bc354ab7b1aa918a4fe3d7696516f592d4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice_main.c
diff --cc drivers/net/ethernet/intel/ice/ice_main.c
index 70911484af91,42c318ceff61..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_main.c
+++ b/drivers/net/ethernet/intel/ice/ice_main.c
@@@ -4639,18 -4574,580 +4639,465 @@@ static int ice_register_netdev(struct i
  	netif_carrier_off(vsi->netdev);
  	netif_tx_stop_all_queues(vsi->netdev);
  
 -	return 0;
 -}
 -
 -static void ice_unregister_netdev(struct ice_vsi *vsi)
 -{
 -	if (!vsi || !vsi->netdev)
 -		return;
 -
 -	unregister_netdev(vsi->netdev);
 -	clear_bit(ICE_VSI_NETDEV_REGISTERED, vsi->state);
 -}
 -
 -/**
 - * ice_cfg_netdev - Allocate, configure and register a netdev
 - * @vsi: the VSI associated with the new netdev
 - *
 - * Returns 0 on success, negative value on failure
 - */
 -static int ice_cfg_netdev(struct ice_vsi *vsi)
 -{
 -	struct ice_netdev_priv *np;
 -	struct net_device *netdev;
 -	u8 mac_addr[ETH_ALEN];
 -
 -	netdev = alloc_etherdev_mqs(sizeof(*np), vsi->alloc_txq,
 -				    vsi->alloc_rxq);
 -	if (!netdev)
 -		return -ENOMEM;
 -
 -	set_bit(ICE_VSI_NETDEV_ALLOCD, vsi->state);
 -	vsi->netdev = netdev;
 -	np = netdev_priv(netdev);
 -	np->vsi = vsi;
 -
 -	ice_set_netdev_features(netdev);
 -	ice_set_ops(vsi);
 -
 -	if (vsi->type == ICE_VSI_PF) {
 -		SET_NETDEV_DEV(netdev, ice_pf_to_dev(vsi->back));
 -		ether_addr_copy(mac_addr, vsi->port_info->mac.perm_addr);
 -		eth_hw_addr_set(netdev, mac_addr);
 -	}
 -
 -	netdev->priv_flags |= IFF_UNICAST_FLT;
 -
 -	/* Setup netdev TC information */
 -	ice_vsi_cfg_netdev_tc(vsi, vsi->tc_cfg.ena_tc);
 -
 -	netdev->max_mtu = ICE_MAX_MTU;
 +	devlink_port_type_eth_set(&pf->devlink_port, vsi->netdev);
  
  	return 0;
 -}
 -
 -static void ice_decfg_netdev(struct ice_vsi *vsi)
 -{
 -	clear_bit(ICE_VSI_NETDEV_ALLOCD, vsi->state);
 +err_register_netdev:
 +	ice_devlink_destroy_pf_port(pf);
 +err_devlink_create:
  	free_netdev(vsi->netdev);
  	vsi->netdev = NULL;
 +	clear_bit(ICE_VSI_NETDEV_ALLOCD, vsi->state);
 +	return err;
  }
  
 -static int ice_start_eth(struct ice_vsi *vsi)
++<<<<<<< HEAD
++=======
++static void ice_deinit_eth(struct ice_pf *pf)
+ {
 -	int err;
 -
 -	err = ice_init_mac_fltr(vsi->back);
 -	if (err)
 -		return err;
 -
 -	rtnl_lock();
 -	err = ice_vsi_open(vsi);
 -	rtnl_unlock();
++	struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
 -	return err;
 -}
++	if (!vsi)
++		return;
+ 
 -static void ice_stop_eth(struct ice_vsi *vsi)
 -{
 -	ice_fltr_remove_all(vsi);
+ 	ice_vsi_close(vsi);
++	ice_unregister_netdev(vsi);
++	ice_devlink_destroy_pf_port(pf);
++	ice_tc_indir_block_unregister(vsi);
++	ice_decfg_netdev(vsi);
+ }
+ 
 -static int ice_init_eth(struct ice_pf *pf)
++static int ice_init_dev(struct ice_pf *pf)
+ {
 -	struct ice_vsi *vsi = ice_get_main_vsi(pf);
++	struct device *dev = ice_pf_to_dev(pf);
++	struct ice_hw *hw = &pf->hw;
+ 	int err;
+ 
 -	if (!vsi)
 -		return -EINVAL;
 -
 -	/* init channel list */
 -	INIT_LIST_HEAD(&vsi->ch_list);
 -
 -	err = ice_cfg_netdev(vsi);
 -	if (err)
 -		return err;
 -	/* Setup DCB netlink interface */
 -	ice_dcbnl_setup(vsi);
 -
 -	err = ice_init_mac_fltr(pf);
 -	if (err)
 -		goto err_init_mac_fltr;
 -
 -	err = ice_devlink_create_pf_port(pf);
 -	if (err)
 -		goto err_devlink_create_pf_port;
 -
 -	SET_NETDEV_DEVLINK_PORT(vsi->netdev, &pf->devlink_port);
 -
 -	err = ice_register_netdev(vsi);
 -	if (err)
 -		goto err_register_netdev;
 -
 -	err = ice_tc_indir_block_register(vsi);
 -	if (err)
 -		goto err_tc_indir_block_register;
 -
 -	ice_napi_add(vsi);
 -
 -	return 0;
 -
 -err_tc_indir_block_register:
 -	ice_unregister_netdev(vsi);
 -err_register_netdev:
 -	ice_devlink_destroy_pf_port(pf);
 -err_devlink_create_pf_port:
 -err_init_mac_fltr:
 -	ice_decfg_netdev(vsi);
 -	return err;
 -}
 -
 -static void ice_deinit_eth(struct ice_pf *pf)
 -{
 -	struct ice_vsi *vsi = ice_get_main_vsi(pf);
 -
 -	if (!vsi)
 -		return;
 -
 -	ice_vsi_close(vsi);
 -	ice_unregister_netdev(vsi);
 -	ice_devlink_destroy_pf_port(pf);
 -	ice_tc_indir_block_unregister(vsi);
 -	ice_decfg_netdev(vsi);
 -}
 -
 -static int ice_init_dev(struct ice_pf *pf)
 -{
 -	struct device *dev = ice_pf_to_dev(pf);
 -	struct ice_hw *hw = &pf->hw;
 -	int err;
 -
 -	err = ice_init_hw(hw);
 -	if (err) {
 -		dev_err(dev, "ice_init_hw failed: %d\n", err);
 -		return err;
 -	}
++	err = ice_init_hw(hw);
++	if (err) {
++		dev_err(dev, "ice_init_hw failed: %d\n", err);
++		return err;
++	}
+ 
+ 	ice_init_feature_support(pf);
+ 
+ 	ice_request_fw(pf);
+ 
+ 	/* if ice_request_fw fails, ICE_FLAG_ADV_FEATURES bit won't be
+ 	 * set in pf->state, which will cause ice_is_safe_mode to return
+ 	 * true
+ 	 */
+ 	if (ice_is_safe_mode(pf)) {
+ 		/* we already got function/device capabilities but these don't
+ 		 * reflect what the driver needs to do in safe mode. Instead of
+ 		 * adding conditional logic everywhere to ignore these
+ 		 * device/function capabilities, override them.
+ 		 */
+ 		ice_set_safe_mode_caps(hw);
+ 	}
+ 
+ 	err = ice_init_pf(pf);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_pf failed: %d\n", err);
+ 		goto err_init_pf;
+ 	}
+ 
+ 	pf->hw.udp_tunnel_nic.set_port = ice_udp_tunnel_set_port;
+ 	pf->hw.udp_tunnel_nic.unset_port = ice_udp_tunnel_unset_port;
+ 	pf->hw.udp_tunnel_nic.flags = UDP_TUNNEL_NIC_INFO_MAY_SLEEP;
+ 	pf->hw.udp_tunnel_nic.shared = &pf->hw.udp_tunnel_shared;
+ 	if (pf->hw.tnl.valid_count[TNL_VXLAN]) {
+ 		pf->hw.udp_tunnel_nic.tables[0].n_entries =
+ 			pf->hw.tnl.valid_count[TNL_VXLAN];
+ 		pf->hw.udp_tunnel_nic.tables[0].tunnel_types =
+ 			UDP_TUNNEL_TYPE_VXLAN;
+ 	}
+ 	if (pf->hw.tnl.valid_count[TNL_GENEVE]) {
+ 		pf->hw.udp_tunnel_nic.tables[1].n_entries =
+ 			pf->hw.tnl.valid_count[TNL_GENEVE];
+ 		pf->hw.udp_tunnel_nic.tables[1].tunnel_types =
+ 			UDP_TUNNEL_TYPE_GENEVE;
+ 	}
+ 
+ 	err = ice_init_interrupt_scheme(pf);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_interrupt_scheme failed: %d\n", err);
+ 		err = -EIO;
+ 		goto err_init_interrupt_scheme;
+ 	}
+ 
+ 	/* In case of MSIX we are going to setup the misc vector right here
+ 	 * to handle admin queue events etc. In case of legacy and MSI
+ 	 * the misc functionality and queue processing is combined in
+ 	 * the same vector and that gets setup at open.
+ 	 */
+ 	err = ice_req_irq_msix_misc(pf);
+ 	if (err) {
+ 		dev_err(dev, "setup of misc vector failed: %d\n", err);
+ 		goto err_req_irq_msix_misc;
+ 	}
+ 
+ 	return 0;
+ 
+ err_req_irq_msix_misc:
+ 	ice_clear_interrupt_scheme(pf);
+ err_init_interrupt_scheme:
+ 	ice_deinit_pf(pf);
+ err_init_pf:
+ 	ice_deinit_hw(hw);
+ 	return err;
+ }
+ 
+ static void ice_deinit_dev(struct ice_pf *pf)
+ {
+ 	ice_free_irq_msix_misc(pf);
+ 	ice_deinit_pf(pf);
+ 	ice_deinit_hw(&pf->hw);
+ 
+ 	/* Service task is already stopped, so call reset directly. */
+ 	ice_reset(&pf->hw, ICE_RESET_PFR);
+ 	pci_wait_for_pending_transaction(pf->pdev);
+ 	ice_clear_interrupt_scheme(pf);
+ }
+ 
+ static void ice_init_features(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 
+ 	if (ice_is_safe_mode(pf))
+ 		return;
+ 
+ 	/* initialize DDP driven features */
+ 	if (test_bit(ICE_FLAG_PTP_SUPPORTED, pf->flags))
+ 		ice_ptp_init(pf);
+ 
+ 	if (ice_is_feature_supported(pf, ICE_F_GNSS))
+ 		ice_gnss_init(pf);
+ 
+ 	/* Note: Flow director init failure is non-fatal to load */
+ 	if (ice_init_fdir(pf))
+ 		dev_err(dev, "could not initialize flow director\n");
+ 
+ 	/* Note: DCB init failure is non-fatal to load */
+ 	if (ice_init_pf_dcb(pf, false)) {
+ 		clear_bit(ICE_FLAG_DCB_CAPABLE, pf->flags);
+ 		clear_bit(ICE_FLAG_DCB_ENA, pf->flags);
+ 	} else {
+ 		ice_cfg_lldp_mib_change(&pf->hw, true);
+ 	}
+ 
+ 	if (ice_init_lag(pf))
+ 		dev_warn(dev, "Failed to init link aggregation support\n");
+ }
+ 
+ static void ice_deinit_features(struct ice_pf *pf)
+ {
+ 	ice_deinit_lag(pf);
+ 	if (test_bit(ICE_FLAG_DCB_CAPABLE, pf->flags))
+ 		ice_cfg_lldp_mib_change(&pf->hw, false);
+ 	ice_deinit_fdir(pf);
+ 	if (ice_is_feature_supported(pf, ICE_F_GNSS))
+ 		ice_gnss_exit(pf);
+ 	if (test_bit(ICE_FLAG_PTP_SUPPORTED, pf->flags))
+ 		ice_ptp_release(pf);
+ }
+ 
+ static void ice_init_wakeup(struct ice_pf *pf)
+ {
+ 	/* Save wakeup reason register for later use */
+ 	pf->wakeup_reason = rd32(&pf->hw, PFPM_WUS);
+ 
+ 	/* check for a power management event */
+ 	ice_print_wake_reason(pf);
+ 
+ 	/* clear wake status, all bits */
+ 	wr32(&pf->hw, PFPM_WUS, U32_MAX);
+ 
+ 	/* Disable WoL at init, wait for user to enable */
+ 	device_set_wakeup_enable(ice_pf_to_dev(pf), false);
+ }
+ 
+ static int ice_init_link(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 	int err;
+ 
+ 	err = ice_init_link_events(pf->hw.port_info);
+ 	if (err) {
+ 		dev_err(dev, "ice_init_link_events failed: %d\n", err);
+ 		return err;
+ 	}
+ 
+ 	/* not a fatal error if this fails */
+ 	err = ice_init_nvm_phy_type(pf->hw.port_info);
+ 	if (err)
+ 		dev_err(dev, "ice_init_nvm_phy_type failed: %d\n", err);
+ 
+ 	/* not a fatal error if this fails */
+ 	err = ice_update_link_info(pf->hw.port_info);
+ 	if (err)
+ 		dev_err(dev, "ice_update_link_info failed: %d\n", err);
+ 
+ 	ice_init_link_dflt_override(pf->hw.port_info);
+ 
+ 	ice_check_link_cfg_err(pf,
+ 			       pf->hw.port_info->phy.link_info.link_cfg_err);
+ 
+ 	/* if media available, initialize PHY settings */
+ 	if (pf->hw.port_info->phy.link_info.link_info &
+ 	    ICE_AQ_MEDIA_AVAILABLE) {
+ 		/* not a fatal error if this fails */
+ 		err = ice_init_phy_user_cfg(pf->hw.port_info);
+ 		if (err)
+ 			dev_err(dev, "ice_init_phy_user_cfg failed: %d\n", err);
+ 
+ 		if (!test_bit(ICE_FLAG_LINK_DOWN_ON_CLOSE_ENA, pf->flags)) {
+ 			struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
+ 			if (vsi)
+ 				ice_configure_phy(vsi);
+ 		}
+ 	} else {
+ 		set_bit(ICE_FLAG_NO_MEDIA, pf->flags);
+ 	}
+ 
+ 	return err;
+ }
+ 
+ static int ice_init_pf_sw(struct ice_pf *pf)
+ {
+ 	bool dvm = ice_is_dvm_ena(&pf->hw);
+ 	struct ice_vsi *vsi;
+ 	int err;
+ 
+ 	/* create switch struct for the switch element created by FW on boot */
+ 	pf->first_sw = kzalloc(sizeof(*pf->first_sw), GFP_KERNEL);
+ 	if (!pf->first_sw)
+ 		return -ENOMEM;
+ 
+ 	if (pf->hw.evb_veb)
+ 		pf->first_sw->bridge_mode = BRIDGE_MODE_VEB;
+ 	else
+ 		pf->first_sw->bridge_mode = BRIDGE_MODE_VEPA;
+ 
+ 	pf->first_sw->pf = pf;
+ 
+ 	/* record the sw_id available for later use */
+ 	pf->first_sw->sw_id = pf->hw.port_info->sw_id;
+ 
+ 	err = ice_aq_set_port_params(pf->hw.port_info, dvm, NULL);
+ 	if (err)
+ 		goto err_aq_set_port_params;
+ 
+ 	vsi = ice_pf_vsi_setup(pf, pf->hw.port_info);
+ 	if (!vsi) {
+ 		err = -ENOMEM;
+ 		goto err_pf_vsi_setup;
+ 	}
+ 
+ 	return 0;
+ 
+ err_pf_vsi_setup:
+ err_aq_set_port_params:
+ 	kfree(pf->first_sw);
+ 	return err;
+ }
+ 
+ static void ice_deinit_pf_sw(struct ice_pf *pf)
+ {
+ 	struct ice_vsi *vsi = ice_get_main_vsi(pf);
+ 
+ 	if (!vsi)
+ 		return;
+ 
+ 	ice_vsi_release(vsi);
+ 	kfree(pf->first_sw);
+ }
+ 
+ static int ice_alloc_vsis(struct ice_pf *pf)
+ {
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 
+ 	pf->num_alloc_vsi = pf->hw.func_caps.guar_num_vsi;
+ 	if (!pf->num_alloc_vsi)
+ 		return -EIO;
+ 
+ 	if (pf->num_alloc_vsi > UDP_TUNNEL_NIC_MAX_SHARING_DEVICES) {
+ 		dev_warn(dev,
+ 			 "limiting the VSI count due to UDP tunnel limitation %d > %d\n",
+ 			 pf->num_alloc_vsi, UDP_TUNNEL_NIC_MAX_SHARING_DEVICES);
+ 		pf->num_alloc_vsi = UDP_TUNNEL_NIC_MAX_SHARING_DEVICES;
+ 	}
+ 
+ 	pf->vsi = devm_kcalloc(dev, pf->num_alloc_vsi, sizeof(*pf->vsi),
+ 			       GFP_KERNEL);
+ 	if (!pf->vsi)
+ 		return -ENOMEM;
+ 
+ 	pf->vsi_stats = devm_kcalloc(dev, pf->num_alloc_vsi,
+ 				     sizeof(*pf->vsi_stats), GFP_KERNEL);
+ 	if (!pf->vsi_stats) {
+ 		devm_kfree(dev, pf->vsi);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void ice_dealloc_vsis(struct ice_pf *pf)
+ {
+ 	devm_kfree(ice_pf_to_dev(pf), pf->vsi_stats);
+ 	pf->vsi_stats = NULL;
+ 
+ 	pf->num_alloc_vsi = 0;
+ 	devm_kfree(ice_pf_to_dev(pf), pf->vsi);
+ 	pf->vsi = NULL;
+ }
+ 
+ static int ice_init_devlink(struct ice_pf *pf)
+ {
+ 	int err;
+ 
+ 	err = ice_devlink_register_params(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	ice_devlink_init_regions(pf);
+ 	ice_devlink_register(pf);
+ 
+ 	return 0;
+ }
+ 
+ static void ice_deinit_devlink(struct ice_pf *pf)
+ {
+ 	ice_devlink_unregister(pf);
+ 	ice_devlink_destroy_regions(pf);
+ 	ice_devlink_unregister_params(pf);
+ }
+ 
+ static int ice_init(struct ice_pf *pf)
+ {
+ 	int err;
+ 
+ 	err = ice_init_dev(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	err = ice_alloc_vsis(pf);
+ 	if (err)
+ 		goto err_alloc_vsis;
+ 
+ 	err = ice_init_pf_sw(pf);
+ 	if (err)
+ 		goto err_init_pf_sw;
+ 
+ 	ice_init_wakeup(pf);
+ 
+ 	err = ice_init_link(pf);
+ 	if (err)
+ 		goto err_init_link;
+ 
+ 	err = ice_send_version(pf);
+ 	if (err)
+ 		goto err_init_link;
+ 
+ 	ice_verify_cacheline_size(pf);
+ 
+ 	if (ice_is_safe_mode(pf))
+ 		ice_set_safe_mode_vlan_cfg(pf);
+ 	else
+ 		/* print PCI link speed and width */
+ 		pcie_print_link_status(pf->pdev);
+ 
+ 	/* ready to go, so clear down state bit */
+ 	clear_bit(ICE_DOWN, pf->state);
+ 	clear_bit(ICE_SERVICE_DIS, pf->state);
+ 
+ 	/* since everything is good, start the service timer */
+ 	mod_timer(&pf->serv_tmr, round_jiffies(jiffies + pf->serv_tmr_period));
+ 
+ 	return 0;
+ 
+ err_init_link:
+ 	ice_deinit_pf_sw(pf);
+ err_init_pf_sw:
+ 	ice_dealloc_vsis(pf);
+ err_alloc_vsis:
+ 	ice_deinit_dev(pf);
+ 	return err;
+ }
+ 
+ static void ice_deinit(struct ice_pf *pf)
+ {
+ 	set_bit(ICE_SERVICE_DIS, pf->state);
+ 	set_bit(ICE_DOWN, pf->state);
+ 
+ 	ice_deinit_pf_sw(pf);
+ 	ice_dealloc_vsis(pf);
+ 	ice_deinit_dev(pf);
+ }
+ 
+ /**
+  * ice_load - load pf by init hw and starting VSI
+  * @pf: pointer to the pf instance
+  */
+ int ice_load(struct ice_pf *pf)
+ {
+ 	struct ice_vsi_cfg_params params = {};
+ 	struct ice_vsi *vsi;
+ 	int err;
+ 
+ 	err = ice_init_dev(pf);
+ 	if (err)
+ 		return err;
+ 
+ 	vsi = ice_get_main_vsi(pf);
+ 
+ 	params = ice_vsi_to_params(vsi);
+ 	params.flags = ICE_VSI_FLAG_INIT;
+ 
+ 	err = ice_vsi_cfg(vsi, &params);
+ 	if (err)
+ 		goto err_vsi_cfg;
+ 
+ 	err = ice_start_eth(ice_get_main_vsi(pf));
+ 	if (err)
+ 		goto err_start_eth;
+ 
+ 	err = ice_init_rdma(pf);
+ 	if (err)
+ 		goto err_init_rdma;
+ 
+ 	ice_init_features(pf);
+ 	ice_service_task_restart(pf);
+ 
+ 	clear_bit(ICE_DOWN, pf->state);
+ 
+ 	return 0;
+ 
+ err_init_rdma:
+ 	ice_vsi_close(ice_get_main_vsi(pf));
+ err_start_eth:
+ 	ice_vsi_decfg(ice_get_main_vsi(pf));
+ err_vsi_cfg:
+ 	ice_deinit_dev(pf);
+ 	return err;
+ }
+ 
+ /**
+  * ice_unload - unload pf by stopping VSI and deinit hw
+  * @pf: pointer to the pf instance
+  */
+ void ice_unload(struct ice_pf *pf)
+ {
+ 	ice_deinit_features(pf);
+ 	ice_deinit_rdma(pf);
+ 	ice_stop_eth(ice_get_main_vsi(pf));
+ 	ice_vsi_decfg(ice_get_main_vsi(pf));
+ 	ice_deinit_dev(pf);
+ }
+ 
++>>>>>>> 24b454bc354a (ice: Fix ice module unload)
  /**
   * ice_probe - Device initialization routine
   * @pdev: PCI device information struct
@@@ -5068,40 -5338,22 +5515,43 @@@ static void ice_remove(struct pci_dev *
  	}
  
  	ice_service_task_stop(pf);
 +
  	ice_aq_cancel_waiting_tasks(pf);
 +	ice_deinit_rdma(pf);
 +	ice_devlink_unregister_params(pf);
  	set_bit(ICE_DOWN, pf->state);
  
 +	ice_deinit_lag(pf);
 +	if (test_bit(ICE_FLAG_PTP_SUPPORTED, pf->flags))
 +		ice_ptp_release(pf);
 +	if (ice_is_feature_supported(pf, ICE_F_GNSS))
 +		ice_gnss_exit(pf);
  	if (!ice_is_safe_mode(pf))
  		ice_remove_arfs(pf);
 -	ice_deinit_features(pf);
 -	ice_deinit_devlink(pf);
 -	ice_deinit_rdma(pf);
 -	ice_deinit_eth(pf);
 -	ice_deinit(pf);
 -
 -	ice_vsi_release_all(pf);
 -
  	ice_setup_mc_magic_wake(pf);
 +	ice_vsi_release_all(pf);
 +	mutex_destroy(&hw->fdir_fltr_lock);
  	ice_set_wake(pf);
 +	ice_free_irq_msix_misc(pf);
 +	ice_for_each_vsi(pf, i) {
 +		if (!pf->vsi[i])
 +			continue;
 +		ice_vsi_free_q_vectors(pf->vsi[i]);
 +	}
 +	ice_deinit_pf(pf);
 +	ice_devlink_destroy_regions(pf);
 +	ice_deinit_hw(hw);
  
++<<<<<<< HEAD
 +	/* Issue a PFR as part of the prescribed driver unload flow.  Do not
 +	 * do it via ice_schedule_reset() since there is no need to rebuild
 +	 * and the service task is already stopped.
 +	 */
 +	ice_reset(hw, ICE_RESET_PFR);
 +	pci_wait_for_pending_transaction(pdev);
 +	ice_clear_interrupt_scheme(pf);
++=======
++>>>>>>> 24b454bc354a (ice: Fix ice module unload)
  	pci_disable_device(pdev);
  }
  
* Unmerged path drivers/net/ethernet/intel/ice/ice_main.c
