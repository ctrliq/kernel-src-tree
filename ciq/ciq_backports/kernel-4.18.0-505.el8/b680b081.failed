kernfs: use dumber locking for kernfs_find_and_get_node_by_ino()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-505.el8
commit-author Tejun Heo <tj@kernel.org>
commit b680b08171ebf890a4ebb7f82ada9959f4534ade
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-505.el8/b680b081.failed

kernfs_find_and_get_node_by_ino() uses RCU protection.  It's currently
a bit buggy because it can look up a node which hasn't been activated
yet and thus may end up exposing a node that the kernfs user is still
prepping.

While it can be fixed by pushing it further in the current direction,
it's already complicated and isn't clear whether the complexity is
justified.  The main use of kernfs_find_and_get_node_by_ino() is for
exportfs operations.  They aren't super hot and all the follow-up
operations (e.g. mapping to path) use normal locking anyway.

Let's switch to a dumber locking scheme and protect the lookup with
kernfs_idr_lock.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Namhyung Kim <namhyung@kernel.org>
(cherry picked from commit b680b08171ebf890a4ebb7f82ada9959f4534ade)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/kernfs/dir.c
diff --cc fs/kernfs/dir.c
index 8df6c1ed5bee,798f0f03b62b..000000000000
--- a/fs/kernfs/dir.c
+++ b/fs/kernfs/dir.c
@@@ -601,14 -639,10 +597,10 @@@ static struct kernfs_node *__kernfs_new
  	idr_preload_end();
  	if (ret < 0)
  		goto err_out2;
 -	kn->id.ino = ret;
 -	kn->id.generation = gen;
 +
 +	kn->id = (u64)gen << 32 | ret;
  
- 	/*
- 	 * set ino first. This RELEASE is paired with atomic_inc_not_zero in
- 	 * kernfs_find_and_get_node_by_ino
- 	 */
- 	atomic_set_release(&kn->count, 1);
+ 	atomic_set(&kn->count, 1);
  	atomic_set(&kn->active, KN_DEACTIVATED_BIAS);
  	RB_CLEAR_NODE(&kn->rb);
  
@@@ -674,38 -708,19 +666,44 @@@ struct kernfs_node *kernfs_find_and_get
  {
  	struct kernfs_node *kn;
  
- 	rcu_read_lock();
+ 	spin_lock(&kernfs_idr_lock);
+ 
  	kn = idr_find(&root->ino_idr, ino);
  	if (!kn)
- 		goto out;
+ 		goto err_unlock;
  
++<<<<<<< HEAD
 +	/*
 +	 * Since kernfs_node is freed in RCU, it's possible an old node for ino
 +	 * is freed, but reused before RCU grace period. But a freed node (see
 +	 * kernfs_put) or an incompletedly initialized node (see
 +	 * __kernfs_new_node) should have 'count' 0. We can use this fact to
 +	 * filter out such node.
 +	 */
 +	if (!atomic_inc_not_zero(&kn->count)) {
 +		kn = NULL;
 +		goto out;
 +	}
 +
 +	/*
 +	 * The node could be a new node or a reused node. If it's a new node,
 +	 * we are ok. If it's reused because of RCU (because of
 +	 * SLAB_TYPESAFE_BY_RCU), the __kernfs_new_node always sets its 'ino'
 +	 * before 'count'. So if 'count' is uptodate, 'ino' should be uptodate,
 +	 * hence we can use 'ino' to filter stale node.
 +	 */
 +	if (kernfs_ino(kn) != ino)
 +		goto out;
 +	rcu_read_unlock();
++=======
+ 	if (unlikely(!atomic_inc_not_zero(&kn->count)))
+ 		goto err_unlock;
++>>>>>>> b680b08171eb (kernfs: use dumber locking for kernfs_find_and_get_node_by_ino())
  
+ 	spin_unlock(&kernfs_idr_lock);
  	return kn;
- out:
- 	rcu_read_unlock();
- 	kernfs_put(kn);
+ err_unlock:
+ 	spin_unlock(&kernfs_idr_lock);
  	return NULL;
  }
  
* Unmerged path fs/kernfs/dir.c
diff --git a/fs/kernfs/mount.c b/fs/kernfs/mount.c
index 365e2fba9170..9319d0d01a83 100644
--- a/fs/kernfs/mount.c
+++ b/fs/kernfs/mount.c
@@ -366,18 +366,9 @@ void kernfs_kill_sb(struct super_block *sb)
 
 void __init kernfs_init(void)
 {
-
-	/*
-	 * the slab is freed in RCU context, so kernfs_find_and_get_node_by_ino
-	 * can access the slab lock free. This could introduce stale nodes,
-	 * please see how kernfs_find_and_get_node_by_ino filters out stale
-	 * nodes.
-	 */
 	kernfs_node_cache = kmem_cache_create("kernfs_node_cache",
 					      sizeof(struct kernfs_node),
-					      0,
-					      SLAB_PANIC | SLAB_TYPESAFE_BY_RCU,
-					      NULL);
+					      0, SLAB_PANIC, NULL);
 
 	/* Creates slab cache for kernfs inode attributes */
 	kernfs_iattrs_cache  = kmem_cache_create("kernfs_iattrs_cache",
