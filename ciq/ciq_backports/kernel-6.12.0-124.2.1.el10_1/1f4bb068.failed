x86/bugs: Restructure SRSO mitigation

jira KERNEL-156
Rebuild_History Non-Buildable kernel-6.12.0-124.2.1.el10_1
commit-author David Kaplan <david.kaplan@amd.com>
commit 1f4bb068b498a544ae913764a797449463ef620c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-6.12.0-124.2.1.el10_1/1f4bb068.failed

Restructure SRSO to use select/update/apply functions to create
consistent vulnerability handling.  Like with retbleed, the command line
options directly select mitigations which can later be modified.

While at it, remove a comment which doesn't apply anymore due to the
changed mitigation detection flow.

	Signed-off-by: David Kaplan <david.kaplan@amd.com>
	Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
	Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
Link: https://lore.kernel.org/20250418161721.1855190-17-david.kaplan@amd.com
(cherry picked from commit 1f4bb068b498a544ae913764a797449463ef620c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
diff --cc arch/x86/kernel/cpu/bugs.c
index eaabc5443ada,a4f3b1d03406..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -34,22 -34,63 +34,24 @@@
  
  #include "cpu.h"
  
 -/*
 - * Speculation Vulnerability Handling
 - *
 - * Each vulnerability is handled with the following functions:
 - *   <vuln>_select_mitigation() -- Selects a mitigation to use.  This should
 - *				   take into account all relevant command line
 - *				   options.
 - *   <vuln>_update_mitigation() -- This is called after all vulnerabilities have
 - *				   selected a mitigation, in case the selection
 - *				   may want to change based on other choices
 - *				   made.  This function is optional.
 - *   <vuln>_apply_mitigation() -- Enable the selected mitigation.
 - *
 - * The compile-time mitigation in all cases should be AUTO.  An explicit
 - * command-line option can override AUTO.  If no such option is
 - * provided, <vuln>_select_mitigation() will override AUTO to the best
 - * mitigation option.
 - */
 -
  static void __init spectre_v1_select_mitigation(void);
 -static void __init spectre_v1_apply_mitigation(void);
  static void __init spectre_v2_select_mitigation(void);
 -static void __init spectre_v2_update_mitigation(void);
 -static void __init spectre_v2_apply_mitigation(void);
  static void __init retbleed_select_mitigation(void);
 -static void __init retbleed_update_mitigation(void);
 -static void __init retbleed_apply_mitigation(void);
  static void __init spectre_v2_user_select_mitigation(void);
 -static void __init spectre_v2_user_update_mitigation(void);
 -static void __init spectre_v2_user_apply_mitigation(void);
  static void __init ssb_select_mitigation(void);
 -static void __init ssb_apply_mitigation(void);
  static void __init l1tf_select_mitigation(void);
 -static void __init l1tf_apply_mitigation(void);
  static void __init mds_select_mitigation(void);
 -static void __init mds_update_mitigation(void);
 -static void __init mds_apply_mitigation(void);
 +static void __init md_clear_update_mitigation(void);
 +static void __init md_clear_select_mitigation(void);
  static void __init taa_select_mitigation(void);
 -static void __init taa_update_mitigation(void);
 -static void __init taa_apply_mitigation(void);
  static void __init mmio_select_mitigation(void);
 -static void __init mmio_update_mitigation(void);
 -static void __init mmio_apply_mitigation(void);
 -static void __init rfds_select_mitigation(void);
 -static void __init rfds_update_mitigation(void);
 -static void __init rfds_apply_mitigation(void);
  static void __init srbds_select_mitigation(void);
 -static void __init srbds_apply_mitigation(void);
  static void __init l1d_flush_select_mitigation(void);
  static void __init srso_select_mitigation(void);
+ static void __init srso_update_mitigation(void);
+ static void __init srso_apply_mitigation(void);
  static void __init gds_select_mitigation(void);
 -static void __init gds_apply_mitigation(void);
 -static void __init bhi_select_mitigation(void);
 -static void __init bhi_update_mitigation(void);
 -static void __init bhi_apply_mitigation(void);
 +static void __init its_select_mitigation(void);
  
  /* The base value of the SPEC_CTRL MSR without task-specific bits set */
  u64 x86_spec_ctrl_base;
@@@ -181,17 -204,56 +183,57 @@@ void __init cpu_select_mitigations(void
  	spectre_v2_user_select_mitigation();
  	ssb_select_mitigation();
  	l1tf_select_mitigation();
 -	mds_select_mitigation();
 -	taa_select_mitigation();
 -	mmio_select_mitigation();
 -	rfds_select_mitigation();
 +	md_clear_select_mitigation();
  	srbds_select_mitigation();
  	l1d_flush_select_mitigation();
- 
- 	/*
- 	 * srso_select_mitigation() depends and must run after
- 	 * retbleed_select_mitigation().
- 	 */
  	srso_select_mitigation();
  	gds_select_mitigation();
++<<<<<<< HEAD
 +	its_select_mitigation();
++=======
+ 	bhi_select_mitigation();
+ 
+ 	/*
+ 	 * After mitigations are selected, some may need to update their
+ 	 * choices.
+ 	 */
+ 	spectre_v2_update_mitigation();
+ 	/*
+ 	 * retbleed_update_mitigation() relies on the state set by
+ 	 * spectre_v2_update_mitigation(); specifically it wants to know about
+ 	 * spectre_v2=ibrs.
+ 	 */
+ 	retbleed_update_mitigation();
+ 
+ 	/*
+ 	 * spectre_v2_user_update_mitigation() depends on
+ 	 * retbleed_update_mitigation(), specifically the STIBP
+ 	 * selection is forced for UNRET or IBPB.
+ 	 */
+ 	spectre_v2_user_update_mitigation();
+ 	mds_update_mitigation();
+ 	taa_update_mitigation();
+ 	mmio_update_mitigation();
+ 	rfds_update_mitigation();
+ 	bhi_update_mitigation();
+ 	/* srso_update_mitigation() depends on retbleed_update_mitigation(). */
+ 	srso_update_mitigation();
+ 
+ 	spectre_v1_apply_mitigation();
+ 	spectre_v2_apply_mitigation();
+ 	retbleed_apply_mitigation();
+ 	spectre_v2_user_apply_mitigation();
+ 	ssb_apply_mitigation();
+ 	l1tf_apply_mitigation();
+ 	mds_apply_mitigation();
+ 	taa_apply_mitigation();
+ 	mmio_apply_mitigation();
+ 	rfds_apply_mitigation();
+ 	srbds_apply_mitigation();
+ 	srso_apply_mitigation();
+ 	gds_apply_mitigation();
+ 	bhi_apply_mitigation();
++>>>>>>> 1f4bb068b498 (x86/bugs: Restructure SRSO mitigation)
  }
  
  /*
@@@ -2737,76 -2748,25 +2767,48 @@@ static void __init srso_select_mitigati
  	} else {
  		pr_warn("IBPB-extending microcode not applied!\n");
  		pr_warn(SRSO_NOTICE);
- 
- 		/* may be overwritten by SRSO_CMD_SAFE_RET below */
- 		srso_mitigation = SRSO_MITIGATION_UCODE_NEEDED;
  	}
  
- 	switch (srso_cmd) {
- 	case SRSO_CMD_MICROCODE:
- 		if (has_microcode) {
- 			srso_mitigation = SRSO_MITIGATION_MICROCODE;
- 			pr_warn(SRSO_NOTICE);
- 		}
- 		break;
- 
- 	case SRSO_CMD_SAFE_RET:
- 		if (boot_cpu_has(X86_FEATURE_SRSO_USER_KERNEL_NO))
+ 	switch (srso_mitigation) {
+ 	case SRSO_MITIGATION_SAFE_RET:
+ 		if (boot_cpu_has(X86_FEATURE_SRSO_USER_KERNEL_NO)) {
+ 			srso_mitigation = SRSO_MITIGATION_IBPB_ON_VMEXIT;
  			goto ibpb_on_vmexit;
+ 		}
  
++<<<<<<< HEAD
 +		if (IS_ENABLED(CONFIG_MITIGATION_SRSO)) {
 +			/*
 +			 * Enable the return thunk for generated code
 +			 * like ftrace, static_call, etc.
 +			 */
 +			setup_force_cpu_cap(X86_FEATURE_RETHUNK);
 +			setup_force_cpu_cap(X86_FEATURE_UNRET);
 +
 +			if (boot_cpu_data.x86 == 0x19) {
 +				setup_force_cpu_cap(X86_FEATURE_SRSO_ALIAS);
 +				set_return_thunk(srso_alias_return_thunk);
 +			} else {
 +				setup_force_cpu_cap(X86_FEATURE_SRSO);
 +				set_return_thunk(srso_return_thunk);
 +			}
 +			if (has_microcode)
 +				srso_mitigation = SRSO_MITIGATION_SAFE_RET;
 +			else
 +				srso_mitigation = SRSO_MITIGATION_SAFE_RET_UCODE_NEEDED;
 +		} else {
++=======
+ 		if (!IS_ENABLED(CONFIG_MITIGATION_SRSO)) {
++>>>>>>> 1f4bb068b498 (x86/bugs: Restructure SRSO mitigation)
  			pr_err("WARNING: kernel not compiled with MITIGATION_SRSO.\n");
+ 			srso_mitigation = SRSO_MITIGATION_NONE;
  		}
- 		break;
  
- 	case SRSO_CMD_IBPB:
- 		if (IS_ENABLED(CONFIG_MITIGATION_IBPB_ENTRY)) {
- 			if (has_microcode) {
- 				setup_force_cpu_cap(X86_FEATURE_ENTRY_IBPB);
- 				setup_force_cpu_cap(X86_FEATURE_IBPB_ON_VMEXIT);
- 				srso_mitigation = SRSO_MITIGATION_IBPB;
- 
- 				/*
- 				 * IBPB on entry already obviates the need for
- 				 * software-based untraining so clear those in case some
- 				 * other mitigation like Retbleed has selected them.
- 				 */
- 				setup_clear_cpu_cap(X86_FEATURE_UNRET);
- 				setup_clear_cpu_cap(X86_FEATURE_RETHUNK);
- 
- 				/*
- 				 * There is no need for RSB filling: write_ibpb() ensures
- 				 * all predictions, including the RSB, are invalidated,
- 				 * regardless of IBPB implementation.
- 				 */
- 				setup_clear_cpu_cap(X86_FEATURE_RSB_VMEXIT);
- 			}
- 		} else {
- 			pr_err("WARNING: kernel not compiled with MITIGATION_IBPB_ENTRY.\n");
- 		}
+ 		if (!has_microcode)
+ 			srso_mitigation = SRSO_MITIGATION_SAFE_RET_UCODE_NEEDED;
  		break;
- 
  ibpb_on_vmexit:
- 	case SRSO_CMD_IBPB_ON_VMEXIT:
+ 	case SRSO_MITIGATION_IBPB_ON_VMEXIT:
  		if (boot_cpu_has(X86_FEATURE_SRSO_BP_SPEC_REDUCE)) {
  			pr_notice("Reducing speculation to address VM/HV SRSO attack vector.\n");
  			srso_mitigation = SRSO_MITIGATION_BP_SPEC_REDUCE;
* Unmerged path arch/x86/kernel/cpu/bugs.c
