perf/x86/amd/uncore: Fix uninitialized return value in amd_uncore_init()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-531.el8
commit-author Dan Carpenter <dan.carpenter@linaro.org>
commit 7543365739a4ff61d40ad53ab68c17d2e7dfb0c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-531.el8/75433657.failed

Some of the error paths in this function return don't initialize the
error code.  Return -ENODEV by default.

Fixes: d6389d3ccc13 ("perf/x86/amd/uncore: Refactor uncore management")
	Signed-off-by: Dan Carpenter <dan.carpenter@linaro.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/cec62eba-c4b8-4cb7-9671-58894dd4b974@moroto.mountain
(cherry picked from commit 7543365739a4ff61d40ad53ab68c17d2e7dfb0c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/events/amd/uncore.c
diff --cc arch/x86/events/amd/uncore.c
index 63fc97aecaf4,a389828f378c..000000000000
--- a/arch/x86/events/amd/uncore.c
+++ b/arch/x86/events/amd/uncore.c
@@@ -646,14 -868,152 +646,20 @@@ static int amd_uncore_cpu_dead(unsigne
  	return 0;
  }
  
 -static void amd_uncore_umc_start(struct perf_event *event, int flags)
 -{
 -	struct hw_perf_event *hwc = &event->hw;
 -
 -	if (flags & PERF_EF_RELOAD)
 -		wrmsrl(hwc->event_base, (u64)local64_read(&hwc->prev_count));
 -
 -	hwc->state = 0;
 -	wrmsrl(hwc->config_base, (hwc->config | AMD64_PERFMON_V2_ENABLE_UMC));
 -	perf_event_update_userpage(event);
 -}
 -
 -static
 -void amd_uncore_umc_ctx_scan(struct amd_uncore *uncore, unsigned int cpu)
 -{
 -	union cpuid_0x80000022_ebx ebx;
 -	union amd_uncore_info info;
 -	unsigned int eax, ecx, edx;
 -
 -	if (pmu_version < 2)
 -		return;
 -
 -	cpuid(EXT_PERFMON_DEBUG_FEATURES, &eax, &ebx.full, &ecx, &edx);
 -	info.split.aux_data = ecx;	/* stash active mask */
 -	info.split.num_pmcs = ebx.split.num_umc_pmc;
 -	info.split.gid = topology_die_id(cpu);
 -	info.split.cid = topology_die_id(cpu);
 -	*per_cpu_ptr(uncore->info, cpu) = info;
 -}
 -
 -static
 -int amd_uncore_umc_ctx_init(struct amd_uncore *uncore, unsigned int cpu)
 -{
 -	DECLARE_BITMAP(gmask, UNCORE_GROUP_MAX) = { 0 };
 -	u8 group_num_pmus[UNCORE_GROUP_MAX] = { 0 };
 -	u8 group_num_pmcs[UNCORE_GROUP_MAX] = { 0 };
 -	union amd_uncore_info info;
 -	struct amd_uncore_pmu *pmu;
 -	int index = 0, gid, i;
 -
 -	if (pmu_version < 2)
 -		return 0;
 -
 -	/* Run just once */
 -	if (uncore->init_done)
 -		return amd_uncore_ctx_init(uncore, cpu);
 -
 -	/* Find unique groups */
 -	for_each_online_cpu(i) {
 -		info = *per_cpu_ptr(uncore->info, i);
 -		gid = info.split.gid;
 -		if (test_bit(gid, gmask))
 -			continue;
 -
 -		__set_bit(gid, gmask);
 -		group_num_pmus[gid] = hweight32(info.split.aux_data);
 -		group_num_pmcs[gid] = info.split.num_pmcs;
 -		uncore->num_pmus += group_num_pmus[gid];
 -	}
 -
 -	uncore->pmus = kzalloc(sizeof(*uncore->pmus) * uncore->num_pmus,
 -			       GFP_KERNEL);
 -	if (!uncore->pmus) {
 -		uncore->num_pmus = 0;
 -		goto done;
 -	}
 -
 -	for_each_set_bit(gid, gmask, UNCORE_GROUP_MAX) {
 -		for (i = 0; i < group_num_pmus[gid]; i++) {
 -			pmu = &uncore->pmus[index];
 -			snprintf(pmu->name, sizeof(pmu->name), "amd_umc_%d", index);
 -			pmu->num_counters = group_num_pmcs[gid] / group_num_pmus[gid];
 -			pmu->msr_base = MSR_F19H_UMC_PERF_CTL + i * pmu->num_counters * 2;
 -			pmu->rdpmc_base = -1;
 -			pmu->group = gid;
 -
 -			pmu->ctx = alloc_percpu(struct amd_uncore_ctx *);
 -			if (!pmu->ctx)
 -				goto done;
 -
 -			pmu->pmu = (struct pmu) {
 -				.task_ctx_nr	= perf_invalid_context,
 -				.attr_groups	= amd_uncore_umc_attr_groups,
 -				.name		= pmu->name,
 -				.event_init	= amd_uncore_umc_event_init,
 -				.add		= amd_uncore_add,
 -				.del		= amd_uncore_del,
 -				.start		= amd_uncore_umc_start,
 -				.stop		= amd_uncore_stop,
 -				.read		= amd_uncore_read,
 -				.capabilities	= PERF_PMU_CAP_NO_EXCLUDE | PERF_PMU_CAP_NO_INTERRUPT,
 -				.module		= THIS_MODULE,
 -			};
 -
 -			if (perf_pmu_register(&pmu->pmu, pmu->pmu.name, -1)) {
 -				free_percpu(pmu->ctx);
 -				pmu->ctx = NULL;
 -				goto done;
 -			}
 -
 -			pr_info("%d %s counters detected\n", pmu->num_counters,
 -				pmu->pmu.name);
 -
 -			index++;
 -		}
 -	}
 -
 -done:
 -	uncore->num_pmus = index;
 -	uncore->init_done = true;
 -
 -	return amd_uncore_ctx_init(uncore, cpu);
 -}
 -
 -static struct amd_uncore uncores[UNCORE_TYPE_MAX] = {
 -	/* UNCORE_TYPE_DF */
 -	{
 -		.scan = amd_uncore_df_ctx_scan,
 -		.init = amd_uncore_df_ctx_init,
 -		.move = amd_uncore_ctx_move,
 -		.free = amd_uncore_ctx_free,
 -	},
 -	/* UNCORE_TYPE_L3 */
 -	{
 -		.scan = amd_uncore_l3_ctx_scan,
 -		.init = amd_uncore_l3_ctx_init,
 -		.move = amd_uncore_ctx_move,
 -		.free = amd_uncore_ctx_free,
 -	},
 -	/* UNCORE_TYPE_UMC */
 -	{
 -		.scan = amd_uncore_umc_ctx_scan,
 -		.init = amd_uncore_umc_ctx_init,
 -		.move = amd_uncore_ctx_move,
 -		.free = amd_uncore_ctx_free,
 -	},
 -};
 -
  static int __init amd_uncore_init(void)
  {
++<<<<<<< HEAD
 +	struct attribute **df_attr = amd_uncore_df_format_attr;
 +	struct attribute **l3_attr = amd_uncore_l3_format_attr;
 +	union cpuid_0x80000022_ebx ebx;
 +	int ret = -ENODEV;
++=======
+ 	struct amd_uncore *uncore;
+ 	int ret = -ENODEV;
+ 	int i;
++>>>>>>> 7543365739a4 (perf/x86/amd/uncore: Fix uninitialized return value in amd_uncore_init())
  
 -	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD &&
 -	    boot_cpu_data.x86_vendor != X86_VENDOR_HYGON)
 +	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
  		return -ENODEV;
  
  	if (!boot_cpu_has(X86_FEATURE_TOPOEXT))
* Unmerged path arch/x86/events/amd/uncore.c
